==== spawn @ 2026-02-08T02:47:23.149Z ====
cmd: codex "exec" "--cd" "/Users/johnlindquist/dev/script-kit-gpui" "--model" "gpt-5.3-codex" "-c" "model_reasoning_effort=\"xhigh\"" "-c" "model_auto_compact_token_limit=120000" "-c" "developer_instructions=\"You are Codex implementer agent \\\"codex-script-gen-builtin\\\".\\n\\n## Coordination\\nThis repo runs parallel agents in ONE working tree. Before editing any file, you MUST claim it.\\nCommands (run via shell):\\n  - View roster: ~/.claude/bin/swarm.ts status\\n  - Claim files (blocks until free): ~/.claude/bin/swarm.ts claim --wait --id codex-script-gen-builtin path/to/file\\n  - Release: ~/.claude/bin/swarm.ts release --id codex-script-gen-builtin path/to/file\\n  - Update status/notes: ~/.claude/bin/swarm.ts update --id codex-script-gen-builtin --status in_progress --notes \\\"...\\\"\\nRules:\\n  - Never edit a file you haven't claimed.\\n  - Keep claims tight (claim only what you're actively changing).\\n  - If blocked, set status=blocked and say what you're waiting on.\\n  - When finished, set status=done and release claims.\\n\\n## Development practices (this code is maintained by AI agents)\\n  - Log state transitions with enough context to diagnose failures from logs alone.\\n  - Structured errors: include what was attempted, what failed, and current state.\\n  - Name things for grepability â€” unique identifiers agents can find on the first search.\\n  - Every behavior change gets a test. Untested code is invisible to the next agent.\\n  - Test names describe the scenario: test_X_does_Y_when_Z.\\n  - Keep functions small and single-purpose. 500-line functions burn agent context.\\n  - Use types to encode constraints (enums > strings for errors).\\n\\n## CRITICAL: Parallel-safe verification\\n  - Other agents are modifying other files RIGHT NOW. Full test suites WILL show their failures.\\n  - ONLY run tests that cover YOUR changed files. Scope every test/check command:\\n    Rust: cargo test -p your-crate -- module::test_name | JS: npx jest your/file.test.ts\\n  - Do NOT run: cargo test (unscoped), cargo check (whole workspace), npm test (unscoped).\\n  - If a scoped test fails, it's YOUR bug â€” fix it. If tests outside your scope fail, ignore them.\\n\\n## Git commit discipline\\n  - NEVER commit unverified work. Run tests/lints/type-checks FIRST. If it fails, fix it before committing.\\n  - A commit is a declaration: \\\"this works and here's the proof.\\\"\\n  - Commit FREQUENTLY â€” after each meaningful unit of VERIFIED work, not just at the end.\\n  - A \\\"unit\\\" = one logical change that passes verification (new function, bug fix, refactor, test added).\\n  - NEVER batch an entire task into one giant commit. Small commits are searchable; big ones aren't.\\n  - Commit message format:\\n      Line 1: <type>(<scope>): <what changed> (imperative, max 72 chars)\\n      Line 3+: WHY this change was made, WHAT was verified, and HOW to test it.\\n    Types: feat, fix, refactor, test, docs, chore\\n    Example:\\n      feat(auth): add refresh token rotation\\n      \\n      Tokens now rotate on each refresh call to prevent replay attacks.\\n      The old token is invalidated immediately on rotation.\\n      \\n      Verified: cargo test --lib -- auth::refresh (4 tests pass)\\n      Verified: manual smoke test via curl â€” token rotates, old token returns 401\\n  - The \\\"Verified:\\\" lines are REQUIRED. Future agents will read git log to understand\\n    what was tested and how to re-verify. This is the most valuable part of the message.\\n  - In your final message, list all commits you made with their hashes.\\n\\n## Time budget\\nYou have approximately 10 minutes. If your task is too broad to complete in time:\\n(1) Commit any verified progress.\\n(2) Run: ~/.claude/bin/swarm.ts update --id YOUR_ID --status needs_split --notes 'suggest: 1) sub-task-desc scope:files 2) sub-task-desc scope:files'.\\n(3) Exit cleanly. The dispatcher will read your suggestions and spawn narrower workers.\"" "--output-last-message" "/Users/johnlindquist/dev/script-kit-gpui/.ai/logs/codex-script-gen-builtin.final.md" "--yolo" "You are agent codex-script-gen-builtin.\n\nCurrent parallel-agent roster (read this first):\n```\nSWARM SNAPSHOT @ 2026-02-08T02:47:23.146Z\n- codex-script-gen-builtin [starting] scope=src/builtins/**,src/app_execute/**,src/ai/**,src/kit_store/** task=In Script Kit GPUI, there needs to be a built-in feature or action for AI script generation triggered by Shift+Tab. Looâ€¦\n- codex-shift-tab-keybind [in_progress] scope=src/actions/dialog/**,src/app_impl/**,src/ai/**,src/execute_script/** task=In Script Kit GPUI, pressing Tab in the main prompt triggers an AI chat scenario. Add a Shift+Tab keyboard shortcut thaâ€¦\n  notes: spawned codex (exec)\n```\n\nYour assignment:\n- Task: In Script Kit GPUI, there needs to be a built-in feature or action for AI script generation triggered by Shift+Tab. Look at how existing built-in features work: BuiltInFeature enum in builtins/, get_builtin_entries(), execute_builtin() in app_execute/builtin_execution.rs. Also check how the AI chat feature works when Tab is pressed - it likely sets up a chat window or sends to an AI endpoint. Create a similar but distinct path for 'generate script' that: 1) Takes the user's input text as a prompt 2) Sends it to the AI with a system prompt instructing it to generate a Script Kit script with best practices (// Name: metadata, // Description:, proper imports like 'import \"@johnlindquist/kit\"', using await arg() for user input, await div() for display, etc.) 3) Saves the generated script to ~/.kenv/scripts/ with a slugified filename 4) Opens the script for editing or runs it. Follow existing patterns for AI integration in src/ai/ directory.\n- Scope: src/builtins/**,src/app_execute/**,src/ai/**,src/kit_store/**\n\nOperating constraints:\n- Single working tree (no worktrees, no patches).\n- You MUST claim files before editing (~/.claude/bin/swarm.ts claim --wait ...).\n\nDeliverables:\n- Make the code changes required by the task.\n- Run the most relevant tests/linters.\n- In your FINAL message, include: changed files, how to test, and any risks/known gaps."

OpenAI Codex v0.98.0 (research preview)
--------
workdir: /Users/johnlindquist/dev/script-kit-gpui
model: gpt-5.3-codex
provider: openai
approval: never
sandbox: danger-full-access
reasoning effort: xhigh
reasoning summaries: auto
session id: 019c3b25-8f3f-7c91-b92d-d0fd74cd4485
--------
user
You are agent codex-script-gen-builtin.

Current parallel-agent roster (read this first):
```
SWARM SNAPSHOT @ 2026-02-08T02:47:23.146Z
- codex-script-gen-builtin [starting] scope=src/builtins/**,src/app_execute/**,src/ai/**,src/kit_store/** task=In Script Kit GPUI, there needs to be a built-in feature or action for AI script generation triggered by Shift+Tab. Looâ€¦
- codex-shift-tab-keybind [in_progress] scope=src/actions/dialog/**,src/app_impl/**,src/ai/**,src/execute_script/** task=In Script Kit GPUI, pressing Tab in the main prompt triggers an AI chat scenario. Add a Shift+Tab keyboard shortcut thaâ€¦
  notes: spawned codex (exec)
```

Your assignment:
- Task: In Script Kit GPUI, there needs to be a built-in feature or action for AI script generation triggered by Shift+Tab. Look at how existing built-in features work: BuiltInFeature enum in builtins/, get_builtin_entries(), execute_builtin() in app_execute/builtin_execution.rs. Also check how the AI chat feature works when Tab is pressed - it likely sets up a chat window or sends to an AI endpoint. Create a similar but distinct path for 'generate script' that: 1) Takes the user's input text as a prompt 2) Sends it to the AI with a system prompt instructing it to generate a Script Kit script with best practices (// Name: metadata, // Description:, proper imports like 'import "@johnlindquist/kit"', using await arg() for user input, await div() for display, etc.) 3) Saves the generated script to ~/.kenv/scripts/ with a slugified filename 4) Opens the script for editing or runs it. Follow existing patterns for AI integration in src/ai/ directory.
- Scope: src/builtins/**,src/app_execute/**,src/ai/**,src/kit_store/**

Operating constraints:
- Single working tree (no worktrees, no patches).
- You MUST claim files before editing (~/.claude/bin/swarm.ts claim --wait ...).

Deliverables:
- Make the code changes required by the task.
- Run the most relevant tests/linters.
- In your FINAL message, include: changed files, how to test, and any risks/known gaps.
warning: Under-development features enabled: responses_websockets. Under-development features are incomplete and may behave unpredictably. To suppress this warning, set `suppress_unstable_features_warning = true` in /Users/johnlindquist/.codex/config.toml.
mcp: deepwiki starting
mcp: deepwiki ready
mcp startup: ready: deepwiki

thinking
**Planning coordination and workflow**
codex
Iâ€™m taking the `codex-script-gen-builtin` assignment and first verifying current swarm status, then Iâ€™ll inspect existing built-in/AI flow code to add a distinct â€œgenerate scriptâ€ built-in path without overlapping unclaimed edits.
exec
/bin/zsh -lc '~/.claude/bin/swarm.ts status' in /Users/johnlindquist/dev/script-kit-gpui succeeded in 52ms:
Repo: /Users/johnlindquist/dev/script-kit-gpui
Updated: 2026-02-08T02:47:32.043Z

Active agents (2):
codex-script-gen-builtin [in_progress] codex/gpt-5.3-codex/exec
  task: In Script Kit GPUI, there needs to be a built-in feature or action for AI script generation triggered by Shift+Tab. Looâ€¦
  scope: src/builtins/**,src/app_execute/**,src/ai/**,src/kit_store/**
  claims: (none)
  notes: spawned codex (exec)

codex-shift-tab-keybind [in_progress] codex/gpt-5.3-codex/exec
  task: In Script Kit GPUI, pressing Tab in the main prompt triggers an AI chat scenario. Add a Shift+Tab keyboard shortcut thaâ€¦
  scope: src/actions/dialog/**,src/app_impl/**,src/ai/**,src/execute_script/**
  claims: (none)
  notes: spawned codex (exec)

Inactive agents (253):
- codex-accessibility [done] done. exit=0. final=.ai/logs/codex-accessibility.final.md. See final message file.
- codex-action-labels [failed] failed. exit=1. final=.ai/logs/codex-action-labels.final.md.
- codex-actions-audit [failed] failed. exit=1. final=.ai/logs/codex-actions-audit.final.md. See final message file.

thinking
**Updating swarm status notes**
exec
/bin/zsh -lc '~/.claude/bin/swarm.ts update --id codex-script-gen-builtin --status in_progress --notes "Inspecting builtins + AI flow to add generate-script builtin path"' in /Users/johnlindquist/dev/script-kit-gpui succeeded in 52ms:
Updated: codex-script-gen-builtin

thinking
**Preparing parallel file scanning**
codex
Iâ€™ve confirmed no file claims are active yet; next Iâ€™m mapping the exact enum/entry/execution and current Tab-triggered AI code paths so the new script-generation flow reuses existing patterns cleanly.
exec
/bin/zsh -lc 'ls -R src/builtins src/app_execute src/ai src/kit_store' in /Users/johnlindquist/dev/script-kit-gpuiexec
/bin/zsh -lc 'rg --line-number "enum BuiltInFeature|get_builtin_entries|execute_builtin|Tab|shift" src/builtins src/app_execute src/ai src/kit_store' in /Users/johnlindquist/dev/script-kit-gpui succeeded in 51ms:
src/ai:
config.rs
mod.rs
model.rs
providers.rs
sdk_handlers.rs
session.rs
storage.rs
window
window.rs

src/ai/window:
chat.rs
command_bar.rs
dropdowns.rs
images.rs
init.rs
interactions.rs
platform.rs
render_input.rs
 succeeded in 51ms:
src/app_execute/builtin_confirmation.rs:24:        let builtin_entries = builtins::get_builtin_entries(&self.config.get_builtins());
src/app_execute/builtin_confirmation.rs:28:            self.execute_builtin_confirmed(entry, cx);
src/app_execute/builtin_confirmation.rs:39:    fn execute_builtin_confirmed(
src/app_execute/builtin_confirmation.rs:52:        // Direct execution - same logic as execute_builtin but without confirmation check
src/app_execute/builtin_confirmation.rs:106:                            // Call the original execute_builtin for these
src/builtins/part_000.rs:106:    SendBrowserTabToAi,
src/builtins/part_000.rs:192:pub enum BuiltInFeature {
src/builtins/part_000.rs:325:    /// For "Shell â†’ New Tab", returns "New Tab".
src/builtins/part_001.rs:12:pub fn get_builtin_entries(config: &BuiltInConfig) -> Vec<BuiltInEntry> {
src/app_execute/builtin_execution.rs:20:    fn execute_builtin(&mut self, entry: &builtins::BuiltInEntry, cx: &mut Context<Self>) {
src/app_execute/builtin_execution.rs:771:                    AiCommandType::SendBrowserTabToAi => {
src/builtins/part_001_entries/entries_002.rs:116:        "Send Focused Browser Tab to AI Chat",
src/builtins/part_001_entries/entries_002.rs:121:        BuiltInFeature::AiCommand(AiCommandType::SendBrowserTabToAi),
src/ai/window/setup.rs:11:        // Fixed height container to prevent layout shift when typing
src/ai/window/setup.rs:20:            .h(TITLEBAR_H) // Fixed height to prevent layout shift
src/ai/window/setup.rs:30:                    .key_binding(gpui::Keystroke::parse("cmd-shift-f").ok().map(Kbd::new))
src/app_execute/builtin_execution/feature_02.rs:239:                    AiCommandType::SendBrowserTabToAi => {
src/builtins/tests/part_000.rs:22:    fn test_get_builtin_entries_all_enabled() {
src/builtins/tests/part_000.rs:24:        let entries = get_builtin_entries(&config);
src/builtins/tests/part_000.rs:70:    fn test_get_builtin_entries_clipboard_only() {

thinking
**Inspecting builtins enum content**
exec
/bin/zsh -lc "sed -n '1,260p' src/builtins/part_000.rs" in /Users/johnlindquist/dev/script-kit-gpui succeeded in 51ms:
use crate::config::BuiltInConfig;
use crate::menu_bar::MenuBarItem;
use tracing::debug;
// ============================================================================
// Command Type Enums
// ============================================================================

/// System action types for macOS system commands
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum SystemActionType {
    // Power management
    EmptyTrash,
    LockScreen,
    Sleep,
    Restart,
    ShutDown,
    LogOut,

    // UI controls
    ToggleDarkMode,
exec
/bin/zsh -lc "sed -n '700,880p' src/app_execute/builtin_execution.rs" in /Users/johnlindquist/dev/script-kit-gpuiexec
/bin/zsh -lc "sed -n '180,320p' src/app_execute/builtin_execution/feature_02.rs" in /Users/johnlindquist/dev/script-kit-gpuiexec
/bin/zsh -lc "sed -n '1,260p' src/builtins/part_001_entries/entries_002.rs" in /Users/johnlindquist/dev/script-kit-gpui succeeded in 51ms:
{
    // Notes Commands
    // =========================================================================

    entries.push(BuiltInEntry::new_with_icon(
        "builtin-open-notes",
        "Open Notes",
        "Open the Notes window",
        vec!["open", "notes", "window", "note"],
        BuiltInFeature::NotesCommand(NotesCommandType::OpenNotes),
        "ðŸ“",
    ));

    entries.push(BuiltInEntry::new_with_icon(
        "builtin-new-note",
        "New Note",
        "Create a new note",
        vec!["new", "note", "create"],
        BuiltInFeature::NotesCommand(NotesCommandType::NewNote),
        "ðŸ“",
 succeeded in 52ms:
                                logging::log("ERROR", &format!("Failed to capture window: {}", e));
                                self.toast_manager.push(
                                    components::toast::Toast::error(
                                        format!("Failed to capture window: {}", e),
                                        &self.theme,
                                    )
                                    .duration_ms(Some(5000)),
                                );
                                cx.notify();
                            }
                        }
                    }

                    AiCommandType::SendSelectedTextToAi => {
                        // Get selected text and send to AI
                        match crate::selected_text::get_selected_text() {
                            Ok(text) if !text.is_empty() => {
                                let message = format!(
                                    "I've selected the following text:\n\n```\n{}\n```\n\nPlease help me with this.",
                                    text
 succeeded in 52ms:
                                    ai::set_ai_input_with_image(cx, &message, &base64_data, false);
                                }
                            }
                            Err(e) => {
                                logging::log("ERROR", &format!("Failed to capture window: {}", e));
                                self.toast_manager.push(
                                    components::toast::Toast::error(
                                        format!("Failed to capture window: {}", e),
                                        &self.theme,
                                    )
                                    .duration_ms(Some(5000)),
                                );
                                cx.notify();
                            }
                        }
                    }

                    AiCommandType::SendSelectedTextToAi => {
                        // Get selected text and send to AI
                        match crate::selected_text::get_selected_text() {

thinking
**Inspecting potential duplicate modules**
exec
/bin/zsh -lc "sed -n '1,260p' src/app_execute/builtin_execution/feature_03.rs" in /Users/johnlindquist/dev/script-kit-gpuiexec
/bin/zsh -lc "sed -n '1,220p' src/app_execute/builtin_execution.rs" in /Users/johnlindquist/dev/script-kit-gpuiexec
/bin/zsh -lc "sed -n '1,260p' src/app_execute/builtin_execution/feature_01.rs" in /Users/johnlindquist/dev/script-kit-gpuiexec
/bin/zsh -lc "sed -n '1,360p' src/app_execute/builtin_execution/feature_02.rs" in /Users/johnlindquist/dev/script-kit-gpui succeeded in 50ms:
            builtins::BuiltInFeature::PermissionCommand(cmd_type) => {
                logging::log(
                    "EXEC",
                    &format!("Executing permission command: {:?}", cmd_type),
                );

                use builtins::PermissionCommandType;

                match cmd_type {
                    PermissionCommandType::CheckPermissions => {
                        let status = permissions_wizard::check_all_permissions();
                        if status.all_granted() {
                            self.toast_manager.push(
                                components::toast::Toast::success(
                                    "All permissions granted!",
                                    &self.theme,
                                )
                                .duration_ms(Some(3000)),
                            );
                        } else {
 succeeded in 50ms:
fn ai_open_failure_message(error: impl std::fmt::Display) -> String {
    format!("Failed to open AI: {}", error)
}

impl ScriptListApp {
    fn system_action_feedback_message(
        &self,
        action_type: &builtins::SystemActionType,
    ) -> Option<String> {
        let dark_mode_enabled = if matches!(action_type, builtins::SystemActionType::ToggleDarkMode)
        {
            system_actions::is_dark_mode().ok()
        } else {
            None
        };

        builtins::system_action_hud_message(*action_type, dark_mode_enabled)
    }

    fn execute_builtin(&mut self, entry: &builtins::BuiltInEntry, cx: &mut Context<Self>) {
 succeeded in 51ms:
            builtins::BuiltInFeature::NotesCommand(cmd_type) => {
                logging::log("EXEC", &format!("Executing notes command: {:?}", cmd_type));

                use builtins::NotesCommandType;

                // All notes commands: reset state, hide main window, open notes
                script_kit_gpui::set_main_window_visible(false);
                self.reset_to_script_list(cx);
                platform::hide_main_window();

                let result = match cmd_type {
                    NotesCommandType::OpenNotes
                    | NotesCommandType::NewNote
                    | NotesCommandType::SearchNotes => notes::open_notes_window(cx),
                    NotesCommandType::QuickCapture => notes::quick_capture(cx),
                };

                if let Err(e) = result {
                    logging::log("ERROR", &format!("Notes command failed: {}", e));
                    self.toast_manager.push(
 succeeded in 51ms:
            builtins::BuiltInFeature::ClipboardHistory => {
                logging::log("EXEC", "Opening Clipboard History");
                // P0 FIX: Store data in self, view holds only state
                self.cached_clipboard_entries = clipboard_history::get_cached_entries(100);
                self.focused_clipboard_entry_id = self
                    .cached_clipboard_entries
                    .first()
                    .map(|entry| entry.id.clone());
                logging::log(
                    "EXEC",
                    &format!(
                        "Loaded {} clipboard entries (cached)",
                        self.cached_clipboard_entries.len()
                    ),
                );
                // Clear the shared input for fresh search (sync on next render)
                self.filter_text = String::new();
                self.pending_filter_sync = true;
                self.pending_placeholder = Some("Search clipboard history...".to_string());
                // Initial selected_index should be 0 (first entry)

thinking
**Inspecting module structure and builtins**
exec
/bin/zsh -lc "sed -n '1,260p' src/builtins/mod.rs" in /Users/johnlindquist/dev/script-kit-gpuiexec
/bin/zsh -lc "sed -n '1,240p' src/builtins/part_001.rs" in /Users/johnlindquist/dev/script-kit-gpuiexec
/bin/zsh -lc "sed -n '1,260p' src/app_execute/mod.rs" in /Users/johnlindquist/dev/script-kit-gpuiexec
/bin/zsh -lc "sed -n '1,260p' src/app_execute/builtin_execution/mod.rs" in /Users/johnlindquist/dev/script-kit-gpui exited 1 in 50ms:
sed: src/app_execute/builtin_execution/mod.rs: No such file or directory
 succeeded in 50ms:
/// Get the list of enabled built-in entries based on configuration
///
/// # Arguments
/// * `config` - The built-in features configuration
///
/// # Returns
/// A vector of enabled built-in entries that should appear in the main search
///
/// Note: AppLauncher built-in is no longer used since apps now appear directly
/// in the main search results. The config option is retained for future use
/// (e.g., to control whether apps are included in search at all).
pub fn get_builtin_entries(config: &BuiltInConfig) -> Vec<BuiltInEntry> {
    let mut entries = Vec::new();

    include!("part_001_entries/entries_000.rs");
    include!("part_001_entries/entries_001.rs");
    include!("part_001_entries/entries_002.rs");
    include!("part_001_entries/entries_003.rs");

    debug!(count = entries.len(), "Built-in entries loaded");
 exited 1 in 50ms:
sed: src/app_execute/mod.rs: No such file or directory
 succeeded in 50ms:
//! Built-in Features Registry
//!
//! Provides a registry of built-in features that appear in the main search
//! alongside scripts. Features like Clipboard History and App Launcher are
//! configurable and can be enabled/disabled via config.
//!
//! ## Command Types
//!
//! The registry supports various command types organized by category:
//! - **System Actions**: Power management, UI controls, volume/brightness
//! - **Window Actions**: Window tiling and management for the frontmost window
//! - **Notes Commands**: Notes window operations
//! - **AI Commands**: AI chat window operations  
//! - **Script Commands**: Create new scripts and scriptlets
//! - **Permission Commands**: Accessibility permission management
//!

include!("part_000.rs");
include!("part_001.rs");
include!("part_002.rs");

thinking
**Searching include locations**
exec
/bin/zsh -lc "ls -la src | sed -n '1,260p' && ls -la src/app_execute | sed -n '1,260p'" in /Users/johnlindquist/dev/script-kit-gpui succeeded in 51ms:
total 856
drwxr-xr-x  145 johnlindquist  staff   4640 Feb  7 16:08 .
drwxr-xr-x  113 johnlindquist  staff   3616 Feb  7 15:42 ..
drwxr-xr-x    3 johnlindquist  staff     96 Feb  7 14:26 action_helpers
-rw-r--r--    1 johnlindquist  staff   9447 Feb  7 15:27 action_helpers.rs
-rw-r--r--    1 johnlindquist  staff   9706 Feb  7 15:27 action_helpers_tests.rs
drwxr-xr-x  122 johnlindquist  staff   3904 Feb  7 17:38 actions
-rw-r--r--    1 johnlindquist  staff   2746 Feb  7 15:27 actions_button_visibility_tests.rs
drwxr-xr-x    7 johnlindquist  staff    224 Jan  4 21:13 agents
drwxr-xr-x   11 johnlindquist  staff    352 Feb  7 15:27 ai
drwxr-xr-x    4 johnlindquist  staff    128 Feb  1 11:13 aliases
drwxr-xr-x    8 johnlindquist  staff    256 Feb  7 14:27 app_actions
-rw-r--r--    1 johnlindquist  staff    182 Feb  7 15:27 app_actions.rs
drwxr-xr-x    7 johnlindquist  staff    224 Feb  7 16:45 app_execute
-rw-r--r--    1 johnlindquist  staff    249 Feb  7 09:29 app_execute.rs
drwxr-xr-x   33 johnlindquist  staff   1056 Feb  7 15:27 app_impl
drwxr-xr-x    8 johnlindquist  staff    256 Feb  7 09:29 app_launcher
-rw-r--r--    1 johnlindquist  staff    292 Feb  7 09:29 app_launcher.rs
drwxr-xr-x    4 johnlindquist  staff    128 Feb  7 09:29 app_layout
-rw-r--r--    1 johnlindquist  staff    158 Feb  7 09:29 app_layout.rs

thinking
**Reviewing execution module imports**
exec
/bin/zsh -lc "sed -n '1,200p' src/app_execute.rs" in /Users/johnlindquist/dev/script-kit-gpui succeeded in 51ms:
// App execution methods split into sub-files for maintainability
include!("app_execute/builtin_execution.rs");
include!("app_execute/execution_helpers.rs");
include!("app_execute/utility_views.rs");
include!("app_execute/builtin_confirmation.rs");

thinking
**Checking feature file inclusions**
exec
/bin/zsh -lc 'rg --line-number "builtin_execution/feature" src' in /Users/johnlindquist/dev/script-kit-gpui exited 1 in 50ms:


thinking
**Inspecting AI module for integration**
codex
I confirmed `src/app_execute.rs` only includes `src/app_execute/builtin_execution.rs`, so the `feature_0*.rs` files appear unused. Iâ€™m now tracing the existing Tab-to-AI plumbing in `src/ai` to reuse its submission path for script generation.
exec
/bin/zsh -lc "sed -n '1,260p' src/ai/mod.rs" in /Users/johnlindquist/dev/script-kit-gpuiexec
/bin/zsh -lc "sed -n '1,320p' src/ai/window/streaming_submit.rs" in /Users/johnlindquist/dev/script-kit-gpuiexec
/bin/zsh -lc "sed -n '1,320p' src/ai/window/interactions.rs" in /Users/johnlindquist/dev/script-kit-gpuiexec
/bin/zsh -lc "rg --line-number \"set_ai_input|open_ai_window|submit|system prompt|prompt\" src/ai src/app_impl src/actions/dialog src/execute_script | sed -n '1,260p'" in /Users/johnlindquist/dev/script-kit-gpui succeeded in 51ms:
//! AI Chat Module
//!
//! This module provides the data layer for the AI chat window feature.
//! It includes data models, SQLite storage with FTS5 search support,
//! and provider abstraction for BYOK (Bring Your Own Key) AI integration.
//!
//! # Architecture
//!
//! ```text
//! src/ai/
//! â”œâ”€â”€ mod.rs       - Module exports and documentation
//! â”œâ”€â”€ model.rs     - Data models (Chat, Message, ChatId, MessageRole)
//! â”œâ”€â”€ storage.rs   - SQLite persistence layer
//! â”œâ”€â”€ config.rs    - Environment variable detection and model configuration
//! â””â”€â”€ providers.rs - Provider trait and implementations (OpenAI, Anthropic, etc.)
//! ```
//!
//! # Database Location
//!
//! The AI chats database is stored at `~/.scriptkit/ai-chats.db`.
 succeeded in 51ms:
use super::*;

impl AiApp {
    pub(super) fn hide_mouse_cursor(&mut self, cx: &mut Context<Self>) {
        if !self.mouse_cursor_hidden {
            self.mouse_cursor_hidden = true;
            crate::platform::hide_cursor_until_mouse_moves();
            cx.notify();
        }
    }

    /// Show the mouse cursor when mouse moves.
    pub(super) fn show_mouse_cursor(&mut self, cx: &mut Context<Self>) {
        if self.mouse_cursor_hidden {
            self.mouse_cursor_hidden = false;
            cx.notify();
        }
    }

    /// Check if a message was recently copied (within 2 seconds)
 succeeded in 51ms:
use super::*;
use crate::ai::model::ImageAttachment;
use crate::ai::providers::{ProviderImage, ProviderMessage};

impl AiApp {
    pub(super) fn submit_message(&mut self, window: &mut Window, cx: &mut Context<Self>) {
        // If we are in editing mode, delegate to the edit-submit flow
        if self.editing_message_id.is_some() {
            self.submit_edited_message(window, cx);
            return;
        }

        let content = self.input_state.read(cx).value().to_string();
        let has_pending_image = self.pending_image.is_some();

        if !ai_window_can_submit_message(&content, has_pending_image) {
            return;
        }

        // Don't allow new messages while streaming for the CURRENT chat
 succeeded in 51ms:
src/actions/dialog/part_01.rs:40:use crate::prompts::PathInfo;
src/app_impl/startup_new_actions.rs:2:        // This handles Cmd+K (toggle), Escape (close), Enter (submit), and typing
src/app_impl/startup_new_actions.rs:88:                                    // Toggle actions for arg prompts (SDK setActions)
src/app_impl/startup_new_actions.rs:95:                                    // Toggle actions for chat prompts
src/app_impl/startup_new_actions.rs:261:                        // Handle Enter to submit selected action
src/ai/model.rs:51:    /// System prompt/instruction
src/ai/model.rs:97:    /// Chat from the chat() SDK prompt
src/ai/model.rs:108:            ChatSource::ChatPrompt => "chat_prompt",
src/ai/model.rs:116:            "chat_prompt" => ChatSource::ChatPrompt,
src/ai/model.rs:147:    /// Source of the chat (ai_window, chat_prompt, script)
src/app_impl/shortcuts_hud_grid.rs:50:        // ESC closes dismissable prompts (when actions popup is not showing)
src/app_impl/shortcuts_hud_grid.rs:55:            logging::log("KEY", "ESC in dismissable prompt - closing window");
src/app_impl/shortcuts_hud_grid.rs:63:    /// Check if the current view is a dismissable prompt
src/app_impl/shortcuts_hud_grid.rs:65:    /// Dismissable prompts are those that feel "closeable" with escape:
src/app_impl/shortcuts_hud_grid.rs:70:    /// Non-dismissable prompts:
src/app_impl/actions_dialog.rs:212:    /// and focus is correctly restored based on which prompt hosted the dialog.
src/execute_script/part_001_body/body_000.rs:20:                // Create async_channel for script thread to send prompt messages to UI (event-driven)
src/execute_script/part_001_body/body_000.rs:25:                self.prompt_receiver = Some(rx);
src/execute_script/part_001_body/body_000.rs:27:                // Spawn event-driven listener for prompt messages (replaces 50ms polling)
src/execute_script/part_001_body/body_000.rs:36:                                app.handle_prompt_message(msg, cx);

thinking
**Inspecting input submission capability**
exec
/bin/zsh -lc "sed -n '300,470p' src/ai/window/window_api.rs" in /Users/johnlindquist/dev/script-kit-gpui succeeded in 51ms:
/// Used for testing the search functionality via stdin commands.
pub fn set_ai_search(cx: &mut App, query: &str) {
    use crate::logging;

    let handle = {
        let slot = AI_WINDOW.get_or_init(|| std::sync::Mutex::new(None));
        slot.lock().ok().and_then(|g| *g)
    };
    let window_is_open = handle.is_some();
    let command_queued = get_pending_commands()
        .lock()
        .ok()
        .map(|mut commands| {
            ai_window_queue_command_if_open(
                &mut commands,
                window_is_open,
                AiCommand::SetSearch(query.to_string()),
            )
        })
        .unwrap_or(false);

thinking
**Assessing AI module extension**
exec
/bin/zsh -lc "rg --line-number \"ProviderRegistry|find_provider_for_model|stream_message|send_message|generate\" src/ai src/app_execute src/kit_store | sed -n '1,300p'" in /Users/johnlindquist/dev/script-kit-gpui succeeded in 50ms:
src/ai/model.rs:129:    /// Chat title (auto-generated from first message or user-set)
src/ai/model.rs:201:    pub fn generate_title_from_content(content: &str) -> String {
src/ai/model.rs:375:    fn test_generate_title() {
src/ai/model.rs:377:            Chat::generate_title_from_content("Hello, how are you?"),
src/ai/model.rs:381:        assert_eq!(Chat::generate_title_from_content(""), "New Chat");
src/ai/model.rs:383:        assert_eq!(Chat::generate_title_from_content("   "), "New Chat");
src/ai/model.rs:386:        let title = Chat::generate_title_from_content(long_text);
src/ai/providers.rs:10://! - `ProviderRegistry` manages available providers based on detected API keys
src/ai/providers.rs:399:    /// The generated response text, or an error.
src/ai/providers.rs:400:    fn send_message(&self, messages: &[ProviderMessage], model_id: &str) -> Result<String>;
src/ai/providers.rs:414:    fn stream_message(
src/ai/providers.rs:562:    fn send_message(&self, messages: &[ProviderMessage], model_id: &str) -> Result<String> {
src/ai/providers.rs:571:        let response = send_json_with_retry("OpenAI", "send_message", || {
src/ai/providers.rs:611:    fn stream_message(
src/ai/providers.rs:626:        let response = send_json_with_retry("OpenAI", "stream_message", || {
src/ai/providers.rs:827:    fn send_message(&self, messages: &[ProviderMessage], model_id: &str) -> Result<String> {
src/ai/providers.rs:836:        let response = send_json_with_retry("Anthropic", "send_message", || {
src/ai/providers.rs:875:    fn stream_message(
src/ai/providers.rs:890:        let response = send_json_with_retry("Anthropic", "stream_message", || {
src/ai/providers.rs:958:    fn send_message(&self, messages: &[ProviderMessage], model_id: &str) -> Result<String> {

thinking
**Planning direct AI provider call**
exec
/bin/zsh -lc "sed -n '1,340p' src/ai/config.rs" in /Users/johnlindquist/dev/script-kit-gpuiexec
/bin/zsh -lc "sed -n '1980,2160p' src/ai/providers.rs" in /Users/johnlindquist/dev/script-kit-gpuiexec
/bin/zsh -lc "sed -n '1,300p' src/kit_store/mod.rs" in /Users/johnlindquist/dev/script-kit-gpuiexec
/bin/zsh -lc "sed -n '1,260p' src/script_creation/mod.rs" in /Users/johnlindquist/dev/script-kit-gpui succeeded in 51ms:
//! AI provider configuration and environment variable detection.
//!
//! This module handles automatic discovery of AI provider API keys from environment
//! variables and the system keyring using the `SCRIPT_KIT_*_API_KEY` pattern for security.
//!
//! # Key Detection Order
//!
//! API keys are detected in the following order (first found wins):
//! 1. Environment variable (`SCRIPT_KIT_*_API_KEY`)
//! 2. System keyring (macOS Keychain via `com.scriptkit.env` service)
//!
//! This allows users to either set environment variables in their shell profile
//! or use the built-in "Configure API Key" commands which store in the keyring.
//!
//! # Environment Variable Pattern
//!
//! API keys are detected with the `SCRIPT_KIT_` prefix:
//! - `SCRIPT_KIT_OPENAI_API_KEY` -> OpenAI provider
//! - `SCRIPT_KIT_ANTHROPIC_API_KEY` -> Anthropic provider
//! - `SCRIPT_KIT_VERCEL_API_KEY` -> Vercel AI Gateway
 succeeded in 50ms:
//! Types and persistence helpers for the git-based kit store.

use std::path::PathBuf;

use serde::{Deserialize, Serialize};

pub mod discover;
pub mod git_ops;
pub mod manifest;
pub mod storage;

/// Metadata describing a kit repository and its installable content.
#[derive(Debug, Clone, Default, Serialize, Deserialize, PartialEq, Eq)]
pub struct KitManifest {
    #[serde(default)]
    pub name: String,
    #[serde(default)]
    pub description: String,
    #[serde(default)]
    pub author: String,
 succeeded in 50ms:
}

/// Registry of available AI providers.
///
/// The registry automatically discovers available providers based on
/// environment variables and provides a unified interface to access them.
#[derive(Clone)]
pub struct ProviderRegistry {
    providers: HashMap<String, Arc<dyn AiProvider>>,
}

impl ProviderRegistry {
    /// Create an empty registry.
    pub fn new() -> Self {
        Self {
            providers: HashMap::new(),
        }
    }

    /// Create a registry populated from environment variables only.
 succeeded in 50ms:
//! Script and Extension Creation Module
//!
//! This module provides functions to create new scripts and extensions
//! in the Script Kit environment, as well as opening files in the configured editor.
//!
//! # Usage
//!
//! ```rust,ignore
//! use script_kit_gpui::script_creation::{create_new_script, create_new_extension, open_in_editor};
//! use script_kit_gpui::config::Config;
//!
//! // Create a new script
//! let script_path = create_new_script("my-script")?;
//!
//! // Create a new extension
//! let extension_path = create_new_extension("my-extension")?;
//!
//! // Open in editor
//! let config = Config::default();
//! open_in_editor(&script_path, &config)?;

thinking
**Locating script creation helpers**
exec
/bin/zsh -lc "sed -n '1,320p' src/script_creation/part_000.rs" in /Users/johnlindquist/dev/script-kit-gpuiexec
/bin/zsh -lc "sed -n '1,360p' src/script_creation/part_001.rs" in /Users/johnlindquist/dev/script-kit-gpui succeeded in 51ms:
use crate::config::Config;
use anyhow::{Context, Result};
use std::fs::{self, OpenOptions};
use std::io::{ErrorKind, Write};
use std::path::{Path, PathBuf};
use std::process::Command;
use tracing::{info, instrument, warn};
/// Scripts directory under ~/.scriptkit/kit/main/
const SCRIPTS_DIR: &str = "~/.scriptkit/kit/main/scripts";
/// Extensions directory under ~/.scriptkit/kit/main/
const EXTENSIONS_DIR: &str = "~/.scriptkit/kit/main/extensions";
/// Maximum filename size on most filesystems (bytes, not chars).
const MAX_FILENAME_BYTES: usize = 255;
/// Reserved filenames on Windows that are invalid even with an extension.
const WINDOWS_RESERVED_FILENAMES: [&str; 22] = [
    "con", "prn", "aux", "nul", "com1", "com2", "com3", "com4", "com5", "com6", "com7", "com8",
    "com9", "lpt1", "lpt2", "lpt3", "lpt4", "lpt5", "lpt6", "lpt7", "lpt8", "lpt9",
];
fn scripts_dir() -> PathBuf {
    PathBuf::from(shellexpand::tilde(SCRIPTS_DIR).as_ref())
 succeeded in 50ms:
#[cfg(test)]
mod tests {
    use super::*;
    use std::env;
    use tempfile::tempdir;

    #[test]
    fn test_sanitize_name_basic() {
        assert_eq!(sanitize_name("hello"), "hello");
        assert_eq!(sanitize_name("Hello World"), "hello-world");
        assert_eq!(sanitize_name("my_script_name"), "my-script-name");
    }

    #[test]
    fn test_sanitize_name_special_chars() {
        assert_eq!(sanitize_name("hello@world!"), "helloworld");
        assert_eq!(sanitize_name("test#$%script"), "testscript");
        assert_eq!(sanitize_name("foo & bar"), "foo-bar");
    }


thinking
**Searching for existing ~/.kenv/scripts usage**
exec
/bin/zsh -lc "rg --line-number \"\\.kenv/scripts|~/.kenv|kenv/scripts|scriptkit/kit/main/scripts\" src | sed -n '1,260p'" in /Users/johnlindquist/dev/script-kit-gpui succeeded in 51ms:
src/scripts/loader.rs:63:/// * `scripts_dir` - Path to the scripts directory (e.g., ~/.scriptkit/kit/main/scripts)
src/designs/core/tests/part_03.rs:286:        s.path = std::path::PathBuf::from("/Users/john/.kenv/scripts/secret-helper.ts");
src/setup/embedded_agents_part_001.md:107:| `~/.scriptkit/kit/main/scripts/` | Your scripts |
src/setup/embedded_agents_part_000.md:346:bun run ~/.scriptkit/kit/main/scripts/my-script.ts
src/setup/part_006.rs:7:    /// Expected structure: ~/.scriptkit/kit/main/scripts, ~/.scriptkit/kit/main/extensions
src/setup/part_006.rs:375:            ("kit/main/scripts", "~/.scriptkit/kit/main/scripts/"),
src/setup/part_002.rs:169:| Scripts | `~/.scriptkit/kit/main/scripts/*.ts` |
src/setup/part_002.rs:211:/// Migrate from legacy ~/.kenv to new ~/.scriptkit structure
src/setup/part_002.rs:214:/// - Moves ~/.kenv contents to ~/.scriptkit
src/setup/part_002.rs:215:/// - Moves ~/.kenv/scripts to ~/.scriptkit/kit/main/scripts
src/setup/part_002.rs:216:/// - Moves ~/.kenv/scriptlets to ~/.scriptkit/kit/main/extensions
src/setup/part_002.rs:217:/// - Creates a symlink ~/.kenv -> ~/.scriptkit for backwards compatibility
src/setup/part_002.rs:238:        "Migrating from ~/.kenv to ~/.scriptkit"
src/setup/part_002.rs:255:    // Move scripts from ~/.kenv/scripts to ~/.scriptkit/kit/main/scripts
src/setup/part_002.rs:276:    // Move scriptlets from ~/.kenv/scriptlets to ~/.scriptkit/kit/main/extensions
src/setup/part_002.rs:341:    // Remove the old ~/.kenv directory (should be mostly empty now)
src/setup/part_002.rs:343:        warn!(error = %e, "Failed to remove old ~/.kenv directory, may have remaining files");
src/setup/part_002.rs:350:            warn!(error = %e, "Failed to create ~/.kenv symlink for backwards compatibility");
src/setup/part_002.rs:352:            info!("Created ~/.kenv -> ~/.scriptkit symlink for backwards compatibility");
src/setup/part_002.rs:356:    info!("Migration from ~/.kenv to ~/.scriptkit complete");

thinking
**Planning script creation integration**
exec
/bin/zsh -lc "rg --line-number \"\\\"tab\\\"|Tab|show_inline_ai_chat|AiChat|builtin\" src/app_impl src/actions/dialog src/execute_script | sed -n '1,300p'" in /Users/johnlindquist/dev/script-kit-gpui succeeded in 51ms:
src/app_impl/filter_input_change.rs:25:        // Sync filter to builtin views that use the shared input
src/app_impl/filter_input_change.rs:31:                if Self::sync_builtin_query_state(filter, selected_index, &new_text) {
src/app_impl/filter_input_change.rs:55:                if Self::sync_builtin_query_state(filter, selected_index, &new_text) {
src/app_impl/filter_input_change.rs:66:                if Self::sync_builtin_query_state(filter, selected_index, &new_text) {
src/app_impl/filter_input_change.rs:77:                if Self::sync_builtin_query_state(filter, selected_index, &new_text) {
src/app_impl/filter_input_change.rs:88:                if Self::sync_builtin_query_state(filter, selected_index, &new_text) {
src/app_impl/filter_input_change.rs:438:                            self.execute_builtin(&entry, cx);
src/app_impl/filtering_cache.rs:54:                    "[4a/5] SEARCH_START for '{}' (scripts={}, scriptlets={}, builtins={}, apps={})",
src/app_impl/filtering_cache.rs:58:                    self.builtin_entries.len(),
src/app_impl/filtering_cache.rs:66:                &self.builtin_entries,
src/app_impl/filtering_cache.rs:152:            &self.builtin_entries,
src/app_impl/startup_new_actions.rs:22:                        // NOTE: Tab is handled by the dedicated Tab interceptor above, so
src/app_impl/startup_new_actions.rs:24:                        if key != "tab"
src/app_impl/selection_fallback.rs:37:            // Check for builtin/{id} command IDs
src/app_impl/selection_fallback.rs:38:            if let Some(builtin_id) = command_id.strip_prefix("builtin/") {
src/app_impl/selection_fallback.rs:40:                if let Some(entry) = builtins::get_builtin_entries(&config)
src/app_impl/selection_fallback.rs:42:                    .find(|e| e.id == builtin_id)
src/app_impl/selection_fallback.rs:46:                        &format!("Found builtin match: '{}' -> '{}'", alias, entry.name),
src/app_impl/selection_fallback.rs:134:                        // Skip frecency tracking for excluded builtins (e.g., "Quit Script Kit")
src/app_impl/selection_fallback.rs:139:                            Some(format!("builtin:{}", bm.entry.name))

thinking
**Reviewing AI script generation integration**
exec
/bin/zsh -lc "sed -n '140,340p' src/app_impl/prompt_ai.rs" in /Users/johnlindquist/dev/script-kit-gpui succeeded in 51ms:
                (b - r) / d + 2.0
            } else {
                (r - g) / d + 4.0
            };
            (h / 6.0, s)
        };

        vec![BoxShadow {
            color: hsla(h, s, l, shadow_config.opacity),
            offset: point(px(shadow_config.offset_x), px(shadow_config.offset_y)),
            blur_radius: px(shadow_config.blur_radius),
            spread_radius: px(shadow_config.spread_radius),
        }]
    }

    /// Show inline AI chat prompt with built-in AI provider support.
    /// This switches to the ChatPrompt view with direct AI integration (no SDK needed).
    /// Prefers Vercel AI Gateway if configured, otherwise uses the first available provider.
    pub fn show_inline_ai_chat(&mut self, initial_query: Option<String>, cx: &mut Context<Self>) {
        use crate::ai::ProviderRegistry;

thinking
**Inspecting prompt integration**
exec
/bin/zsh -lc "rg --line-number \"with_builtin_ai|builtin ai|system prompt|generate\" src/prompts | sed -n '1,320p'" in /Users/johnlindquist/dev/script-kit-gpui succeeded in 51ms:
src/prompts/select/tests.rs:158:fn test_select_prompt_generates_stable_semantic_id_when_filter_order_changes() {
src/prompts/select/mod.rs:25:use crate::protocol::{generate_semantic_id, Choice};
src/prompts/select/types.rs:285:    generate_semantic_id("select", source_index, value)
src/prompts/commands.rs:67:    /// Get the system prompt prefix for this command type
src/prompts/commands.rs:81:                "You are an expert at writing comprehensive unit tests. Your task is to generate thorough test cases \
src/prompts/chat/prompt.rs:274:    pub fn with_builtin_ai(mut self, registry: ProviderRegistry, prefer_vercel: bool) -> Self {
src/prompts/chat/streaming.rs:18:            // We need the user message ID, which will be generated in handle_builtin_ai_submit
src/prompts/chat/streaming.rs:56:        // Add user message to UI (ChatPromptMessage::user auto-generates UUID)
src/prompts/chat/streaming.rs:147:        // Add placeholder for assistant response (assistant() auto-generates UUID)
src/prompts/chat/actions.rs:36:            .map(|m| Chat::generate_title_from_content(m.get_content()))

thinking
**Inspecting AI integration prompts**
exec
/bin/zsh -lc "sed -n '220,420p' src/prompts/chat/prompt.rs" in /Users/johnlindquist/dev/script-kit-gpuiexec
/bin/zsh -lc "sed -n '1,260p' src/prompts/commands.rs" in /Users/johnlindquist/dev/script-kit-gpuiexec
/bin/zsh -lc "sed -n '1,260p' src/prompts/chat/streaming.rs" in /Users/johnlindquist/dev/script-kit-gpui succeeded in 51ms:

    /// Set models from string names (creates ChatModel entries with name=id)
    pub fn with_model_names(mut self, model_names: Vec<String>) -> Self {
        if !model_names.is_empty() {
            self.models = model_names
                .into_iter()
                .map(|name| ChatModel::new(name.clone(), name.clone(), "Custom"))
                .collect();
            if self.model.is_none() {
                self.model = self.models.first().map(|m| m.name.clone());
            }
        }
        self
    }

    /// Set the default model
    pub fn with_default_model(mut self, model: String) -> Self {
        self.model = Some(model);
        self
    }
 succeeded in 51ms:
use super::*;

impl ChatPrompt {
    pub(super) fn handle_submit(&mut self, cx: &mut Context<Self>) {
        let text = self.input.text().to_string();
        let pending_image = self.pending_image.take();
        let pending_render = self.pending_image_render.take();

        if text.trim().is_empty() && pending_image.is_none() {
            return;
        }
        logging::log("CHAT", &format!("User submitted: {}", text));
        self.input.clear();

        // If built-in AI mode is enabled, handle the AI call directly
        if self.has_builtin_ai() {
            // Cache the render image for conversation history display
            // We need the user message ID, which will be generated in handle_builtin_ai_submit
            self.handle_builtin_ai_submit(text, pending_image, pending_render, cx);
        } else {
 succeeded in 51ms:
//! Slash command system for AI chat
//!
//! Provides /command support for common AI operations:
//! - `/explain` - Explain selected code or topic
//! - `/fix` - Fix errors in code
//! - `/test` - Generate unit tests
//! - `/improve` - Improve writing or code
//! - `/summarize` - Summarize text
//!
//! Based on patterns from GitHub Copilot and Raycast.

/// Types of slash commands available
#[derive(Clone, Copy, Debug, PartialEq, Eq)]
pub enum SlashCommandType {
    /// Explain code or concepts clearly
    Explain,
    /// Fix errors or bugs in code
    Fix,
    /// Generate unit tests for code
    Test,

thinking
**Scoping script generation approach**
exec
/bin/zsh -lc "sed -n '1,360p' src/ai/sdk_handlers.rs" in /Users/johnlindquist/dev/script-kit-gpui succeeded in 51ms:
//! AI SDK Protocol Handlers
//!
//! This module handles AI SDK protocol messages from scripts.
//! It converts between protocol types and storage/window operations.

use anyhow::Result;
use tracing::{debug, error, info};

use crate::protocol::{AiChatInfo, AiMessageInfo, Message};

use super::model::{Chat, ChatId, Message as AiMessage, MessageRole};
use super::storage;

/// Convert a Chat from storage to AiChatInfo for protocol
fn chat_to_info(chat: &Chat, message_count: usize) -> AiChatInfo {
    AiChatInfo {
        id: chat.id.as_str(),
        title: chat.title.clone(),
        model_id: chat.model_id.clone(),
        provider: chat.provider.clone(),

thinking
**Assessing built-in chat message flow**
exec
/bin/zsh -lc "sed -n '1,470p' src/builtins/tests/part_000.rs" in /Users/johnlindquist/dev/script-kit-gpuiexec
/bin/zsh -lc "sed -n '1,220p' src/builtins/tests/part_001.rs" in /Users/johnlindquist/dev/script-kit-gpui succeeded in 51ms:
    use super::*;
    use crate::config::BuiltInConfig;
    #[test]
    fn test_builtin_config_default() {
        let config = BuiltInConfig::default();
        assert!(config.clipboard_history);
        assert!(config.app_launcher);
        assert!(config.window_switcher);
    }
    #[test]
    fn test_builtin_config_custom() {
        let config = BuiltInConfig {
            clipboard_history: false,
            app_launcher: true,
            window_switcher: false,
        };
        assert!(!config.clipboard_history);
        assert!(config.app_launcher);
        assert!(!config.window_switcher);
    }
 succeeded in 51ms:
    // NOTE: test_builtin_feature_window_action removed - WindowAction no longer in BuiltInFeature

    #[test]
    fn test_file_search_builtin_exists() {
        let config = BuiltInConfig::default();
        let entries = get_builtin_entries(&config);

        // Check that FileSearch entry exists
        let file_search = entries.iter().find(|e| e.id == "builtin-file-search");
        assert!(
            file_search.is_some(),
            "FileSearch builtin should exist in the main menu"
        );

        let file_search = file_search.unwrap();
        assert_eq!(file_search.name, "Search Files");
        assert_eq!(file_search.feature, BuiltInFeature::FileSearch);
        assert!(file_search.keywords.contains(&"file".to_string()));
        assert!(file_search.keywords.contains(&"search".to_string()));
        assert!(file_search.keywords.contains(&"find".to_string()));

thinking
**Inspecting command and core entries**
exec
/bin/zsh -lc "sed -n '1,260p' src/builtins/part_001_entries/entries_000.rs" in /Users/johnlindquist/dev/script-kit-gpuiexec
/bin/zsh -lc "sed -n '1,260p' src/builtins/part_001_entries/entries_003.rs" in /Users/johnlindquist/dev/script-kit-gpuiexec
/bin/zsh -lc "sed -n '1,260p' src/builtins/part_001_entries/entries_001.rs" in /Users/johnlindquist/dev/script-kit-gpui succeeded in 51ms:
{
    if config.clipboard_history {
        entries.push(BuiltInEntry::new_with_icon(
            "builtin-clipboard-history",
            "Clipboard History",
            "Open clipboard history to view, search, and reuse copied items",
            vec!["clipboard", "history", "paste", "copy"],
            BuiltInFeature::ClipboardHistory,
            "ðŸ“‹",
        ));
        debug!("Added Clipboard History built-in entry");
    }

    // Note: AppLauncher built-in removed - apps now appear directly in main search
    // The app_launcher config flag is kept for future use (e.g., to disable app search entirely)
    if config.app_launcher {
        debug!("app_launcher enabled - apps will appear in main search");
    }

    if config.window_switcher {
 succeeded in 50ms:
{
    // System Actions
    // =========================================================================

    // Power management
    entries.push(BuiltInEntry::new_with_icon(
        "builtin-empty-trash",
        "Empty Trash",
        "Empty the macOS Trash",
        vec!["empty", "trash", "delete", "clean"],
        BuiltInFeature::SystemAction(SystemActionType::EmptyTrash),
        "ðŸ—‘ï¸",
    ));

    entries.push(BuiltInEntry::new_with_icon(
        "builtin-lock-screen",
        "Lock Screen",
        "Lock the screen",
        vec!["lock", "screen", "security"],
        BuiltInFeature::SystemAction(SystemActionType::LockScreen),
 succeeded in 50ms:
{
    // Settings Commands
    // =========================================================================

    // Only show reset if there are custom positions
    if crate::window_state::has_custom_positions() {
        entries.push(BuiltInEntry::new_with_icon(
            "builtin-reset-window-positions",
            "Reset Window Positions",
            "Restore all windows to default positions",
            vec![
                "reset", "window", "position", "default", "restore", "layout", "location",
            ],
            BuiltInFeature::SettingsCommand(SettingsCommandType::ResetWindowPositions),
            "ðŸ”„",
        ));
    }

    // API Key Configuration
    entries.push(BuiltInEntry::new_with_icon(

thinking
**Reviewing script execution and builtin handling**
exec
/bin/zsh -lc "rg --line-number \"std::thread::spawn|cx\\.spawn\\(async move\" src/app_execute/builtin_execution.rs | sed -n '1,260p'" in /Users/johnlindquist/dev/script-kit-gpui succeeded in 51ms:
44:            cx.spawn(async move |this, cx| {
281:                cx.spawn(async move |this, cx| {

thinking
**Inspecting async background execution**
exec
/bin/zsh -lc "rg --line-number \"send_blocking|async_channel::bounded|std::thread::spawn\\(|cx\\.spawn\\(async move\" src/app_execute src/app_impl src/ai | sed -n '1,320p'" in /Users/johnlindquist/dev/script-kit-gpui succeeded in 51ms:
src/app_impl/alias_input.rs:198:                    cx.spawn(async move |_this, cx| {
src/app_impl/alias_input.rs:218:                    cx.spawn(async move |_this, cx| {
src/app_execute/utility_views.rs:37:                cx.spawn(async move |_this, _cx| {
src/app_execute/utility_views.rs:299:                cx.spawn(async move |_this, _cx| {
src/app_execute/utility_views.rs:353:                cx.spawn(async move |_this, cx| {
src/app_execute/utility_views.rs:381:        cx.spawn(async move |_this, cx| {
src/ai/providers.rs:1681:            std::thread::spawn(move || {
src/app_impl/filter_input_change.rs:162:                            let task = cx.spawn(async move |this, cx| {
src/app_impl/filter_input_change.rs:170:                                std::thread::spawn({
src/app_impl/filter_input_change.rs:287:                    let task = cx.spawn(async move |this, cx| {
src/app_impl/filter_input_change.rs:295:                        std::thread::spawn({
src/app_execute/execution_helpers.rs:419:        cx.spawn(async move |_this, cx| {
src/app_execute/execution_helpers.rs:457:        cx.spawn(async move |_this, _cx| {
src/app_execute/builtin_execution.rs:44:            cx.spawn(async move |this, cx| {
src/app_execute/builtin_execution.rs:281:                cx.spawn(async move |this, cx| {
src/app_impl/actions_dialog.rs:250:            cx.spawn(async move |_this, cx| {
src/ai/window/setup.rs:58:        cx.spawn(async move |this, cx| {
src/app_execute/builtin_execution/feature_01.rs:155:                cx.spawn(async move |this, cx| {
src/app_impl/lifecycle_reset.rs:98:            cx.spawn(async move |_this, cx| {
src/app_impl/actions_toggle.rs:100:            cx.spawn(async move |_this, cx| {

thinking
**Reviewing pattern for UI update**
exec
/bin/zsh -lc "sed -n '130,230p' src/app_impl/filter_input_change.rs && sed -n '250,360p' src/app_impl/filter_input_change.rs" in /Users/johnlindquist/dev/script-kit-gpui succeeded in 51ms:

                    // Cancel any in-flight search by setting the cancel token
                    if let Some(cancel) = self.file_search_cancel.take() {
                        cancel.store(true, std::sync::atomic::Ordering::Relaxed);
                    }

                    // Cancel existing debounce task (drops the Task, stopping the async work)
                    self.file_search_debounce_task = None;

                    // Check if this is a directory path with potential filter
                    // e.g., ~/dev/fin -> list ~/dev/ and filter by "fin"
                    if let Some(parsed) = crate::file_search::parse_directory_path(&new_text) {
                        // Directory path mode - check if we need to reload directory
                        let dir_changed =
                            self.file_search_current_dir.as_ref() != Some(&parsed.directory);

                        if dir_changed {
                            // Directory changed - need to load new directory contents
                            // DON'T clear results - keep old results with frozen filter
                            // This prevents visual flash during directory transitions

thinking
**Inspecting provider call patterns**
exec
/bin/zsh -lc "sed -n '340,460p' src/ai/providers.rs" in /Users/johnlindquist/dev/script-kit-gpui succeeded in 52ms:
            images,
        }
    }

    /// Create a new assistant message.
    pub fn assistant(content: impl Into<String>) -> Self {
        Self {
            role: "assistant".to_string(),
            content: content.into(),
            images: Vec::new(),
        }
    }

    /// Create a new system message.
    pub fn system(content: impl Into<String>) -> Self {
        Self {
            role: "system".to_string(),
            content: content.into(),
            images: Vec::new(),
        }

thinking
**Planning robust code extraction**
exec
/bin/zsh -lc 'rg --line-number "```|code block|extract.*code|fence|markdown" src | sed -n '"'1,260p'" in /Users/johnlindquist/dev/script-kit-gpui exited 1 in 52ms:
zsh:1: unmatched "

thinking
**Adjusting command quoting and pattern**
exec
/bin/zsh -lc "rg --line-number \"extract.*code|code block|markdown\" src/ai src/script_creation src/app_execute src/prompts | sed -n '1,260p'" in /Users/johnlindquist/dev/script-kit-gpui succeeded in 51ms:
src/script_creation/part_000.rs:201:/// Generate the extension template as markdown with embedded code.
src/script_creation/part_000.rs:203:/// Extensions are markdown files with code blocks that can be executed.
src/script_creation/part_001.rs:144:        // Verify the content is markdown with a code block
src/app_execute/execution_helpers.rs:406:            "markdown".to_string(), // Use markdown for nice highlighting
src/prompts/mod.rs:25:pub mod markdown;
src/ai/window/render_overlays_shortcuts.rs:28:            ("\u{2318} Shift E", "Export chat as markdown"),
src/ai/window/render_keydown.rs:246:                // Cmd+Shift+E to export chat to clipboard as markdown
src/prompts/markdown/api.rs:3:/// Render markdown text to GPUI elements.
src/prompts/markdown/api.rs:5:/// Uses a global cache to avoid re-parsing markdown and re-highlighting code
src/prompts/markdown/api.rs:7:pub fn render_markdown(text: &str, colors: &PromptColors) -> gpui::Div {
src/prompts/markdown/api.rs:8:    render_markdown_with_scope(text, colors, None)
src/prompts/markdown/api.rs:11:/// Render markdown with a stable scope identifier.
src/prompts/markdown/api.rs:15:/// unchanged subtrees instead of replacing the entire markdown tree every tick.
src/prompts/markdown/api.rs:16:pub fn render_markdown_with_scope(
src/prompts/markdown/api.rs:22:    let key = markdown_cache_key(text, colors.is_dark);
src/prompts/markdown/api.rs:25:        .map(|s| stable_markdown_scope_hash(Some(s)))
src/prompts/markdown/api.rs:26:        .unwrap_or_else(|| inferred_markdown_scope_hash(text));
src/prompts/markdown/api.rs:35:        let blocks = Arc::new(parse_markdown(text, colors.is_dark));
src/prompts/markdown/api.rs:48:    let elements = build_markdown_elements(parsed_blocks.as_slice(), colors, render_scope_hash);
src/prompts/markdown/tests.rs:6:    let blocks = parse_markdown_blocks(md);

thinking
**Inspecting existing code reuse**
exec
/bin/zsh -lc "sed -n '420,500p' src/ai/window/command_bar.rs" in /Users/johnlindquist/dev/script-kit-gpui succeeded in 51ms:
        {
            cx.write_to_clipboard(gpui::ClipboardItem::new_string(
                last_response.content.clone(),
            ));
            info!("Copied last response to clipboard");
        }
    }

    /// Copy the entire chat to clipboard
    pub(super) fn copy_entire_chat(&self, cx: &mut Context<Self>) {
        let chat_text: String = self
            .current_messages
            .iter()
            .map(|m| {
                let role = if m.role == MessageRole::User {
                    "You"
                } else {
                    "AI"
                };
                format!("**{}**: {}\n\n", role, m.content)

thinking
**Identifying script execution utilities**
exec
/bin/zsh -lc "rg --line-number \"open_in_editor|execute.*script|run script|run_script\" src/app_execute src/app_impl src/script_creation | sed -n '1,300p'" in /Users/johnlindquist/dev/script-kit-gpui succeeded in 51ms:
src/script_creation/part_000.rs:402:#[instrument(name = "open_in_editor", skip(config), fields(path = %path.display()))]
src/script_creation/part_000.rs:403:pub fn open_in_editor(path: &Path, config: &Config) -> Result<()> {
src/script_creation/mod.rs:9://! use script_kit_gpui::script_creation::{create_new_script, create_new_extension, open_in_editor};
src/script_creation/mod.rs:20://! open_in_editor(&script_path, &config)?;
src/app_execute/builtin_execution.rs:503:            // SDK tileWindow() still works via protocol messages in execute_script.rs
src/app_execute/builtin_execution.rs:870:                        if let Err(e) = script_creation::open_in_editor(&path, &self.config) {
src/app_impl/filter_input_change.rs:432:                            self.execute_interactive(&script, cx);
src/app_impl/filter_input_change.rs:435:                            self.execute_scriptlet(&scriptlet, cx);
src/app_execute/builtin_execution/feature_02.rs:323:                        if let Err(e) = script_creation::open_in_editor(&path, &self.config) {
src/app_impl/selection_fallback.rs:174:                        self.execute_interactive(&script_match.script, cx);
src/app_impl/selection_fallback.rs:177:                        self.execute_scriptlet(&scriptlet_match.scriptlet, cx);
src/app_impl/selection_fallback.rs:238:                self.execute_interactive(&config.script, cx);
src/app_impl/selection_fallback.rs:278:                    self.execute_interactive(&config.script, cx);
src/app_execute/builtin_execution/feature_01.rs:377:            // SDK tileWindow() still works via protocol messages in execute_script.rs
src/app_impl/execution_scripts.rs:39:    pub(crate) fn execute_scriptlet(&mut self, scriptlet: &scripts::Scriptlet, cx: &mut Context<Self>) {
src/app_impl/execution_scripts.rs:99:            self.execute_interactive(&script, cx);
src/app_impl/execution_scripts.rs:146:            // Build the command to execute the script file
src/app_impl/execution_scripts.rs:184:        match executor::run_scriptlet(&exec_scriptlet, options) {
src/app_impl/execution_scripts.rs:250:                    &format!("Failed to execute scriptlet '{}': {}", scriptlet.name, e),
src/app_impl/execution_scripts.rs:268:    pub(crate) fn execute_script_by_path(&mut self, path: &str, cx: &mut Context<Self>) {

thinking
**Inspecting editor launch function**
exec
/bin/zsh -lc "sed -n '330,470p' src/script_creation/part_000.rs" in /Users/johnlindquist/dev/script-kit-gpui succeeded in 51ms:
        "Created new extension"
    );

    Ok(extension_path)
}
/// Open a file in the configured editor.
///
/// Uses the editor from config, falling back to $EDITOR env var,
/// then to "code" (VS Code) as the final default.
///
/// # Arguments
///
/// * `path` - The path to the file to open
/// * `config` - The application configuration
///
/// # Errors
///
/// Returns an error if the editor command fails to spawn.
fn parse_editor_command(editor: &str) -> Result<Vec<String>> {
    let mut parts = Vec::new();

thinking
**Inspecting AI command execution paths**
exec
/bin/zsh -lc "sed -n '1,260p' src/app_execute/builtin_confirmation.rs" in /Users/johnlindquist/dev/script-kit-gpui succeeded in 50ms:
impl ScriptListApp {
    /// Handle builtin confirmation modal result.
    /// Called when user confirms or cancels a dangerous action from the modal.
    fn handle_builtin_confirmation(
        &mut self,
        entry_id: String,
        confirmed: bool,
        cx: &mut Context<Self>,
    ) {
        if !confirmed {
            logging::log(
                "EXEC",
                &format!("Builtin confirmation cancelled: {}", entry_id),
            );
            return;
        }

        logging::log(
            "EXEC",
            &format!("Builtin confirmation accepted, executing: {}", entry_id),

thinking
**Planning AI script generation**
codex
I have enough context and the implementation path is clear. Iâ€™m going to add a new AI built-in command for script generation and wire execution to a new `src/ai` helper so the flow is testable and isolated.

Plan:
1. Add `AiCommandType::GenerateScript` and register a built-in entry in `get_builtin_entries()` with discoverable keywords.
2. Implement `src/ai/script_generation.rs`:
   - provider/model selection via existing `ProviderRegistry` patterns
   - fixed system prompt for Script Kit best practices
   - response code extraction (prefer fenced TS/JS blocks)
   - slugified unique filename under `~/.kenv/scripts`
   - file write + return created path/model metadata
3. Wire `execute_builtin()` for the new command in `src/app_execute/builtin_execution.rs`:
   - read current `filter_text` as user prompt
   - run generation in background thread
   - on success open in editor and show success HUD/toast
   - on failure show structured error toast and log details
4. Add focused tests:
   - built-in entry presence/feature mapping
   - script-generation helper unit tests (slugging, code extraction, fallback behavior)
5. Run scoped tests for changed modules and report results.

thinking
**Planning sequential file claiming**
exec
/bin/zsh -lc '~/.claude/bin/swarm.ts claim --wait --id codex-script-gen-builtin src/builtins/part_001_entries/entries_002.rs' in /Users/johnlindquist/dev/script-kit-gpui succeeded in 52ms:
Claimed for codex-script-gen-builtin: src/builtins/part_001_entries/entries_002.rs
exec
/bin/zsh -lc '~/.claude/bin/swarm.ts claim --wait --id codex-script-gen-builtin src/builtins/part_000.rs' in /Users/johnlindquist/dev/script-kit-gpuiexec
/bin/zsh -lc '~/.claude/bin/swarm.ts claim --wait --id codex-script-gen-builtin src/builtins/tests/part_000.rs' in /Users/johnlindquist/dev/script-kit-gpui succeeded in 51ms:
Claimed for codex-script-gen-builtin: src/builtins/part_000.rs
 succeeded in 123ms:
Claimed for codex-script-gen-builtin: src/builtins/tests/part_000.rs

thinking
**Expanding file and path claims**
exec
/bin/zsh -lc '~/.claude/bin/swarm.ts claim --wait --id codex-script-gen-builtin src/app_execute/builtin_execution.rs' in /Users/johnlindquist/dev/script-kit-gpui succeeded in 52ms:
Claimed for codex-script-gen-builtin: src/app_execute/builtin_execution.rs
exec
/bin/zsh -lc '~/.claude/bin/swarm.ts claim --wait --id codex-script-gen-builtin src/ai/script_generation.rs' in /Users/johnlindquist/dev/script-kit-gpuiexec
/bin/zsh -lc '~/.claude/bin/swarm.ts claim --wait --id codex-script-gen-builtin src/ai/mod.rs' in /Users/johnlindquist/dev/script-kit-gpui succeeded in 59ms:
Claimed for codex-script-gen-builtin: src/ai/script_generation.rs
 succeeded in 62ms:
Claimed for codex-script-gen-builtin: src/ai/mod.rs
exec
/bin/zsh -lc '~/.claude/bin/swarm.ts update --id codex-script-gen-builtin --status in_progress --notes "Claimed builtin/app_execute/ai files; implementing AI script generation command + tests"' in /Users/johnlindquist/dev/script-kit-gpui succeeded in 51ms:
Updated: codex-script-gen-builtin

thinking
**Inspecting dependencies in builtin_execution.rs**
exec
/bin/zsh -lc "sed -n '1,120p' src/app_execute/builtin_execution.rs" in /Users/johnlindquist/dev/script-kit-gpui succeeded in 50ms:
fn ai_open_failure_message(error: impl std::fmt::Display) -> String {
    format!("Failed to open AI: {}", error)
}

impl ScriptListApp {
    fn system_action_feedback_message(
        &self,
        action_type: &builtins::SystemActionType,
    ) -> Option<String> {
        let dark_mode_enabled = if matches!(action_type, builtins::SystemActionType::ToggleDarkMode)
        {
            system_actions::is_dark_mode().ok()
        } else {
            None
        };

        builtins::system_action_hud_message(*action_type, dark_mode_enabled)
    }

    fn execute_builtin(&mut self, entry: &builtins::BuiltInEntry, cx: &mut Context<Self>) {

thinking
**Inspecting import declarations around include**
exec
/bin/zsh -lc "sed -n '1,220p' src/lib.rs" in /Users/johnlindquist/dev/script-kit-gpui succeeded in 50ms:
#![allow(unexpected_cfgs)]
#![recursion_limit = "2048"]

//! Script Kit GPUI - A GPUI-based launcher for Script Kit
//!
//! This library provides the core functionality for executing scripts
//! with bidirectional JSONL communication.

// Actions - Reusable action dialog component
// Provides ActionsDialog with configurable layout for script actions, AI command bar, etc.
pub mod actions;

// App Shell - Unified frame and chrome for all prompts
// Provides ShellSpec, HeaderSpec, FooterSpec, ChromeSpec for consistent prompt layout
pub mod app_shell;

#[cfg(target_os = "macos")]
pub mod camera;
pub mod components;
pub mod config;

thinking
**Searching for relevant imports**
exec
/bin/zsh -lc 'rg --line-number "include!'"\\(\\\"app_execute\\.rs\\\"\\)|use crate::ai|use crate::builtins|use gpui|use anyhow\" src/lib.rs | sed -n '1,260p'" in /Users/johnlindquist/dev/script-kit-gpui succeeded in 52ms:


thinking
**Identifying unnecessary includes near struct definitions**
exec
/bin/zsh -lc 'rg --line-number "include!'"\\(\" src/lib.rs | sed -n '1,260p'" in /Users/johnlindquist/dev/script-kit-gpui succeeded in 51ms:


thinking
**Inspecting module inclusion patterns**
exec
/bin/zsh -lc 'tail -n 260 src/lib.rs' in /Users/johnlindquist/dev/script-kit-gpui succeeded in 50ms:
#[cfg(target_os = "macos")]
pub mod menu_executor;

// Menu cache - SQLite-backed menu bar data caching
// Caches application menu hierarchies by bundle_id to avoid expensive rescans
#[cfg(target_os = "macos")]
pub mod menu_cache;

// Frontmost app tracker - Background observer for tracking active application
// Pre-fetches menu bar items when apps activate (before Script Kit opens)
#[cfg(target_os = "macos")]
pub mod frontmost_app_tracker;

// Action helpers - centralized path extraction, SDK action routing, pbcopy
pub mod action_helpers;

// Built-in features registry
pub mod app_launcher;
pub mod builtins;


thinking
**Inspecting main.rs imports**
exec
/bin/zsh -lc "sed -n '1,260p' src/main.rs" in /Users/johnlindquist/dev/script-kit-gpui succeeded in 51ms:
#![allow(unexpected_cfgs)]

//! Binary entrypoint and GPUI application composition for Script Kit GPUI.
//! It defines the `ScriptListApp` runtime, wires stdin protocol handling in `main`,
//! and includes prompt/builtin render implementations for the primary window.
//! This module depends on app subsystems like `protocol`, `hotkeys`, `watcher`, and `window_manager`.

use gpui::{
    div, hsla, list, point, prelude::*, px, rgb, rgba, size, svg, uniform_list, AnyElement, App,
    Application, BoxShadow, Context, CursorStyle, ElementId, Entity, FocusHandle, Focusable,
    FontWeight, KeyDownEvent, ListAlignment, ListOffset, ListSizingBehavior, ListState,
    MouseMoveEvent, Render, ScrollStrategy, SharedString, Subscription, Timer,
    UniformListScrollHandle, Window, WindowBackgroundAppearance, WindowBounds, WindowHandle,
    WindowKind, WindowOptions,
};

// gpui-component Root wrapper for theme and context provision
use gpui_component::input::{Input, InputEvent, InputState};
use gpui_component::notification::{Notification, NotificationType};
use gpui_component::Root;

thinking
**Designing AI script generation module**
exec
/bin/zsh -lc "rg --line-number \"fn reset_to_script_list\" -n src/app_impl src | sed -n '1,120p'" in /Users/johnlindquist/dev/script-kit-gpui succeeded in 51ms:
src/app_impl/registries_state.rs:141:    pub(crate) fn reset_to_script_list(&mut self, cx: &mut Context<Self>) {
src/app_impl/registries_state.rs:141:    pub(crate) fn reset_to_script_list(&mut self, cx: &mut Context<Self>) {
exec
/bin/zsh -lc "sed -n '141,250p' src/app_impl/registries_state.rs" in /Users/johnlindquist/dev/script-kit-gpui succeeded in 51ms:
    pub(crate) fn reset_to_script_list(&mut self, cx: &mut Context<Self>) {
        let old_view = match &self.current_view {
            AppView::ScriptList => "ScriptList",
            AppView::ActionsDialog => "ActionsDialog",
            AppView::ArgPrompt { .. } => "ArgPrompt",
            AppView::DivPrompt { .. } => "DivPrompt",
            AppView::FormPrompt { .. } => "FormPrompt",
            AppView::TermPrompt { .. } => "TermPrompt",
            AppView::EditorPrompt { .. } => "EditorPrompt",
            AppView::SelectPrompt { .. } => "SelectPrompt",
            AppView::PathPrompt { .. } => "PathPrompt",
            AppView::EnvPrompt { .. } => "EnvPrompt",
            AppView::DropPrompt { .. } => "DropPrompt",
            AppView::TemplatePrompt { .. } => "TemplatePrompt",
            AppView::ChatPrompt { .. } => "ChatPrompt",
            AppView::ClipboardHistoryView { .. } => "ClipboardHistoryView",
            AppView::AppLauncherView { .. } => "AppLauncherView",
            AppView::WindowSwitcherView { .. } => "WindowSwitcherView",
            AppView::DesignGalleryView { .. } => "DesignGalleryView",
            AppView::ScratchPadView { .. } => "ScratchPadView",

thinking
**Refining AI command script generation**
exec
/bin/zsh -lc "rg --line-number \"struct Config\" -n src/config | sed -n '1,80p' && sed -n '1,140p' src/config/mod.rs" in /Users/johnlindquist/dev/script-kit-gpui succeeded in 51ms:
src/config/editor/part_01.rs:17:pub struct ConfigProperty {
src/config/types/part_02.rs:144:pub struct Config {
//! Configuration module - Application settings and user preferences
//!
//! This module provides functionality for:
//! - Loading configuration from ~/.scriptkit/kit/config.ts
//! - Default values for all settings
//! - Type definitions for config structures
//!
//! # Module Structure
//!
//! - `defaults` - All default constant values
//! - `types` - Configuration struct definitions (Config, HotkeyConfig, etc.)
//! - `loader` - File system loading and parsing

pub mod defaults;
pub mod editor;
mod loader;
mod types;


thinking
**Checking trait derivations**
exec
/bin/zsh -lc "sed -n '120,240p' src/config/types/part_02.rs" in /Users/johnlindquist/dev/script-kit-gpui succeeded in 52ms:
        parts.join("+")
    }
}

fn default_main_hotkey() -> HotkeyConfig {
    HotkeyConfig {
        modifiers: vec!["meta".to_string()],
        key: "Semicolon".to_string(),
    }
}

fn default_ai_hotkey_enabled() -> bool {
    DEFAULT_AI_HOTKEY_ENABLED
}

fn default_logs_hotkey_enabled() -> bool {
    DEFAULT_LOGS_HOTKEY_ENABLED
}

// ============================================

thinking
**Planning modular patch and tests**
codex
Iâ€™m starting file edits now: first Iâ€™ll add a dedicated `ai::script_generation` module and export it through `src/ai/mod.rs`, then wire built-ins and execution to call it.
file update
M /Users/johnlindquist/dev/script-kit-gpui/src/ai/mod.rs
@@ -39,2 +39,3 @@
 pub(crate) mod session;
+pub(crate) mod script_generation;
 pub(crate) mod storage;
@@ -46,2 +47,3 @@
 pub use self::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+pub use self::script_generation::{generate_script_from_prompt, GeneratedScriptOutput};
 pub use self::sdk_handlers::try_handle_ai_message;
apply_patch(auto_approved=true) exited 0 in 11ms:
Success. Updated the following files:
M src/ai/mod.rs
file update:
diff --git a/src/ai/mod.rs b/src/ai/mod.rs
index a420b1a5faf59506acdb7caf60681c153a3f9bb6..9a73e9491862633b325b2c52b51a3e20395ff85c
--- a/src/ai/mod.rs
+++ b/src/ai/mod.rs
@@ -37,6 +37,7 @@
 pub(crate) mod providers;
 pub(crate) mod sdk_handlers;
 pub(crate) mod session;
+pub(crate) mod script_generation;
 pub(crate) mod storage;
 pub(crate) mod window;
 
@@ -44,6 +45,7 @@
 pub use self::config::{DetectedKeys, ModelInfo, ProviderConfig};
 pub use self::model::{Chat, ChatId, ChatSource, Message, MessageRole};
 pub use self::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+pub use self::script_generation::{generate_script_from_prompt, GeneratedScriptOutput};
 pub use self::sdk_handlers::try_handle_ai_message;
 pub use self::storage::{
     clear_all_chats, create_chat, delete_chat, get_all_chats, get_chat, get_chat_messages,

file update:
diff --git a/src/ai/mod.rs b/src/ai/mod.rs
index a420b1a5faf59506acdb7caf60681c153a3f9bb6..9a73e9491862633b325b2c52b51a3e20395ff85c
--- a/src/ai/mod.rs
+++ b/src/ai/mod.rs
@@ -37,6 +37,7 @@
 pub(crate) mod providers;
 pub(crate) mod sdk_handlers;
 pub(crate) mod session;
+pub(crate) mod script_generation;
 pub(crate) mod storage;
 pub(crate) mod window;
 
@@ -44,6 +45,7 @@
 pub use self::config::{DetectedKeys, ModelInfo, ProviderConfig};
 pub use self::model::{Chat, ChatId, ChatSource, Message, MessageRole};
 pub use self::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+pub use self::script_generation::{generate_script_from_prompt, GeneratedScriptOutput};
 pub use self::sdk_handlers::try_handle_ai_message;
 pub use self::storage::{
     clear_all_chats, create_chat, delete_chat, get_all_chats, get_chat, get_chat_messages,


thinking
**Implementing AI script generation module**
file update
A /Users/johnlindquist/dev/script-kit-gpui/src/ai/script_generation.rs
use anyhow::{Context, Result};
use std::fs::{self, OpenOptions};
use std::io::{ErrorKind, Write};
use std::path::{Path, PathBuf};
use std::sync::Arc;

use super::config::ModelInfo;
use super::providers::{AiProvider, ProviderMessage, ProviderRegistry};

const AI_SCRIPT_OUTPUT_DIR: &str = "~/.kenv/scripts";
const AI_SCRIPT_DEFAULT_SLUG: &str = "ai-script";
const AI_SCRIPT_MAX_SLUG_LEN: usize = 64;

const AI_SCRIPT_GENERATION_SYSTEM_PROMPT: &str = r#"You write production-ready Script Kit scripts.

Return ONLY TypeScript source code for one Script Kit script. Do not include explanations.

Required output conventions:
1) Include metadata comments at the top:
   // Name: <clear title>
   // Description: <one-line summary>
2) Include: import "@johnlindquist/kit";
3) Use await arg() for user input when useful.
4) Use await div() for display output when useful.
5) Keep the script runnable as-is with sensible defaults and light error handling."#;

#[derive(Debug, Clone)]
pub struct GeneratedScriptOutput {
    pub path: PathBuf,
    pub slug: String,
    pub model_id: String,
    pub provider_id: String,
}

pub fn generate_script_from_prompt(
    prompt: &str,
    config: Option<&crate::config::Config>,
) -> Result<GeneratedScriptOutput> {
    let normalized_prompt = prompt.trim();
    if normalized_prompt.is_empty() {
        anyhow::bail!("AI script generation requires a non-empty prompt");
    }

    let registry = ProviderRegistry::from_environment_with_config(config);
    if !registry.has_any_provider() {
        anyhow::bail!(
            "No AI providers configured. Configure an API key first (Vercel, OpenAI, Anthropic, etc.)."
        );
    }

    let (selected_model, provider) = select_generation_model(&registry)?;
    crate::logging::log(
        "AI",
        &format!(
            "correlation_id=ai-script-generation state=provider_ready model_id={} provider_id={} prompt_len={}",
            selected_model.id,
            selected_model.provider,
            normalized_prompt.len()
        ),
    );

    let messages = vec![
        ProviderMessage::system(AI_SCRIPT_GENERATION_SYSTEM_PROMPT),
        ProviderMessage::user(format!(
            "Generate a Script Kit script for this user request:\n\n{}",
            normalized_prompt
        )),
    ];

    let raw_response = provider
        .send_message(&messages, &selected_model.id)
        .with_context(|| {
            format!(
                "AI script generation failed (attempted=send_message, model_id={}, provider_id={})",
                selected_model.id, selected_model.provider
            )
        })?;

    let extracted = extract_script_code(&raw_response);
    if extracted.trim().is_empty() {
        anyhow::bail!(
            "AI returned an empty response for script generation (state=empty_response)"
        );
    }

    let slug = slugify_script_name(normalized_prompt);
    let finalized = enforce_script_kit_conventions(&extracted, normalized_prompt, &slug);
    let path = write_generated_script(&slug, &finalized).with_context(|| {
        format!(
            "Failed writing AI-generated script (state=write_failed, slug={})",
            slug
        )
    })?;

    crate::logging::log(
        "AI",
        &format!(
            "correlation_id=ai-script-generation state=script_written path={} slug={}",
            path.display(),
            slug
        ),
    );

    Ok(GeneratedScriptOutput {
        path,
        slug,
        model_id: selected_model.id,
        provider_id: selected_model.provider,
    })
}

fn select_generation_model(registry: &ProviderRegistry) -> Result<(ModelInfo, Arc<dyn AiProvider>)> {
    let models = registry.get_all_models();
    let selected_model = models
        .iter()
        .find(|model| model.provider.eq_ignore_ascii_case("vercel"))
        .or_else(|| models.first())
        .cloned()
        .context("No AI models available in provider registry")?;

    let provider = registry
        .find_provider_for_model(&selected_model.id)
        .cloned()
        .with_context(|| {
            format!(
                "No provider found for selected model '{}' (state=provider_missing)",
                selected_model.id
            )
        })?;

    Ok((selected_model, provider))
}

fn generated_scripts_dir() -> PathBuf {
    PathBuf::from(shellexpand::tilde(AI_SCRIPT_OUTPUT_DIR).as_ref())
}

fn split_fence_header_and_body(fence: &str) -> (&str, &str) {
    match fence.find('\n') {
        Some(newline_index) => (&fence[..newline_index], &fence[newline_index + 1..]),
        None => ("", fence),
    }
}

fn extract_fenced_code(response: &str, preferred_languages: Option<&[&str]>) -> Option<String> {
    let mut remaining = response;

    while let Some(start) = remaining.find("```") {
        let after_start = &remaining[start + 3..];
        let Some(end) = after_start.find("```") else {
            break;
        };

        let fence_contents = &after_start[..end];
        let (header, body) = split_fence_header_and_body(fence_contents);
        let language = header
            .trim()
            .split(|c: char| c.is_whitespace() || c == '{')
            .next()
            .unwrap_or("")
            .to_ascii_lowercase();
        let code = body.trim();

        if !code.is_empty() {
            match preferred_languages {
                Some(preferred) => {
                    if preferred.iter().any(|candidate| *candidate == language) {
                        return Some(code.to_string());
                    }
                }
                None => return Some(code.to_string()),
            }
        }

        remaining = &after_start[end + 3..];
    }

    None
}

fn extract_script_code(response: &str) -> String {
    const PREFERRED_LANGUAGES: [&str; 6] = ["typescript", "ts", "javascript", "js", "tsx", "jsx"];

    extract_fenced_code(response, Some(&PREFERRED_LANGUAGES))
        .or_else(|| extract_fenced_code(response, None))
        .unwrap_or_else(|| response.trim().to_string())
}

fn slugify_script_name(prompt: &str) -> String {
    let mut slug = String::new();
    let mut last_was_hyphen = false;

    for character in prompt.to_ascii_lowercase().chars() {
        if character.is_ascii_alphanumeric() {
            slug.push(character);
            last_was_hyphen = false;
        } else if matches!(character, ' ' | '_' | '-') {
            if !slug.is_empty() && !last_was_hyphen {
                slug.push('-');
                last_was_hyphen = true;
            }
        }
    }

    while slug.ends_with('-') {
        slug.pop();
    }

    if slug.len() > AI_SCRIPT_MAX_SLUG_LEN {
        slug.truncate(AI_SCRIPT_MAX_SLUG_LEN);
        while slug.ends_with('-') {
            slug.pop();
        }
    }

    if slug.is_empty() {
        AI_SCRIPT_DEFAULT_SLUG.to_string()
    } else {
        slug
    }
}

fn slug_to_title(slug: &str) -> String {
    slug.split('-')
        .filter(|segment| !segment.is_empty())
        .map(|segment| {
            let mut chars = segment.chars();
            match chars.next() {
                Some(first) => first.to_uppercase().collect::<String>() + chars.as_str(),
                None => String::new(),
            }
        })
        .collect::<Vec<_>>()
        .join(" ")
}

fn description_from_prompt(prompt: &str) -> String {
    let normalized = prompt.split_whitespace().collect::<Vec<_>>().join(" ");
    if normalized.is_empty() {
        return "AI-generated Script Kit script".to_string();
    }

    let mut shortened = normalized;
    if shortened.chars().count() > 110 {
        shortened = format!("{}...", shortened.chars().take(107).collect::<String>());
    }
    shortened
}

fn has_kit_import(script: &str) -> bool {
    script.contains("import \"@johnlindquist/kit\";")
        || script.contains("import '@johnlindquist/kit';")
        || script.contains("import \"@scriptkit/sdk\";")
        || script.contains("import '@scriptkit/sdk';")
}

fn enforce_script_kit_conventions(script: &str, prompt: &str, slug: &str) -> String {
    let mut prefix_lines: Vec<String> = Vec::new();
    let trimmed_script = script.trim();

    if !trimmed_script
        .lines()
        .any(|line| line.trim_start().starts_with("// Name:"))
    {
        prefix_lines.push(format!("// Name: {}", slug_to_title(slug)));
    }

    if !trimmed_script
        .lines()
        .any(|line| line.trim_start().starts_with("// Description:"))
    {
        prefix_lines.push(format!("// Description: {}", description_from_prompt(prompt)));
    }

    if !has_kit_import(trimmed_script) {
        prefix_lines.push("import \"@johnlindquist/kit\";".to_string());
    }

    let mut output = String::new();
    if !prefix_lines.is_empty() {
        output.push_str(&prefix_lines.join("\n"));
        output.push_str("\n\n");
    }

    output.push_str(trimmed_script);
    if !output.ends_with('\n') {
        output.push('\n');
    }
    output
}

fn write_generated_script(slug: &str, script_content: &str) -> Result<PathBuf> {
    write_generated_script_in_dir(&generated_scripts_dir(), slug, script_content)
}

fn write_generated_script_in_dir(output_dir: &Path, slug: &str, script_content: &str) -> Result<PathBuf> {
    fs::create_dir_all(output_dir)
        .with_context(|| format!("Failed to create output dir: {}", output_dir.display()))?;

    for suffix in 0usize.. {
        let candidate = if suffix == 0 {
            slug.to_string()
        } else {
            format!("{slug}-{suffix}")
        };
        let path = output_dir.join(format!("{}.ts", candidate));
        match OpenOptions::new().write(true).create_new(true).open(&path) {
            Ok(mut file) => {
                file.write_all(script_content.as_bytes())
                    .with_context(|| format!("Failed writing generated script to {}", path.display()))?;
                return Ok(path);
            }
            Err(error) if error.kind() == ErrorKind::AlreadyExists => continue,
            Err(error) => {
                return Err(error).with_context(|| {
                    format!(
                        "Failed creating generated script file {} (slug={})",
                        path.display(),
                        slug
                    )
                });
            }
        }
    }

    unreachable!("suffix loop should eventually create a unique script filename")
}

#[cfg(test)]
mod tests {
    use super::*;
    use tempfile::tempdir;

    #[test]
    fn test_slugify_script_name_handles_spaces_and_symbols() {
        assert_eq!(slugify_script_name("Build: API Client!"), "build-api-client");
        assert_eq!(slugify_script_name("  ___  "), "ai-script");
    }

    #[test]
    fn test_extract_script_code_prefers_typescript_fence_when_multiple_blocks_exist() {
        let response = r#"
Here's one idea:
```markdown
Not code
```
```typescript
await div("hello");
```
"#;
        assert_eq!(extract_script_code(response), "await div(\"hello\");");
    }

    #[test]
    fn test_extract_script_code_falls_back_to_first_fenced_block() {
        let response = r#"
```python
print("hello")
```
"#;
        assert_eq!(extract_script_code(response), "print(\"hello\")");
    }

    #[test]
    fn test_extract_script_code_returns_trimmed_response_when_no_fence_exists() {
        let response = "const answer = 42;";
        assert_eq!(extract_script_code(response), "const answer = 42;");
    }

    #[test]
    fn test_enforce_script_kit_conventions_adds_missing_metadata_and_import() {
        let script = "const name = await arg(\"Name?\");";
        let output = enforce_script_kit_conventions(script, "Ask for user name", "ask-user-name");

        assert!(output.contains("// Name: Ask User Name"));
        assert!(output.contains("// Description: Ask for user name"));
        assert!(output.contains("import \"@johnlindquist/kit\";"));
        assert!(output.contains("await arg(\"Name?\");"));
    }

    #[test]
    fn test_enforce_script_kit_conventions_keeps_existing_metadata_and_import() {
        let script = r#"// Name: Existing
// Description: Existing description
import "@johnlindquist/kit";

await div("ready");
"#;
        let output = enforce_script_kit_conventions(script, "ignored", "ignored");

        assert_eq!(
            output.matches("// Name:").count(),
            1,
            "should not duplicate existing Name metadata"
        );
        assert_eq!(
            output.matches("// Description:").count(),
            1,
            "should not duplicate existing Description metadata"
        );
        assert_eq!(
            output.matches("import \"@johnlindquist/kit\";").count(),
            1,
            "should not duplicate existing import"
        );
    }

    #[test]
    fn test_write_generated_script_in_dir_appends_numeric_suffix_for_collisions() {
        let temp_dir = tempdir().unwrap();
        let first = write_generated_script_in_dir(temp_dir.path(), "my-script", "a").unwrap();
        let second = write_generated_script_in_dir(temp_dir.path(), "my-script", "b").unwrap();

        assert_eq!(first.file_name().unwrap(), "my-script.ts");
        assert_eq!(second.file_name().unwrap(), "my-script-1.ts");
    }
}
apply_patch(auto_approved=true) exited 0 in 21ms:
Success. Updated the following files:
A src/ai/script_generation.rs
file update:
diff --git a/src/ai/mod.rs b/src/ai/mod.rs
index a420b1a5faf59506acdb7caf60681c153a3f9bb6..9a73e9491862633b325b2c52b51a3e20395ff85c
--- a/src/ai/mod.rs
+++ b/src/ai/mod.rs
@@ -37,6 +37,7 @@
 pub(crate) mod providers;
 pub(crate) mod sdk_handlers;
 pub(crate) mod session;
+pub(crate) mod script_generation;
 pub(crate) mod storage;
 pub(crate) mod window;
 
@@ -44,6 +45,7 @@
 pub use self::config::{DetectedKeys, ModelInfo, ProviderConfig};
 pub use self::model::{Chat, ChatId, ChatSource, Message, MessageRole};
 pub use self::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+pub use self::script_generation::{generate_script_from_prompt, GeneratedScriptOutput};
 pub use self::sdk_handlers::try_handle_ai_message;
 pub use self::storage::{
     clear_all_chats, create_chat, delete_chat, get_all_chats, get_chat, get_chat_messages,
diff --git a/src/ai/script_generation.rs b/src/ai/script_generation.rs
new file mode 100644
index 0000000000000000000000000000000000000000..7f2ec8e7576ed50cd10f7aea31a6522875ef667a
--- /dev/null
+++ b/src/ai/script_generation.rs
@@ -0,0 +1,417 @@
+use anyhow::{Context, Result};
+use std::fs::{self, OpenOptions};
+use std::io::{ErrorKind, Write};
+use std::path::{Path, PathBuf};
+use std::sync::Arc;
+
+use super::config::ModelInfo;
+use super::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+
+const AI_SCRIPT_OUTPUT_DIR: &str = "~/.kenv/scripts";
+const AI_SCRIPT_DEFAULT_SLUG: &str = "ai-script";
+const AI_SCRIPT_MAX_SLUG_LEN: usize = 64;
+
+const AI_SCRIPT_GENERATION_SYSTEM_PROMPT: &str = r#"You write production-ready Script Kit scripts.
+
+Return ONLY TypeScript source code for one Script Kit script. Do not include explanations.
+
+Required output conventions:
+1) Include metadata comments at the top:
+   // Name: <clear title>
+   // Description: <one-line summary>
+2) Include: import "@johnlindquist/kit";
+3) Use await arg() for user input when useful.
+4) Use await div() for display output when useful.
+5) Keep the script runnable as-is with sensible defaults and light error handling."#;
+
+#[derive(Debug, Clone)]
+pub struct GeneratedScriptOutput {
+    pub path: PathBuf,
+    pub slug: String,
+    pub model_id: String,
+    pub provider_id: String,
+}
+
+pub fn generate_script_from_prompt(
+    prompt: &str,
+    config: Option<&crate::config::Config>,
+) -> Result<GeneratedScriptOutput> {
+    let normalized_prompt = prompt.trim();
+    if normalized_prompt.is_empty() {
+        anyhow::bail!("AI script generation requires a non-empty prompt");
+    }
+
+    let registry = ProviderRegistry::from_environment_with_config(config);
+    if !registry.has_any_provider() {
+        anyhow::bail!(
+            "No AI providers configured. Configure an API key first (Vercel, OpenAI, Anthropic, etc.)."
+        );
+    }
+
+    let (selected_model, provider) = select_generation_model(&registry)?;
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=provider_ready model_id={} provider_id={} prompt_len={}",
+            selected_model.id,
+            selected_model.provider,
+            normalized_prompt.len()
+        ),
+    );
+
+    let messages = vec![
+        ProviderMessage::system(AI_SCRIPT_GENERATION_SYSTEM_PROMPT),
+        ProviderMessage::user(format!(
+            "Generate a Script Kit script for this user request:\n\n{}",
+            normalized_prompt
+        )),
+    ];
+
+    let raw_response = provider
+        .send_message(&messages, &selected_model.id)
+        .with_context(|| {
+            format!(
+                "AI script generation failed (attempted=send_message, model_id={}, provider_id={})",
+                selected_model.id, selected_model.provider
+            )
+        })?;
+
+    let extracted = extract_script_code(&raw_response);
+    if extracted.trim().is_empty() {
+        anyhow::bail!(
+            "AI returned an empty response for script generation (state=empty_response)"
+        );
+    }
+
+    let slug = slugify_script_name(normalized_prompt);
+    let finalized = enforce_script_kit_conventions(&extracted, normalized_prompt, &slug);
+    let path = write_generated_script(&slug, &finalized).with_context(|| {
+        format!(
+            "Failed writing AI-generated script (state=write_failed, slug={})",
+            slug
+        )
+    })?;
+
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=script_written path={} slug={}",
+            path.display(),
+            slug
+        ),
+    );
+
+    Ok(GeneratedScriptOutput {
+        path,
+        slug,
+        model_id: selected_model.id,
+        provider_id: selected_model.provider,
+    })
+}
+
+fn select_generation_model(registry: &ProviderRegistry) -> Result<(ModelInfo, Arc<dyn AiProvider>)> {
+    let models = registry.get_all_models();
+    let selected_model = models
+        .iter()
+        .find(|model| model.provider.eq_ignore_ascii_case("vercel"))
+        .or_else(|| models.first())
+        .cloned()
+        .context("No AI models available in provider registry")?;
+
+    let provider = registry
+        .find_provider_for_model(&selected_model.id)
+        .cloned()
+        .with_context(|| {
+            format!(
+                "No provider found for selected model '{}' (state=provider_missing)",
+                selected_model.id
+            )
+        })?;
+
+    Ok((selected_model, provider))
+}
+
+fn generated_scripts_dir() -> PathBuf {
+    PathBuf::from(shellexpand::tilde(AI_SCRIPT_OUTPUT_DIR).as_ref())
+}
+
+fn split_fence_header_and_body(fence: &str) -> (&str, &str) {
+    match fence.find('\n') {
+        Some(newline_index) => (&fence[..newline_index], &fence[newline_index + 1..]),
+        None => ("", fence),
+    }
+}
+
+fn extract_fenced_code(response: &str, preferred_languages: Option<&[&str]>) -> Option<String> {
+    let mut remaining = response;
+
+    while let Some(start) = remaining.find("```") {
+        let after_start = &remaining[start + 3..];
+        let Some(end) = after_start.find("```") else {
+            break;
+        };
+
+        let fence_contents = &after_start[..end];
+        let (header, body) = split_fence_header_and_body(fence_contents);
+        let language = header
+            .trim()
+            .split(|c: char| c.is_whitespace() || c == '{')
+            .next()
+            .unwrap_or("")
+            .to_ascii_lowercase();
+        let code = body.trim();
+
+        if !code.is_empty() {
+            match preferred_languages {
+                Some(preferred) => {
+                    if preferred.iter().any(|candidate| *candidate == language) {
+                        return Some(code.to_string());
+                    }
+                }
+                None => return Some(code.to_string()),
+            }
+        }
+
+        remaining = &after_start[end + 3..];
+    }
+
+    None
+}
+
+fn extract_script_code(response: &str) -> String {
+    const PREFERRED_LANGUAGES: [&str; 6] = ["typescript", "ts", "javascript", "js", "tsx", "jsx"];
+
+    extract_fenced_code(response, Some(&PREFERRED_LANGUAGES))
+        .or_else(|| extract_fenced_code(response, None))
+        .unwrap_or_else(|| response.trim().to_string())
+}
+
+fn slugify_script_name(prompt: &str) -> String {
+    let mut slug = String::new();
+    let mut last_was_hyphen = false;
+
+    for character in prompt.to_ascii_lowercase().chars() {
+        if character.is_ascii_alphanumeric() {
+            slug.push(character);
+            last_was_hyphen = false;
+        } else if matches!(character, ' ' | '_' | '-') {
+            if !slug.is_empty() && !last_was_hyphen {
+                slug.push('-');
+                last_was_hyphen = true;
+            }
+        }
+    }
+
+    while slug.ends_with('-') {
+        slug.pop();
+    }
+
+    if slug.len() > AI_SCRIPT_MAX_SLUG_LEN {
+        slug.truncate(AI_SCRIPT_MAX_SLUG_LEN);
+        while slug.ends_with('-') {
+            slug.pop();
+        }
+    }
+
+    if slug.is_empty() {
+        AI_SCRIPT_DEFAULT_SLUG.to_string()
+    } else {
+        slug
+    }
+}
+
+fn slug_to_title(slug: &str) -> String {
+    slug.split('-')
+        .filter(|segment| !segment.is_empty())
+        .map(|segment| {
+            let mut chars = segment.chars();
+            match chars.next() {
+                Some(first) => first.to_uppercase().collect::<String>() + chars.as_str(),
+                None => String::new(),
+            }
+        })
+        .collect::<Vec<_>>()
+        .join(" ")
+}
+
+fn description_from_prompt(prompt: &str) -> String {
+    let normalized = prompt.split_whitespace().collect::<Vec<_>>().join(" ");
+    if normalized.is_empty() {
+        return "AI-generated Script Kit script".to_string();
+    }
+
+    let mut shortened = normalized;
+    if shortened.chars().count() > 110 {
+        shortened = format!("{}...", shortened.chars().take(107).collect::<String>());
+    }
+    shortened
+}
+
+fn has_kit_import(script: &str) -> bool {
+    script.contains("import \"@johnlindquist/kit\";")
+        || script.contains("import '@johnlindquist/kit';")
+        || script.contains("import \"@scriptkit/sdk\";")
+        || script.contains("import '@scriptkit/sdk';")
+}
+
+fn enforce_script_kit_conventions(script: &str, prompt: &str, slug: &str) -> String {
+    let mut prefix_lines: Vec<String> = Vec::new();
+    let trimmed_script = script.trim();
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Name:"))
+    {
+        prefix_lines.push(format!("// Name: {}", slug_to_title(slug)));
+    }
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Description:"))
+    {
+        prefix_lines.push(format!("// Description: {}", description_from_prompt(prompt)));
+    }
+
+    if !has_kit_import(trimmed_script) {
+        prefix_lines.push("import \"@johnlindquist/kit\";".to_string());
+    }
+
+    let mut output = String::new();
+    if !prefix_lines.is_empty() {
+        output.push_str(&prefix_lines.join("\n"));
+        output.push_str("\n\n");
+    }
+
+    output.push_str(trimmed_script);
+    if !output.ends_with('\n') {
+        output.push('\n');
+    }
+    output
+}
+
+fn write_generated_script(slug: &str, script_content: &str) -> Result<PathBuf> {
+    write_generated_script_in_dir(&generated_scripts_dir(), slug, script_content)
+}
+
+fn write_generated_script_in_dir(output_dir: &Path, slug: &str, script_content: &str) -> Result<PathBuf> {
+    fs::create_dir_all(output_dir)
+        .with_context(|| format!("Failed to create output dir: {}", output_dir.display()))?;
+
+    for suffix in 0usize.. {
+        let candidate = if suffix == 0 {
+            slug.to_string()
+        } else {
+            format!("{slug}-{suffix}")
+        };
+        let path = output_dir.join(format!("{}.ts", candidate));
+        match OpenOptions::new().write(true).create_new(true).open(&path) {
+            Ok(mut file) => {
+                file.write_all(script_content.as_bytes())
+                    .with_context(|| format!("Failed writing generated script to {}", path.display()))?;
+                return Ok(path);
+            }
+            Err(error) if error.kind() == ErrorKind::AlreadyExists => continue,
+            Err(error) => {
+                return Err(error).with_context(|| {
+                    format!(
+                        "Failed creating generated script file {} (slug={})",
+                        path.display(),
+                        slug
+                    )
+                });
+            }
+        }
+    }
+
+    unreachable!("suffix loop should eventually create a unique script filename")
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+    use tempfile::tempdir;
+
+    #[test]
+    fn test_slugify_script_name_handles_spaces_and_symbols() {
+        assert_eq!(slugify_script_name("Build: API Client!"), "build-api-client");
+        assert_eq!(slugify_script_name("  ___  "), "ai-script");
+    }
+
+    #[test]
+    fn test_extract_script_code_prefers_typescript_fence_when_multiple_blocks_exist() {
+        let response = r#"
+Here's one idea:
+```markdown
+Not code
+```
+```typescript
+await div("hello");
+```
+"#;
+        assert_eq!(extract_script_code(response), "await div(\"hello\");");
+    }
+
+    #[test]
+    fn test_extract_script_code_falls_back_to_first_fenced_block() {
+        let response = r#"
+```python
+print("hello")
+```
+"#;
+        assert_eq!(extract_script_code(response), "print(\"hello\")");
+    }
+
+    #[test]
+    fn test_extract_script_code_returns_trimmed_response_when_no_fence_exists() {
+        let response = "const answer = 42;";
+        assert_eq!(extract_script_code(response), "const answer = 42;");
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_adds_missing_metadata_and_import() {
+        let script = "const name = await arg(\"Name?\");";
+        let output = enforce_script_kit_conventions(script, "Ask for user name", "ask-user-name");
+
+        assert!(output.contains("// Name: Ask User Name"));
+        assert!(output.contains("// Description: Ask for user name"));
+        assert!(output.contains("import \"@johnlindquist/kit\";"));
+        assert!(output.contains("await arg(\"Name?\");"));
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_keeps_existing_metadata_and_import() {
+        let script = r#"// Name: Existing
+// Description: Existing description
+import "@johnlindquist/kit";
+
+await div("ready");
+"#;
+        let output = enforce_script_kit_conventions(script, "ignored", "ignored");
+
+        assert_eq!(
+            output.matches("// Name:").count(),
+            1,
+            "should not duplicate existing Name metadata"
+        );
+        assert_eq!(
+            output.matches("// Description:").count(),
+            1,
+            "should not duplicate existing Description metadata"
+        );
+        assert_eq!(
+            output.matches("import \"@johnlindquist/kit\";").count(),
+            1,
+            "should not duplicate existing import"
+        );
+    }
+
+    #[test]
+    fn test_write_generated_script_in_dir_appends_numeric_suffix_for_collisions() {
+        let temp_dir = tempdir().unwrap();
+        let first = write_generated_script_in_dir(temp_dir.path(), "my-script", "a").unwrap();
+        let second = write_generated_script_in_dir(temp_dir.path(), "my-script", "b").unwrap();
+
+        assert_eq!(first.file_name().unwrap(), "my-script.ts");
+        assert_eq!(second.file_name().unwrap(), "my-script-1.ts");
+    }
+}

file update:
diff --git a/src/ai/mod.rs b/src/ai/mod.rs
index a420b1a5faf59506acdb7caf60681c153a3f9bb6..9a73e9491862633b325b2c52b51a3e20395ff85c
--- a/src/ai/mod.rs
+++ b/src/ai/mod.rs
@@ -37,6 +37,7 @@
 pub(crate) mod providers;
 pub(crate) mod sdk_handlers;
 pub(crate) mod session;
+pub(crate) mod script_generation;
 pub(crate) mod storage;
 pub(crate) mod window;
 
@@ -44,6 +45,7 @@
 pub use self::config::{DetectedKeys, ModelInfo, ProviderConfig};
 pub use self::model::{Chat, ChatId, ChatSource, Message, MessageRole};
 pub use self::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+pub use self::script_generation::{generate_script_from_prompt, GeneratedScriptOutput};
 pub use self::sdk_handlers::try_handle_ai_message;
 pub use self::storage::{
     clear_all_chats, create_chat, delete_chat, get_all_chats, get_chat, get_chat_messages,
diff --git a/src/ai/script_generation.rs b/src/ai/script_generation.rs
new file mode 100644
index 0000000000000000000000000000000000000000..7f2ec8e7576ed50cd10f7aea31a6522875ef667a
--- /dev/null
+++ b/src/ai/script_generation.rs
@@ -0,0 +1,417 @@
+use anyhow::{Context, Result};
+use std::fs::{self, OpenOptions};
+use std::io::{ErrorKind, Write};
+use std::path::{Path, PathBuf};
+use std::sync::Arc;
+
+use super::config::ModelInfo;
+use super::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+
+const AI_SCRIPT_OUTPUT_DIR: &str = "~/.kenv/scripts";
+const AI_SCRIPT_DEFAULT_SLUG: &str = "ai-script";
+const AI_SCRIPT_MAX_SLUG_LEN: usize = 64;
+
+const AI_SCRIPT_GENERATION_SYSTEM_PROMPT: &str = r#"You write production-ready Script Kit scripts.
+
+Return ONLY TypeScript source code for one Script Kit script. Do not include explanations.
+
+Required output conventions:
+1) Include metadata comments at the top:
+   // Name: <clear title>
+   // Description: <one-line summary>
+2) Include: import "@johnlindquist/kit";
+3) Use await arg() for user input when useful.
+4) Use await div() for display output when useful.
+5) Keep the script runnable as-is with sensible defaults and light error handling."#;
+
+#[derive(Debug, Clone)]
+pub struct GeneratedScriptOutput {
+    pub path: PathBuf,
+    pub slug: String,
+    pub model_id: String,
+    pub provider_id: String,
+}
+
+pub fn generate_script_from_prompt(
+    prompt: &str,
+    config: Option<&crate::config::Config>,
+) -> Result<GeneratedScriptOutput> {
+    let normalized_prompt = prompt.trim();
+    if normalized_prompt.is_empty() {
+        anyhow::bail!("AI script generation requires a non-empty prompt");
+    }
+
+    let registry = ProviderRegistry::from_environment_with_config(config);
+    if !registry.has_any_provider() {
+        anyhow::bail!(
+            "No AI providers configured. Configure an API key first (Vercel, OpenAI, Anthropic, etc.)."
+        );
+    }
+
+    let (selected_model, provider) = select_generation_model(&registry)?;
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=provider_ready model_id={} provider_id={} prompt_len={}",
+            selected_model.id,
+            selected_model.provider,
+            normalized_prompt.len()
+        ),
+    );
+
+    let messages = vec![
+        ProviderMessage::system(AI_SCRIPT_GENERATION_SYSTEM_PROMPT),
+        ProviderMessage::user(format!(
+            "Generate a Script Kit script for this user request:\n\n{}",
+            normalized_prompt
+        )),
+    ];
+
+    let raw_response = provider
+        .send_message(&messages, &selected_model.id)
+        .with_context(|| {
+            format!(
+                "AI script generation failed (attempted=send_message, model_id={}, provider_id={})",
+                selected_model.id, selected_model.provider
+            )
+        })?;
+
+    let extracted = extract_script_code(&raw_response);
+    if extracted.trim().is_empty() {
+        anyhow::bail!(
+            "AI returned an empty response for script generation (state=empty_response)"
+        );
+    }
+
+    let slug = slugify_script_name(normalized_prompt);
+    let finalized = enforce_script_kit_conventions(&extracted, normalized_prompt, &slug);
+    let path = write_generated_script(&slug, &finalized).with_context(|| {
+        format!(
+            "Failed writing AI-generated script (state=write_failed, slug={})",
+            slug
+        )
+    })?;
+
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=script_written path={} slug={}",
+            path.display(),
+            slug
+        ),
+    );
+
+    Ok(GeneratedScriptOutput {
+        path,
+        slug,
+        model_id: selected_model.id,
+        provider_id: selected_model.provider,
+    })
+}
+
+fn select_generation_model(registry: &ProviderRegistry) -> Result<(ModelInfo, Arc<dyn AiProvider>)> {
+    let models = registry.get_all_models();
+    let selected_model = models
+        .iter()
+        .find(|model| model.provider.eq_ignore_ascii_case("vercel"))
+        .or_else(|| models.first())
+        .cloned()
+        .context("No AI models available in provider registry")?;
+
+    let provider = registry
+        .find_provider_for_model(&selected_model.id)
+        .cloned()
+        .with_context(|| {
+            format!(
+                "No provider found for selected model '{}' (state=provider_missing)",
+                selected_model.id
+            )
+        })?;
+
+    Ok((selected_model, provider))
+}
+
+fn generated_scripts_dir() -> PathBuf {
+    PathBuf::from(shellexpand::tilde(AI_SCRIPT_OUTPUT_DIR).as_ref())
+}
+
+fn split_fence_header_and_body(fence: &str) -> (&str, &str) {
+    match fence.find('\n') {
+        Some(newline_index) => (&fence[..newline_index], &fence[newline_index + 1..]),
+        None => ("", fence),
+    }
+}
+
+fn extract_fenced_code(response: &str, preferred_languages: Option<&[&str]>) -> Option<String> {
+    let mut remaining = response;
+
+    while let Some(start) = remaining.find("```") {
+        let after_start = &remaining[start + 3..];
+        let Some(end) = after_start.find("```") else {
+            break;
+        };
+
+        let fence_contents = &after_start[..end];
+        let (header, body) = split_fence_header_and_body(fence_contents);
+        let language = header
+            .trim()
+            .split(|c: char| c.is_whitespace() || c == '{')
+            .next()
+            .unwrap_or("")
+            .to_ascii_lowercase();
+        let code = body.trim();
+
+        if !code.is_empty() {
+            match preferred_languages {
+                Some(preferred) => {
+                    if preferred.iter().any(|candidate| *candidate == language) {
+                        return Some(code.to_string());
+                    }
+                }
+                None => return Some(code.to_string()),
+            }
+        }
+
+        remaining = &after_start[end + 3..];
+    }
+
+    None
+}
+
+fn extract_script_code(response: &str) -> String {
+    const PREFERRED_LANGUAGES: [&str; 6] = ["typescript", "ts", "javascript", "js", "tsx", "jsx"];
+
+    extract_fenced_code(response, Some(&PREFERRED_LANGUAGES))
+        .or_else(|| extract_fenced_code(response, None))
+        .unwrap_or_else(|| response.trim().to_string())
+}
+
+fn slugify_script_name(prompt: &str) -> String {
+    let mut slug = String::new();
+    let mut last_was_hyphen = false;
+
+    for character in prompt.to_ascii_lowercase().chars() {
+        if character.is_ascii_alphanumeric() {
+            slug.push(character);
+            last_was_hyphen = false;
+        } else if matches!(character, ' ' | '_' | '-') {
+            if !slug.is_empty() && !last_was_hyphen {
+                slug.push('-');
+                last_was_hyphen = true;
+            }
+        }
+    }
+
+    while slug.ends_with('-') {
+        slug.pop();
+    }
+
+    if slug.len() > AI_SCRIPT_MAX_SLUG_LEN {
+        slug.truncate(AI_SCRIPT_MAX_SLUG_LEN);
+        while slug.ends_with('-') {
+            slug.pop();
+        }
+    }
+
+    if slug.is_empty() {
+        AI_SCRIPT_DEFAULT_SLUG.to_string()
+    } else {
+        slug
+    }
+}
+
+fn slug_to_title(slug: &str) -> String {
+    slug.split('-')
+        .filter(|segment| !segment.is_empty())
+        .map(|segment| {
+            let mut chars = segment.chars();
+            match chars.next() {
+                Some(first) => first.to_uppercase().collect::<String>() + chars.as_str(),
+                None => String::new(),
+            }
+        })
+        .collect::<Vec<_>>()
+        .join(" ")
+}
+
+fn description_from_prompt(prompt: &str) -> String {
+    let normalized = prompt.split_whitespace().collect::<Vec<_>>().join(" ");
+    if normalized.is_empty() {
+        return "AI-generated Script Kit script".to_string();
+    }
+
+    let mut shortened = normalized;
+    if shortened.chars().count() > 110 {
+        shortened = format!("{}...", shortened.chars().take(107).collect::<String>());
+    }
+    shortened
+}
+
+fn has_kit_import(script: &str) -> bool {
+    script.contains("import \"@johnlindquist/kit\";")
+        || script.contains("import '@johnlindquist/kit';")
+        || script.contains("import \"@scriptkit/sdk\";")
+        || script.contains("import '@scriptkit/sdk';")
+}
+
+fn enforce_script_kit_conventions(script: &str, prompt: &str, slug: &str) -> String {
+    let mut prefix_lines: Vec<String> = Vec::new();
+    let trimmed_script = script.trim();
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Name:"))
+    {
+        prefix_lines.push(format!("// Name: {}", slug_to_title(slug)));
+    }
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Description:"))
+    {
+        prefix_lines.push(format!("// Description: {}", description_from_prompt(prompt)));
+    }
+
+    if !has_kit_import(trimmed_script) {
+        prefix_lines.push("import \"@johnlindquist/kit\";".to_string());
+    }
+
+    let mut output = String::new();
+    if !prefix_lines.is_empty() {
+        output.push_str(&prefix_lines.join("\n"));
+        output.push_str("\n\n");
+    }
+
+    output.push_str(trimmed_script);
+    if !output.ends_with('\n') {
+        output.push('\n');
+    }
+    output
+}
+
+fn write_generated_script(slug: &str, script_content: &str) -> Result<PathBuf> {
+    write_generated_script_in_dir(&generated_scripts_dir(), slug, script_content)
+}
+
+fn write_generated_script_in_dir(output_dir: &Path, slug: &str, script_content: &str) -> Result<PathBuf> {
+    fs::create_dir_all(output_dir)
+        .with_context(|| format!("Failed to create output dir: {}", output_dir.display()))?;
+
+    for suffix in 0usize.. {
+        let candidate = if suffix == 0 {
+            slug.to_string()
+        } else {
+            format!("{slug}-{suffix}")
+        };
+        let path = output_dir.join(format!("{}.ts", candidate));
+        match OpenOptions::new().write(true).create_new(true).open(&path) {
+            Ok(mut file) => {
+                file.write_all(script_content.as_bytes())
+                    .with_context(|| format!("Failed writing generated script to {}", path.display()))?;
+                return Ok(path);
+            }
+            Err(error) if error.kind() == ErrorKind::AlreadyExists => continue,
+            Err(error) => {
+                return Err(error).with_context(|| {
+                    format!(
+                        "Failed creating generated script file {} (slug={})",
+                        path.display(),
+                        slug
+                    )
+                });
+            }
+        }
+    }
+
+    unreachable!("suffix loop should eventually create a unique script filename")
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+    use tempfile::tempdir;
+
+    #[test]
+    fn test_slugify_script_name_handles_spaces_and_symbols() {
+        assert_eq!(slugify_script_name("Build: API Client!"), "build-api-client");
+        assert_eq!(slugify_script_name("  ___  "), "ai-script");
+    }
+
+    #[test]
+    fn test_extract_script_code_prefers_typescript_fence_when_multiple_blocks_exist() {
+        let response = r#"
+Here's one idea:
+```markdown
+Not code
+```
+```typescript
+await div("hello");
+```
+"#;
+        assert_eq!(extract_script_code(response), "await div(\"hello\");");
+    }
+
+    #[test]
+    fn test_extract_script_code_falls_back_to_first_fenced_block() {
+        let response = r#"
+```python
+print("hello")
+```
+"#;
+        assert_eq!(extract_script_code(response), "print(\"hello\")");
+    }
+
+    #[test]
+    fn test_extract_script_code_returns_trimmed_response_when_no_fence_exists() {
+        let response = "const answer = 42;";
+        assert_eq!(extract_script_code(response), "const answer = 42;");
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_adds_missing_metadata_and_import() {
+        let script = "const name = await arg(\"Name?\");";
+        let output = enforce_script_kit_conventions(script, "Ask for user name", "ask-user-name");
+
+        assert!(output.contains("// Name: Ask User Name"));
+        assert!(output.contains("// Description: Ask for user name"));
+        assert!(output.contains("import \"@johnlindquist/kit\";"));
+        assert!(output.contains("await arg(\"Name?\");"));
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_keeps_existing_metadata_and_import() {
+        let script = r#"// Name: Existing
+// Description: Existing description
+import "@johnlindquist/kit";
+
+await div("ready");
+"#;
+        let output = enforce_script_kit_conventions(script, "ignored", "ignored");
+
+        assert_eq!(
+            output.matches("// Name:").count(),
+            1,
+            "should not duplicate existing Name metadata"
+        );
+        assert_eq!(
+            output.matches("// Description:").count(),
+            1,
+            "should not duplicate existing Description metadata"
+        );
+        assert_eq!(
+            output.matches("import \"@johnlindquist/kit\";").count(),
+            1,
+            "should not duplicate existing import"
+        );
+    }
+
+    #[test]
+    fn test_write_generated_script_in_dir_appends_numeric_suffix_for_collisions() {
+        let temp_dir = tempdir().unwrap();
+        let first = write_generated_script_in_dir(temp_dir.path(), "my-script", "a").unwrap();
+        let second = write_generated_script_in_dir(temp_dir.path(), "my-script", "b").unwrap();
+
+        assert_eq!(first.file_name().unwrap(), "my-script.ts");
+        assert_eq!(second.file_name().unwrap(), "my-script-1.ts");
+    }
+}


thinking
**Modifying builtins with enum variant**
file update
M /Users/johnlindquist/dev/script-kit-gpui/src/builtins/part_000.rs
@@ -98,2 +98,4 @@
     ClearConversation,
+    /// Generate a new Script Kit script from the main prompt text
+    GenerateScript,
     /// Send a screenshot of the entire screen to AI Chat
apply_patch(auto_approved=true) exited 0 in 23ms:
Success. Updated the following files:
M src/builtins/part_000.rs
file update:
diff --git a/src/ai/mod.rs b/src/ai/mod.rs
index a420b1a5faf59506acdb7caf60681c153a3f9bb6..9a73e9491862633b325b2c52b51a3e20395ff85c
--- a/src/ai/mod.rs
+++ b/src/ai/mod.rs
@@ -37,6 +37,7 @@
 pub(crate) mod providers;
 pub(crate) mod sdk_handlers;
 pub(crate) mod session;
+pub(crate) mod script_generation;
 pub(crate) mod storage;
 pub(crate) mod window;
 
@@ -44,6 +45,7 @@
 pub use self::config::{DetectedKeys, ModelInfo, ProviderConfig};
 pub use self::model::{Chat, ChatId, ChatSource, Message, MessageRole};
 pub use self::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+pub use self::script_generation::{generate_script_from_prompt, GeneratedScriptOutput};
 pub use self::sdk_handlers::try_handle_ai_message;
 pub use self::storage::{
     clear_all_chats, create_chat, delete_chat, get_all_chats, get_chat, get_chat_messages,
diff --git a/src/ai/script_generation.rs b/src/ai/script_generation.rs
new file mode 100644
index 0000000000000000000000000000000000000000..7f2ec8e7576ed50cd10f7aea31a6522875ef667a
--- /dev/null
+++ b/src/ai/script_generation.rs
@@ -0,0 +1,417 @@
+use anyhow::{Context, Result};
+use std::fs::{self, OpenOptions};
+use std::io::{ErrorKind, Write};
+use std::path::{Path, PathBuf};
+use std::sync::Arc;
+
+use super::config::ModelInfo;
+use super::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+
+const AI_SCRIPT_OUTPUT_DIR: &str = "~/.kenv/scripts";
+const AI_SCRIPT_DEFAULT_SLUG: &str = "ai-script";
+const AI_SCRIPT_MAX_SLUG_LEN: usize = 64;
+
+const AI_SCRIPT_GENERATION_SYSTEM_PROMPT: &str = r#"You write production-ready Script Kit scripts.
+
+Return ONLY TypeScript source code for one Script Kit script. Do not include explanations.
+
+Required output conventions:
+1) Include metadata comments at the top:
+   // Name: <clear title>
+   // Description: <one-line summary>
+2) Include: import "@johnlindquist/kit";
+3) Use await arg() for user input when useful.
+4) Use await div() for display output when useful.
+5) Keep the script runnable as-is with sensible defaults and light error handling."#;
+
+#[derive(Debug, Clone)]
+pub struct GeneratedScriptOutput {
+    pub path: PathBuf,
+    pub slug: String,
+    pub model_id: String,
+    pub provider_id: String,
+}
+
+pub fn generate_script_from_prompt(
+    prompt: &str,
+    config: Option<&crate::config::Config>,
+) -> Result<GeneratedScriptOutput> {
+    let normalized_prompt = prompt.trim();
+    if normalized_prompt.is_empty() {
+        anyhow::bail!("AI script generation requires a non-empty prompt");
+    }
+
+    let registry = ProviderRegistry::from_environment_with_config(config);
+    if !registry.has_any_provider() {
+        anyhow::bail!(
+            "No AI providers configured. Configure an API key first (Vercel, OpenAI, Anthropic, etc.)."
+        );
+    }
+
+    let (selected_model, provider) = select_generation_model(&registry)?;
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=provider_ready model_id={} provider_id={} prompt_len={}",
+            selected_model.id,
+            selected_model.provider,
+            normalized_prompt.len()
+        ),
+    );
+
+    let messages = vec![
+        ProviderMessage::system(AI_SCRIPT_GENERATION_SYSTEM_PROMPT),
+        ProviderMessage::user(format!(
+            "Generate a Script Kit script for this user request:\n\n{}",
+            normalized_prompt
+        )),
+    ];
+
+    let raw_response = provider
+        .send_message(&messages, &selected_model.id)
+        .with_context(|| {
+            format!(
+                "AI script generation failed (attempted=send_message, model_id={}, provider_id={})",
+                selected_model.id, selected_model.provider
+            )
+        })?;
+
+    let extracted = extract_script_code(&raw_response);
+    if extracted.trim().is_empty() {
+        anyhow::bail!(
+            "AI returned an empty response for script generation (state=empty_response)"
+        );
+    }
+
+    let slug = slugify_script_name(normalized_prompt);
+    let finalized = enforce_script_kit_conventions(&extracted, normalized_prompt, &slug);
+    let path = write_generated_script(&slug, &finalized).with_context(|| {
+        format!(
+            "Failed writing AI-generated script (state=write_failed, slug={})",
+            slug
+        )
+    })?;
+
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=script_written path={} slug={}",
+            path.display(),
+            slug
+        ),
+    );
+
+    Ok(GeneratedScriptOutput {
+        path,
+        slug,
+        model_id: selected_model.id,
+        provider_id: selected_model.provider,
+    })
+}
+
+fn select_generation_model(registry: &ProviderRegistry) -> Result<(ModelInfo, Arc<dyn AiProvider>)> {
+    let models = registry.get_all_models();
+    let selected_model = models
+        .iter()
+        .find(|model| model.provider.eq_ignore_ascii_case("vercel"))
+        .or_else(|| models.first())
+        .cloned()
+        .context("No AI models available in provider registry")?;
+
+    let provider = registry
+        .find_provider_for_model(&selected_model.id)
+        .cloned()
+        .with_context(|| {
+            format!(
+                "No provider found for selected model '{}' (state=provider_missing)",
+                selected_model.id
+            )
+        })?;
+
+    Ok((selected_model, provider))
+}
+
+fn generated_scripts_dir() -> PathBuf {
+    PathBuf::from(shellexpand::tilde(AI_SCRIPT_OUTPUT_DIR).as_ref())
+}
+
+fn split_fence_header_and_body(fence: &str) -> (&str, &str) {
+    match fence.find('\n') {
+        Some(newline_index) => (&fence[..newline_index], &fence[newline_index + 1..]),
+        None => ("", fence),
+    }
+}
+
+fn extract_fenced_code(response: &str, preferred_languages: Option<&[&str]>) -> Option<String> {
+    let mut remaining = response;
+
+    while let Some(start) = remaining.find("```") {
+        let after_start = &remaining[start + 3..];
+        let Some(end) = after_start.find("```") else {
+            break;
+        };
+
+        let fence_contents = &after_start[..end];
+        let (header, body) = split_fence_header_and_body(fence_contents);
+        let language = header
+            .trim()
+            .split(|c: char| c.is_whitespace() || c == '{')
+            .next()
+            .unwrap_or("")
+            .to_ascii_lowercase();
+        let code = body.trim();
+
+        if !code.is_empty() {
+            match preferred_languages {
+                Some(preferred) => {
+                    if preferred.iter().any(|candidate| *candidate == language) {
+                        return Some(code.to_string());
+                    }
+                }
+                None => return Some(code.to_string()),
+            }
+        }
+
+        remaining = &after_start[end + 3..];
+    }
+
+    None
+}
+
+fn extract_script_code(response: &str) -> String {
+    const PREFERRED_LANGUAGES: [&str; 6] = ["typescript", "ts", "javascript", "js", "tsx", "jsx"];
+
+    extract_fenced_code(response, Some(&PREFERRED_LANGUAGES))
+        .or_else(|| extract_fenced_code(response, None))
+        .unwrap_or_else(|| response.trim().to_string())
+}
+
+fn slugify_script_name(prompt: &str) -> String {
+    let mut slug = String::new();
+    let mut last_was_hyphen = false;
+
+    for character in prompt.to_ascii_lowercase().chars() {
+        if character.is_ascii_alphanumeric() {
+            slug.push(character);
+            last_was_hyphen = false;
+        } else if matches!(character, ' ' | '_' | '-') {
+            if !slug.is_empty() && !last_was_hyphen {
+                slug.push('-');
+                last_was_hyphen = true;
+            }
+        }
+    }
+
+    while slug.ends_with('-') {
+        slug.pop();
+    }
+
+    if slug.len() > AI_SCRIPT_MAX_SLUG_LEN {
+        slug.truncate(AI_SCRIPT_MAX_SLUG_LEN);
+        while slug.ends_with('-') {
+            slug.pop();
+        }
+    }
+
+    if slug.is_empty() {
+        AI_SCRIPT_DEFAULT_SLUG.to_string()
+    } else {
+        slug
+    }
+}
+
+fn slug_to_title(slug: &str) -> String {
+    slug.split('-')
+        .filter(|segment| !segment.is_empty())
+        .map(|segment| {
+            let mut chars = segment.chars();
+            match chars.next() {
+                Some(first) => first.to_uppercase().collect::<String>() + chars.as_str(),
+                None => String::new(),
+            }
+        })
+        .collect::<Vec<_>>()
+        .join(" ")
+}
+
+fn description_from_prompt(prompt: &str) -> String {
+    let normalized = prompt.split_whitespace().collect::<Vec<_>>().join(" ");
+    if normalized.is_empty() {
+        return "AI-generated Script Kit script".to_string();
+    }
+
+    let mut shortened = normalized;
+    if shortened.chars().count() > 110 {
+        shortened = format!("{}...", shortened.chars().take(107).collect::<String>());
+    }
+    shortened
+}
+
+fn has_kit_import(script: &str) -> bool {
+    script.contains("import \"@johnlindquist/kit\";")
+        || script.contains("import '@johnlindquist/kit';")
+        || script.contains("import \"@scriptkit/sdk\";")
+        || script.contains("import '@scriptkit/sdk';")
+}
+
+fn enforce_script_kit_conventions(script: &str, prompt: &str, slug: &str) -> String {
+    let mut prefix_lines: Vec<String> = Vec::new();
+    let trimmed_script = script.trim();
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Name:"))
+    {
+        prefix_lines.push(format!("// Name: {}", slug_to_title(slug)));
+    }
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Description:"))
+    {
+        prefix_lines.push(format!("// Description: {}", description_from_prompt(prompt)));
+    }
+
+    if !has_kit_import(trimmed_script) {
+        prefix_lines.push("import \"@johnlindquist/kit\";".to_string());
+    }
+
+    let mut output = String::new();
+    if !prefix_lines.is_empty() {
+        output.push_str(&prefix_lines.join("\n"));
+        output.push_str("\n\n");
+    }
+
+    output.push_str(trimmed_script);
+    if !output.ends_with('\n') {
+        output.push('\n');
+    }
+    output
+}
+
+fn write_generated_script(slug: &str, script_content: &str) -> Result<PathBuf> {
+    write_generated_script_in_dir(&generated_scripts_dir(), slug, script_content)
+}
+
+fn write_generated_script_in_dir(output_dir: &Path, slug: &str, script_content: &str) -> Result<PathBuf> {
+    fs::create_dir_all(output_dir)
+        .with_context(|| format!("Failed to create output dir: {}", output_dir.display()))?;
+
+    for suffix in 0usize.. {
+        let candidate = if suffix == 0 {
+            slug.to_string()
+        } else {
+            format!("{slug}-{suffix}")
+        };
+        let path = output_dir.join(format!("{}.ts", candidate));
+        match OpenOptions::new().write(true).create_new(true).open(&path) {
+            Ok(mut file) => {
+                file.write_all(script_content.as_bytes())
+                    .with_context(|| format!("Failed writing generated script to {}", path.display()))?;
+                return Ok(path);
+            }
+            Err(error) if error.kind() == ErrorKind::AlreadyExists => continue,
+            Err(error) => {
+                return Err(error).with_context(|| {
+                    format!(
+                        "Failed creating generated script file {} (slug={})",
+                        path.display(),
+                        slug
+                    )
+                });
+            }
+        }
+    }
+
+    unreachable!("suffix loop should eventually create a unique script filename")
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+    use tempfile::tempdir;
+
+    #[test]
+    fn test_slugify_script_name_handles_spaces_and_symbols() {
+        assert_eq!(slugify_script_name("Build: API Client!"), "build-api-client");
+        assert_eq!(slugify_script_name("  ___  "), "ai-script");
+    }
+
+    #[test]
+    fn test_extract_script_code_prefers_typescript_fence_when_multiple_blocks_exist() {
+        let response = r#"
+Here's one idea:
+```markdown
+Not code
+```
+```typescript
+await div("hello");
+```
+"#;
+        assert_eq!(extract_script_code(response), "await div(\"hello\");");
+    }
+
+    #[test]
+    fn test_extract_script_code_falls_back_to_first_fenced_block() {
+        let response = r#"
+```python
+print("hello")
+```
+"#;
+        assert_eq!(extract_script_code(response), "print(\"hello\")");
+    }
+
+    #[test]
+    fn test_extract_script_code_returns_trimmed_response_when_no_fence_exists() {
+        let response = "const answer = 42;";
+        assert_eq!(extract_script_code(response), "const answer = 42;");
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_adds_missing_metadata_and_import() {
+        let script = "const name = await arg(\"Name?\");";
+        let output = enforce_script_kit_conventions(script, "Ask for user name", "ask-user-name");
+
+        assert!(output.contains("// Name: Ask User Name"));
+        assert!(output.contains("// Description: Ask for user name"));
+        assert!(output.contains("import \"@johnlindquist/kit\";"));
+        assert!(output.contains("await arg(\"Name?\");"));
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_keeps_existing_metadata_and_import() {
+        let script = r#"// Name: Existing
+// Description: Existing description
+import "@johnlindquist/kit";
+
+await div("ready");
+"#;
+        let output = enforce_script_kit_conventions(script, "ignored", "ignored");
+
+        assert_eq!(
+            output.matches("// Name:").count(),
+            1,
+            "should not duplicate existing Name metadata"
+        );
+        assert_eq!(
+            output.matches("// Description:").count(),
+            1,
+            "should not duplicate existing Description metadata"
+        );
+        assert_eq!(
+            output.matches("import \"@johnlindquist/kit\";").count(),
+            1,
+            "should not duplicate existing import"
+        );
+    }
+
+    #[test]
+    fn test_write_generated_script_in_dir_appends_numeric_suffix_for_collisions() {
+        let temp_dir = tempdir().unwrap();
+        let first = write_generated_script_in_dir(temp_dir.path(), "my-script", "a").unwrap();
+        let second = write_generated_script_in_dir(temp_dir.path(), "my-script", "b").unwrap();
+
+        assert_eq!(first.file_name().unwrap(), "my-script.ts");
+        assert_eq!(second.file_name().unwrap(), "my-script-1.ts");
+    }
+}
diff --git a/src/builtins/part_000.rs b/src/builtins/part_000.rs
index d6b9c2a9b35b40c5005dbb9f65147f528702cb9e..5f6d27d28d72e51126d10d8beccf931c689ef2bb
--- a/src/builtins/part_000.rs
+++ b/src/builtins/part_000.rs
@@ -96,6 +96,8 @@
     OpenAi,
     NewConversation,
     ClearConversation,
+    /// Generate a new Script Kit script from the main prompt text
+    GenerateScript,
     /// Send a screenshot of the entire screen to AI Chat
     SendScreenToAi,
     /// Send a screenshot of the focused window to AI Chat

file update:
diff --git a/src/ai/mod.rs b/src/ai/mod.rs
index a420b1a5faf59506acdb7caf60681c153a3f9bb6..9a73e9491862633b325b2c52b51a3e20395ff85c
--- a/src/ai/mod.rs
+++ b/src/ai/mod.rs
@@ -37,6 +37,7 @@
 pub(crate) mod providers;
 pub(crate) mod sdk_handlers;
 pub(crate) mod session;
+pub(crate) mod script_generation;
 pub(crate) mod storage;
 pub(crate) mod window;
 
@@ -44,6 +45,7 @@
 pub use self::config::{DetectedKeys, ModelInfo, ProviderConfig};
 pub use self::model::{Chat, ChatId, ChatSource, Message, MessageRole};
 pub use self::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+pub use self::script_generation::{generate_script_from_prompt, GeneratedScriptOutput};
 pub use self::sdk_handlers::try_handle_ai_message;
 pub use self::storage::{
     clear_all_chats, create_chat, delete_chat, get_all_chats, get_chat, get_chat_messages,
diff --git a/src/ai/script_generation.rs b/src/ai/script_generation.rs
new file mode 100644
index 0000000000000000000000000000000000000000..7f2ec8e7576ed50cd10f7aea31a6522875ef667a
--- /dev/null
+++ b/src/ai/script_generation.rs
@@ -0,0 +1,417 @@
+use anyhow::{Context, Result};
+use std::fs::{self, OpenOptions};
+use std::io::{ErrorKind, Write};
+use std::path::{Path, PathBuf};
+use std::sync::Arc;
+
+use super::config::ModelInfo;
+use super::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+
+const AI_SCRIPT_OUTPUT_DIR: &str = "~/.kenv/scripts";
+const AI_SCRIPT_DEFAULT_SLUG: &str = "ai-script";
+const AI_SCRIPT_MAX_SLUG_LEN: usize = 64;
+
+const AI_SCRIPT_GENERATION_SYSTEM_PROMPT: &str = r#"You write production-ready Script Kit scripts.
+
+Return ONLY TypeScript source code for one Script Kit script. Do not include explanations.
+
+Required output conventions:
+1) Include metadata comments at the top:
+   // Name: <clear title>
+   // Description: <one-line summary>
+2) Include: import "@johnlindquist/kit";
+3) Use await arg() for user input when useful.
+4) Use await div() for display output when useful.
+5) Keep the script runnable as-is with sensible defaults and light error handling."#;
+
+#[derive(Debug, Clone)]
+pub struct GeneratedScriptOutput {
+    pub path: PathBuf,
+    pub slug: String,
+    pub model_id: String,
+    pub provider_id: String,
+}
+
+pub fn generate_script_from_prompt(
+    prompt: &str,
+    config: Option<&crate::config::Config>,
+) -> Result<GeneratedScriptOutput> {
+    let normalized_prompt = prompt.trim();
+    if normalized_prompt.is_empty() {
+        anyhow::bail!("AI script generation requires a non-empty prompt");
+    }
+
+    let registry = ProviderRegistry::from_environment_with_config(config);
+    if !registry.has_any_provider() {
+        anyhow::bail!(
+            "No AI providers configured. Configure an API key first (Vercel, OpenAI, Anthropic, etc.)."
+        );
+    }
+
+    let (selected_model, provider) = select_generation_model(&registry)?;
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=provider_ready model_id={} provider_id={} prompt_len={}",
+            selected_model.id,
+            selected_model.provider,
+            normalized_prompt.len()
+        ),
+    );
+
+    let messages = vec![
+        ProviderMessage::system(AI_SCRIPT_GENERATION_SYSTEM_PROMPT),
+        ProviderMessage::user(format!(
+            "Generate a Script Kit script for this user request:\n\n{}",
+            normalized_prompt
+        )),
+    ];
+
+    let raw_response = provider
+        .send_message(&messages, &selected_model.id)
+        .with_context(|| {
+            format!(
+                "AI script generation failed (attempted=send_message, model_id={}, provider_id={})",
+                selected_model.id, selected_model.provider
+            )
+        })?;
+
+    let extracted = extract_script_code(&raw_response);
+    if extracted.trim().is_empty() {
+        anyhow::bail!(
+            "AI returned an empty response for script generation (state=empty_response)"
+        );
+    }
+
+    let slug = slugify_script_name(normalized_prompt);
+    let finalized = enforce_script_kit_conventions(&extracted, normalized_prompt, &slug);
+    let path = write_generated_script(&slug, &finalized).with_context(|| {
+        format!(
+            "Failed writing AI-generated script (state=write_failed, slug={})",
+            slug
+        )
+    })?;
+
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=script_written path={} slug={}",
+            path.display(),
+            slug
+        ),
+    );
+
+    Ok(GeneratedScriptOutput {
+        path,
+        slug,
+        model_id: selected_model.id,
+        provider_id: selected_model.provider,
+    })
+}
+
+fn select_generation_model(registry: &ProviderRegistry) -> Result<(ModelInfo, Arc<dyn AiProvider>)> {
+    let models = registry.get_all_models();
+    let selected_model = models
+        .iter()
+        .find(|model| model.provider.eq_ignore_ascii_case("vercel"))
+        .or_else(|| models.first())
+        .cloned()
+        .context("No AI models available in provider registry")?;
+
+    let provider = registry
+        .find_provider_for_model(&selected_model.id)
+        .cloned()
+        .with_context(|| {
+            format!(
+                "No provider found for selected model '{}' (state=provider_missing)",
+                selected_model.id
+            )
+        })?;
+
+    Ok((selected_model, provider))
+}
+
+fn generated_scripts_dir() -> PathBuf {
+    PathBuf::from(shellexpand::tilde(AI_SCRIPT_OUTPUT_DIR).as_ref())
+}
+
+fn split_fence_header_and_body(fence: &str) -> (&str, &str) {
+    match fence.find('\n') {
+        Some(newline_index) => (&fence[..newline_index], &fence[newline_index + 1..]),
+        None => ("", fence),
+    }
+}
+
+fn extract_fenced_code(response: &str, preferred_languages: Option<&[&str]>) -> Option<String> {
+    let mut remaining = response;
+
+    while let Some(start) = remaining.find("```") {
+        let after_start = &remaining[start + 3..];
+        let Some(end) = after_start.find("```") else {
+            break;
+        };
+
+        let fence_contents = &after_start[..end];
+        let (header, body) = split_fence_header_and_body(fence_contents);
+        let language = header
+            .trim()
+            .split(|c: char| c.is_whitespace() || c == '{')
+            .next()
+            .unwrap_or("")
+            .to_ascii_lowercase();
+        let code = body.trim();
+
+        if !code.is_empty() {
+            match preferred_languages {
+                Some(preferred) => {
+                    if preferred.iter().any(|candidate| *candidate == language) {
+                        return Some(code.to_string());
+                    }
+                }
+                None => return Some(code.to_string()),
+            }
+        }
+
+        remaining = &after_start[end + 3..];
+    }
+
+    None
+}
+
+fn extract_script_code(response: &str) -> String {
+    const PREFERRED_LANGUAGES: [&str; 6] = ["typescript", "ts", "javascript", "js", "tsx", "jsx"];
+
+    extract_fenced_code(response, Some(&PREFERRED_LANGUAGES))
+        .or_else(|| extract_fenced_code(response, None))
+        .unwrap_or_else(|| response.trim().to_string())
+}
+
+fn slugify_script_name(prompt: &str) -> String {
+    let mut slug = String::new();
+    let mut last_was_hyphen = false;
+
+    for character in prompt.to_ascii_lowercase().chars() {
+        if character.is_ascii_alphanumeric() {
+            slug.push(character);
+            last_was_hyphen = false;
+        } else if matches!(character, ' ' | '_' | '-') {
+            if !slug.is_empty() && !last_was_hyphen {
+                slug.push('-');
+                last_was_hyphen = true;
+            }
+        }
+    }
+
+    while slug.ends_with('-') {
+        slug.pop();
+    }
+
+    if slug.len() > AI_SCRIPT_MAX_SLUG_LEN {
+        slug.truncate(AI_SCRIPT_MAX_SLUG_LEN);
+        while slug.ends_with('-') {
+            slug.pop();
+        }
+    }
+
+    if slug.is_empty() {
+        AI_SCRIPT_DEFAULT_SLUG.to_string()
+    } else {
+        slug
+    }
+}
+
+fn slug_to_title(slug: &str) -> String {
+    slug.split('-')
+        .filter(|segment| !segment.is_empty())
+        .map(|segment| {
+            let mut chars = segment.chars();
+            match chars.next() {
+                Some(first) => first.to_uppercase().collect::<String>() + chars.as_str(),
+                None => String::new(),
+            }
+        })
+        .collect::<Vec<_>>()
+        .join(" ")
+}
+
+fn description_from_prompt(prompt: &str) -> String {
+    let normalized = prompt.split_whitespace().collect::<Vec<_>>().join(" ");
+    if normalized.is_empty() {
+        return "AI-generated Script Kit script".to_string();
+    }
+
+    let mut shortened = normalized;
+    if shortened.chars().count() > 110 {
+        shortened = format!("{}...", shortened.chars().take(107).collect::<String>());
+    }
+    shortened
+}
+
+fn has_kit_import(script: &str) -> bool {
+    script.contains("import \"@johnlindquist/kit\";")
+        || script.contains("import '@johnlindquist/kit';")
+        || script.contains("import \"@scriptkit/sdk\";")
+        || script.contains("import '@scriptkit/sdk';")
+}
+
+fn enforce_script_kit_conventions(script: &str, prompt: &str, slug: &str) -> String {
+    let mut prefix_lines: Vec<String> = Vec::new();
+    let trimmed_script = script.trim();
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Name:"))
+    {
+        prefix_lines.push(format!("// Name: {}", slug_to_title(slug)));
+    }
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Description:"))
+    {
+        prefix_lines.push(format!("// Description: {}", description_from_prompt(prompt)));
+    }
+
+    if !has_kit_import(trimmed_script) {
+        prefix_lines.push("import \"@johnlindquist/kit\";".to_string());
+    }
+
+    let mut output = String::new();
+    if !prefix_lines.is_empty() {
+        output.push_str(&prefix_lines.join("\n"));
+        output.push_str("\n\n");
+    }
+
+    output.push_str(trimmed_script);
+    if !output.ends_with('\n') {
+        output.push('\n');
+    }
+    output
+}
+
+fn write_generated_script(slug: &str, script_content: &str) -> Result<PathBuf> {
+    write_generated_script_in_dir(&generated_scripts_dir(), slug, script_content)
+}
+
+fn write_generated_script_in_dir(output_dir: &Path, slug: &str, script_content: &str) -> Result<PathBuf> {
+    fs::create_dir_all(output_dir)
+        .with_context(|| format!("Failed to create output dir: {}", output_dir.display()))?;
+
+    for suffix in 0usize.. {
+        let candidate = if suffix == 0 {
+            slug.to_string()
+        } else {
+            format!("{slug}-{suffix}")
+        };
+        let path = output_dir.join(format!("{}.ts", candidate));
+        match OpenOptions::new().write(true).create_new(true).open(&path) {
+            Ok(mut file) => {
+                file.write_all(script_content.as_bytes())
+                    .with_context(|| format!("Failed writing generated script to {}", path.display()))?;
+                return Ok(path);
+            }
+            Err(error) if error.kind() == ErrorKind::AlreadyExists => continue,
+            Err(error) => {
+                return Err(error).with_context(|| {
+                    format!(
+                        "Failed creating generated script file {} (slug={})",
+                        path.display(),
+                        slug
+                    )
+                });
+            }
+        }
+    }
+
+    unreachable!("suffix loop should eventually create a unique script filename")
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+    use tempfile::tempdir;
+
+    #[test]
+    fn test_slugify_script_name_handles_spaces_and_symbols() {
+        assert_eq!(slugify_script_name("Build: API Client!"), "build-api-client");
+        assert_eq!(slugify_script_name("  ___  "), "ai-script");
+    }
+
+    #[test]
+    fn test_extract_script_code_prefers_typescript_fence_when_multiple_blocks_exist() {
+        let response = r#"
+Here's one idea:
+```markdown
+Not code
+```
+```typescript
+await div("hello");
+```
+"#;
+        assert_eq!(extract_script_code(response), "await div(\"hello\");");
+    }
+
+    #[test]
+    fn test_extract_script_code_falls_back_to_first_fenced_block() {
+        let response = r#"
+```python
+print("hello")
+```
+"#;
+        assert_eq!(extract_script_code(response), "print(\"hello\")");
+    }
+
+    #[test]
+    fn test_extract_script_code_returns_trimmed_response_when_no_fence_exists() {
+        let response = "const answer = 42;";
+        assert_eq!(extract_script_code(response), "const answer = 42;");
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_adds_missing_metadata_and_import() {
+        let script = "const name = await arg(\"Name?\");";
+        let output = enforce_script_kit_conventions(script, "Ask for user name", "ask-user-name");
+
+        assert!(output.contains("// Name: Ask User Name"));
+        assert!(output.contains("// Description: Ask for user name"));
+        assert!(output.contains("import \"@johnlindquist/kit\";"));
+        assert!(output.contains("await arg(\"Name?\");"));
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_keeps_existing_metadata_and_import() {
+        let script = r#"// Name: Existing
+// Description: Existing description
+import "@johnlindquist/kit";
+
+await div("ready");
+"#;
+        let output = enforce_script_kit_conventions(script, "ignored", "ignored");
+
+        assert_eq!(
+            output.matches("// Name:").count(),
+            1,
+            "should not duplicate existing Name metadata"
+        );
+        assert_eq!(
+            output.matches("// Description:").count(),
+            1,
+            "should not duplicate existing Description metadata"
+        );
+        assert_eq!(
+            output.matches("import \"@johnlindquist/kit\";").count(),
+            1,
+            "should not duplicate existing import"
+        );
+    }
+
+    #[test]
+    fn test_write_generated_script_in_dir_appends_numeric_suffix_for_collisions() {
+        let temp_dir = tempdir().unwrap();
+        let first = write_generated_script_in_dir(temp_dir.path(), "my-script", "a").unwrap();
+        let second = write_generated_script_in_dir(temp_dir.path(), "my-script", "b").unwrap();
+
+        assert_eq!(first.file_name().unwrap(), "my-script.ts");
+        assert_eq!(second.file_name().unwrap(), "my-script-1.ts");
+    }
+}
diff --git a/src/builtins/part_000.rs b/src/builtins/part_000.rs
index d6b9c2a9b35b40c5005dbb9f65147f528702cb9e..5f6d27d28d72e51126d10d8beccf931c689ef2bb
--- a/src/builtins/part_000.rs
+++ b/src/builtins/part_000.rs
@@ -96,6 +96,8 @@
     OpenAi,
     NewConversation,
     ClearConversation,
+    /// Generate a new Script Kit script from the main prompt text
+    GenerateScript,
     /// Send a screenshot of the entire screen to AI Chat
     SendScreenToAi,
     /// Send a screenshot of the focused window to AI Chat


thinking
**Adding entry to AI commands**
codex
Iâ€™ve added the new AI command enum variant. Next Iâ€™m wiring discoverability by adding a built-in entry, then Iâ€™ll connect execution logic and background generation.
file update
M /Users/johnlindquist/dev/script-kit-gpui/src/builtins/part_001_entries/entries_002.rs
@@ -63,2 +63,13 @@
     entries.push(BuiltInEntry::new_with_icon(
+        "builtin-generate-script-with-ai",
+        "Generate Script with AI",
+        "Generate a Script Kit script from your current prompt text",
+        vec![
+            "generate", "script", "ai", "create", "code", "typescript", "shift", "tab",
+        ],
+        BuiltInFeature::AiCommand(AiCommandType::GenerateScript),
+        "ðŸ§ ",
+    ));
+
+    entries.push(BuiltInEntry::new_with_icon(
         "builtin-send-screen-to-ai",
apply_patch(auto_approved=true) exited 0 in 26ms:
Success. Updated the following files:
M src/builtins/part_001_entries/entries_002.rs
file update:
diff --git a/src/ai/mod.rs b/src/ai/mod.rs
index a420b1a5faf59506acdb7caf60681c153a3f9bb6..9a73e9491862633b325b2c52b51a3e20395ff85c
--- a/src/ai/mod.rs
+++ b/src/ai/mod.rs
@@ -37,6 +37,7 @@
 pub(crate) mod providers;
 pub(crate) mod sdk_handlers;
 pub(crate) mod session;
+pub(crate) mod script_generation;
 pub(crate) mod storage;
 pub(crate) mod window;
 
@@ -44,6 +45,7 @@
 pub use self::config::{DetectedKeys, ModelInfo, ProviderConfig};
 pub use self::model::{Chat, ChatId, ChatSource, Message, MessageRole};
 pub use self::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+pub use self::script_generation::{generate_script_from_prompt, GeneratedScriptOutput};
 pub use self::sdk_handlers::try_handle_ai_message;
 pub use self::storage::{
     clear_all_chats, create_chat, delete_chat, get_all_chats, get_chat, get_chat_messages,
diff --git a/src/ai/script_generation.rs b/src/ai/script_generation.rs
new file mode 100644
index 0000000000000000000000000000000000000000..7f2ec8e7576ed50cd10f7aea31a6522875ef667a
--- /dev/null
+++ b/src/ai/script_generation.rs
@@ -0,0 +1,417 @@
+use anyhow::{Context, Result};
+use std::fs::{self, OpenOptions};
+use std::io::{ErrorKind, Write};
+use std::path::{Path, PathBuf};
+use std::sync::Arc;
+
+use super::config::ModelInfo;
+use super::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+
+const AI_SCRIPT_OUTPUT_DIR: &str = "~/.kenv/scripts";
+const AI_SCRIPT_DEFAULT_SLUG: &str = "ai-script";
+const AI_SCRIPT_MAX_SLUG_LEN: usize = 64;
+
+const AI_SCRIPT_GENERATION_SYSTEM_PROMPT: &str = r#"You write production-ready Script Kit scripts.
+
+Return ONLY TypeScript source code for one Script Kit script. Do not include explanations.
+
+Required output conventions:
+1) Include metadata comments at the top:
+   // Name: <clear title>
+   // Description: <one-line summary>
+2) Include: import "@johnlindquist/kit";
+3) Use await arg() for user input when useful.
+4) Use await div() for display output when useful.
+5) Keep the script runnable as-is with sensible defaults and light error handling."#;
+
+#[derive(Debug, Clone)]
+pub struct GeneratedScriptOutput {
+    pub path: PathBuf,
+    pub slug: String,
+    pub model_id: String,
+    pub provider_id: String,
+}
+
+pub fn generate_script_from_prompt(
+    prompt: &str,
+    config: Option<&crate::config::Config>,
+) -> Result<GeneratedScriptOutput> {
+    let normalized_prompt = prompt.trim();
+    if normalized_prompt.is_empty() {
+        anyhow::bail!("AI script generation requires a non-empty prompt");
+    }
+
+    let registry = ProviderRegistry::from_environment_with_config(config);
+    if !registry.has_any_provider() {
+        anyhow::bail!(
+            "No AI providers configured. Configure an API key first (Vercel, OpenAI, Anthropic, etc.)."
+        );
+    }
+
+    let (selected_model, provider) = select_generation_model(&registry)?;
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=provider_ready model_id={} provider_id={} prompt_len={}",
+            selected_model.id,
+            selected_model.provider,
+            normalized_prompt.len()
+        ),
+    );
+
+    let messages = vec![
+        ProviderMessage::system(AI_SCRIPT_GENERATION_SYSTEM_PROMPT),
+        ProviderMessage::user(format!(
+            "Generate a Script Kit script for this user request:\n\n{}",
+            normalized_prompt
+        )),
+    ];
+
+    let raw_response = provider
+        .send_message(&messages, &selected_model.id)
+        .with_context(|| {
+            format!(
+                "AI script generation failed (attempted=send_message, model_id={}, provider_id={})",
+                selected_model.id, selected_model.provider
+            )
+        })?;
+
+    let extracted = extract_script_code(&raw_response);
+    if extracted.trim().is_empty() {
+        anyhow::bail!(
+            "AI returned an empty response for script generation (state=empty_response)"
+        );
+    }
+
+    let slug = slugify_script_name(normalized_prompt);
+    let finalized = enforce_script_kit_conventions(&extracted, normalized_prompt, &slug);
+    let path = write_generated_script(&slug, &finalized).with_context(|| {
+        format!(
+            "Failed writing AI-generated script (state=write_failed, slug={})",
+            slug
+        )
+    })?;
+
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=script_written path={} slug={}",
+            path.display(),
+            slug
+        ),
+    );
+
+    Ok(GeneratedScriptOutput {
+        path,
+        slug,
+        model_id: selected_model.id,
+        provider_id: selected_model.provider,
+    })
+}
+
+fn select_generation_model(registry: &ProviderRegistry) -> Result<(ModelInfo, Arc<dyn AiProvider>)> {
+    let models = registry.get_all_models();
+    let selected_model = models
+        .iter()
+        .find(|model| model.provider.eq_ignore_ascii_case("vercel"))
+        .or_else(|| models.first())
+        .cloned()
+        .context("No AI models available in provider registry")?;
+
+    let provider = registry
+        .find_provider_for_model(&selected_model.id)
+        .cloned()
+        .with_context(|| {
+            format!(
+                "No provider found for selected model '{}' (state=provider_missing)",
+                selected_model.id
+            )
+        })?;
+
+    Ok((selected_model, provider))
+}
+
+fn generated_scripts_dir() -> PathBuf {
+    PathBuf::from(shellexpand::tilde(AI_SCRIPT_OUTPUT_DIR).as_ref())
+}
+
+fn split_fence_header_and_body(fence: &str) -> (&str, &str) {
+    match fence.find('\n') {
+        Some(newline_index) => (&fence[..newline_index], &fence[newline_index + 1..]),
+        None => ("", fence),
+    }
+}
+
+fn extract_fenced_code(response: &str, preferred_languages: Option<&[&str]>) -> Option<String> {
+    let mut remaining = response;
+
+    while let Some(start) = remaining.find("```") {
+        let after_start = &remaining[start + 3..];
+        let Some(end) = after_start.find("```") else {
+            break;
+        };
+
+        let fence_contents = &after_start[..end];
+        let (header, body) = split_fence_header_and_body(fence_contents);
+        let language = header
+            .trim()
+            .split(|c: char| c.is_whitespace() || c == '{')
+            .next()
+            .unwrap_or("")
+            .to_ascii_lowercase();
+        let code = body.trim();
+
+        if !code.is_empty() {
+            match preferred_languages {
+                Some(preferred) => {
+                    if preferred.iter().any(|candidate| *candidate == language) {
+                        return Some(code.to_string());
+                    }
+                }
+                None => return Some(code.to_string()),
+            }
+        }
+
+        remaining = &after_start[end + 3..];
+    }
+
+    None
+}
+
+fn extract_script_code(response: &str) -> String {
+    const PREFERRED_LANGUAGES: [&str; 6] = ["typescript", "ts", "javascript", "js", "tsx", "jsx"];
+
+    extract_fenced_code(response, Some(&PREFERRED_LANGUAGES))
+        .or_else(|| extract_fenced_code(response, None))
+        .unwrap_or_else(|| response.trim().to_string())
+}
+
+fn slugify_script_name(prompt: &str) -> String {
+    let mut slug = String::new();
+    let mut last_was_hyphen = false;
+
+    for character in prompt.to_ascii_lowercase().chars() {
+        if character.is_ascii_alphanumeric() {
+            slug.push(character);
+            last_was_hyphen = false;
+        } else if matches!(character, ' ' | '_' | '-') {
+            if !slug.is_empty() && !last_was_hyphen {
+                slug.push('-');
+                last_was_hyphen = true;
+            }
+        }
+    }
+
+    while slug.ends_with('-') {
+        slug.pop();
+    }
+
+    if slug.len() > AI_SCRIPT_MAX_SLUG_LEN {
+        slug.truncate(AI_SCRIPT_MAX_SLUG_LEN);
+        while slug.ends_with('-') {
+            slug.pop();
+        }
+    }
+
+    if slug.is_empty() {
+        AI_SCRIPT_DEFAULT_SLUG.to_string()
+    } else {
+        slug
+    }
+}
+
+fn slug_to_title(slug: &str) -> String {
+    slug.split('-')
+        .filter(|segment| !segment.is_empty())
+        .map(|segment| {
+            let mut chars = segment.chars();
+            match chars.next() {
+                Some(first) => first.to_uppercase().collect::<String>() + chars.as_str(),
+                None => String::new(),
+            }
+        })
+        .collect::<Vec<_>>()
+        .join(" ")
+}
+
+fn description_from_prompt(prompt: &str) -> String {
+    let normalized = prompt.split_whitespace().collect::<Vec<_>>().join(" ");
+    if normalized.is_empty() {
+        return "AI-generated Script Kit script".to_string();
+    }
+
+    let mut shortened = normalized;
+    if shortened.chars().count() > 110 {
+        shortened = format!("{}...", shortened.chars().take(107).collect::<String>());
+    }
+    shortened
+}
+
+fn has_kit_import(script: &str) -> bool {
+    script.contains("import \"@johnlindquist/kit\";")
+        || script.contains("import '@johnlindquist/kit';")
+        || script.contains("import \"@scriptkit/sdk\";")
+        || script.contains("import '@scriptkit/sdk';")
+}
+
+fn enforce_script_kit_conventions(script: &str, prompt: &str, slug: &str) -> String {
+    let mut prefix_lines: Vec<String> = Vec::new();
+    let trimmed_script = script.trim();
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Name:"))
+    {
+        prefix_lines.push(format!("// Name: {}", slug_to_title(slug)));
+    }
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Description:"))
+    {
+        prefix_lines.push(format!("// Description: {}", description_from_prompt(prompt)));
+    }
+
+    if !has_kit_import(trimmed_script) {
+        prefix_lines.push("import \"@johnlindquist/kit\";".to_string());
+    }
+
+    let mut output = String::new();
+    if !prefix_lines.is_empty() {
+        output.push_str(&prefix_lines.join("\n"));
+        output.push_str("\n\n");
+    }
+
+    output.push_str(trimmed_script);
+    if !output.ends_with('\n') {
+        output.push('\n');
+    }
+    output
+}
+
+fn write_generated_script(slug: &str, script_content: &str) -> Result<PathBuf> {
+    write_generated_script_in_dir(&generated_scripts_dir(), slug, script_content)
+}
+
+fn write_generated_script_in_dir(output_dir: &Path, slug: &str, script_content: &str) -> Result<PathBuf> {
+    fs::create_dir_all(output_dir)
+        .with_context(|| format!("Failed to create output dir: {}", output_dir.display()))?;
+
+    for suffix in 0usize.. {
+        let candidate = if suffix == 0 {
+            slug.to_string()
+        } else {
+            format!("{slug}-{suffix}")
+        };
+        let path = output_dir.join(format!("{}.ts", candidate));
+        match OpenOptions::new().write(true).create_new(true).open(&path) {
+            Ok(mut file) => {
+                file.write_all(script_content.as_bytes())
+                    .with_context(|| format!("Failed writing generated script to {}", path.display()))?;
+                return Ok(path);
+            }
+            Err(error) if error.kind() == ErrorKind::AlreadyExists => continue,
+            Err(error) => {
+                return Err(error).with_context(|| {
+                    format!(
+                        "Failed creating generated script file {} (slug={})",
+                        path.display(),
+                        slug
+                    )
+                });
+            }
+        }
+    }
+
+    unreachable!("suffix loop should eventually create a unique script filename")
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+    use tempfile::tempdir;
+
+    #[test]
+    fn test_slugify_script_name_handles_spaces_and_symbols() {
+        assert_eq!(slugify_script_name("Build: API Client!"), "build-api-client");
+        assert_eq!(slugify_script_name("  ___  "), "ai-script");
+    }
+
+    #[test]
+    fn test_extract_script_code_prefers_typescript_fence_when_multiple_blocks_exist() {
+        let response = r#"
+Here's one idea:
+```markdown
+Not code
+```
+```typescript
+await div("hello");
+```
+"#;
+        assert_eq!(extract_script_code(response), "await div(\"hello\");");
+    }
+
+    #[test]
+    fn test_extract_script_code_falls_back_to_first_fenced_block() {
+        let response = r#"
+```python
+print("hello")
+```
+"#;
+        assert_eq!(extract_script_code(response), "print(\"hello\")");
+    }
+
+    #[test]
+    fn test_extract_script_code_returns_trimmed_response_when_no_fence_exists() {
+        let response = "const answer = 42;";
+        assert_eq!(extract_script_code(response), "const answer = 42;");
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_adds_missing_metadata_and_import() {
+        let script = "const name = await arg(\"Name?\");";
+        let output = enforce_script_kit_conventions(script, "Ask for user name", "ask-user-name");
+
+        assert!(output.contains("// Name: Ask User Name"));
+        assert!(output.contains("// Description: Ask for user name"));
+        assert!(output.contains("import \"@johnlindquist/kit\";"));
+        assert!(output.contains("await arg(\"Name?\");"));
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_keeps_existing_metadata_and_import() {
+        let script = r#"// Name: Existing
+// Description: Existing description
+import "@johnlindquist/kit";
+
+await div("ready");
+"#;
+        let output = enforce_script_kit_conventions(script, "ignored", "ignored");
+
+        assert_eq!(
+            output.matches("// Name:").count(),
+            1,
+            "should not duplicate existing Name metadata"
+        );
+        assert_eq!(
+            output.matches("// Description:").count(),
+            1,
+            "should not duplicate existing Description metadata"
+        );
+        assert_eq!(
+            output.matches("import \"@johnlindquist/kit\";").count(),
+            1,
+            "should not duplicate existing import"
+        );
+    }
+
+    #[test]
+    fn test_write_generated_script_in_dir_appends_numeric_suffix_for_collisions() {
+        let temp_dir = tempdir().unwrap();
+        let first = write_generated_script_in_dir(temp_dir.path(), "my-script", "a").unwrap();
+        let second = write_generated_script_in_dir(temp_dir.path(), "my-script", "b").unwrap();
+
+        assert_eq!(first.file_name().unwrap(), "my-script.ts");
+        assert_eq!(second.file_name().unwrap(), "my-script-1.ts");
+    }
+}
diff --git a/src/builtins/part_000.rs b/src/builtins/part_000.rs
index d6b9c2a9b35b40c5005dbb9f65147f528702cb9e..5f6d27d28d72e51126d10d8beccf931c689ef2bb
--- a/src/builtins/part_000.rs
+++ b/src/builtins/part_000.rs
@@ -96,6 +96,8 @@
     OpenAi,
     NewConversation,
     ClearConversation,
+    /// Generate a new Script Kit script from the main prompt text
+    GenerateScript,
     /// Send a screenshot of the entire screen to AI Chat
     SendScreenToAi,
     /// Send a screenshot of the focused window to AI Chat
diff --git a/src/builtins/part_001_entries/entries_002.rs b/src/builtins/part_001_entries/entries_002.rs
index 6d1c9334f0ccaf0aab48582aaf42dcb129e1cb6e..72b318c66aeaf124359f4ecd276dae0350287328
--- a/src/builtins/part_001_entries/entries_002.rs
+++ b/src/builtins/part_001_entries/entries_002.rs
@@ -61,6 +61,17 @@
     ));
 
     entries.push(BuiltInEntry::new_with_icon(
+        "builtin-generate-script-with-ai",
+        "Generate Script with AI",
+        "Generate a Script Kit script from your current prompt text",
+        vec![
+            "generate", "script", "ai", "create", "code", "typescript", "shift", "tab",
+        ],
+        BuiltInFeature::AiCommand(AiCommandType::GenerateScript),
+        "ðŸ§ ",
+    ));
+
+    entries.push(BuiltInEntry::new_with_icon(
         "builtin-send-screen-to-ai",
         "Send Screen to AI Chat",
         "Capture the full screen and send it to AI Chat",

file update:
diff --git a/src/ai/mod.rs b/src/ai/mod.rs
index a420b1a5faf59506acdb7caf60681c153a3f9bb6..9a73e9491862633b325b2c52b51a3e20395ff85c
--- a/src/ai/mod.rs
+++ b/src/ai/mod.rs
@@ -37,6 +37,7 @@
 pub(crate) mod providers;
 pub(crate) mod sdk_handlers;
 pub(crate) mod session;
+pub(crate) mod script_generation;
 pub(crate) mod storage;
 pub(crate) mod window;
 
@@ -44,6 +45,7 @@
 pub use self::config::{DetectedKeys, ModelInfo, ProviderConfig};
 pub use self::model::{Chat, ChatId, ChatSource, Message, MessageRole};
 pub use self::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+pub use self::script_generation::{generate_script_from_prompt, GeneratedScriptOutput};
 pub use self::sdk_handlers::try_handle_ai_message;
 pub use self::storage::{
     clear_all_chats, create_chat, delete_chat, get_all_chats, get_chat, get_chat_messages,
diff --git a/src/ai/script_generation.rs b/src/ai/script_generation.rs
new file mode 100644
index 0000000000000000000000000000000000000000..7f2ec8e7576ed50cd10f7aea31a6522875ef667a
--- /dev/null
+++ b/src/ai/script_generation.rs
@@ -0,0 +1,417 @@
+use anyhow::{Context, Result};
+use std::fs::{self, OpenOptions};
+use std::io::{ErrorKind, Write};
+use std::path::{Path, PathBuf};
+use std::sync::Arc;
+
+use super::config::ModelInfo;
+use super::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+
+const AI_SCRIPT_OUTPUT_DIR: &str = "~/.kenv/scripts";
+const AI_SCRIPT_DEFAULT_SLUG: &str = "ai-script";
+const AI_SCRIPT_MAX_SLUG_LEN: usize = 64;
+
+const AI_SCRIPT_GENERATION_SYSTEM_PROMPT: &str = r#"You write production-ready Script Kit scripts.
+
+Return ONLY TypeScript source code for one Script Kit script. Do not include explanations.
+
+Required output conventions:
+1) Include metadata comments at the top:
+   // Name: <clear title>
+   // Description: <one-line summary>
+2) Include: import "@johnlindquist/kit";
+3) Use await arg() for user input when useful.
+4) Use await div() for display output when useful.
+5) Keep the script runnable as-is with sensible defaults and light error handling."#;
+
+#[derive(Debug, Clone)]
+pub struct GeneratedScriptOutput {
+    pub path: PathBuf,
+    pub slug: String,
+    pub model_id: String,
+    pub provider_id: String,
+}
+
+pub fn generate_script_from_prompt(
+    prompt: &str,
+    config: Option<&crate::config::Config>,
+) -> Result<GeneratedScriptOutput> {
+    let normalized_prompt = prompt.trim();
+    if normalized_prompt.is_empty() {
+        anyhow::bail!("AI script generation requires a non-empty prompt");
+    }
+
+    let registry = ProviderRegistry::from_environment_with_config(config);
+    if !registry.has_any_provider() {
+        anyhow::bail!(
+            "No AI providers configured. Configure an API key first (Vercel, OpenAI, Anthropic, etc.)."
+        );
+    }
+
+    let (selected_model, provider) = select_generation_model(&registry)?;
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=provider_ready model_id={} provider_id={} prompt_len={}",
+            selected_model.id,
+            selected_model.provider,
+            normalized_prompt.len()
+        ),
+    );
+
+    let messages = vec![
+        ProviderMessage::system(AI_SCRIPT_GENERATION_SYSTEM_PROMPT),
+        ProviderMessage::user(format!(
+            "Generate a Script Kit script for this user request:\n\n{}",
+            normalized_prompt
+        )),
+    ];
+
+    let raw_response = provider
+        .send_message(&messages, &selected_model.id)
+        .with_context(|| {
+            format!(
+                "AI script generation failed (attempted=send_message, model_id={}, provider_id={})",
+                selected_model.id, selected_model.provider
+            )
+        })?;
+
+    let extracted = extract_script_code(&raw_response);
+    if extracted.trim().is_empty() {
+        anyhow::bail!(
+            "AI returned an empty response for script generation (state=empty_response)"
+        );
+    }
+
+    let slug = slugify_script_name(normalized_prompt);
+    let finalized = enforce_script_kit_conventions(&extracted, normalized_prompt, &slug);
+    let path = write_generated_script(&slug, &finalized).with_context(|| {
+        format!(
+            "Failed writing AI-generated script (state=write_failed, slug={})",
+            slug
+        )
+    })?;
+
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=script_written path={} slug={}",
+            path.display(),
+            slug
+        ),
+    );
+
+    Ok(GeneratedScriptOutput {
+        path,
+        slug,
+        model_id: selected_model.id,
+        provider_id: selected_model.provider,
+    })
+}
+
+fn select_generation_model(registry: &ProviderRegistry) -> Result<(ModelInfo, Arc<dyn AiProvider>)> {
+    let models = registry.get_all_models();
+    let selected_model = models
+        .iter()
+        .find(|model| model.provider.eq_ignore_ascii_case("vercel"))
+        .or_else(|| models.first())
+        .cloned()
+        .context("No AI models available in provider registry")?;
+
+    let provider = registry
+        .find_provider_for_model(&selected_model.id)
+        .cloned()
+        .with_context(|| {
+            format!(
+                "No provider found for selected model '{}' (state=provider_missing)",
+                selected_model.id
+            )
+        })?;
+
+    Ok((selected_model, provider))
+}
+
+fn generated_scripts_dir() -> PathBuf {
+    PathBuf::from(shellexpand::tilde(AI_SCRIPT_OUTPUT_DIR).as_ref())
+}
+
+fn split_fence_header_and_body(fence: &str) -> (&str, &str) {
+    match fence.find('\n') {
+        Some(newline_index) => (&fence[..newline_index], &fence[newline_index + 1..]),
+        None => ("", fence),
+    }
+}
+
+fn extract_fenced_code(response: &str, preferred_languages: Option<&[&str]>) -> Option<String> {
+    let mut remaining = response;
+
+    while let Some(start) = remaining.find("```") {
+        let after_start = &remaining[start + 3..];
+        let Some(end) = after_start.find("```") else {
+            break;
+        };
+
+        let fence_contents = &after_start[..end];
+        let (header, body) = split_fence_header_and_body(fence_contents);
+        let language = header
+            .trim()
+            .split(|c: char| c.is_whitespace() || c == '{')
+            .next()
+            .unwrap_or("")
+            .to_ascii_lowercase();
+        let code = body.trim();
+
+        if !code.is_empty() {
+            match preferred_languages {
+                Some(preferred) => {
+                    if preferred.iter().any(|candidate| *candidate == language) {
+                        return Some(code.to_string());
+                    }
+                }
+                None => return Some(code.to_string()),
+            }
+        }
+
+        remaining = &after_start[end + 3..];
+    }
+
+    None
+}
+
+fn extract_script_code(response: &str) -> String {
+    const PREFERRED_LANGUAGES: [&str; 6] = ["typescript", "ts", "javascript", "js", "tsx", "jsx"];
+
+    extract_fenced_code(response, Some(&PREFERRED_LANGUAGES))
+        .or_else(|| extract_fenced_code(response, None))
+        .unwrap_or_else(|| response.trim().to_string())
+}
+
+fn slugify_script_name(prompt: &str) -> String {
+    let mut slug = String::new();
+    let mut last_was_hyphen = false;
+
+    for character in prompt.to_ascii_lowercase().chars() {
+        if character.is_ascii_alphanumeric() {
+            slug.push(character);
+            last_was_hyphen = false;
+        } else if matches!(character, ' ' | '_' | '-') {
+            if !slug.is_empty() && !last_was_hyphen {
+                slug.push('-');
+                last_was_hyphen = true;
+            }
+        }
+    }
+
+    while slug.ends_with('-') {
+        slug.pop();
+    }
+
+    if slug.len() > AI_SCRIPT_MAX_SLUG_LEN {
+        slug.truncate(AI_SCRIPT_MAX_SLUG_LEN);
+        while slug.ends_with('-') {
+            slug.pop();
+        }
+    }
+
+    if slug.is_empty() {
+        AI_SCRIPT_DEFAULT_SLUG.to_string()
+    } else {
+        slug
+    }
+}
+
+fn slug_to_title(slug: &str) -> String {
+    slug.split('-')
+        .filter(|segment| !segment.is_empty())
+        .map(|segment| {
+            let mut chars = segment.chars();
+            match chars.next() {
+                Some(first) => first.to_uppercase().collect::<String>() + chars.as_str(),
+                None => String::new(),
+            }
+        })
+        .collect::<Vec<_>>()
+        .join(" ")
+}
+
+fn description_from_prompt(prompt: &str) -> String {
+    let normalized = prompt.split_whitespace().collect::<Vec<_>>().join(" ");
+    if normalized.is_empty() {
+        return "AI-generated Script Kit script".to_string();
+    }
+
+    let mut shortened = normalized;
+    if shortened.chars().count() > 110 {
+        shortened = format!("{}...", shortened.chars().take(107).collect::<String>());
+    }
+    shortened
+}
+
+fn has_kit_import(script: &str) -> bool {
+    script.contains("import \"@johnlindquist/kit\";")
+        || script.contains("import '@johnlindquist/kit';")
+        || script.contains("import \"@scriptkit/sdk\";")
+        || script.contains("import '@scriptkit/sdk';")
+}
+
+fn enforce_script_kit_conventions(script: &str, prompt: &str, slug: &str) -> String {
+    let mut prefix_lines: Vec<String> = Vec::new();
+    let trimmed_script = script.trim();
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Name:"))
+    {
+        prefix_lines.push(format!("// Name: {}", slug_to_title(slug)));
+    }
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Description:"))
+    {
+        prefix_lines.push(format!("// Description: {}", description_from_prompt(prompt)));
+    }
+
+    if !has_kit_import(trimmed_script) {
+        prefix_lines.push("import \"@johnlindquist/kit\";".to_string());
+    }
+
+    let mut output = String::new();
+    if !prefix_lines.is_empty() {
+        output.push_str(&prefix_lines.join("\n"));
+        output.push_str("\n\n");
+    }
+
+    output.push_str(trimmed_script);
+    if !output.ends_with('\n') {
+        output.push('\n');
+    }
+    output
+}
+
+fn write_generated_script(slug: &str, script_content: &str) -> Result<PathBuf> {
+    write_generated_script_in_dir(&generated_scripts_dir(), slug, script_content)
+}
+
+fn write_generated_script_in_dir(output_dir: &Path, slug: &str, script_content: &str) -> Result<PathBuf> {
+    fs::create_dir_all(output_dir)
+        .with_context(|| format!("Failed to create output dir: {}", output_dir.display()))?;
+
+    for suffix in 0usize.. {
+        let candidate = if suffix == 0 {
+            slug.to_string()
+        } else {
+            format!("{slug}-{suffix}")
+        };
+        let path = output_dir.join(format!("{}.ts", candidate));
+        match OpenOptions::new().write(true).create_new(true).open(&path) {
+            Ok(mut file) => {
+                file.write_all(script_content.as_bytes())
+                    .with_context(|| format!("Failed writing generated script to {}", path.display()))?;
+                return Ok(path);
+            }
+            Err(error) if error.kind() == ErrorKind::AlreadyExists => continue,
+            Err(error) => {
+                return Err(error).with_context(|| {
+                    format!(
+                        "Failed creating generated script file {} (slug={})",
+                        path.display(),
+                        slug
+                    )
+                });
+            }
+        }
+    }
+
+    unreachable!("suffix loop should eventually create a unique script filename")
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+    use tempfile::tempdir;
+
+    #[test]
+    fn test_slugify_script_name_handles_spaces_and_symbols() {
+        assert_eq!(slugify_script_name("Build: API Client!"), "build-api-client");
+        assert_eq!(slugify_script_name("  ___  "), "ai-script");
+    }
+
+    #[test]
+    fn test_extract_script_code_prefers_typescript_fence_when_multiple_blocks_exist() {
+        let response = r#"
+Here's one idea:
+```markdown
+Not code
+```
+```typescript
+await div("hello");
+```
+"#;
+        assert_eq!(extract_script_code(response), "await div(\"hello\");");
+    }
+
+    #[test]
+    fn test_extract_script_code_falls_back_to_first_fenced_block() {
+        let response = r#"
+```python
+print("hello")
+```
+"#;
+        assert_eq!(extract_script_code(response), "print(\"hello\")");
+    }
+
+    #[test]
+    fn test_extract_script_code_returns_trimmed_response_when_no_fence_exists() {
+        let response = "const answer = 42;";
+        assert_eq!(extract_script_code(response), "const answer = 42;");
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_adds_missing_metadata_and_import() {
+        let script = "const name = await arg(\"Name?\");";
+        let output = enforce_script_kit_conventions(script, "Ask for user name", "ask-user-name");
+
+        assert!(output.contains("// Name: Ask User Name"));
+        assert!(output.contains("// Description: Ask for user name"));
+        assert!(output.contains("import \"@johnlindquist/kit\";"));
+        assert!(output.contains("await arg(\"Name?\");"));
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_keeps_existing_metadata_and_import() {
+        let script = r#"// Name: Existing
+// Description: Existing description
+import "@johnlindquist/kit";
+
+await div("ready");
+"#;
+        let output = enforce_script_kit_conventions(script, "ignored", "ignored");
+
+        assert_eq!(
+            output.matches("// Name:").count(),
+            1,
+            "should not duplicate existing Name metadata"
+        );
+        assert_eq!(
+            output.matches("// Description:").count(),
+            1,
+            "should not duplicate existing Description metadata"
+        );
+        assert_eq!(
+            output.matches("import \"@johnlindquist/kit\";").count(),
+            1,
+            "should not duplicate existing import"
+        );
+    }
+
+    #[test]
+    fn test_write_generated_script_in_dir_appends_numeric_suffix_for_collisions() {
+        let temp_dir = tempdir().unwrap();
+        let first = write_generated_script_in_dir(temp_dir.path(), "my-script", "a").unwrap();
+        let second = write_generated_script_in_dir(temp_dir.path(), "my-script", "b").unwrap();
+
+        assert_eq!(first.file_name().unwrap(), "my-script.ts");
+        assert_eq!(second.file_name().unwrap(), "my-script-1.ts");
+    }
+}
diff --git a/src/builtins/part_000.rs b/src/builtins/part_000.rs
index d6b9c2a9b35b40c5005dbb9f65147f528702cb9e..5f6d27d28d72e51126d10d8beccf931c689ef2bb
--- a/src/builtins/part_000.rs
+++ b/src/builtins/part_000.rs
@@ -96,6 +96,8 @@
     OpenAi,
     NewConversation,
     ClearConversation,
+    /// Generate a new Script Kit script from the main prompt text
+    GenerateScript,
     /// Send a screenshot of the entire screen to AI Chat
     SendScreenToAi,
     /// Send a screenshot of the focused window to AI Chat
diff --git a/src/builtins/part_001_entries/entries_002.rs b/src/builtins/part_001_entries/entries_002.rs
index 6d1c9334f0ccaf0aab48582aaf42dcb129e1cb6e..72b318c66aeaf124359f4ecd276dae0350287328
--- a/src/builtins/part_001_entries/entries_002.rs
+++ b/src/builtins/part_001_entries/entries_002.rs
@@ -61,6 +61,17 @@
     ));
 
     entries.push(BuiltInEntry::new_with_icon(
+        "builtin-generate-script-with-ai",
+        "Generate Script with AI",
+        "Generate a Script Kit script from your current prompt text",
+        vec![
+            "generate", "script", "ai", "create", "code", "typescript", "shift", "tab",
+        ],
+        BuiltInFeature::AiCommand(AiCommandType::GenerateScript),
+        "ðŸ§ ",
+    ));
+
+    entries.push(BuiltInEntry::new_with_icon(
         "builtin-send-screen-to-ai",
         "Send Screen to AI Chat",
         "Capture the full screen and send it to AI Chat",

context compacted
Reconnecting... 1/5 (stream disconnected before completion: An error occurred while processing your request. You can retry your request, or contact us through our help center at help.openai.com if the error persists. Please include the request ID d3e3bf55-07b3-48a1-9126-51baa852806a in your message.)

thinking
**Clarifying testing scope conflict**
codex
Continuing from the partial implementation: Iâ€™ll finish wiring `GenerateScript` into built-in execution, add/adjust tests for the new built-in entry, then run scoped verification on only the touched modules before finalizing and releasing claims.

thinking
**Orchestrating parallel git commands**
exec
/bin/zsh -lc 'git status --short' in /Users/johnlindquist/dev/script-kit-gpuiexec
/bin/zsh -lc 'rg -n "GenerateScript|builtin-generate-script-with-ai|script_generation" src/builtins src/app_execute src/ai src/kit_store' in /Users/johnlindquist/dev/script-kit-gpuiexec
/bin/zsh -lc '~/.claude/bin/swarm.ts status' in /Users/johnlindquist/dev/script-kit-gpui succeeded in 51ms:
 M .ai/logs/codex-audit-act-description-quality-v2.final.md
 M .ai/logs/codex-audit-act-execution-builtin.final.md
 M .ai/logs/codex-audit-act-execution-scripts.final.md
 M .ai/logs/codex-audit-act-keyboard-nav.final.md
 M .ai/logs/codex-audit-act-section-grouping.final.md
 M .ai/logs/codex-audit-act-theme-dialog-render.final.md
 M .ai/roster.json
 M src/actions/builders.rs
 M src/actions/builders/chat.rs
 M src/actions/builders/clipboard.rs
 M src/actions/builders/file_path.rs
 M src/actions/builders/notes.rs
 M src/actions/builders/script_context.rs
 M src/actions/builders/scriptlet.rs
 M src/actions/builders/shared.rs
 M src/actions/command_bar/part_01.rs
 M src/actions/command_bar/part_02.rs
 M src/actions/constants.rs
 M src/actions/dialog/part_01.rs
 M src/actions/dialog/part_02/part_01.rs
 succeeded in 50ms:
src/builtins/part_000.rs:100:    GenerateScript,
src/builtins/part_001_entries/entries_002.rs:64:        "builtin-generate-script-with-ai",
src/builtins/part_001_entries/entries_002.rs:70:        BuiltInFeature::AiCommand(AiCommandType::GenerateScript),
src/ai/mod.rs:40:pub(crate) mod script_generation;
src/ai/mod.rs:48:pub use self::script_generation::{generate_script_from_prompt, GeneratedScriptOutput};
 succeeded in 51ms:
Repo: /Users/johnlindquist/dev/script-kit-gpui
Updated: 2026-02-08T02:52:49.956Z

Active agents (2):
codex-script-gen-builtin [in_progress] codex/gpt-5.3-codex/exec
  task: In Script Kit GPUI, there needs to be a built-in feature or action for AI script generation triggered by Shift+Tab. Looâ€¦
  scope: src/builtins/**,src/app_execute/**,src/ai/**,src/kit_store/**
  claims(6): src/builtins/part_001_entries/entries_002.rs, src/builtins/part_000.rs, src/builtins/tests/part_000.rs, src/app_execute/builtin_execution.rs, src/ai/script_genâ€¦
  notes: Claimed builtin/app_execute/ai files; implementing AI script generation command + tests

codex-shift-tab-keybind [in_progress] codex/gpt-5.3-codex/exec
  task: In Script Kit GPUI, pressing Tab in the main prompt triggers an AI chat scenario. Add a Shift+Tab keyboard shortcut thaâ€¦
  scope: src/actions/dialog/**,src/app_impl/**,src/ai/**,src/execute_script/**
  claims(4): src/app_impl/startup.rs, src/app_impl/prompt_ai.rs, src/app_impl/startup_new_tab.rs, src/app_impl/tests.rs
  notes: Implementing Shift+Tab AI script generation in startup tab interceptor + prompt_ai backend action.

Inactive agents (253):
- codex-accessibility [done] done. exit=0. final=.ai/logs/codex-accessibility.final.md. See final message file.
- codex-action-labels [failed] failed. exit=1. final=.ai/logs/codex-action-labels.final.md.
- codex-actions-audit [failed] failed. exit=1. final=.ai/logs/codex-actions-audit.final.md. See final message file.
file update:
diff --git a/src/ai/mod.rs b/src/ai/mod.rs
index a420b1a5faf59506acdb7caf60681c153a3f9bb6..9a73e9491862633b325b2c52b51a3e20395ff85c
--- a/src/ai/mod.rs
+++ b/src/ai/mod.rs
@@ -37,6 +37,7 @@
 pub(crate) mod providers;
 pub(crate) mod sdk_handlers;
 pub(crate) mod session;
+pub(crate) mod script_generation;
 pub(crate) mod storage;
 pub(crate) mod window;
 
@@ -44,6 +45,7 @@
 pub use self::config::{DetectedKeys, ModelInfo, ProviderConfig};
 pub use self::model::{Chat, ChatId, ChatSource, Message, MessageRole};
 pub use self::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+pub use self::script_generation::{generate_script_from_prompt, GeneratedScriptOutput};
 pub use self::sdk_handlers::try_handle_ai_message;
 pub use self::storage::{
     clear_all_chats, create_chat, delete_chat, get_all_chats, get_chat, get_chat_messages,
diff --git a/src/ai/script_generation.rs b/src/ai/script_generation.rs
new file mode 100644
index 0000000000000000000000000000000000000000..7f2ec8e7576ed50cd10f7aea31a6522875ef667a
--- /dev/null
+++ b/src/ai/script_generation.rs
@@ -0,0 +1,417 @@
+use anyhow::{Context, Result};
+use std::fs::{self, OpenOptions};
+use std::io::{ErrorKind, Write};
+use std::path::{Path, PathBuf};
+use std::sync::Arc;
+
+use super::config::ModelInfo;
+use super::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+
+const AI_SCRIPT_OUTPUT_DIR: &str = "~/.kenv/scripts";
+const AI_SCRIPT_DEFAULT_SLUG: &str = "ai-script";
+const AI_SCRIPT_MAX_SLUG_LEN: usize = 64;
+
+const AI_SCRIPT_GENERATION_SYSTEM_PROMPT: &str = r#"You write production-ready Script Kit scripts.
+
+Return ONLY TypeScript source code for one Script Kit script. Do not include explanations.
+
+Required output conventions:
+1) Include metadata comments at the top:
+   // Name: <clear title>
+   // Description: <one-line summary>
+2) Include: import "@johnlindquist/kit";
+3) Use await arg() for user input when useful.
+4) Use await div() for display output when useful.
+5) Keep the script runnable as-is with sensible defaults and light error handling."#;
+
+#[derive(Debug, Clone)]
+pub struct GeneratedScriptOutput {
+    pub path: PathBuf,
+    pub slug: String,
+    pub model_id: String,
+    pub provider_id: String,
+}
+
+pub fn generate_script_from_prompt(
+    prompt: &str,
+    config: Option<&crate::config::Config>,
+) -> Result<GeneratedScriptOutput> {
+    let normalized_prompt = prompt.trim();
+    if normalized_prompt.is_empty() {
+        anyhow::bail!("AI script generation requires a non-empty prompt");
+    }
+
+    let registry = ProviderRegistry::from_environment_with_config(config);
+    if !registry.has_any_provider() {
+        anyhow::bail!(
+            "No AI providers configured. Configure an API key first (Vercel, OpenAI, Anthropic, etc.)."
+        );
+    }
+
+    let (selected_model, provider) = select_generation_model(&registry)?;
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=provider_ready model_id={} provider_id={} prompt_len={}",
+            selected_model.id,
+            selected_model.provider,
+            normalized_prompt.len()
+        ),
+    );
+
+    let messages = vec![
+        ProviderMessage::system(AI_SCRIPT_GENERATION_SYSTEM_PROMPT),
+        ProviderMessage::user(format!(
+            "Generate a Script Kit script for this user request:\n\n{}",
+            normalized_prompt
+        )),
+    ];
+
+    let raw_response = provider
+        .send_message(&messages, &selected_model.id)
+        .with_context(|| {
+            format!(
+                "AI script generation failed (attempted=send_message, model_id={}, provider_id={})",
+                selected_model.id, selected_model.provider
+            )
+        })?;
+
+    let extracted = extract_script_code(&raw_response);
+    if extracted.trim().is_empty() {
+        anyhow::bail!(
+            "AI returned an empty response for script generation (state=empty_response)"
+        );
+    }
+
+    let slug = slugify_script_name(normalized_prompt);
+    let finalized = enforce_script_kit_conventions(&extracted, normalized_prompt, &slug);
+    let path = write_generated_script(&slug, &finalized).with_context(|| {
+        format!(
+            "Failed writing AI-generated script (state=write_failed, slug={})",
+            slug
+        )
+    })?;
+
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=script_written path={} slug={}",
+            path.display(),
+            slug
+        ),
+    );
+
+    Ok(GeneratedScriptOutput {
+        path,
+        slug,
+        model_id: selected_model.id,
+        provider_id: selected_model.provider,
+    })
+}
+
+fn select_generation_model(registry: &ProviderRegistry) -> Result<(ModelInfo, Arc<dyn AiProvider>)> {
+    let models = registry.get_all_models();
+    let selected_model = models
+        .iter()
+        .find(|model| model.provider.eq_ignore_ascii_case("vercel"))
+        .or_else(|| models.first())
+        .cloned()
+        .context("No AI models available in provider registry")?;
+
+    let provider = registry
+        .find_provider_for_model(&selected_model.id)
+        .cloned()
+        .with_context(|| {
+            format!(
+                "No provider found for selected model '{}' (state=provider_missing)",
+                selected_model.id
+            )
+        })?;
+
+    Ok((selected_model, provider))
+}
+
+fn generated_scripts_dir() -> PathBuf {
+    PathBuf::from(shellexpand::tilde(AI_SCRIPT_OUTPUT_DIR).as_ref())
+}
+
+fn split_fence_header_and_body(fence: &str) -> (&str, &str) {
+    match fence.find('\n') {
+        Some(newline_index) => (&fence[..newline_index], &fence[newline_index + 1..]),
+        None => ("", fence),
+    }
+}
+
+fn extract_fenced_code(response: &str, preferred_languages: Option<&[&str]>) -> Option<String> {
+    let mut remaining = response;
+
+    while let Some(start) = remaining.find("```") {
+        let after_start = &remaining[start + 3..];
+        let Some(end) = after_start.find("```") else {
+            break;
+        };
+
+        let fence_contents = &after_start[..end];
+        let (header, body) = split_fence_header_and_body(fence_contents);
+        let language = header
+            .trim()
+            .split(|c: char| c.is_whitespace() || c == '{')
+            .next()
+            .unwrap_or("")
+            .to_ascii_lowercase();
+        let code = body.trim();
+
+        if !code.is_empty() {
+            match preferred_languages {
+                Some(preferred) => {
+                    if preferred.iter().any(|candidate| *candidate == language) {
+                        return Some(code.to_string());
+                    }
+                }
+                None => return Some(code.to_string()),
+            }
+        }
+
+        remaining = &after_start[end + 3..];
+    }
+
+    None
+}
+
+fn extract_script_code(response: &str) -> String {
+    const PREFERRED_LANGUAGES: [&str; 6] = ["typescript", "ts", "javascript", "js", "tsx", "jsx"];
+
+    extract_fenced_code(response, Some(&PREFERRED_LANGUAGES))
+        .or_else(|| extract_fenced_code(response, None))
+        .unwrap_or_else(|| response.trim().to_string())
+}
+
+fn slugify_script_name(prompt: &str) -> String {
+    let mut slug = String::new();
+    let mut last_was_hyphen = false;
+
+    for character in prompt.to_ascii_lowercase().chars() {
+        if character.is_ascii_alphanumeric() {
+            slug.push(character);
+            last_was_hyphen = false;
+        } else if matches!(character, ' ' | '_' | '-') {
+            if !slug.is_empty() && !last_was_hyphen {
+                slug.push('-');
+                last_was_hyphen = true;
+            }
+        }
+    }
+
+    while slug.ends_with('-') {
+        slug.pop();
+    }
+
+    if slug.len() > AI_SCRIPT_MAX_SLUG_LEN {
+        slug.truncate(AI_SCRIPT_MAX_SLUG_LEN);
+        while slug.ends_with('-') {
+            slug.pop();
+        }
+    }
+
+    if slug.is_empty() {
+        AI_SCRIPT_DEFAULT_SLUG.to_string()
+    } else {
+        slug
+    }
+}
+
+fn slug_to_title(slug: &str) -> String {
+    slug.split('-')
+        .filter(|segment| !segment.is_empty())
+        .map(|segment| {
+            let mut chars = segment.chars();
+            match chars.next() {
+                Some(first) => first.to_uppercase().collect::<String>() + chars.as_str(),
+                None => String::new(),
+            }
+        })
+        .collect::<Vec<_>>()
+        .join(" ")
+}
+
+fn description_from_prompt(prompt: &str) -> String {
+    let normalized = prompt.split_whitespace().collect::<Vec<_>>().join(" ");
+    if normalized.is_empty() {
+        return "AI-generated Script Kit script".to_string();
+    }
+
+    let mut shortened = normalized;
+    if shortened.chars().count() > 110 {
+        shortened = format!("{}...", shortened.chars().take(107).collect::<String>());
+    }
+    shortened
+}
+
+fn has_kit_import(script: &str) -> bool {
+    script.contains("import \"@johnlindquist/kit\";")
+        || script.contains("import '@johnlindquist/kit';")
+        || script.contains("import \"@scriptkit/sdk\";")
+        || script.contains("import '@scriptkit/sdk';")
+}
+
+fn enforce_script_kit_conventions(script: &str, prompt: &str, slug: &str) -> String {
+    let mut prefix_lines: Vec<String> = Vec::new();
+    let trimmed_script = script.trim();
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Name:"))
+    {
+        prefix_lines.push(format!("// Name: {}", slug_to_title(slug)));
+    }
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Description:"))
+    {
+        prefix_lines.push(format!("// Description: {}", description_from_prompt(prompt)));
+    }
+
+    if !has_kit_import(trimmed_script) {
+        prefix_lines.push("import \"@johnlindquist/kit\";".to_string());
+    }
+
+    let mut output = String::new();
+    if !prefix_lines.is_empty() {
+        output.push_str(&prefix_lines.join("\n"));
+        output.push_str("\n\n");
+    }
+
+    output.push_str(trimmed_script);
+    if !output.ends_with('\n') {
+        output.push('\n');
+    }
+    output
+}
+
+fn write_generated_script(slug: &str, script_content: &str) -> Result<PathBuf> {
+    write_generated_script_in_dir(&generated_scripts_dir(), slug, script_content)
+}
+
+fn write_generated_script_in_dir(output_dir: &Path, slug: &str, script_content: &str) -> Result<PathBuf> {
+    fs::create_dir_all(output_dir)
+        .with_context(|| format!("Failed to create output dir: {}", output_dir.display()))?;
+
+    for suffix in 0usize.. {
+        let candidate = if suffix == 0 {
+            slug.to_string()
+        } else {
+            format!("{slug}-{suffix}")
+        };
+        let path = output_dir.join(format!("{}.ts", candidate));
+        match OpenOptions::new().write(true).create_new(true).open(&path) {
+            Ok(mut file) => {
+                file.write_all(script_content.as_bytes())
+                    .with_context(|| format!("Failed writing generated script to {}", path.display()))?;
+                return Ok(path);
+            }
+            Err(error) if error.kind() == ErrorKind::AlreadyExists => continue,
+            Err(error) => {
+                return Err(error).with_context(|| {
+                    format!(
+                        "Failed creating generated script file {} (slug={})",
+                        path.display(),
+                        slug
+                    )
+                });
+            }
+        }
+    }
+
+    unreachable!("suffix loop should eventually create a unique script filename")
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+    use tempfile::tempdir;
+
+    #[test]
+    fn test_slugify_script_name_handles_spaces_and_symbols() {
+        assert_eq!(slugify_script_name("Build: API Client!"), "build-api-client");
+        assert_eq!(slugify_script_name("  ___  "), "ai-script");
+    }
+
+    #[test]
+    fn test_extract_script_code_prefers_typescript_fence_when_multiple_blocks_exist() {
+        let response = r#"
+Here's one idea:
+```markdown
+Not code
+```
+```typescript
+await div("hello");
+```
+"#;
+        assert_eq!(extract_script_code(response), "await div(\"hello\");");
+    }
+
+    #[test]
+    fn test_extract_script_code_falls_back_to_first_fenced_block() {
+        let response = r#"
+```python
+print("hello")
+```
+"#;
+        assert_eq!(extract_script_code(response), "print(\"hello\")");
+    }
+
+    #[test]
+    fn test_extract_script_code_returns_trimmed_response_when_no_fence_exists() {
+        let response = "const answer = 42;";
+        assert_eq!(extract_script_code(response), "const answer = 42;");
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_adds_missing_metadata_and_import() {
+        let script = "const name = await arg(\"Name?\");";
+        let output = enforce_script_kit_conventions(script, "Ask for user name", "ask-user-name");
+
+        assert!(output.contains("// Name: Ask User Name"));
+        assert!(output.contains("// Description: Ask for user name"));
+        assert!(output.contains("import \"@johnlindquist/kit\";"));
+        assert!(output.contains("await arg(\"Name?\");"));
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_keeps_existing_metadata_and_import() {
+        let script = r#"// Name: Existing
+// Description: Existing description
+import "@johnlindquist/kit";
+
+await div("ready");
+"#;
+        let output = enforce_script_kit_conventions(script, "ignored", "ignored");
+
+        assert_eq!(
+            output.matches("// Name:").count(),
+            1,
+            "should not duplicate existing Name metadata"
+        );
+        assert_eq!(
+            output.matches("// Description:").count(),
+            1,
+            "should not duplicate existing Description metadata"
+        );
+        assert_eq!(
+            output.matches("import \"@johnlindquist/kit\";").count(),
+            1,
+            "should not duplicate existing import"
+        );
+    }
+
+    #[test]
+    fn test_write_generated_script_in_dir_appends_numeric_suffix_for_collisions() {
+        let temp_dir = tempdir().unwrap();
+        let first = write_generated_script_in_dir(temp_dir.path(), "my-script", "a").unwrap();
+        let second = write_generated_script_in_dir(temp_dir.path(), "my-script", "b").unwrap();
+
+        assert_eq!(first.file_name().unwrap(), "my-script.ts");
+        assert_eq!(second.file_name().unwrap(), "my-script-1.ts");
+    }
+}
diff --git a/src/builtins/part_000.rs b/src/builtins/part_000.rs
index d6b9c2a9b35b40c5005dbb9f65147f528702cb9e..5f6d27d28d72e51126d10d8beccf931c689ef2bb
--- a/src/builtins/part_000.rs
+++ b/src/builtins/part_000.rs
@@ -96,6 +96,8 @@
     OpenAi,
     NewConversation,
     ClearConversation,
+    /// Generate a new Script Kit script from the main prompt text
+    GenerateScript,
     /// Send a screenshot of the entire screen to AI Chat
     SendScreenToAi,
     /// Send a screenshot of the focused window to AI Chat
diff --git a/src/builtins/part_001_entries/entries_002.rs b/src/builtins/part_001_entries/entries_002.rs
index 6d1c9334f0ccaf0aab48582aaf42dcb129e1cb6e..72b318c66aeaf124359f4ecd276dae0350287328
--- a/src/builtins/part_001_entries/entries_002.rs
+++ b/src/builtins/part_001_entries/entries_002.rs
@@ -61,6 +61,17 @@
     ));
 
     entries.push(BuiltInEntry::new_with_icon(
+        "builtin-generate-script-with-ai",
+        "Generate Script with AI",
+        "Generate a Script Kit script from your current prompt text",
+        vec![
+            "generate", "script", "ai", "create", "code", "typescript", "shift", "tab",
+        ],
+        BuiltInFeature::AiCommand(AiCommandType::GenerateScript),
+        "ðŸ§ ",
+    ));
+
+    entries.push(BuiltInEntry::new_with_icon(
         "builtin-send-screen-to-ai",
         "Send Screen to AI Chat",
         "Capture the full screen and send it to AI Chat",


thinking
**Inspecting modified files content**
codex
I confirmed the in-progress edits are present and claims are active. Next Iâ€™m inspecting `builtin_execution` and related tests to finish the command wiring and validate behavior end-to-end.
exec
/bin/zsh -lc "sed -n '1,220p' src/app_execute/builtin_execution.rs" in /Users/johnlindquist/dev/script-kit-gpuiexec
/bin/zsh -lc "sed -n '1,260p' src/ai/script_generation.rs" in /Users/johnlindquist/dev/script-kit-gpuiexec
/bin/zsh -lc "sed -n '260,560p' src/ai/script_generation.rs" in /Users/johnlindquist/dev/script-kit-gpui succeeded in 50ms:
fn ai_open_failure_message(error: impl std::fmt::Display) -> String {
    format!("Failed to open AI: {}", error)
}

impl ScriptListApp {
    fn system_action_feedback_message(
        &self,
        action_type: &builtins::SystemActionType,
    ) -> Option<String> {
        let dark_mode_enabled = if matches!(action_type, builtins::SystemActionType::ToggleDarkMode)
        {
            system_actions::is_dark_mode().ok()
        } else {
            None
        };

        builtins::system_action_hud_message(*action_type, dark_mode_enabled)
    }

    fn execute_builtin(&mut self, entry: &builtins::BuiltInEntry, cx: &mut Context<Self>) {
 succeeded in 52ms:
use anyhow::{Context, Result};
use std::fs::{self, OpenOptions};
use std::io::{ErrorKind, Write};
use std::path::{Path, PathBuf};
use std::sync::Arc;

use super::config::ModelInfo;
use super::providers::{AiProvider, ProviderMessage, ProviderRegistry};

const AI_SCRIPT_OUTPUT_DIR: &str = "~/.kenv/scripts";
const AI_SCRIPT_DEFAULT_SLUG: &str = "ai-script";
const AI_SCRIPT_MAX_SLUG_LEN: usize = 64;

const AI_SCRIPT_GENERATION_SYSTEM_PROMPT: &str = r#"You write production-ready Script Kit scripts.

Return ONLY TypeScript source code for one Script Kit script. Do not include explanations.

Required output conventions:
1) Include metadata comments at the top:
   // Name: <clear title>
 succeeded in 52ms:

    if !trimmed_script
        .lines()
        .any(|line| line.trim_start().starts_with("// Name:"))
    {
        prefix_lines.push(format!("// Name: {}", slug_to_title(slug)));
    }

    if !trimmed_script
        .lines()
        .any(|line| line.trim_start().starts_with("// Description:"))
    {
        prefix_lines.push(format!("// Description: {}", description_from_prompt(prompt)));
    }

    if !has_kit_import(trimmed_script) {
        prefix_lines.push("import \"@johnlindquist/kit\";".to_string());
    }

    let mut output = String::new();
file update:
diff --git a/src/ai/mod.rs b/src/ai/mod.rs
index a420b1a5faf59506acdb7caf60681c153a3f9bb6..9a73e9491862633b325b2c52b51a3e20395ff85c
--- a/src/ai/mod.rs
+++ b/src/ai/mod.rs
@@ -37,6 +37,7 @@
 pub(crate) mod providers;
 pub(crate) mod sdk_handlers;
 pub(crate) mod session;
+pub(crate) mod script_generation;
 pub(crate) mod storage;
 pub(crate) mod window;
 
@@ -44,6 +45,7 @@
 pub use self::config::{DetectedKeys, ModelInfo, ProviderConfig};
 pub use self::model::{Chat, ChatId, ChatSource, Message, MessageRole};
 pub use self::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+pub use self::script_generation::{generate_script_from_prompt, GeneratedScriptOutput};
 pub use self::sdk_handlers::try_handle_ai_message;
 pub use self::storage::{
     clear_all_chats, create_chat, delete_chat, get_all_chats, get_chat, get_chat_messages,
diff --git a/src/ai/script_generation.rs b/src/ai/script_generation.rs
new file mode 100644
index 0000000000000000000000000000000000000000..7f2ec8e7576ed50cd10f7aea31a6522875ef667a
--- /dev/null
+++ b/src/ai/script_generation.rs
@@ -0,0 +1,417 @@
+use anyhow::{Context, Result};
+use std::fs::{self, OpenOptions};
+use std::io::{ErrorKind, Write};
+use std::path::{Path, PathBuf};
+use std::sync::Arc;
+
+use super::config::ModelInfo;
+use super::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+
+const AI_SCRIPT_OUTPUT_DIR: &str = "~/.kenv/scripts";
+const AI_SCRIPT_DEFAULT_SLUG: &str = "ai-script";
+const AI_SCRIPT_MAX_SLUG_LEN: usize = 64;
+
+const AI_SCRIPT_GENERATION_SYSTEM_PROMPT: &str = r#"You write production-ready Script Kit scripts.
+
+Return ONLY TypeScript source code for one Script Kit script. Do not include explanations.
+
+Required output conventions:
+1) Include metadata comments at the top:
+   // Name: <clear title>
+   // Description: <one-line summary>
+2) Include: import "@johnlindquist/kit";
+3) Use await arg() for user input when useful.
+4) Use await div() for display output when useful.
+5) Keep the script runnable as-is with sensible defaults and light error handling."#;
+
+#[derive(Debug, Clone)]
+pub struct GeneratedScriptOutput {
+    pub path: PathBuf,
+    pub slug: String,
+    pub model_id: String,
+    pub provider_id: String,
+}
+
+pub fn generate_script_from_prompt(
+    prompt: &str,
+    config: Option<&crate::config::Config>,
+) -> Result<GeneratedScriptOutput> {
+    let normalized_prompt = prompt.trim();
+    if normalized_prompt.is_empty() {
+        anyhow::bail!("AI script generation requires a non-empty prompt");
+    }
+
+    let registry = ProviderRegistry::from_environment_with_config(config);
+    if !registry.has_any_provider() {
+        anyhow::bail!(
+            "No AI providers configured. Configure an API key first (Vercel, OpenAI, Anthropic, etc.)."
+        );
+    }
+
+    let (selected_model, provider) = select_generation_model(&registry)?;
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=provider_ready model_id={} provider_id={} prompt_len={}",
+            selected_model.id,
+            selected_model.provider,
+            normalized_prompt.len()
+        ),
+    );
+
+    let messages = vec![
+        ProviderMessage::system(AI_SCRIPT_GENERATION_SYSTEM_PROMPT),
+        ProviderMessage::user(format!(
+            "Generate a Script Kit script for this user request:\n\n{}",
+            normalized_prompt
+        )),
+    ];
+
+    let raw_response = provider
+        .send_message(&messages, &selected_model.id)
+        .with_context(|| {
+            format!(
+                "AI script generation failed (attempted=send_message, model_id={}, provider_id={})",
+                selected_model.id, selected_model.provider
+            )
+        })?;
+
+    let extracted = extract_script_code(&raw_response);
+    if extracted.trim().is_empty() {
+        anyhow::bail!(
+            "AI returned an empty response for script generation (state=empty_response)"
+        );
+    }
+
+    let slug = slugify_script_name(normalized_prompt);
+    let finalized = enforce_script_kit_conventions(&extracted, normalized_prompt, &slug);
+    let path = write_generated_script(&slug, &finalized).with_context(|| {
+        format!(
+            "Failed writing AI-generated script (state=write_failed, slug={})",
+            slug
+        )
+    })?;
+
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=script_written path={} slug={}",
+            path.display(),
+            slug
+        ),
+    );
+
+    Ok(GeneratedScriptOutput {
+        path,
+        slug,
+        model_id: selected_model.id,
+        provider_id: selected_model.provider,
+    })
+}
+
+fn select_generation_model(registry: &ProviderRegistry) -> Result<(ModelInfo, Arc<dyn AiProvider>)> {
+    let models = registry.get_all_models();
+    let selected_model = models
+        .iter()
+        .find(|model| model.provider.eq_ignore_ascii_case("vercel"))
+        .or_else(|| models.first())
+        .cloned()
+        .context("No AI models available in provider registry")?;
+
+    let provider = registry
+        .find_provider_for_model(&selected_model.id)
+        .cloned()
+        .with_context(|| {
+            format!(
+                "No provider found for selected model '{}' (state=provider_missing)",
+                selected_model.id
+            )
+        })?;
+
+    Ok((selected_model, provider))
+}
+
+fn generated_scripts_dir() -> PathBuf {
+    PathBuf::from(shellexpand::tilde(AI_SCRIPT_OUTPUT_DIR).as_ref())
+}
+
+fn split_fence_header_and_body(fence: &str) -> (&str, &str) {
+    match fence.find('\n') {
+        Some(newline_index) => (&fence[..newline_index], &fence[newline_index + 1..]),
+        None => ("", fence),
+    }
+}
+
+fn extract_fenced_code(response: &str, preferred_languages: Option<&[&str]>) -> Option<String> {
+    let mut remaining = response;
+
+    while let Some(start) = remaining.find("```") {
+        let after_start = &remaining[start + 3..];
+        let Some(end) = after_start.find("```") else {
+            break;
+        };
+
+        let fence_contents = &after_start[..end];
+        let (header, body) = split_fence_header_and_body(fence_contents);
+        let language = header
+            .trim()
+            .split(|c: char| c.is_whitespace() || c == '{')
+            .next()
+            .unwrap_or("")
+            .to_ascii_lowercase();
+        let code = body.trim();
+
+        if !code.is_empty() {
+            match preferred_languages {
+                Some(preferred) => {
+                    if preferred.iter().any(|candidate| *candidate == language) {
+                        return Some(code.to_string());
+                    }
+                }
+                None => return Some(code.to_string()),
+            }
+        }
+
+        remaining = &after_start[end + 3..];
+    }
+
+    None
+}
+
+fn extract_script_code(response: &str) -> String {
+    const PREFERRED_LANGUAGES: [&str; 6] = ["typescript", "ts", "javascript", "js", "tsx", "jsx"];
+
+    extract_fenced_code(response, Some(&PREFERRED_LANGUAGES))
+        .or_else(|| extract_fenced_code(response, None))
+        .unwrap_or_else(|| response.trim().to_string())
+}
+
+fn slugify_script_name(prompt: &str) -> String {
+    let mut slug = String::new();
+    let mut last_was_hyphen = false;
+
+    for character in prompt.to_ascii_lowercase().chars() {
+        if character.is_ascii_alphanumeric() {
+            slug.push(character);
+            last_was_hyphen = false;
+        } else if matches!(character, ' ' | '_' | '-') {
+            if !slug.is_empty() && !last_was_hyphen {
+                slug.push('-');
+                last_was_hyphen = true;
+            }
+        }
+    }
+
+    while slug.ends_with('-') {
+        slug.pop();
+    }
+
+    if slug.len() > AI_SCRIPT_MAX_SLUG_LEN {
+        slug.truncate(AI_SCRIPT_MAX_SLUG_LEN);
+        while slug.ends_with('-') {
+            slug.pop();
+        }
+    }
+
+    if slug.is_empty() {
+        AI_SCRIPT_DEFAULT_SLUG.to_string()
+    } else {
+        slug
+    }
+}
+
+fn slug_to_title(slug: &str) -> String {
+    slug.split('-')
+        .filter(|segment| !segment.is_empty())
+        .map(|segment| {
+            let mut chars = segment.chars();
+            match chars.next() {
+                Some(first) => first.to_uppercase().collect::<String>() + chars.as_str(),
+                None => String::new(),
+            }
+        })
+        .collect::<Vec<_>>()
+        .join(" ")
+}
+
+fn description_from_prompt(prompt: &str) -> String {
+    let normalized = prompt.split_whitespace().collect::<Vec<_>>().join(" ");
+    if normalized.is_empty() {
+        return "AI-generated Script Kit script".to_string();
+    }
+
+    let mut shortened = normalized;
+    if shortened.chars().count() > 110 {
+        shortened = format!("{}...", shortened.chars().take(107).collect::<String>());
+    }
+    shortened
+}
+
+fn has_kit_import(script: &str) -> bool {
+    script.contains("import \"@johnlindquist/kit\";")
+        || script.contains("import '@johnlindquist/kit';")
+        || script.contains("import \"@scriptkit/sdk\";")
+        || script.contains("import '@scriptkit/sdk';")
+}
+
+fn enforce_script_kit_conventions(script: &str, prompt: &str, slug: &str) -> String {
+    let mut prefix_lines: Vec<String> = Vec::new();
+    let trimmed_script = script.trim();
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Name:"))
+    {
+        prefix_lines.push(format!("// Name: {}", slug_to_title(slug)));
+    }
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Description:"))
+    {
+        prefix_lines.push(format!("// Description: {}", description_from_prompt(prompt)));
+    }
+
+    if !has_kit_import(trimmed_script) {
+        prefix_lines.push("import \"@johnlindquist/kit\";".to_string());
+    }
+
+    let mut output = String::new();
+    if !prefix_lines.is_empty() {
+        output.push_str(&prefix_lines.join("\n"));
+        output.push_str("\n\n");
+    }
+
+    output.push_str(trimmed_script);
+    if !output.ends_with('\n') {
+        output.push('\n');
+    }
+    output
+}
+
+fn write_generated_script(slug: &str, script_content: &str) -> Result<PathBuf> {
+    write_generated_script_in_dir(&generated_scripts_dir(), slug, script_content)
+}
+
+fn write_generated_script_in_dir(output_dir: &Path, slug: &str, script_content: &str) -> Result<PathBuf> {
+    fs::create_dir_all(output_dir)
+        .with_context(|| format!("Failed to create output dir: {}", output_dir.display()))?;
+
+    for suffix in 0usize.. {
+        let candidate = if suffix == 0 {
+            slug.to_string()
+        } else {
+            format!("{slug}-{suffix}")
+        };
+        let path = output_dir.join(format!("{}.ts", candidate));
+        match OpenOptions::new().write(true).create_new(true).open(&path) {
+            Ok(mut file) => {
+                file.write_all(script_content.as_bytes())
+                    .with_context(|| format!("Failed writing generated script to {}", path.display()))?;
+                return Ok(path);
+            }
+            Err(error) if error.kind() == ErrorKind::AlreadyExists => continue,
+            Err(error) => {
+                return Err(error).with_context(|| {
+                    format!(
+                        "Failed creating generated script file {} (slug={})",
+                        path.display(),
+                        slug
+                    )
+                });
+            }
+        }
+    }
+
+    unreachable!("suffix loop should eventually create a unique script filename")
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+    use tempfile::tempdir;
+
+    #[test]
+    fn test_slugify_script_name_handles_spaces_and_symbols() {
+        assert_eq!(slugify_script_name("Build: API Client!"), "build-api-client");
+        assert_eq!(slugify_script_name("  ___  "), "ai-script");
+    }
+
+    #[test]
+    fn test_extract_script_code_prefers_typescript_fence_when_multiple_blocks_exist() {
+        let response = r#"
+Here's one idea:
+```markdown
+Not code
+```
+```typescript
+await div("hello");
+```
+"#;
+        assert_eq!(extract_script_code(response), "await div(\"hello\");");
+    }
+
+    #[test]
+    fn test_extract_script_code_falls_back_to_first_fenced_block() {
+        let response = r#"
+```python
+print("hello")
+```
+"#;
+        assert_eq!(extract_script_code(response), "print(\"hello\")");
+    }
+
+    #[test]
+    fn test_extract_script_code_returns_trimmed_response_when_no_fence_exists() {
+        let response = "const answer = 42;";
+        assert_eq!(extract_script_code(response), "const answer = 42;");
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_adds_missing_metadata_and_import() {
+        let script = "const name = await arg(\"Name?\");";
+        let output = enforce_script_kit_conventions(script, "Ask for user name", "ask-user-name");
+
+        assert!(output.contains("// Name: Ask User Name"));
+        assert!(output.contains("// Description: Ask for user name"));
+        assert!(output.contains("import \"@johnlindquist/kit\";"));
+        assert!(output.contains("await arg(\"Name?\");"));
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_keeps_existing_metadata_and_import() {
+        let script = r#"// Name: Existing
+// Description: Existing description
+import "@johnlindquist/kit";
+
+await div("ready");
+"#;
+        let output = enforce_script_kit_conventions(script, "ignored", "ignored");
+
+        assert_eq!(
+            output.matches("// Name:").count(),
+            1,
+            "should not duplicate existing Name metadata"
+        );
+        assert_eq!(
+            output.matches("// Description:").count(),
+            1,
+            "should not duplicate existing Description metadata"
+        );
+        assert_eq!(
+            output.matches("import \"@johnlindquist/kit\";").count(),
+            1,
+            "should not duplicate existing import"
+        );
+    }
+
+    #[test]
+    fn test_write_generated_script_in_dir_appends_numeric_suffix_for_collisions() {
+        let temp_dir = tempdir().unwrap();
+        let first = write_generated_script_in_dir(temp_dir.path(), "my-script", "a").unwrap();
+        let second = write_generated_script_in_dir(temp_dir.path(), "my-script", "b").unwrap();
+
+        assert_eq!(first.file_name().unwrap(), "my-script.ts");
+        assert_eq!(second.file_name().unwrap(), "my-script-1.ts");
+    }
+}
diff --git a/src/builtins/part_000.rs b/src/builtins/part_000.rs
index d6b9c2a9b35b40c5005dbb9f65147f528702cb9e..5f6d27d28d72e51126d10d8beccf931c689ef2bb
--- a/src/builtins/part_000.rs
+++ b/src/builtins/part_000.rs
@@ -96,6 +96,8 @@
     OpenAi,
     NewConversation,
     ClearConversation,
+    /// Generate a new Script Kit script from the main prompt text
+    GenerateScript,
     /// Send a screenshot of the entire screen to AI Chat
     SendScreenToAi,
     /// Send a screenshot of the focused window to AI Chat
diff --git a/src/builtins/part_001_entries/entries_002.rs b/src/builtins/part_001_entries/entries_002.rs
index 6d1c9334f0ccaf0aab48582aaf42dcb129e1cb6e..72b318c66aeaf124359f4ecd276dae0350287328
--- a/src/builtins/part_001_entries/entries_002.rs
+++ b/src/builtins/part_001_entries/entries_002.rs
@@ -61,6 +61,17 @@
     ));
 
     entries.push(BuiltInEntry::new_with_icon(
+        "builtin-generate-script-with-ai",
+        "Generate Script with AI",
+        "Generate a Script Kit script from your current prompt text",
+        vec![
+            "generate", "script", "ai", "create", "code", "typescript", "shift", "tab",
+        ],
+        BuiltInFeature::AiCommand(AiCommandType::GenerateScript),
+        "ðŸ§ ",
+    ));
+
+    entries.push(BuiltInEntry::new_with_icon(
         "builtin-send-screen-to-ai",
         "Send Screen to AI Chat",
         "Capture the full screen and send it to AI Chat",


thinking
**Inspecting AI command handling**
exec
/bin/zsh -lc 'rg -n "AiCommand|OpenAiChat|generate_script_from_prompt|open_in_editor|AiCommandType" src/app_execute/builtin_execution.rs' in /Users/johnlindquist/dev/script-kit-gpui succeeded in 51ms:
542:            builtins::BuiltInFeature::AiCommand(cmd_type) => {
545:                use builtins::AiCommandType;
553:                    AiCommandType::OpenAi | AiCommandType::NewConversation => {
568:                    AiCommandType::ClearConversation => {
617:                    AiCommandType::SendScreenToAi => {
667:                    AiCommandType::SendFocusedWindowToAi => {
717:                    AiCommandType::SendSelectedTextToAi => {
771:                    AiCommandType::SendBrowserTabToAi => {
808:                    AiCommandType::SendScreenAreaToAi => {
821:                    AiCommandType::CreateAiPreset
822:                    | AiCommandType::ImportAiPresets
823:                    | AiCommandType::SearchAiPresets => {
870:                        if let Err(e) = script_creation::open_in_editor(&path, &self.config) {
file update:
diff --git a/src/ai/mod.rs b/src/ai/mod.rs
index a420b1a5faf59506acdb7caf60681c153a3f9bb6..9a73e9491862633b325b2c52b51a3e20395ff85c
--- a/src/ai/mod.rs
+++ b/src/ai/mod.rs
@@ -37,6 +37,7 @@
 pub(crate) mod providers;
 pub(crate) mod sdk_handlers;
 pub(crate) mod session;
+pub(crate) mod script_generation;
 pub(crate) mod storage;
 pub(crate) mod window;
 
@@ -44,6 +45,7 @@
 pub use self::config::{DetectedKeys, ModelInfo, ProviderConfig};
 pub use self::model::{Chat, ChatId, ChatSource, Message, MessageRole};
 pub use self::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+pub use self::script_generation::{generate_script_from_prompt, GeneratedScriptOutput};
 pub use self::sdk_handlers::try_handle_ai_message;
 pub use self::storage::{
     clear_all_chats, create_chat, delete_chat, get_all_chats, get_chat, get_chat_messages,
diff --git a/src/ai/script_generation.rs b/src/ai/script_generation.rs
new file mode 100644
index 0000000000000000000000000000000000000000..7f2ec8e7576ed50cd10f7aea31a6522875ef667a
--- /dev/null
+++ b/src/ai/script_generation.rs
@@ -0,0 +1,417 @@
+use anyhow::{Context, Result};
+use std::fs::{self, OpenOptions};
+use std::io::{ErrorKind, Write};
+use std::path::{Path, PathBuf};
+use std::sync::Arc;
+
+use super::config::ModelInfo;
+use super::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+
+const AI_SCRIPT_OUTPUT_DIR: &str = "~/.kenv/scripts";
+const AI_SCRIPT_DEFAULT_SLUG: &str = "ai-script";
+const AI_SCRIPT_MAX_SLUG_LEN: usize = 64;
+
+const AI_SCRIPT_GENERATION_SYSTEM_PROMPT: &str = r#"You write production-ready Script Kit scripts.
+
+Return ONLY TypeScript source code for one Script Kit script. Do not include explanations.
+
+Required output conventions:
+1) Include metadata comments at the top:
+   // Name: <clear title>
+   // Description: <one-line summary>
+2) Include: import "@johnlindquist/kit";
+3) Use await arg() for user input when useful.
+4) Use await div() for display output when useful.
+5) Keep the script runnable as-is with sensible defaults and light error handling."#;
+
+#[derive(Debug, Clone)]
+pub struct GeneratedScriptOutput {
+    pub path: PathBuf,
+    pub slug: String,
+    pub model_id: String,
+    pub provider_id: String,
+}
+
+pub fn generate_script_from_prompt(
+    prompt: &str,
+    config: Option<&crate::config::Config>,
+) -> Result<GeneratedScriptOutput> {
+    let normalized_prompt = prompt.trim();
+    if normalized_prompt.is_empty() {
+        anyhow::bail!("AI script generation requires a non-empty prompt");
+    }
+
+    let registry = ProviderRegistry::from_environment_with_config(config);
+    if !registry.has_any_provider() {
+        anyhow::bail!(
+            "No AI providers configured. Configure an API key first (Vercel, OpenAI, Anthropic, etc.)."
+        );
+    }
+
+    let (selected_model, provider) = select_generation_model(&registry)?;
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=provider_ready model_id={} provider_id={} prompt_len={}",
+            selected_model.id,
+            selected_model.provider,
+            normalized_prompt.len()
+        ),
+    );
+
+    let messages = vec![
+        ProviderMessage::system(AI_SCRIPT_GENERATION_SYSTEM_PROMPT),
+        ProviderMessage::user(format!(
+            "Generate a Script Kit script for this user request:\n\n{}",
+            normalized_prompt
+        )),
+    ];
+
+    let raw_response = provider
+        .send_message(&messages, &selected_model.id)
+        .with_context(|| {
+            format!(
+                "AI script generation failed (attempted=send_message, model_id={}, provider_id={})",
+                selected_model.id, selected_model.provider
+            )
+        })?;
+
+    let extracted = extract_script_code(&raw_response);
+    if extracted.trim().is_empty() {
+        anyhow::bail!(
+            "AI returned an empty response for script generation (state=empty_response)"
+        );
+    }
+
+    let slug = slugify_script_name(normalized_prompt);
+    let finalized = enforce_script_kit_conventions(&extracted, normalized_prompt, &slug);
+    let path = write_generated_script(&slug, &finalized).with_context(|| {
+        format!(
+            "Failed writing AI-generated script (state=write_failed, slug={})",
+            slug
+        )
+    })?;
+
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=script_written path={} slug={}",
+            path.display(),
+            slug
+        ),
+    );
+
+    Ok(GeneratedScriptOutput {
+        path,
+        slug,
+        model_id: selected_model.id,
+        provider_id: selected_model.provider,
+    })
+}
+
+fn select_generation_model(registry: &ProviderRegistry) -> Result<(ModelInfo, Arc<dyn AiProvider>)> {
+    let models = registry.get_all_models();
+    let selected_model = models
+        .iter()
+        .find(|model| model.provider.eq_ignore_ascii_case("vercel"))
+        .or_else(|| models.first())
+        .cloned()
+        .context("No AI models available in provider registry")?;
+
+    let provider = registry
+        .find_provider_for_model(&selected_model.id)
+        .cloned()
+        .with_context(|| {
+            format!(
+                "No provider found for selected model '{}' (state=provider_missing)",
+                selected_model.id
+            )
+        })?;
+
+    Ok((selected_model, provider))
+}
+
+fn generated_scripts_dir() -> PathBuf {
+    PathBuf::from(shellexpand::tilde(AI_SCRIPT_OUTPUT_DIR).as_ref())
+}
+
+fn split_fence_header_and_body(fence: &str) -> (&str, &str) {
+    match fence.find('\n') {
+        Some(newline_index) => (&fence[..newline_index], &fence[newline_index + 1..]),
+        None => ("", fence),
+    }
+}
+
+fn extract_fenced_code(response: &str, preferred_languages: Option<&[&str]>) -> Option<String> {
+    let mut remaining = response;
+
+    while let Some(start) = remaining.find("```") {
+        let after_start = &remaining[start + 3..];
+        let Some(end) = after_start.find("```") else {
+            break;
+        };
+
+        let fence_contents = &after_start[..end];
+        let (header, body) = split_fence_header_and_body(fence_contents);
+        let language = header
+            .trim()
+            .split(|c: char| c.is_whitespace() || c == '{')
+            .next()
+            .unwrap_or("")
+            .to_ascii_lowercase();
+        let code = body.trim();
+
+        if !code.is_empty() {
+            match preferred_languages {
+                Some(preferred) => {
+                    if preferred.iter().any(|candidate| *candidate == language) {
+                        return Some(code.to_string());
+                    }
+                }
+                None => return Some(code.to_string()),
+            }
+        }
+
+        remaining = &after_start[end + 3..];
+    }
+
+    None
+}
+
+fn extract_script_code(response: &str) -> String {
+    const PREFERRED_LANGUAGES: [&str; 6] = ["typescript", "ts", "javascript", "js", "tsx", "jsx"];
+
+    extract_fenced_code(response, Some(&PREFERRED_LANGUAGES))
+        .or_else(|| extract_fenced_code(response, None))
+        .unwrap_or_else(|| response.trim().to_string())
+}
+
+fn slugify_script_name(prompt: &str) -> String {
+    let mut slug = String::new();
+    let mut last_was_hyphen = false;
+
+    for character in prompt.to_ascii_lowercase().chars() {
+        if character.is_ascii_alphanumeric() {
+            slug.push(character);
+            last_was_hyphen = false;
+        } else if matches!(character, ' ' | '_' | '-') {
+            if !slug.is_empty() && !last_was_hyphen {
+                slug.push('-');
+                last_was_hyphen = true;
+            }
+        }
+    }
+
+    while slug.ends_with('-') {
+        slug.pop();
+    }
+
+    if slug.len() > AI_SCRIPT_MAX_SLUG_LEN {
+        slug.truncate(AI_SCRIPT_MAX_SLUG_LEN);
+        while slug.ends_with('-') {
+            slug.pop();
+        }
+    }
+
+    if slug.is_empty() {
+        AI_SCRIPT_DEFAULT_SLUG.to_string()
+    } else {
+        slug
+    }
+}
+
+fn slug_to_title(slug: &str) -> String {
+    slug.split('-')
+        .filter(|segment| !segment.is_empty())
+        .map(|segment| {
+            let mut chars = segment.chars();
+            match chars.next() {
+                Some(first) => first.to_uppercase().collect::<String>() + chars.as_str(),
+                None => String::new(),
+            }
+        })
+        .collect::<Vec<_>>()
+        .join(" ")
+}
+
+fn description_from_prompt(prompt: &str) -> String {
+    let normalized = prompt.split_whitespace().collect::<Vec<_>>().join(" ");
+    if normalized.is_empty() {
+        return "AI-generated Script Kit script".to_string();
+    }
+
+    let mut shortened = normalized;
+    if shortened.chars().count() > 110 {
+        shortened = format!("{}...", shortened.chars().take(107).collect::<String>());
+    }
+    shortened
+}
+
+fn has_kit_import(script: &str) -> bool {
+    script.contains("import \"@johnlindquist/kit\";")
+        || script.contains("import '@johnlindquist/kit';")
+        || script.contains("import \"@scriptkit/sdk\";")
+        || script.contains("import '@scriptkit/sdk';")
+}
+
+fn enforce_script_kit_conventions(script: &str, prompt: &str, slug: &str) -> String {
+    let mut prefix_lines: Vec<String> = Vec::new();
+    let trimmed_script = script.trim();
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Name:"))
+    {
+        prefix_lines.push(format!("// Name: {}", slug_to_title(slug)));
+    }
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Description:"))
+    {
+        prefix_lines.push(format!("// Description: {}", description_from_prompt(prompt)));
+    }
+
+    if !has_kit_import(trimmed_script) {
+        prefix_lines.push("import \"@johnlindquist/kit\";".to_string());
+    }
+
+    let mut output = String::new();
+    if !prefix_lines.is_empty() {
+        output.push_str(&prefix_lines.join("\n"));
+        output.push_str("\n\n");
+    }
+
+    output.push_str(trimmed_script);
+    if !output.ends_with('\n') {
+        output.push('\n');
+    }
+    output
+}
+
+fn write_generated_script(slug: &str, script_content: &str) -> Result<PathBuf> {
+    write_generated_script_in_dir(&generated_scripts_dir(), slug, script_content)
+}
+
+fn write_generated_script_in_dir(output_dir: &Path, slug: &str, script_content: &str) -> Result<PathBuf> {
+    fs::create_dir_all(output_dir)
+        .with_context(|| format!("Failed to create output dir: {}", output_dir.display()))?;
+
+    for suffix in 0usize.. {
+        let candidate = if suffix == 0 {
+            slug.to_string()
+        } else {
+            format!("{slug}-{suffix}")
+        };
+        let path = output_dir.join(format!("{}.ts", candidate));
+        match OpenOptions::new().write(true).create_new(true).open(&path) {
+            Ok(mut file) => {
+                file.write_all(script_content.as_bytes())
+                    .with_context(|| format!("Failed writing generated script to {}", path.display()))?;
+                return Ok(path);
+            }
+            Err(error) if error.kind() == ErrorKind::AlreadyExists => continue,
+            Err(error) => {
+                return Err(error).with_context(|| {
+                    format!(
+                        "Failed creating generated script file {} (slug={})",
+                        path.display(),
+                        slug
+                    )
+                });
+            }
+        }
+    }
+
+    unreachable!("suffix loop should eventually create a unique script filename")
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+    use tempfile::tempdir;
+
+    #[test]
+    fn test_slugify_script_name_handles_spaces_and_symbols() {
+        assert_eq!(slugify_script_name("Build: API Client!"), "build-api-client");
+        assert_eq!(slugify_script_name("  ___  "), "ai-script");
+    }
+
+    #[test]
+    fn test_extract_script_code_prefers_typescript_fence_when_multiple_blocks_exist() {
+        let response = r#"
+Here's one idea:
+```markdown
+Not code
+```
+```typescript
+await div("hello");
+```
+"#;
+        assert_eq!(extract_script_code(response), "await div(\"hello\");");
+    }
+
+    #[test]
+    fn test_extract_script_code_falls_back_to_first_fenced_block() {
+        let response = r#"
+```python
+print("hello")
+```
+"#;
+        assert_eq!(extract_script_code(response), "print(\"hello\")");
+    }
+
+    #[test]
+    fn test_extract_script_code_returns_trimmed_response_when_no_fence_exists() {
+        let response = "const answer = 42;";
+        assert_eq!(extract_script_code(response), "const answer = 42;");
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_adds_missing_metadata_and_import() {
+        let script = "const name = await arg(\"Name?\");";
+        let output = enforce_script_kit_conventions(script, "Ask for user name", "ask-user-name");
+
+        assert!(output.contains("// Name: Ask User Name"));
+        assert!(output.contains("// Description: Ask for user name"));
+        assert!(output.contains("import \"@johnlindquist/kit\";"));
+        assert!(output.contains("await arg(\"Name?\");"));
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_keeps_existing_metadata_and_import() {
+        let script = r#"// Name: Existing
+// Description: Existing description
+import "@johnlindquist/kit";
+
+await div("ready");
+"#;
+        let output = enforce_script_kit_conventions(script, "ignored", "ignored");
+
+        assert_eq!(
+            output.matches("// Name:").count(),
+            1,
+            "should not duplicate existing Name metadata"
+        );
+        assert_eq!(
+            output.matches("// Description:").count(),
+            1,
+            "should not duplicate existing Description metadata"
+        );
+        assert_eq!(
+            output.matches("import \"@johnlindquist/kit\";").count(),
+            1,
+            "should not duplicate existing import"
+        );
+    }
+
+    #[test]
+    fn test_write_generated_script_in_dir_appends_numeric_suffix_for_collisions() {
+        let temp_dir = tempdir().unwrap();
+        let first = write_generated_script_in_dir(temp_dir.path(), "my-script", "a").unwrap();
+        let second = write_generated_script_in_dir(temp_dir.path(), "my-script", "b").unwrap();
+
+        assert_eq!(first.file_name().unwrap(), "my-script.ts");
+        assert_eq!(second.file_name().unwrap(), "my-script-1.ts");
+    }
+}
diff --git a/src/builtins/part_000.rs b/src/builtins/part_000.rs
index d6b9c2a9b35b40c5005dbb9f65147f528702cb9e..5f6d27d28d72e51126d10d8beccf931c689ef2bb
--- a/src/builtins/part_000.rs
+++ b/src/builtins/part_000.rs
@@ -96,6 +96,8 @@
     OpenAi,
     NewConversation,
     ClearConversation,
+    /// Generate a new Script Kit script from the main prompt text
+    GenerateScript,
     /// Send a screenshot of the entire screen to AI Chat
     SendScreenToAi,
     /// Send a screenshot of the focused window to AI Chat
diff --git a/src/builtins/part_001_entries/entries_002.rs b/src/builtins/part_001_entries/entries_002.rs
index 6d1c9334f0ccaf0aab48582aaf42dcb129e1cb6e..72b318c66aeaf124359f4ecd276dae0350287328
--- a/src/builtins/part_001_entries/entries_002.rs
+++ b/src/builtins/part_001_entries/entries_002.rs
@@ -61,6 +61,17 @@
     ));
 
     entries.push(BuiltInEntry::new_with_icon(
+        "builtin-generate-script-with-ai",
+        "Generate Script with AI",
+        "Generate a Script Kit script from your current prompt text",
+        vec![
+            "generate", "script", "ai", "create", "code", "typescript", "shift", "tab",
+        ],
+        BuiltInFeature::AiCommand(AiCommandType::GenerateScript),
+        "ðŸ§ ",
+    ));
+
+    entries.push(BuiltInEntry::new_with_icon(
         "builtin-send-screen-to-ai",
         "Send Screen to AI Chat",
         "Capture the full screen and send it to AI Chat",


thinking
**Inspecting AI section integration**
codex
I found the AI command match in `builtin_execution`; Iâ€™m reviewing that block now to confirm whether `GenerateScript` is fully wired and whether prompt capture/reset behavior is correct.
exec
/bin/zsh -lc "sed -n '500,940p' src/app_execute/builtin_execution.rs" in /Users/johnlindquist/dev/script-kit-gpui succeeded in 51ms:
            }

            // NOTE: Window Actions removed - now handled by window-management extension
            // SDK tileWindow() still works via protocol messages in execute_script.rs

            // =========================================================================
            // Notes Commands
            // =========================================================================

            builtins::BuiltInFeature::NotesCommand(cmd_type) => {
                logging::log("EXEC", &format!("Executing notes command: {:?}", cmd_type));

                use builtins::NotesCommandType;

                // All notes commands: reset state, hide main window, open notes
                script_kit_gpui::set_main_window_visible(false);
                self.reset_to_script_list(cx);
                platform::hide_main_window();

                let result = match cmd_type {
file update:
diff --git a/src/ai/mod.rs b/src/ai/mod.rs
index a420b1a5faf59506acdb7caf60681c153a3f9bb6..9a73e9491862633b325b2c52b51a3e20395ff85c
--- a/src/ai/mod.rs
+++ b/src/ai/mod.rs
@@ -37,6 +37,7 @@
 pub(crate) mod providers;
 pub(crate) mod sdk_handlers;
 pub(crate) mod session;
+pub(crate) mod script_generation;
 pub(crate) mod storage;
 pub(crate) mod window;
 
@@ -44,6 +45,7 @@
 pub use self::config::{DetectedKeys, ModelInfo, ProviderConfig};
 pub use self::model::{Chat, ChatId, ChatSource, Message, MessageRole};
 pub use self::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+pub use self::script_generation::{generate_script_from_prompt, GeneratedScriptOutput};
 pub use self::sdk_handlers::try_handle_ai_message;
 pub use self::storage::{
     clear_all_chats, create_chat, delete_chat, get_all_chats, get_chat, get_chat_messages,
diff --git a/src/ai/script_generation.rs b/src/ai/script_generation.rs
new file mode 100644
index 0000000000000000000000000000000000000000..7f2ec8e7576ed50cd10f7aea31a6522875ef667a
--- /dev/null
+++ b/src/ai/script_generation.rs
@@ -0,0 +1,417 @@
+use anyhow::{Context, Result};
+use std::fs::{self, OpenOptions};
+use std::io::{ErrorKind, Write};
+use std::path::{Path, PathBuf};
+use std::sync::Arc;
+
+use super::config::ModelInfo;
+use super::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+
+const AI_SCRIPT_OUTPUT_DIR: &str = "~/.kenv/scripts";
+const AI_SCRIPT_DEFAULT_SLUG: &str = "ai-script";
+const AI_SCRIPT_MAX_SLUG_LEN: usize = 64;
+
+const AI_SCRIPT_GENERATION_SYSTEM_PROMPT: &str = r#"You write production-ready Script Kit scripts.
+
+Return ONLY TypeScript source code for one Script Kit script. Do not include explanations.
+
+Required output conventions:
+1) Include metadata comments at the top:
+   // Name: <clear title>
+   // Description: <one-line summary>
+2) Include: import "@johnlindquist/kit";
+3) Use await arg() for user input when useful.
+4) Use await div() for display output when useful.
+5) Keep the script runnable as-is with sensible defaults and light error handling."#;
+
+#[derive(Debug, Clone)]
+pub struct GeneratedScriptOutput {
+    pub path: PathBuf,
+    pub slug: String,
+    pub model_id: String,
+    pub provider_id: String,
+}
+
+pub fn generate_script_from_prompt(
+    prompt: &str,
+    config: Option<&crate::config::Config>,
+) -> Result<GeneratedScriptOutput> {
+    let normalized_prompt = prompt.trim();
+    if normalized_prompt.is_empty() {
+        anyhow::bail!("AI script generation requires a non-empty prompt");
+    }
+
+    let registry = ProviderRegistry::from_environment_with_config(config);
+    if !registry.has_any_provider() {
+        anyhow::bail!(
+            "No AI providers configured. Configure an API key first (Vercel, OpenAI, Anthropic, etc.)."
+        );
+    }
+
+    let (selected_model, provider) = select_generation_model(&registry)?;
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=provider_ready model_id={} provider_id={} prompt_len={}",
+            selected_model.id,
+            selected_model.provider,
+            normalized_prompt.len()
+        ),
+    );
+
+    let messages = vec![
+        ProviderMessage::system(AI_SCRIPT_GENERATION_SYSTEM_PROMPT),
+        ProviderMessage::user(format!(
+            "Generate a Script Kit script for this user request:\n\n{}",
+            normalized_prompt
+        )),
+    ];
+
+    let raw_response = provider
+        .send_message(&messages, &selected_model.id)
+        .with_context(|| {
+            format!(
+                "AI script generation failed (attempted=send_message, model_id={}, provider_id={})",
+                selected_model.id, selected_model.provider
+            )
+        })?;
+
+    let extracted = extract_script_code(&raw_response);
+    if extracted.trim().is_empty() {
+        anyhow::bail!(
+            "AI returned an empty response for script generation (state=empty_response)"
+        );
+    }
+
+    let slug = slugify_script_name(normalized_prompt);
+    let finalized = enforce_script_kit_conventions(&extracted, normalized_prompt, &slug);
+    let path = write_generated_script(&slug, &finalized).with_context(|| {
+        format!(
+            "Failed writing AI-generated script (state=write_failed, slug={})",
+            slug
+        )
+    })?;
+
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=script_written path={} slug={}",
+            path.display(),
+            slug
+        ),
+    );
+
+    Ok(GeneratedScriptOutput {
+        path,
+        slug,
+        model_id: selected_model.id,
+        provider_id: selected_model.provider,
+    })
+}
+
+fn select_generation_model(registry: &ProviderRegistry) -> Result<(ModelInfo, Arc<dyn AiProvider>)> {
+    let models = registry.get_all_models();
+    let selected_model = models
+        .iter()
+        .find(|model| model.provider.eq_ignore_ascii_case("vercel"))
+        .or_else(|| models.first())
+        .cloned()
+        .context("No AI models available in provider registry")?;
+
+    let provider = registry
+        .find_provider_for_model(&selected_model.id)
+        .cloned()
+        .with_context(|| {
+            format!(
+                "No provider found for selected model '{}' (state=provider_missing)",
+                selected_model.id
+            )
+        })?;
+
+    Ok((selected_model, provider))
+}
+
+fn generated_scripts_dir() -> PathBuf {
+    PathBuf::from(shellexpand::tilde(AI_SCRIPT_OUTPUT_DIR).as_ref())
+}
+
+fn split_fence_header_and_body(fence: &str) -> (&str, &str) {
+    match fence.find('\n') {
+        Some(newline_index) => (&fence[..newline_index], &fence[newline_index + 1..]),
+        None => ("", fence),
+    }
+}
+
+fn extract_fenced_code(response: &str, preferred_languages: Option<&[&str]>) -> Option<String> {
+    let mut remaining = response;
+
+    while let Some(start) = remaining.find("```") {
+        let after_start = &remaining[start + 3..];
+        let Some(end) = after_start.find("```") else {
+            break;
+        };
+
+        let fence_contents = &after_start[..end];
+        let (header, body) = split_fence_header_and_body(fence_contents);
+        let language = header
+            .trim()
+            .split(|c: char| c.is_whitespace() || c == '{')
+            .next()
+            .unwrap_or("")
+            .to_ascii_lowercase();
+        let code = body.trim();
+
+        if !code.is_empty() {
+            match preferred_languages {
+                Some(preferred) => {
+                    if preferred.iter().any(|candidate| *candidate == language) {
+                        return Some(code.to_string());
+                    }
+                }
+                None => return Some(code.to_string()),
+            }
+        }
+
+        remaining = &after_start[end + 3..];
+    }
+
+    None
+}
+
+fn extract_script_code(response: &str) -> String {
+    const PREFERRED_LANGUAGES: [&str; 6] = ["typescript", "ts", "javascript", "js", "tsx", "jsx"];
+
+    extract_fenced_code(response, Some(&PREFERRED_LANGUAGES))
+        .or_else(|| extract_fenced_code(response, None))
+        .unwrap_or_else(|| response.trim().to_string())
+}
+
+fn slugify_script_name(prompt: &str) -> String {
+    let mut slug = String::new();
+    let mut last_was_hyphen = false;
+
+    for character in prompt.to_ascii_lowercase().chars() {
+        if character.is_ascii_alphanumeric() {
+            slug.push(character);
+            last_was_hyphen = false;
+        } else if matches!(character, ' ' | '_' | '-') {
+            if !slug.is_empty() && !last_was_hyphen {
+                slug.push('-');
+                last_was_hyphen = true;
+            }
+        }
+    }
+
+    while slug.ends_with('-') {
+        slug.pop();
+    }
+
+    if slug.len() > AI_SCRIPT_MAX_SLUG_LEN {
+        slug.truncate(AI_SCRIPT_MAX_SLUG_LEN);
+        while slug.ends_with('-') {
+            slug.pop();
+        }
+    }
+
+    if slug.is_empty() {
+        AI_SCRIPT_DEFAULT_SLUG.to_string()
+    } else {
+        slug
+    }
+}
+
+fn slug_to_title(slug: &str) -> String {
+    slug.split('-')
+        .filter(|segment| !segment.is_empty())
+        .map(|segment| {
+            let mut chars = segment.chars();
+            match chars.next() {
+                Some(first) => first.to_uppercase().collect::<String>() + chars.as_str(),
+                None => String::new(),
+            }
+        })
+        .collect::<Vec<_>>()
+        .join(" ")
+}
+
+fn description_from_prompt(prompt: &str) -> String {
+    let normalized = prompt.split_whitespace().collect::<Vec<_>>().join(" ");
+    if normalized.is_empty() {
+        return "AI-generated Script Kit script".to_string();
+    }
+
+    let mut shortened = normalized;
+    if shortened.chars().count() > 110 {
+        shortened = format!("{}...", shortened.chars().take(107).collect::<String>());
+    }
+    shortened
+}
+
+fn has_kit_import(script: &str) -> bool {
+    script.contains("import \"@johnlindquist/kit\";")
+        || script.contains("import '@johnlindquist/kit';")
+        || script.contains("import \"@scriptkit/sdk\";")
+        || script.contains("import '@scriptkit/sdk';")
+}
+
+fn enforce_script_kit_conventions(script: &str, prompt: &str, slug: &str) -> String {
+    let mut prefix_lines: Vec<String> = Vec::new();
+    let trimmed_script = script.trim();
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Name:"))
+    {
+        prefix_lines.push(format!("// Name: {}", slug_to_title(slug)));
+    }
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Description:"))
+    {
+        prefix_lines.push(format!("// Description: {}", description_from_prompt(prompt)));
+    }
+
+    if !has_kit_import(trimmed_script) {
+        prefix_lines.push("import \"@johnlindquist/kit\";".to_string());
+    }
+
+    let mut output = String::new();
+    if !prefix_lines.is_empty() {
+        output.push_str(&prefix_lines.join("\n"));
+        output.push_str("\n\n");
+    }
+
+    output.push_str(trimmed_script);
+    if !output.ends_with('\n') {
+        output.push('\n');
+    }
+    output
+}
+
+fn write_generated_script(slug: &str, script_content: &str) -> Result<PathBuf> {
+    write_generated_script_in_dir(&generated_scripts_dir(), slug, script_content)
+}
+
+fn write_generated_script_in_dir(output_dir: &Path, slug: &str, script_content: &str) -> Result<PathBuf> {
+    fs::create_dir_all(output_dir)
+        .with_context(|| format!("Failed to create output dir: {}", output_dir.display()))?;
+
+    for suffix in 0usize.. {
+        let candidate = if suffix == 0 {
+            slug.to_string()
+        } else {
+            format!("{slug}-{suffix}")
+        };
+        let path = output_dir.join(format!("{}.ts", candidate));
+        match OpenOptions::new().write(true).create_new(true).open(&path) {
+            Ok(mut file) => {
+                file.write_all(script_content.as_bytes())
+                    .with_context(|| format!("Failed writing generated script to {}", path.display()))?;
+                return Ok(path);
+            }
+            Err(error) if error.kind() == ErrorKind::AlreadyExists => continue,
+            Err(error) => {
+                return Err(error).with_context(|| {
+                    format!(
+                        "Failed creating generated script file {} (slug={})",
+                        path.display(),
+                        slug
+                    )
+                });
+            }
+        }
+    }
+
+    unreachable!("suffix loop should eventually create a unique script filename")
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+    use tempfile::tempdir;
+
+    #[test]
+    fn test_slugify_script_name_handles_spaces_and_symbols() {
+        assert_eq!(slugify_script_name("Build: API Client!"), "build-api-client");
+        assert_eq!(slugify_script_name("  ___  "), "ai-script");
+    }
+
+    #[test]
+    fn test_extract_script_code_prefers_typescript_fence_when_multiple_blocks_exist() {
+        let response = r#"
+Here's one idea:
+```markdown
+Not code
+```
+```typescript
+await div("hello");
+```
+"#;
+        assert_eq!(extract_script_code(response), "await div(\"hello\");");
+    }
+
+    #[test]
+    fn test_extract_script_code_falls_back_to_first_fenced_block() {
+        let response = r#"
+```python
+print("hello")
+```
+"#;
+        assert_eq!(extract_script_code(response), "print(\"hello\")");
+    }
+
+    #[test]
+    fn test_extract_script_code_returns_trimmed_response_when_no_fence_exists() {
+        let response = "const answer = 42;";
+        assert_eq!(extract_script_code(response), "const answer = 42;");
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_adds_missing_metadata_and_import() {
+        let script = "const name = await arg(\"Name?\");";
+        let output = enforce_script_kit_conventions(script, "Ask for user name", "ask-user-name");
+
+        assert!(output.contains("// Name: Ask User Name"));
+        assert!(output.contains("// Description: Ask for user name"));
+        assert!(output.contains("import \"@johnlindquist/kit\";"));
+        assert!(output.contains("await arg(\"Name?\");"));
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_keeps_existing_metadata_and_import() {
+        let script = r#"// Name: Existing
+// Description: Existing description
+import "@johnlindquist/kit";
+
+await div("ready");
+"#;
+        let output = enforce_script_kit_conventions(script, "ignored", "ignored");
+
+        assert_eq!(
+            output.matches("// Name:").count(),
+            1,
+            "should not duplicate existing Name metadata"
+        );
+        assert_eq!(
+            output.matches("// Description:").count(),
+            1,
+            "should not duplicate existing Description metadata"
+        );
+        assert_eq!(
+            output.matches("import \"@johnlindquist/kit\";").count(),
+            1,
+            "should not duplicate existing import"
+        );
+    }
+
+    #[test]
+    fn test_write_generated_script_in_dir_appends_numeric_suffix_for_collisions() {
+        let temp_dir = tempdir().unwrap();
+        let first = write_generated_script_in_dir(temp_dir.path(), "my-script", "a").unwrap();
+        let second = write_generated_script_in_dir(temp_dir.path(), "my-script", "b").unwrap();
+
+        assert_eq!(first.file_name().unwrap(), "my-script.ts");
+        assert_eq!(second.file_name().unwrap(), "my-script-1.ts");
+    }
+}
diff --git a/src/builtins/part_000.rs b/src/builtins/part_000.rs
index d6b9c2a9b35b40c5005dbb9f65147f528702cb9e..5f6d27d28d72e51126d10d8beccf931c689ef2bb
--- a/src/builtins/part_000.rs
+++ b/src/builtins/part_000.rs
@@ -96,6 +96,8 @@
     OpenAi,
     NewConversation,
     ClearConversation,
+    /// Generate a new Script Kit script from the main prompt text
+    GenerateScript,
     /// Send a screenshot of the entire screen to AI Chat
     SendScreenToAi,
     /// Send a screenshot of the focused window to AI Chat
diff --git a/src/builtins/part_001_entries/entries_002.rs b/src/builtins/part_001_entries/entries_002.rs
index 6d1c9334f0ccaf0aab48582aaf42dcb129e1cb6e..72b318c66aeaf124359f4ecd276dae0350287328
--- a/src/builtins/part_001_entries/entries_002.rs
+++ b/src/builtins/part_001_entries/entries_002.rs
@@ -61,6 +61,17 @@
     ));
 
     entries.push(BuiltInEntry::new_with_icon(
+        "builtin-generate-script-with-ai",
+        "Generate Script with AI",
+        "Generate a Script Kit script from your current prompt text",
+        vec![
+            "generate", "script", "ai", "create", "code", "typescript", "shift", "tab",
+        ],
+        BuiltInFeature::AiCommand(AiCommandType::GenerateScript),
+        "ðŸ§ ",
+    ));
+
+    entries.push(BuiltInEntry::new_with_icon(
         "builtin-send-screen-to-ai",
         "Send Screen to AI Chat",
         "Capture the full screen and send it to AI Chat",


thinking
**Identifying compile errors in AI command handling**
exec
/bin/zsh -lc "sed -n '1,220p' src/builtins/tests/part_000.rs" in /Users/johnlindquist/dev/script-kit-gpuiexec
/bin/zsh -lc "sed -n '1,180p' src/builtins/part_000.rs" in /Users/johnlindquist/dev/script-kit-gpuiexec
/bin/zsh -lc "sed -n '1,220p' src/builtins/part_001_entries/entries_002.rs" in /Users/johnlindquist/dev/script-kit-gpui succeeded in 51ms:
    use super::*;
    use crate::config::BuiltInConfig;
    #[test]
    fn test_builtin_config_default() {
        let config = BuiltInConfig::default();
        assert!(config.clipboard_history);
        assert!(config.app_launcher);
        assert!(config.window_switcher);
    }
    #[test]
    fn test_builtin_config_custom() {
        let config = BuiltInConfig {
            clipboard_history: false,
            app_launcher: true,
            window_switcher: false,
        };
        assert!(!config.clipboard_history);
        assert!(config.app_launcher);
        assert!(!config.window_switcher);
    }
 succeeded in 51ms:
{
    // Notes Commands
    // =========================================================================

    entries.push(BuiltInEntry::new_with_icon(
        "builtin-open-notes",
        "Open Notes",
        "Open the Notes window",
        vec!["open", "notes", "window", "note"],
        BuiltInFeature::NotesCommand(NotesCommandType::OpenNotes),
        "ðŸ“",
    ));

    entries.push(BuiltInEntry::new_with_icon(
        "builtin-new-note",
        "New Note",
        "Create a new note",
        vec!["new", "note", "create"],
        BuiltInFeature::NotesCommand(NotesCommandType::NewNote),
        "ðŸ“",
 succeeded in 51ms:
use crate::config::BuiltInConfig;
use crate::menu_bar::MenuBarItem;
use tracing::debug;
// ============================================================================
// Command Type Enums
// ============================================================================

/// System action types for macOS system commands
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum SystemActionType {
    // Power management
    EmptyTrash,
    LockScreen,
    Sleep,
    Restart,
    ShutDown,
    LogOut,

    // UI controls
    ToggleDarkMode,
file update:
diff --git a/src/ai/mod.rs b/src/ai/mod.rs
index a420b1a5faf59506acdb7caf60681c153a3f9bb6..9a73e9491862633b325b2c52b51a3e20395ff85c
--- a/src/ai/mod.rs
+++ b/src/ai/mod.rs
@@ -37,6 +37,7 @@
 pub(crate) mod providers;
 pub(crate) mod sdk_handlers;
 pub(crate) mod session;
+pub(crate) mod script_generation;
 pub(crate) mod storage;
 pub(crate) mod window;
 
@@ -44,6 +45,7 @@
 pub use self::config::{DetectedKeys, ModelInfo, ProviderConfig};
 pub use self::model::{Chat, ChatId, ChatSource, Message, MessageRole};
 pub use self::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+pub use self::script_generation::{generate_script_from_prompt, GeneratedScriptOutput};
 pub use self::sdk_handlers::try_handle_ai_message;
 pub use self::storage::{
     clear_all_chats, create_chat, delete_chat, get_all_chats, get_chat, get_chat_messages,
diff --git a/src/ai/script_generation.rs b/src/ai/script_generation.rs
new file mode 100644
index 0000000000000000000000000000000000000000..7f2ec8e7576ed50cd10f7aea31a6522875ef667a
--- /dev/null
+++ b/src/ai/script_generation.rs
@@ -0,0 +1,417 @@
+use anyhow::{Context, Result};
+use std::fs::{self, OpenOptions};
+use std::io::{ErrorKind, Write};
+use std::path::{Path, PathBuf};
+use std::sync::Arc;
+
+use super::config::ModelInfo;
+use super::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+
+const AI_SCRIPT_OUTPUT_DIR: &str = "~/.kenv/scripts";
+const AI_SCRIPT_DEFAULT_SLUG: &str = "ai-script";
+const AI_SCRIPT_MAX_SLUG_LEN: usize = 64;
+
+const AI_SCRIPT_GENERATION_SYSTEM_PROMPT: &str = r#"You write production-ready Script Kit scripts.
+
+Return ONLY TypeScript source code for one Script Kit script. Do not include explanations.
+
+Required output conventions:
+1) Include metadata comments at the top:
+   // Name: <clear title>
+   // Description: <one-line summary>
+2) Include: import "@johnlindquist/kit";
+3) Use await arg() for user input when useful.
+4) Use await div() for display output when useful.
+5) Keep the script runnable as-is with sensible defaults and light error handling."#;
+
+#[derive(Debug, Clone)]
+pub struct GeneratedScriptOutput {
+    pub path: PathBuf,
+    pub slug: String,
+    pub model_id: String,
+    pub provider_id: String,
+}
+
+pub fn generate_script_from_prompt(
+    prompt: &str,
+    config: Option<&crate::config::Config>,
+) -> Result<GeneratedScriptOutput> {
+    let normalized_prompt = prompt.trim();
+    if normalized_prompt.is_empty() {
+        anyhow::bail!("AI script generation requires a non-empty prompt");
+    }
+
+    let registry = ProviderRegistry::from_environment_with_config(config);
+    if !registry.has_any_provider() {
+        anyhow::bail!(
+            "No AI providers configured. Configure an API key first (Vercel, OpenAI, Anthropic, etc.)."
+        );
+    }
+
+    let (selected_model, provider) = select_generation_model(&registry)?;
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=provider_ready model_id={} provider_id={} prompt_len={}",
+            selected_model.id,
+            selected_model.provider,
+            normalized_prompt.len()
+        ),
+    );
+
+    let messages = vec![
+        ProviderMessage::system(AI_SCRIPT_GENERATION_SYSTEM_PROMPT),
+        ProviderMessage::user(format!(
+            "Generate a Script Kit script for this user request:\n\n{}",
+            normalized_prompt
+        )),
+    ];
+
+    let raw_response = provider
+        .send_message(&messages, &selected_model.id)
+        .with_context(|| {
+            format!(
+                "AI script generation failed (attempted=send_message, model_id={}, provider_id={})",
+                selected_model.id, selected_model.provider
+            )
+        })?;
+
+    let extracted = extract_script_code(&raw_response);
+    if extracted.trim().is_empty() {
+        anyhow::bail!(
+            "AI returned an empty response for script generation (state=empty_response)"
+        );
+    }
+
+    let slug = slugify_script_name(normalized_prompt);
+    let finalized = enforce_script_kit_conventions(&extracted, normalized_prompt, &slug);
+    let path = write_generated_script(&slug, &finalized).with_context(|| {
+        format!(
+            "Failed writing AI-generated script (state=write_failed, slug={})",
+            slug
+        )
+    })?;
+
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=script_written path={} slug={}",
+            path.display(),
+            slug
+        ),
+    );
+
+    Ok(GeneratedScriptOutput {
+        path,
+        slug,
+        model_id: selected_model.id,
+        provider_id: selected_model.provider,
+    })
+}
+
+fn select_generation_model(registry: &ProviderRegistry) -> Result<(ModelInfo, Arc<dyn AiProvider>)> {
+    let models = registry.get_all_models();
+    let selected_model = models
+        .iter()
+        .find(|model| model.provider.eq_ignore_ascii_case("vercel"))
+        .or_else(|| models.first())
+        .cloned()
+        .context("No AI models available in provider registry")?;
+
+    let provider = registry
+        .find_provider_for_model(&selected_model.id)
+        .cloned()
+        .with_context(|| {
+            format!(
+                "No provider found for selected model '{}' (state=provider_missing)",
+                selected_model.id
+            )
+        })?;
+
+    Ok((selected_model, provider))
+}
+
+fn generated_scripts_dir() -> PathBuf {
+    PathBuf::from(shellexpand::tilde(AI_SCRIPT_OUTPUT_DIR).as_ref())
+}
+
+fn split_fence_header_and_body(fence: &str) -> (&str, &str) {
+    match fence.find('\n') {
+        Some(newline_index) => (&fence[..newline_index], &fence[newline_index + 1..]),
+        None => ("", fence),
+    }
+}
+
+fn extract_fenced_code(response: &str, preferred_languages: Option<&[&str]>) -> Option<String> {
+    let mut remaining = response;
+
+    while let Some(start) = remaining.find("```") {
+        let after_start = &remaining[start + 3..];
+        let Some(end) = after_start.find("```") else {
+            break;
+        };
+
+        let fence_contents = &after_start[..end];
+        let (header, body) = split_fence_header_and_body(fence_contents);
+        let language = header
+            .trim()
+            .split(|c: char| c.is_whitespace() || c == '{')
+            .next()
+            .unwrap_or("")
+            .to_ascii_lowercase();
+        let code = body.trim();
+
+        if !code.is_empty() {
+            match preferred_languages {
+                Some(preferred) => {
+                    if preferred.iter().any(|candidate| *candidate == language) {
+                        return Some(code.to_string());
+                    }
+                }
+                None => return Some(code.to_string()),
+            }
+        }
+
+        remaining = &after_start[end + 3..];
+    }
+
+    None
+}
+
+fn extract_script_code(response: &str) -> String {
+    const PREFERRED_LANGUAGES: [&str; 6] = ["typescript", "ts", "javascript", "js", "tsx", "jsx"];
+
+    extract_fenced_code(response, Some(&PREFERRED_LANGUAGES))
+        .or_else(|| extract_fenced_code(response, None))
+        .unwrap_or_else(|| response.trim().to_string())
+}
+
+fn slugify_script_name(prompt: &str) -> String {
+    let mut slug = String::new();
+    let mut last_was_hyphen = false;
+
+    for character in prompt.to_ascii_lowercase().chars() {
+        if character.is_ascii_alphanumeric() {
+            slug.push(character);
+            last_was_hyphen = false;
+        } else if matches!(character, ' ' | '_' | '-') {
+            if !slug.is_empty() && !last_was_hyphen {
+                slug.push('-');
+                last_was_hyphen = true;
+            }
+        }
+    }
+
+    while slug.ends_with('-') {
+        slug.pop();
+    }
+
+    if slug.len() > AI_SCRIPT_MAX_SLUG_LEN {
+        slug.truncate(AI_SCRIPT_MAX_SLUG_LEN);
+        while slug.ends_with('-') {
+            slug.pop();
+        }
+    }
+
+    if slug.is_empty() {
+        AI_SCRIPT_DEFAULT_SLUG.to_string()
+    } else {
+        slug
+    }
+}
+
+fn slug_to_title(slug: &str) -> String {
+    slug.split('-')
+        .filter(|segment| !segment.is_empty())
+        .map(|segment| {
+            let mut chars = segment.chars();
+            match chars.next() {
+                Some(first) => first.to_uppercase().collect::<String>() + chars.as_str(),
+                None => String::new(),
+            }
+        })
+        .collect::<Vec<_>>()
+        .join(" ")
+}
+
+fn description_from_prompt(prompt: &str) -> String {
+    let normalized = prompt.split_whitespace().collect::<Vec<_>>().join(" ");
+    if normalized.is_empty() {
+        return "AI-generated Script Kit script".to_string();
+    }
+
+    let mut shortened = normalized;
+    if shortened.chars().count() > 110 {
+        shortened = format!("{}...", shortened.chars().take(107).collect::<String>());
+    }
+    shortened
+}
+
+fn has_kit_import(script: &str) -> bool {
+    script.contains("import \"@johnlindquist/kit\";")
+        || script.contains("import '@johnlindquist/kit';")
+        || script.contains("import \"@scriptkit/sdk\";")
+        || script.contains("import '@scriptkit/sdk';")
+}
+
+fn enforce_script_kit_conventions(script: &str, prompt: &str, slug: &str) -> String {
+    let mut prefix_lines: Vec<String> = Vec::new();
+    let trimmed_script = script.trim();
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Name:"))
+    {
+        prefix_lines.push(format!("// Name: {}", slug_to_title(slug)));
+    }
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Description:"))
+    {
+        prefix_lines.push(format!("// Description: {}", description_from_prompt(prompt)));
+    }
+
+    if !has_kit_import(trimmed_script) {
+        prefix_lines.push("import \"@johnlindquist/kit\";".to_string());
+    }
+
+    let mut output = String::new();
+    if !prefix_lines.is_empty() {
+        output.push_str(&prefix_lines.join("\n"));
+        output.push_str("\n\n");
+    }
+
+    output.push_str(trimmed_script);
+    if !output.ends_with('\n') {
+        output.push('\n');
+    }
+    output
+}
+
+fn write_generated_script(slug: &str, script_content: &str) -> Result<PathBuf> {
+    write_generated_script_in_dir(&generated_scripts_dir(), slug, script_content)
+}
+
+fn write_generated_script_in_dir(output_dir: &Path, slug: &str, script_content: &str) -> Result<PathBuf> {
+    fs::create_dir_all(output_dir)
+        .with_context(|| format!("Failed to create output dir: {}", output_dir.display()))?;
+
+    for suffix in 0usize.. {
+        let candidate = if suffix == 0 {
+            slug.to_string()
+        } else {
+            format!("{slug}-{suffix}")
+        };
+        let path = output_dir.join(format!("{}.ts", candidate));
+        match OpenOptions::new().write(true).create_new(true).open(&path) {
+            Ok(mut file) => {
+                file.write_all(script_content.as_bytes())
+                    .with_context(|| format!("Failed writing generated script to {}", path.display()))?;
+                return Ok(path);
+            }
+            Err(error) if error.kind() == ErrorKind::AlreadyExists => continue,
+            Err(error) => {
+                return Err(error).with_context(|| {
+                    format!(
+                        "Failed creating generated script file {} (slug={})",
+                        path.display(),
+                        slug
+                    )
+                });
+            }
+        }
+    }
+
+    unreachable!("suffix loop should eventually create a unique script filename")
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+    use tempfile::tempdir;
+
+    #[test]
+    fn test_slugify_script_name_handles_spaces_and_symbols() {
+        assert_eq!(slugify_script_name("Build: API Client!"), "build-api-client");
+        assert_eq!(slugify_script_name("  ___  "), "ai-script");
+    }
+
+    #[test]
+    fn test_extract_script_code_prefers_typescript_fence_when_multiple_blocks_exist() {
+        let response = r#"
+Here's one idea:
+```markdown
+Not code
+```
+```typescript
+await div("hello");
+```
+"#;
+        assert_eq!(extract_script_code(response), "await div(\"hello\");");
+    }
+
+    #[test]
+    fn test_extract_script_code_falls_back_to_first_fenced_block() {
+        let response = r#"
+```python
+print("hello")
+```
+"#;
+        assert_eq!(extract_script_code(response), "print(\"hello\")");
+    }
+
+    #[test]
+    fn test_extract_script_code_returns_trimmed_response_when_no_fence_exists() {
+        let response = "const answer = 42;";
+        assert_eq!(extract_script_code(response), "const answer = 42;");
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_adds_missing_metadata_and_import() {
+        let script = "const name = await arg(\"Name?\");";
+        let output = enforce_script_kit_conventions(script, "Ask for user name", "ask-user-name");
+
+        assert!(output.contains("// Name: Ask User Name"));
+        assert!(output.contains("// Description: Ask for user name"));
+        assert!(output.contains("import \"@johnlindquist/kit\";"));
+        assert!(output.contains("await arg(\"Name?\");"));
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_keeps_existing_metadata_and_import() {
+        let script = r#"// Name: Existing
+// Description: Existing description
+import "@johnlindquist/kit";
+
+await div("ready");
+"#;
+        let output = enforce_script_kit_conventions(script, "ignored", "ignored");
+
+        assert_eq!(
+            output.matches("// Name:").count(),
+            1,
+            "should not duplicate existing Name metadata"
+        );
+        assert_eq!(
+            output.matches("// Description:").count(),
+            1,
+            "should not duplicate existing Description metadata"
+        );
+        assert_eq!(
+            output.matches("import \"@johnlindquist/kit\";").count(),
+            1,
+            "should not duplicate existing import"
+        );
+    }
+
+    #[test]
+    fn test_write_generated_script_in_dir_appends_numeric_suffix_for_collisions() {
+        let temp_dir = tempdir().unwrap();
+        let first = write_generated_script_in_dir(temp_dir.path(), "my-script", "a").unwrap();
+        let second = write_generated_script_in_dir(temp_dir.path(), "my-script", "b").unwrap();
+
+        assert_eq!(first.file_name().unwrap(), "my-script.ts");
+        assert_eq!(second.file_name().unwrap(), "my-script-1.ts");
+    }
+}
diff --git a/src/builtins/part_000.rs b/src/builtins/part_000.rs
index d6b9c2a9b35b40c5005dbb9f65147f528702cb9e..5f6d27d28d72e51126d10d8beccf931c689ef2bb
--- a/src/builtins/part_000.rs
+++ b/src/builtins/part_000.rs
@@ -96,6 +96,8 @@
     OpenAi,
     NewConversation,
     ClearConversation,
+    /// Generate a new Script Kit script from the main prompt text
+    GenerateScript,
     /// Send a screenshot of the entire screen to AI Chat
     SendScreenToAi,
     /// Send a screenshot of the focused window to AI Chat
diff --git a/src/builtins/part_001_entries/entries_002.rs b/src/builtins/part_001_entries/entries_002.rs
index 6d1c9334f0ccaf0aab48582aaf42dcb129e1cb6e..72b318c66aeaf124359f4ecd276dae0350287328
--- a/src/builtins/part_001_entries/entries_002.rs
+++ b/src/builtins/part_001_entries/entries_002.rs
@@ -61,6 +61,17 @@
     ));
 
     entries.push(BuiltInEntry::new_with_icon(
+        "builtin-generate-script-with-ai",
+        "Generate Script with AI",
+        "Generate a Script Kit script from your current prompt text",
+        vec![
+            "generate", "script", "ai", "create", "code", "typescript", "shift", "tab",
+        ],
+        BuiltInFeature::AiCommand(AiCommandType::GenerateScript),
+        "ðŸ§ ",
+    ));
+
+    entries.push(BuiltInEntry::new_with_icon(
         "builtin-send-screen-to-ai",
         "Send Screen to AI Chat",
         "Capture the full screen and send it to AI Chat",


thinking
**Inspecting command variant tests**
exec
/bin/zsh -lc "rg -n \"AiCommandType::|builtin-generate-script-with-ai|Generate Script with AI|AiCommand\\(\" src/builtins src/app_execute src/app_impl src/ai | head -n 200" in /Users/johnlindquist/dev/script-kit-gpui succeeded in 51ms:
src/builtins/part_000.rs:219:    AiCommand(AiCommandType),
src/app_execute/builtin_execution.rs:542:            builtins::BuiltInFeature::AiCommand(cmd_type) => {
src/app_execute/builtin_execution.rs:553:                    AiCommandType::OpenAi | AiCommandType::NewConversation => {
src/app_execute/builtin_execution.rs:568:                    AiCommandType::ClearConversation => {
src/app_execute/builtin_execution.rs:617:                    AiCommandType::SendScreenToAi => {
src/app_execute/builtin_execution.rs:667:                    AiCommandType::SendFocusedWindowToAi => {
src/app_execute/builtin_execution.rs:717:                    AiCommandType::SendSelectedTextToAi => {
src/app_execute/builtin_execution.rs:771:                    AiCommandType::SendBrowserTabToAi => {
src/app_execute/builtin_execution.rs:808:                    AiCommandType::SendScreenAreaToAi => {
src/app_execute/builtin_execution.rs:821:                    AiCommandType::CreateAiPreset
src/app_execute/builtin_execution.rs:822:                    | AiCommandType::ImportAiPresets
src/app_execute/builtin_execution.rs:823:                    | AiCommandType::SearchAiPresets => {
src/builtins/part_001_entries/entries_002.rs:50:        BuiltInFeature::AiCommand(AiCommandType::OpenAi),
src/builtins/part_001_entries/entries_002.rs:59:        BuiltInFeature::AiCommand(AiCommandType::NewConversation),
src/builtins/part_001_entries/entries_002.rs:64:        "builtin-generate-script-with-ai",
src/builtins/part_001_entries/entries_002.rs:65:        "Generate Script with AI",
src/builtins/part_001_entries/entries_002.rs:70:        BuiltInFeature::AiCommand(AiCommandType::GenerateScript),
src/builtins/part_001_entries/entries_002.rs:87:        BuiltInFeature::AiCommand(AiCommandType::SendScreenToAi),
src/builtins/part_001_entries/entries_002.rs:104:        BuiltInFeature::AiCommand(AiCommandType::SendFocusedWindowToAi),
src/builtins/part_001_entries/entries_002.rs:121:        BuiltInFeature::AiCommand(AiCommandType::SendSelectedTextToAi),
file update:
diff --git a/src/ai/mod.rs b/src/ai/mod.rs
index a420b1a5faf59506acdb7caf60681c153a3f9bb6..9a73e9491862633b325b2c52b51a3e20395ff85c
--- a/src/ai/mod.rs
+++ b/src/ai/mod.rs
@@ -37,6 +37,7 @@
 pub(crate) mod providers;
 pub(crate) mod sdk_handlers;
 pub(crate) mod session;
+pub(crate) mod script_generation;
 pub(crate) mod storage;
 pub(crate) mod window;
 
@@ -44,6 +45,7 @@
 pub use self::config::{DetectedKeys, ModelInfo, ProviderConfig};
 pub use self::model::{Chat, ChatId, ChatSource, Message, MessageRole};
 pub use self::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+pub use self::script_generation::{generate_script_from_prompt, GeneratedScriptOutput};
 pub use self::sdk_handlers::try_handle_ai_message;
 pub use self::storage::{
     clear_all_chats, create_chat, delete_chat, get_all_chats, get_chat, get_chat_messages,
diff --git a/src/ai/script_generation.rs b/src/ai/script_generation.rs
new file mode 100644
index 0000000000000000000000000000000000000000..7f2ec8e7576ed50cd10f7aea31a6522875ef667a
--- /dev/null
+++ b/src/ai/script_generation.rs
@@ -0,0 +1,417 @@
+use anyhow::{Context, Result};
+use std::fs::{self, OpenOptions};
+use std::io::{ErrorKind, Write};
+use std::path::{Path, PathBuf};
+use std::sync::Arc;
+
+use super::config::ModelInfo;
+use super::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+
+const AI_SCRIPT_OUTPUT_DIR: &str = "~/.kenv/scripts";
+const AI_SCRIPT_DEFAULT_SLUG: &str = "ai-script";
+const AI_SCRIPT_MAX_SLUG_LEN: usize = 64;
+
+const AI_SCRIPT_GENERATION_SYSTEM_PROMPT: &str = r#"You write production-ready Script Kit scripts.
+
+Return ONLY TypeScript source code for one Script Kit script. Do not include explanations.
+
+Required output conventions:
+1) Include metadata comments at the top:
+   // Name: <clear title>
+   // Description: <one-line summary>
+2) Include: import "@johnlindquist/kit";
+3) Use await arg() for user input when useful.
+4) Use await div() for display output when useful.
+5) Keep the script runnable as-is with sensible defaults and light error handling."#;
+
+#[derive(Debug, Clone)]
+pub struct GeneratedScriptOutput {
+    pub path: PathBuf,
+    pub slug: String,
+    pub model_id: String,
+    pub provider_id: String,
+}
+
+pub fn generate_script_from_prompt(
+    prompt: &str,
+    config: Option<&crate::config::Config>,
+) -> Result<GeneratedScriptOutput> {
+    let normalized_prompt = prompt.trim();
+    if normalized_prompt.is_empty() {
+        anyhow::bail!("AI script generation requires a non-empty prompt");
+    }
+
+    let registry = ProviderRegistry::from_environment_with_config(config);
+    if !registry.has_any_provider() {
+        anyhow::bail!(
+            "No AI providers configured. Configure an API key first (Vercel, OpenAI, Anthropic, etc.)."
+        );
+    }
+
+    let (selected_model, provider) = select_generation_model(&registry)?;
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=provider_ready model_id={} provider_id={} prompt_len={}",
+            selected_model.id,
+            selected_model.provider,
+            normalized_prompt.len()
+        ),
+    );
+
+    let messages = vec![
+        ProviderMessage::system(AI_SCRIPT_GENERATION_SYSTEM_PROMPT),
+        ProviderMessage::user(format!(
+            "Generate a Script Kit script for this user request:\n\n{}",
+            normalized_prompt
+        )),
+    ];
+
+    let raw_response = provider
+        .send_message(&messages, &selected_model.id)
+        .with_context(|| {
+            format!(
+                "AI script generation failed (attempted=send_message, model_id={}, provider_id={})",
+                selected_model.id, selected_model.provider
+            )
+        })?;
+
+    let extracted = extract_script_code(&raw_response);
+    if extracted.trim().is_empty() {
+        anyhow::bail!(
+            "AI returned an empty response for script generation (state=empty_response)"
+        );
+    }
+
+    let slug = slugify_script_name(normalized_prompt);
+    let finalized = enforce_script_kit_conventions(&extracted, normalized_prompt, &slug);
+    let path = write_generated_script(&slug, &finalized).with_context(|| {
+        format!(
+            "Failed writing AI-generated script (state=write_failed, slug={})",
+            slug
+        )
+    })?;
+
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=script_written path={} slug={}",
+            path.display(),
+            slug
+        ),
+    );
+
+    Ok(GeneratedScriptOutput {
+        path,
+        slug,
+        model_id: selected_model.id,
+        provider_id: selected_model.provider,
+    })
+}
+
+fn select_generation_model(registry: &ProviderRegistry) -> Result<(ModelInfo, Arc<dyn AiProvider>)> {
+    let models = registry.get_all_models();
+    let selected_model = models
+        .iter()
+        .find(|model| model.provider.eq_ignore_ascii_case("vercel"))
+        .or_else(|| models.first())
+        .cloned()
+        .context("No AI models available in provider registry")?;
+
+    let provider = registry
+        .find_provider_for_model(&selected_model.id)
+        .cloned()
+        .with_context(|| {
+            format!(
+                "No provider found for selected model '{}' (state=provider_missing)",
+                selected_model.id
+            )
+        })?;
+
+    Ok((selected_model, provider))
+}
+
+fn generated_scripts_dir() -> PathBuf {
+    PathBuf::from(shellexpand::tilde(AI_SCRIPT_OUTPUT_DIR).as_ref())
+}
+
+fn split_fence_header_and_body(fence: &str) -> (&str, &str) {
+    match fence.find('\n') {
+        Some(newline_index) => (&fence[..newline_index], &fence[newline_index + 1..]),
+        None => ("", fence),
+    }
+}
+
+fn extract_fenced_code(response: &str, preferred_languages: Option<&[&str]>) -> Option<String> {
+    let mut remaining = response;
+
+    while let Some(start) = remaining.find("```") {
+        let after_start = &remaining[start + 3..];
+        let Some(end) = after_start.find("```") else {
+            break;
+        };
+
+        let fence_contents = &after_start[..end];
+        let (header, body) = split_fence_header_and_body(fence_contents);
+        let language = header
+            .trim()
+            .split(|c: char| c.is_whitespace() || c == '{')
+            .next()
+            .unwrap_or("")
+            .to_ascii_lowercase();
+        let code = body.trim();
+
+        if !code.is_empty() {
+            match preferred_languages {
+                Some(preferred) => {
+                    if preferred.iter().any(|candidate| *candidate == language) {
+                        return Some(code.to_string());
+                    }
+                }
+                None => return Some(code.to_string()),
+            }
+        }
+
+        remaining = &after_start[end + 3..];
+    }
+
+    None
+}
+
+fn extract_script_code(response: &str) -> String {
+    const PREFERRED_LANGUAGES: [&str; 6] = ["typescript", "ts", "javascript", "js", "tsx", "jsx"];
+
+    extract_fenced_code(response, Some(&PREFERRED_LANGUAGES))
+        .or_else(|| extract_fenced_code(response, None))
+        .unwrap_or_else(|| response.trim().to_string())
+}
+
+fn slugify_script_name(prompt: &str) -> String {
+    let mut slug = String::new();
+    let mut last_was_hyphen = false;
+
+    for character in prompt.to_ascii_lowercase().chars() {
+        if character.is_ascii_alphanumeric() {
+            slug.push(character);
+            last_was_hyphen = false;
+        } else if matches!(character, ' ' | '_' | '-') {
+            if !slug.is_empty() && !last_was_hyphen {
+                slug.push('-');
+                last_was_hyphen = true;
+            }
+        }
+    }
+
+    while slug.ends_with('-') {
+        slug.pop();
+    }
+
+    if slug.len() > AI_SCRIPT_MAX_SLUG_LEN {
+        slug.truncate(AI_SCRIPT_MAX_SLUG_LEN);
+        while slug.ends_with('-') {
+            slug.pop();
+        }
+    }
+
+    if slug.is_empty() {
+        AI_SCRIPT_DEFAULT_SLUG.to_string()
+    } else {
+        slug
+    }
+}
+
+fn slug_to_title(slug: &str) -> String {
+    slug.split('-')
+        .filter(|segment| !segment.is_empty())
+        .map(|segment| {
+            let mut chars = segment.chars();
+            match chars.next() {
+                Some(first) => first.to_uppercase().collect::<String>() + chars.as_str(),
+                None => String::new(),
+            }
+        })
+        .collect::<Vec<_>>()
+        .join(" ")
+}
+
+fn description_from_prompt(prompt: &str) -> String {
+    let normalized = prompt.split_whitespace().collect::<Vec<_>>().join(" ");
+    if normalized.is_empty() {
+        return "AI-generated Script Kit script".to_string();
+    }
+
+    let mut shortened = normalized;
+    if shortened.chars().count() > 110 {
+        shortened = format!("{}...", shortened.chars().take(107).collect::<String>());
+    }
+    shortened
+}
+
+fn has_kit_import(script: &str) -> bool {
+    script.contains("import \"@johnlindquist/kit\";")
+        || script.contains("import '@johnlindquist/kit';")
+        || script.contains("import \"@scriptkit/sdk\";")
+        || script.contains("import '@scriptkit/sdk';")
+}
+
+fn enforce_script_kit_conventions(script: &str, prompt: &str, slug: &str) -> String {
+    let mut prefix_lines: Vec<String> = Vec::new();
+    let trimmed_script = script.trim();
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Name:"))
+    {
+        prefix_lines.push(format!("// Name: {}", slug_to_title(slug)));
+    }
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Description:"))
+    {
+        prefix_lines.push(format!("// Description: {}", description_from_prompt(prompt)));
+    }
+
+    if !has_kit_import(trimmed_script) {
+        prefix_lines.push("import \"@johnlindquist/kit\";".to_string());
+    }
+
+    let mut output = String::new();
+    if !prefix_lines.is_empty() {
+        output.push_str(&prefix_lines.join("\n"));
+        output.push_str("\n\n");
+    }
+
+    output.push_str(trimmed_script);
+    if !output.ends_with('\n') {
+        output.push('\n');
+    }
+    output
+}
+
+fn write_generated_script(slug: &str, script_content: &str) -> Result<PathBuf> {
+    write_generated_script_in_dir(&generated_scripts_dir(), slug, script_content)
+}
+
+fn write_generated_script_in_dir(output_dir: &Path, slug: &str, script_content: &str) -> Result<PathBuf> {
+    fs::create_dir_all(output_dir)
+        .with_context(|| format!("Failed to create output dir: {}", output_dir.display()))?;
+
+    for suffix in 0usize.. {
+        let candidate = if suffix == 0 {
+            slug.to_string()
+        } else {
+            format!("{slug}-{suffix}")
+        };
+        let path = output_dir.join(format!("{}.ts", candidate));
+        match OpenOptions::new().write(true).create_new(true).open(&path) {
+            Ok(mut file) => {
+                file.write_all(script_content.as_bytes())
+                    .with_context(|| format!("Failed writing generated script to {}", path.display()))?;
+                return Ok(path);
+            }
+            Err(error) if error.kind() == ErrorKind::AlreadyExists => continue,
+            Err(error) => {
+                return Err(error).with_context(|| {
+                    format!(
+                        "Failed creating generated script file {} (slug={})",
+                        path.display(),
+                        slug
+                    )
+                });
+            }
+        }
+    }
+
+    unreachable!("suffix loop should eventually create a unique script filename")
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+    use tempfile::tempdir;
+
+    #[test]
+    fn test_slugify_script_name_handles_spaces_and_symbols() {
+        assert_eq!(slugify_script_name("Build: API Client!"), "build-api-client");
+        assert_eq!(slugify_script_name("  ___  "), "ai-script");
+    }
+
+    #[test]
+    fn test_extract_script_code_prefers_typescript_fence_when_multiple_blocks_exist() {
+        let response = r#"
+Here's one idea:
+```markdown
+Not code
+```
+```typescript
+await div("hello");
+```
+"#;
+        assert_eq!(extract_script_code(response), "await div(\"hello\");");
+    }
+
+    #[test]
+    fn test_extract_script_code_falls_back_to_first_fenced_block() {
+        let response = r#"
+```python
+print("hello")
+```
+"#;
+        assert_eq!(extract_script_code(response), "print(\"hello\")");
+    }
+
+    #[test]
+    fn test_extract_script_code_returns_trimmed_response_when_no_fence_exists() {
+        let response = "const answer = 42;";
+        assert_eq!(extract_script_code(response), "const answer = 42;");
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_adds_missing_metadata_and_import() {
+        let script = "const name = await arg(\"Name?\");";
+        let output = enforce_script_kit_conventions(script, "Ask for user name", "ask-user-name");
+
+        assert!(output.contains("// Name: Ask User Name"));
+        assert!(output.contains("// Description: Ask for user name"));
+        assert!(output.contains("import \"@johnlindquist/kit\";"));
+        assert!(output.contains("await arg(\"Name?\");"));
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_keeps_existing_metadata_and_import() {
+        let script = r#"// Name: Existing
+// Description: Existing description
+import "@johnlindquist/kit";
+
+await div("ready");
+"#;
+        let output = enforce_script_kit_conventions(script, "ignored", "ignored");
+
+        assert_eq!(
+            output.matches("// Name:").count(),
+            1,
+            "should not duplicate existing Name metadata"
+        );
+        assert_eq!(
+            output.matches("// Description:").count(),
+            1,
+            "should not duplicate existing Description metadata"
+        );
+        assert_eq!(
+            output.matches("import \"@johnlindquist/kit\";").count(),
+            1,
+            "should not duplicate existing import"
+        );
+    }
+
+    #[test]
+    fn test_write_generated_script_in_dir_appends_numeric_suffix_for_collisions() {
+        let temp_dir = tempdir().unwrap();
+        let first = write_generated_script_in_dir(temp_dir.path(), "my-script", "a").unwrap();
+        let second = write_generated_script_in_dir(temp_dir.path(), "my-script", "b").unwrap();
+
+        assert_eq!(first.file_name().unwrap(), "my-script.ts");
+        assert_eq!(second.file_name().unwrap(), "my-script-1.ts");
+    }
+}
diff --git a/src/builtins/part_000.rs b/src/builtins/part_000.rs
index d6b9c2a9b35b40c5005dbb9f65147f528702cb9e..5f6d27d28d72e51126d10d8beccf931c689ef2bb
--- a/src/builtins/part_000.rs
+++ b/src/builtins/part_000.rs
@@ -96,6 +96,8 @@
     OpenAi,
     NewConversation,
     ClearConversation,
+    /// Generate a new Script Kit script from the main prompt text
+    GenerateScript,
     /// Send a screenshot of the entire screen to AI Chat
     SendScreenToAi,
     /// Send a screenshot of the focused window to AI Chat
diff --git a/src/builtins/part_001_entries/entries_002.rs b/src/builtins/part_001_entries/entries_002.rs
index 6d1c9334f0ccaf0aab48582aaf42dcb129e1cb6e..72b318c66aeaf124359f4ecd276dae0350287328
--- a/src/builtins/part_001_entries/entries_002.rs
+++ b/src/builtins/part_001_entries/entries_002.rs
@@ -61,6 +61,17 @@
     ));
 
     entries.push(BuiltInEntry::new_with_icon(
+        "builtin-generate-script-with-ai",
+        "Generate Script with AI",
+        "Generate a Script Kit script from your current prompt text",
+        vec![
+            "generate", "script", "ai", "create", "code", "typescript", "shift", "tab",
+        ],
+        BuiltInFeature::AiCommand(AiCommandType::GenerateScript),
+        "ðŸ§ ",
+    ));
+
+    entries.push(BuiltInEntry::new_with_icon(
         "builtin-send-screen-to-ai",
         "Send Screen to AI Chat",
         "Capture the full screen and send it to AI Chat",


thinking
**Inspecting imports in file header**
exec
/bin/zsh -lc "sed -n '1,140p' src/app_execute/builtin_execution.rs" in /Users/johnlindquist/dev/script-kit-gpui succeeded in 51ms:
fn ai_open_failure_message(error: impl std::fmt::Display) -> String {
    format!("Failed to open AI: {}", error)
}

impl ScriptListApp {
    fn system_action_feedback_message(
        &self,
        action_type: &builtins::SystemActionType,
    ) -> Option<String> {
        let dark_mode_enabled = if matches!(action_type, builtins::SystemActionType::ToggleDarkMode)
        {
            system_actions::is_dark_mode().ok()
        } else {
            None
        };

        builtins::system_action_hud_message(*action_type, dark_mode_enabled)
    }

    fn execute_builtin(&mut self, entry: &builtins::BuiltInEntry, cx: &mut Context<Self>) {
file update:
diff --git a/src/ai/mod.rs b/src/ai/mod.rs
index a420b1a5faf59506acdb7caf60681c153a3f9bb6..9a73e9491862633b325b2c52b51a3e20395ff85c
--- a/src/ai/mod.rs
+++ b/src/ai/mod.rs
@@ -37,6 +37,7 @@
 pub(crate) mod providers;
 pub(crate) mod sdk_handlers;
 pub(crate) mod session;
+pub(crate) mod script_generation;
 pub(crate) mod storage;
 pub(crate) mod window;
 
@@ -44,6 +45,7 @@
 pub use self::config::{DetectedKeys, ModelInfo, ProviderConfig};
 pub use self::model::{Chat, ChatId, ChatSource, Message, MessageRole};
 pub use self::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+pub use self::script_generation::{generate_script_from_prompt, GeneratedScriptOutput};
 pub use self::sdk_handlers::try_handle_ai_message;
 pub use self::storage::{
     clear_all_chats, create_chat, delete_chat, get_all_chats, get_chat, get_chat_messages,
diff --git a/src/ai/script_generation.rs b/src/ai/script_generation.rs
new file mode 100644
index 0000000000000000000000000000000000000000..7f2ec8e7576ed50cd10f7aea31a6522875ef667a
--- /dev/null
+++ b/src/ai/script_generation.rs
@@ -0,0 +1,417 @@
+use anyhow::{Context, Result};
+use std::fs::{self, OpenOptions};
+use std::io::{ErrorKind, Write};
+use std::path::{Path, PathBuf};
+use std::sync::Arc;
+
+use super::config::ModelInfo;
+use super::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+
+const AI_SCRIPT_OUTPUT_DIR: &str = "~/.kenv/scripts";
+const AI_SCRIPT_DEFAULT_SLUG: &str = "ai-script";
+const AI_SCRIPT_MAX_SLUG_LEN: usize = 64;
+
+const AI_SCRIPT_GENERATION_SYSTEM_PROMPT: &str = r#"You write production-ready Script Kit scripts.
+
+Return ONLY TypeScript source code for one Script Kit script. Do not include explanations.
+
+Required output conventions:
+1) Include metadata comments at the top:
+   // Name: <clear title>
+   // Description: <one-line summary>
+2) Include: import "@johnlindquist/kit";
+3) Use await arg() for user input when useful.
+4) Use await div() for display output when useful.
+5) Keep the script runnable as-is with sensible defaults and light error handling."#;
+
+#[derive(Debug, Clone)]
+pub struct GeneratedScriptOutput {
+    pub path: PathBuf,
+    pub slug: String,
+    pub model_id: String,
+    pub provider_id: String,
+}
+
+pub fn generate_script_from_prompt(
+    prompt: &str,
+    config: Option<&crate::config::Config>,
+) -> Result<GeneratedScriptOutput> {
+    let normalized_prompt = prompt.trim();
+    if normalized_prompt.is_empty() {
+        anyhow::bail!("AI script generation requires a non-empty prompt");
+    }
+
+    let registry = ProviderRegistry::from_environment_with_config(config);
+    if !registry.has_any_provider() {
+        anyhow::bail!(
+            "No AI providers configured. Configure an API key first (Vercel, OpenAI, Anthropic, etc.)."
+        );
+    }
+
+    let (selected_model, provider) = select_generation_model(&registry)?;
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=provider_ready model_id={} provider_id={} prompt_len={}",
+            selected_model.id,
+            selected_model.provider,
+            normalized_prompt.len()
+        ),
+    );
+
+    let messages = vec![
+        ProviderMessage::system(AI_SCRIPT_GENERATION_SYSTEM_PROMPT),
+        ProviderMessage::user(format!(
+            "Generate a Script Kit script for this user request:\n\n{}",
+            normalized_prompt
+        )),
+    ];
+
+    let raw_response = provider
+        .send_message(&messages, &selected_model.id)
+        .with_context(|| {
+            format!(
+                "AI script generation failed (attempted=send_message, model_id={}, provider_id={})",
+                selected_model.id, selected_model.provider
+            )
+        })?;
+
+    let extracted = extract_script_code(&raw_response);
+    if extracted.trim().is_empty() {
+        anyhow::bail!(
+            "AI returned an empty response for script generation (state=empty_response)"
+        );
+    }
+
+    let slug = slugify_script_name(normalized_prompt);
+    let finalized = enforce_script_kit_conventions(&extracted, normalized_prompt, &slug);
+    let path = write_generated_script(&slug, &finalized).with_context(|| {
+        format!(
+            "Failed writing AI-generated script (state=write_failed, slug={})",
+            slug
+        )
+    })?;
+
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=script_written path={} slug={}",
+            path.display(),
+            slug
+        ),
+    );
+
+    Ok(GeneratedScriptOutput {
+        path,
+        slug,
+        model_id: selected_model.id,
+        provider_id: selected_model.provider,
+    })
+}
+
+fn select_generation_model(registry: &ProviderRegistry) -> Result<(ModelInfo, Arc<dyn AiProvider>)> {
+    let models = registry.get_all_models();
+    let selected_model = models
+        .iter()
+        .find(|model| model.provider.eq_ignore_ascii_case("vercel"))
+        .or_else(|| models.first())
+        .cloned()
+        .context("No AI models available in provider registry")?;
+
+    let provider = registry
+        .find_provider_for_model(&selected_model.id)
+        .cloned()
+        .with_context(|| {
+            format!(
+                "No provider found for selected model '{}' (state=provider_missing)",
+                selected_model.id
+            )
+        })?;
+
+    Ok((selected_model, provider))
+}
+
+fn generated_scripts_dir() -> PathBuf {
+    PathBuf::from(shellexpand::tilde(AI_SCRIPT_OUTPUT_DIR).as_ref())
+}
+
+fn split_fence_header_and_body(fence: &str) -> (&str, &str) {
+    match fence.find('\n') {
+        Some(newline_index) => (&fence[..newline_index], &fence[newline_index + 1..]),
+        None => ("", fence),
+    }
+}
+
+fn extract_fenced_code(response: &str, preferred_languages: Option<&[&str]>) -> Option<String> {
+    let mut remaining = response;
+
+    while let Some(start) = remaining.find("```") {
+        let after_start = &remaining[start + 3..];
+        let Some(end) = after_start.find("```") else {
+            break;
+        };
+
+        let fence_contents = &after_start[..end];
+        let (header, body) = split_fence_header_and_body(fence_contents);
+        let language = header
+            .trim()
+            .split(|c: char| c.is_whitespace() || c == '{')
+            .next()
+            .unwrap_or("")
+            .to_ascii_lowercase();
+        let code = body.trim();
+
+        if !code.is_empty() {
+            match preferred_languages {
+                Some(preferred) => {
+                    if preferred.iter().any(|candidate| *candidate == language) {
+                        return Some(code.to_string());
+                    }
+                }
+                None => return Some(code.to_string()),
+            }
+        }
+
+        remaining = &after_start[end + 3..];
+    }
+
+    None
+}
+
+fn extract_script_code(response: &str) -> String {
+    const PREFERRED_LANGUAGES: [&str; 6] = ["typescript", "ts", "javascript", "js", "tsx", "jsx"];
+
+    extract_fenced_code(response, Some(&PREFERRED_LANGUAGES))
+        .or_else(|| extract_fenced_code(response, None))
+        .unwrap_or_else(|| response.trim().to_string())
+}
+
+fn slugify_script_name(prompt: &str) -> String {
+    let mut slug = String::new();
+    let mut last_was_hyphen = false;
+
+    for character in prompt.to_ascii_lowercase().chars() {
+        if character.is_ascii_alphanumeric() {
+            slug.push(character);
+            last_was_hyphen = false;
+        } else if matches!(character, ' ' | '_' | '-') {
+            if !slug.is_empty() && !last_was_hyphen {
+                slug.push('-');
+                last_was_hyphen = true;
+            }
+        }
+    }
+
+    while slug.ends_with('-') {
+        slug.pop();
+    }
+
+    if slug.len() > AI_SCRIPT_MAX_SLUG_LEN {
+        slug.truncate(AI_SCRIPT_MAX_SLUG_LEN);
+        while slug.ends_with('-') {
+            slug.pop();
+        }
+    }
+
+    if slug.is_empty() {
+        AI_SCRIPT_DEFAULT_SLUG.to_string()
+    } else {
+        slug
+    }
+}
+
+fn slug_to_title(slug: &str) -> String {
+    slug.split('-')
+        .filter(|segment| !segment.is_empty())
+        .map(|segment| {
+            let mut chars = segment.chars();
+            match chars.next() {
+                Some(first) => first.to_uppercase().collect::<String>() + chars.as_str(),
+                None => String::new(),
+            }
+        })
+        .collect::<Vec<_>>()
+        .join(" ")
+}
+
+fn description_from_prompt(prompt: &str) -> String {
+    let normalized = prompt.split_whitespace().collect::<Vec<_>>().join(" ");
+    if normalized.is_empty() {
+        return "AI-generated Script Kit script".to_string();
+    }
+
+    let mut shortened = normalized;
+    if shortened.chars().count() > 110 {
+        shortened = format!("{}...", shortened.chars().take(107).collect::<String>());
+    }
+    shortened
+}
+
+fn has_kit_import(script: &str) -> bool {
+    script.contains("import \"@johnlindquist/kit\";")
+        || script.contains("import '@johnlindquist/kit';")
+        || script.contains("import \"@scriptkit/sdk\";")
+        || script.contains("import '@scriptkit/sdk';")
+}
+
+fn enforce_script_kit_conventions(script: &str, prompt: &str, slug: &str) -> String {
+    let mut prefix_lines: Vec<String> = Vec::new();
+    let trimmed_script = script.trim();
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Name:"))
+    {
+        prefix_lines.push(format!("// Name: {}", slug_to_title(slug)));
+    }
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Description:"))
+    {
+        prefix_lines.push(format!("// Description: {}", description_from_prompt(prompt)));
+    }
+
+    if !has_kit_import(trimmed_script) {
+        prefix_lines.push("import \"@johnlindquist/kit\";".to_string());
+    }
+
+    let mut output = String::new();
+    if !prefix_lines.is_empty() {
+        output.push_str(&prefix_lines.join("\n"));
+        output.push_str("\n\n");
+    }
+
+    output.push_str(trimmed_script);
+    if !output.ends_with('\n') {
+        output.push('\n');
+    }
+    output
+}
+
+fn write_generated_script(slug: &str, script_content: &str) -> Result<PathBuf> {
+    write_generated_script_in_dir(&generated_scripts_dir(), slug, script_content)
+}
+
+fn write_generated_script_in_dir(output_dir: &Path, slug: &str, script_content: &str) -> Result<PathBuf> {
+    fs::create_dir_all(output_dir)
+        .with_context(|| format!("Failed to create output dir: {}", output_dir.display()))?;
+
+    for suffix in 0usize.. {
+        let candidate = if suffix == 0 {
+            slug.to_string()
+        } else {
+            format!("{slug}-{suffix}")
+        };
+        let path = output_dir.join(format!("{}.ts", candidate));
+        match OpenOptions::new().write(true).create_new(true).open(&path) {
+            Ok(mut file) => {
+                file.write_all(script_content.as_bytes())
+                    .with_context(|| format!("Failed writing generated script to {}", path.display()))?;
+                return Ok(path);
+            }
+            Err(error) if error.kind() == ErrorKind::AlreadyExists => continue,
+            Err(error) => {
+                return Err(error).with_context(|| {
+                    format!(
+                        "Failed creating generated script file {} (slug={})",
+                        path.display(),
+                        slug
+                    )
+                });
+            }
+        }
+    }
+
+    unreachable!("suffix loop should eventually create a unique script filename")
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+    use tempfile::tempdir;
+
+    #[test]
+    fn test_slugify_script_name_handles_spaces_and_symbols() {
+        assert_eq!(slugify_script_name("Build: API Client!"), "build-api-client");
+        assert_eq!(slugify_script_name("  ___  "), "ai-script");
+    }
+
+    #[test]
+    fn test_extract_script_code_prefers_typescript_fence_when_multiple_blocks_exist() {
+        let response = r#"
+Here's one idea:
+```markdown
+Not code
+```
+```typescript
+await div("hello");
+```
+"#;
+        assert_eq!(extract_script_code(response), "await div(\"hello\");");
+    }
+
+    #[test]
+    fn test_extract_script_code_falls_back_to_first_fenced_block() {
+        let response = r#"
+```python
+print("hello")
+```
+"#;
+        assert_eq!(extract_script_code(response), "print(\"hello\")");
+    }
+
+    #[test]
+    fn test_extract_script_code_returns_trimmed_response_when_no_fence_exists() {
+        let response = "const answer = 42;";
+        assert_eq!(extract_script_code(response), "const answer = 42;");
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_adds_missing_metadata_and_import() {
+        let script = "const name = await arg(\"Name?\");";
+        let output = enforce_script_kit_conventions(script, "Ask for user name", "ask-user-name");
+
+        assert!(output.contains("// Name: Ask User Name"));
+        assert!(output.contains("// Description: Ask for user name"));
+        assert!(output.contains("import \"@johnlindquist/kit\";"));
+        assert!(output.contains("await arg(\"Name?\");"));
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_keeps_existing_metadata_and_import() {
+        let script = r#"// Name: Existing
+// Description: Existing description
+import "@johnlindquist/kit";
+
+await div("ready");
+"#;
+        let output = enforce_script_kit_conventions(script, "ignored", "ignored");
+
+        assert_eq!(
+            output.matches("// Name:").count(),
+            1,
+            "should not duplicate existing Name metadata"
+        );
+        assert_eq!(
+            output.matches("// Description:").count(),
+            1,
+            "should not duplicate existing Description metadata"
+        );
+        assert_eq!(
+            output.matches("import \"@johnlindquist/kit\";").count(),
+            1,
+            "should not duplicate existing import"
+        );
+    }
+
+    #[test]
+    fn test_write_generated_script_in_dir_appends_numeric_suffix_for_collisions() {
+        let temp_dir = tempdir().unwrap();
+        let first = write_generated_script_in_dir(temp_dir.path(), "my-script", "a").unwrap();
+        let second = write_generated_script_in_dir(temp_dir.path(), "my-script", "b").unwrap();
+
+        assert_eq!(first.file_name().unwrap(), "my-script.ts");
+        assert_eq!(second.file_name().unwrap(), "my-script-1.ts");
+    }
+}
diff --git a/src/builtins/part_000.rs b/src/builtins/part_000.rs
index d6b9c2a9b35b40c5005dbb9f65147f528702cb9e..5f6d27d28d72e51126d10d8beccf931c689ef2bb
--- a/src/builtins/part_000.rs
+++ b/src/builtins/part_000.rs
@@ -96,6 +96,8 @@
     OpenAi,
     NewConversation,
     ClearConversation,
+    /// Generate a new Script Kit script from the main prompt text
+    GenerateScript,
     /// Send a screenshot of the entire screen to AI Chat
     SendScreenToAi,
     /// Send a screenshot of the focused window to AI Chat
diff --git a/src/builtins/part_001_entries/entries_002.rs b/src/builtins/part_001_entries/entries_002.rs
index 6d1c9334f0ccaf0aab48582aaf42dcb129e1cb6e..72b318c66aeaf124359f4ecd276dae0350287328
--- a/src/builtins/part_001_entries/entries_002.rs
+++ b/src/builtins/part_001_entries/entries_002.rs
@@ -61,6 +61,17 @@
     ));
 
     entries.push(BuiltInEntry::new_with_icon(
+        "builtin-generate-script-with-ai",
+        "Generate Script with AI",
+        "Generate a Script Kit script from your current prompt text",
+        vec![
+            "generate", "script", "ai", "create", "code", "typescript", "shift", "tab",
+        ],
+        BuiltInFeature::AiCommand(AiCommandType::GenerateScript),
+        "ðŸ§ ",
+    ));
+
+    entries.push(BuiltInEntry::new_with_icon(
         "builtin-send-screen-to-ai",
         "Send Screen to AI Chat",
         "Capture the full screen and send it to AI Chat",


thinking
**Investigating module inclusion**
exec
/bin/zsh -lc "sed -n '1,220p' src/app_execute/mod.rs" in /Users/johnlindquist/dev/script-kit-gpui exited 1 in 52ms:
sed: src/app_execute/mod.rs: No such file or directory
file update:
diff --git a/src/ai/mod.rs b/src/ai/mod.rs
index a420b1a5faf59506acdb7caf60681c153a3f9bb6..9a73e9491862633b325b2c52b51a3e20395ff85c
--- a/src/ai/mod.rs
+++ b/src/ai/mod.rs
@@ -37,6 +37,7 @@
 pub(crate) mod providers;
 pub(crate) mod sdk_handlers;
 pub(crate) mod session;
+pub(crate) mod script_generation;
 pub(crate) mod storage;
 pub(crate) mod window;
 
@@ -44,6 +45,7 @@
 pub use self::config::{DetectedKeys, ModelInfo, ProviderConfig};
 pub use self::model::{Chat, ChatId, ChatSource, Message, MessageRole};
 pub use self::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+pub use self::script_generation::{generate_script_from_prompt, GeneratedScriptOutput};
 pub use self::sdk_handlers::try_handle_ai_message;
 pub use self::storage::{
     clear_all_chats, create_chat, delete_chat, get_all_chats, get_chat, get_chat_messages,
diff --git a/src/ai/script_generation.rs b/src/ai/script_generation.rs
new file mode 100644
index 0000000000000000000000000000000000000000..7f2ec8e7576ed50cd10f7aea31a6522875ef667a
--- /dev/null
+++ b/src/ai/script_generation.rs
@@ -0,0 +1,417 @@
+use anyhow::{Context, Result};
+use std::fs::{self, OpenOptions};
+use std::io::{ErrorKind, Write};
+use std::path::{Path, PathBuf};
+use std::sync::Arc;
+
+use super::config::ModelInfo;
+use super::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+
+const AI_SCRIPT_OUTPUT_DIR: &str = "~/.kenv/scripts";
+const AI_SCRIPT_DEFAULT_SLUG: &str = "ai-script";
+const AI_SCRIPT_MAX_SLUG_LEN: usize = 64;
+
+const AI_SCRIPT_GENERATION_SYSTEM_PROMPT: &str = r#"You write production-ready Script Kit scripts.
+
+Return ONLY TypeScript source code for one Script Kit script. Do not include explanations.
+
+Required output conventions:
+1) Include metadata comments at the top:
+   // Name: <clear title>
+   // Description: <one-line summary>
+2) Include: import "@johnlindquist/kit";
+3) Use await arg() for user input when useful.
+4) Use await div() for display output when useful.
+5) Keep the script runnable as-is with sensible defaults and light error handling."#;
+
+#[derive(Debug, Clone)]
+pub struct GeneratedScriptOutput {
+    pub path: PathBuf,
+    pub slug: String,
+    pub model_id: String,
+    pub provider_id: String,
+}
+
+pub fn generate_script_from_prompt(
+    prompt: &str,
+    config: Option<&crate::config::Config>,
+) -> Result<GeneratedScriptOutput> {
+    let normalized_prompt = prompt.trim();
+    if normalized_prompt.is_empty() {
+        anyhow::bail!("AI script generation requires a non-empty prompt");
+    }
+
+    let registry = ProviderRegistry::from_environment_with_config(config);
+    if !registry.has_any_provider() {
+        anyhow::bail!(
+            "No AI providers configured. Configure an API key first (Vercel, OpenAI, Anthropic, etc.)."
+        );
+    }
+
+    let (selected_model, provider) = select_generation_model(&registry)?;
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=provider_ready model_id={} provider_id={} prompt_len={}",
+            selected_model.id,
+            selected_model.provider,
+            normalized_prompt.len()
+        ),
+    );
+
+    let messages = vec![
+        ProviderMessage::system(AI_SCRIPT_GENERATION_SYSTEM_PROMPT),
+        ProviderMessage::user(format!(
+            "Generate a Script Kit script for this user request:\n\n{}",
+            normalized_prompt
+        )),
+    ];
+
+    let raw_response = provider
+        .send_message(&messages, &selected_model.id)
+        .with_context(|| {
+            format!(
+                "AI script generation failed (attempted=send_message, model_id={}, provider_id={})",
+                selected_model.id, selected_model.provider
+            )
+        })?;
+
+    let extracted = extract_script_code(&raw_response);
+    if extracted.trim().is_empty() {
+        anyhow::bail!(
+            "AI returned an empty response for script generation (state=empty_response)"
+        );
+    }
+
+    let slug = slugify_script_name(normalized_prompt);
+    let finalized = enforce_script_kit_conventions(&extracted, normalized_prompt, &slug);
+    let path = write_generated_script(&slug, &finalized).with_context(|| {
+        format!(
+            "Failed writing AI-generated script (state=write_failed, slug={})",
+            slug
+        )
+    })?;
+
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=script_written path={} slug={}",
+            path.display(),
+            slug
+        ),
+    );
+
+    Ok(GeneratedScriptOutput {
+        path,
+        slug,
+        model_id: selected_model.id,
+        provider_id: selected_model.provider,
+    })
+}
+
+fn select_generation_model(registry: &ProviderRegistry) -> Result<(ModelInfo, Arc<dyn AiProvider>)> {
+    let models = registry.get_all_models();
+    let selected_model = models
+        .iter()
+        .find(|model| model.provider.eq_ignore_ascii_case("vercel"))
+        .or_else(|| models.first())
+        .cloned()
+        .context("No AI models available in provider registry")?;
+
+    let provider = registry
+        .find_provider_for_model(&selected_model.id)
+        .cloned()
+        .with_context(|| {
+            format!(
+                "No provider found for selected model '{}' (state=provider_missing)",
+                selected_model.id
+            )
+        })?;
+
+    Ok((selected_model, provider))
+}
+
+fn generated_scripts_dir() -> PathBuf {
+    PathBuf::from(shellexpand::tilde(AI_SCRIPT_OUTPUT_DIR).as_ref())
+}
+
+fn split_fence_header_and_body(fence: &str) -> (&str, &str) {
+    match fence.find('\n') {
+        Some(newline_index) => (&fence[..newline_index], &fence[newline_index + 1..]),
+        None => ("", fence),
+    }
+}
+
+fn extract_fenced_code(response: &str, preferred_languages: Option<&[&str]>) -> Option<String> {
+    let mut remaining = response;
+
+    while let Some(start) = remaining.find("```") {
+        let after_start = &remaining[start + 3..];
+        let Some(end) = after_start.find("```") else {
+            break;
+        };
+
+        let fence_contents = &after_start[..end];
+        let (header, body) = split_fence_header_and_body(fence_contents);
+        let language = header
+            .trim()
+            .split(|c: char| c.is_whitespace() || c == '{')
+            .next()
+            .unwrap_or("")
+            .to_ascii_lowercase();
+        let code = body.trim();
+
+        if !code.is_empty() {
+            match preferred_languages {
+                Some(preferred) => {
+                    if preferred.iter().any(|candidate| *candidate == language) {
+                        return Some(code.to_string());
+                    }
+                }
+                None => return Some(code.to_string()),
+            }
+        }
+
+        remaining = &after_start[end + 3..];
+    }
+
+    None
+}
+
+fn extract_script_code(response: &str) -> String {
+    const PREFERRED_LANGUAGES: [&str; 6] = ["typescript", "ts", "javascript", "js", "tsx", "jsx"];
+
+    extract_fenced_code(response, Some(&PREFERRED_LANGUAGES))
+        .or_else(|| extract_fenced_code(response, None))
+        .unwrap_or_else(|| response.trim().to_string())
+}
+
+fn slugify_script_name(prompt: &str) -> String {
+    let mut slug = String::new();
+    let mut last_was_hyphen = false;
+
+    for character in prompt.to_ascii_lowercase().chars() {
+        if character.is_ascii_alphanumeric() {
+            slug.push(character);
+            last_was_hyphen = false;
+        } else if matches!(character, ' ' | '_' | '-') {
+            if !slug.is_empty() && !last_was_hyphen {
+                slug.push('-');
+                last_was_hyphen = true;
+            }
+        }
+    }
+
+    while slug.ends_with('-') {
+        slug.pop();
+    }
+
+    if slug.len() > AI_SCRIPT_MAX_SLUG_LEN {
+        slug.truncate(AI_SCRIPT_MAX_SLUG_LEN);
+        while slug.ends_with('-') {
+            slug.pop();
+        }
+    }
+
+    if slug.is_empty() {
+        AI_SCRIPT_DEFAULT_SLUG.to_string()
+    } else {
+        slug
+    }
+}
+
+fn slug_to_title(slug: &str) -> String {
+    slug.split('-')
+        .filter(|segment| !segment.is_empty())
+        .map(|segment| {
+            let mut chars = segment.chars();
+            match chars.next() {
+                Some(first) => first.to_uppercase().collect::<String>() + chars.as_str(),
+                None => String::new(),
+            }
+        })
+        .collect::<Vec<_>>()
+        .join(" ")
+}
+
+fn description_from_prompt(prompt: &str) -> String {
+    let normalized = prompt.split_whitespace().collect::<Vec<_>>().join(" ");
+    if normalized.is_empty() {
+        return "AI-generated Script Kit script".to_string();
+    }
+
+    let mut shortened = normalized;
+    if shortened.chars().count() > 110 {
+        shortened = format!("{}...", shortened.chars().take(107).collect::<String>());
+    }
+    shortened
+}
+
+fn has_kit_import(script: &str) -> bool {
+    script.contains("import \"@johnlindquist/kit\";")
+        || script.contains("import '@johnlindquist/kit';")
+        || script.contains("import \"@scriptkit/sdk\";")
+        || script.contains("import '@scriptkit/sdk';")
+}
+
+fn enforce_script_kit_conventions(script: &str, prompt: &str, slug: &str) -> String {
+    let mut prefix_lines: Vec<String> = Vec::new();
+    let trimmed_script = script.trim();
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Name:"))
+    {
+        prefix_lines.push(format!("// Name: {}", slug_to_title(slug)));
+    }
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Description:"))
+    {
+        prefix_lines.push(format!("// Description: {}", description_from_prompt(prompt)));
+    }
+
+    if !has_kit_import(trimmed_script) {
+        prefix_lines.push("import \"@johnlindquist/kit\";".to_string());
+    }
+
+    let mut output = String::new();
+    if !prefix_lines.is_empty() {
+        output.push_str(&prefix_lines.join("\n"));
+        output.push_str("\n\n");
+    }
+
+    output.push_str(trimmed_script);
+    if !output.ends_with('\n') {
+        output.push('\n');
+    }
+    output
+}
+
+fn write_generated_script(slug: &str, script_content: &str) -> Result<PathBuf> {
+    write_generated_script_in_dir(&generated_scripts_dir(), slug, script_content)
+}
+
+fn write_generated_script_in_dir(output_dir: &Path, slug: &str, script_content: &str) -> Result<PathBuf> {
+    fs::create_dir_all(output_dir)
+        .with_context(|| format!("Failed to create output dir: {}", output_dir.display()))?;
+
+    for suffix in 0usize.. {
+        let candidate = if suffix == 0 {
+            slug.to_string()
+        } else {
+            format!("{slug}-{suffix}")
+        };
+        let path = output_dir.join(format!("{}.ts", candidate));
+        match OpenOptions::new().write(true).create_new(true).open(&path) {
+            Ok(mut file) => {
+                file.write_all(script_content.as_bytes())
+                    .with_context(|| format!("Failed writing generated script to {}", path.display()))?;
+                return Ok(path);
+            }
+            Err(error) if error.kind() == ErrorKind::AlreadyExists => continue,
+            Err(error) => {
+                return Err(error).with_context(|| {
+                    format!(
+                        "Failed creating generated script file {} (slug={})",
+                        path.display(),
+                        slug
+                    )
+                });
+            }
+        }
+    }
+
+    unreachable!("suffix loop should eventually create a unique script filename")
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+    use tempfile::tempdir;
+
+    #[test]
+    fn test_slugify_script_name_handles_spaces_and_symbols() {
+        assert_eq!(slugify_script_name("Build: API Client!"), "build-api-client");
+        assert_eq!(slugify_script_name("  ___  "), "ai-script");
+    }
+
+    #[test]
+    fn test_extract_script_code_prefers_typescript_fence_when_multiple_blocks_exist() {
+        let response = r#"
+Here's one idea:
+```markdown
+Not code
+```
+```typescript
+await div("hello");
+```
+"#;
+        assert_eq!(extract_script_code(response), "await div(\"hello\");");
+    }
+
+    #[test]
+    fn test_extract_script_code_falls_back_to_first_fenced_block() {
+        let response = r#"
+```python
+print("hello")
+```
+"#;
+        assert_eq!(extract_script_code(response), "print(\"hello\")");
+    }
+
+    #[test]
+    fn test_extract_script_code_returns_trimmed_response_when_no_fence_exists() {
+        let response = "const answer = 42;";
+        assert_eq!(extract_script_code(response), "const answer = 42;");
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_adds_missing_metadata_and_import() {
+        let script = "const name = await arg(\"Name?\");";
+        let output = enforce_script_kit_conventions(script, "Ask for user name", "ask-user-name");
+
+        assert!(output.contains("// Name: Ask User Name"));
+        assert!(output.contains("// Description: Ask for user name"));
+        assert!(output.contains("import \"@johnlindquist/kit\";"));
+        assert!(output.contains("await arg(\"Name?\");"));
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_keeps_existing_metadata_and_import() {
+        let script = r#"// Name: Existing
+// Description: Existing description
+import "@johnlindquist/kit";
+
+await div("ready");
+"#;
+        let output = enforce_script_kit_conventions(script, "ignored", "ignored");
+
+        assert_eq!(
+            output.matches("// Name:").count(),
+            1,
+            "should not duplicate existing Name metadata"
+        );
+        assert_eq!(
+            output.matches("// Description:").count(),
+            1,
+            "should not duplicate existing Description metadata"
+        );
+        assert_eq!(
+            output.matches("import \"@johnlindquist/kit\";").count(),
+            1,
+            "should not duplicate existing import"
+        );
+    }
+
+    #[test]
+    fn test_write_generated_script_in_dir_appends_numeric_suffix_for_collisions() {
+        let temp_dir = tempdir().unwrap();
+        let first = write_generated_script_in_dir(temp_dir.path(), "my-script", "a").unwrap();
+        let second = write_generated_script_in_dir(temp_dir.path(), "my-script", "b").unwrap();
+
+        assert_eq!(first.file_name().unwrap(), "my-script.ts");
+        assert_eq!(second.file_name().unwrap(), "my-script-1.ts");
+    }
+}
diff --git a/src/builtins/part_000.rs b/src/builtins/part_000.rs
index d6b9c2a9b35b40c5005dbb9f65147f528702cb9e..5f6d27d28d72e51126d10d8beccf931c689ef2bb
--- a/src/builtins/part_000.rs
+++ b/src/builtins/part_000.rs
@@ -96,6 +96,8 @@
     OpenAi,
     NewConversation,
     ClearConversation,
+    /// Generate a new Script Kit script from the main prompt text
+    GenerateScript,
     /// Send a screenshot of the entire screen to AI Chat
     SendScreenToAi,
     /// Send a screenshot of the focused window to AI Chat
diff --git a/src/builtins/part_001_entries/entries_002.rs b/src/builtins/part_001_entries/entries_002.rs
index 6d1c9334f0ccaf0aab48582aaf42dcb129e1cb6e..72b318c66aeaf124359f4ecd276dae0350287328
--- a/src/builtins/part_001_entries/entries_002.rs
+++ b/src/builtins/part_001_entries/entries_002.rs
@@ -61,6 +61,17 @@
     ));
 
     entries.push(BuiltInEntry::new_with_icon(
+        "builtin-generate-script-with-ai",
+        "Generate Script with AI",
+        "Generate a Script Kit script from your current prompt text",
+        vec![
+            "generate", "script", "ai", "create", "code", "typescript", "shift", "tab",
+        ],
+        BuiltInFeature::AiCommand(AiCommandType::GenerateScript),
+        "ðŸ§ ",
+    ));
+
+    entries.push(BuiltInEntry::new_with_icon(
         "builtin-send-screen-to-ai",
         "Send Screen to AI Chat",
         "Capture the full screen and send it to AI Chat",


thinking
**Locating module files**
exec
/bin/zsh -lc 'ls -la src | rg app_execute' in /Users/johnlindquist/dev/script-kit-gpui succeeded in 51ms:
drwxr-xr-x    7 johnlindquist  staff    224 Feb  7 16:45 app_execute
-rw-r--r--    1 johnlindquist  staff    249 Feb  7 09:29 app_execute.rs
file update:
diff --git a/src/ai/mod.rs b/src/ai/mod.rs
index a420b1a5faf59506acdb7caf60681c153a3f9bb6..9a73e9491862633b325b2c52b51a3e20395ff85c
--- a/src/ai/mod.rs
+++ b/src/ai/mod.rs
@@ -37,6 +37,7 @@
 pub(crate) mod providers;
 pub(crate) mod sdk_handlers;
 pub(crate) mod session;
+pub(crate) mod script_generation;
 pub(crate) mod storage;
 pub(crate) mod window;
 
@@ -44,6 +45,7 @@
 pub use self::config::{DetectedKeys, ModelInfo, ProviderConfig};
 pub use self::model::{Chat, ChatId, ChatSource, Message, MessageRole};
 pub use self::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+pub use self::script_generation::{generate_script_from_prompt, GeneratedScriptOutput};
 pub use self::sdk_handlers::try_handle_ai_message;
 pub use self::storage::{
     clear_all_chats, create_chat, delete_chat, get_all_chats, get_chat, get_chat_messages,
diff --git a/src/ai/script_generation.rs b/src/ai/script_generation.rs
new file mode 100644
index 0000000000000000000000000000000000000000..7f2ec8e7576ed50cd10f7aea31a6522875ef667a
--- /dev/null
+++ b/src/ai/script_generation.rs
@@ -0,0 +1,417 @@
+use anyhow::{Context, Result};
+use std::fs::{self, OpenOptions};
+use std::io::{ErrorKind, Write};
+use std::path::{Path, PathBuf};
+use std::sync::Arc;
+
+use super::config::ModelInfo;
+use super::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+
+const AI_SCRIPT_OUTPUT_DIR: &str = "~/.kenv/scripts";
+const AI_SCRIPT_DEFAULT_SLUG: &str = "ai-script";
+const AI_SCRIPT_MAX_SLUG_LEN: usize = 64;
+
+const AI_SCRIPT_GENERATION_SYSTEM_PROMPT: &str = r#"You write production-ready Script Kit scripts.
+
+Return ONLY TypeScript source code for one Script Kit script. Do not include explanations.
+
+Required output conventions:
+1) Include metadata comments at the top:
+   // Name: <clear title>
+   // Description: <one-line summary>
+2) Include: import "@johnlindquist/kit";
+3) Use await arg() for user input when useful.
+4) Use await div() for display output when useful.
+5) Keep the script runnable as-is with sensible defaults and light error handling."#;
+
+#[derive(Debug, Clone)]
+pub struct GeneratedScriptOutput {
+    pub path: PathBuf,
+    pub slug: String,
+    pub model_id: String,
+    pub provider_id: String,
+}
+
+pub fn generate_script_from_prompt(
+    prompt: &str,
+    config: Option<&crate::config::Config>,
+) -> Result<GeneratedScriptOutput> {
+    let normalized_prompt = prompt.trim();
+    if normalized_prompt.is_empty() {
+        anyhow::bail!("AI script generation requires a non-empty prompt");
+    }
+
+    let registry = ProviderRegistry::from_environment_with_config(config);
+    if !registry.has_any_provider() {
+        anyhow::bail!(
+            "No AI providers configured. Configure an API key first (Vercel, OpenAI, Anthropic, etc.)."
+        );
+    }
+
+    let (selected_model, provider) = select_generation_model(&registry)?;
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=provider_ready model_id={} provider_id={} prompt_len={}",
+            selected_model.id,
+            selected_model.provider,
+            normalized_prompt.len()
+        ),
+    );
+
+    let messages = vec![
+        ProviderMessage::system(AI_SCRIPT_GENERATION_SYSTEM_PROMPT),
+        ProviderMessage::user(format!(
+            "Generate a Script Kit script for this user request:\n\n{}",
+            normalized_prompt
+        )),
+    ];
+
+    let raw_response = provider
+        .send_message(&messages, &selected_model.id)
+        .with_context(|| {
+            format!(
+                "AI script generation failed (attempted=send_message, model_id={}, provider_id={})",
+                selected_model.id, selected_model.provider
+            )
+        })?;
+
+    let extracted = extract_script_code(&raw_response);
+    if extracted.trim().is_empty() {
+        anyhow::bail!(
+            "AI returned an empty response for script generation (state=empty_response)"
+        );
+    }
+
+    let slug = slugify_script_name(normalized_prompt);
+    let finalized = enforce_script_kit_conventions(&extracted, normalized_prompt, &slug);
+    let path = write_generated_script(&slug, &finalized).with_context(|| {
+        format!(
+            "Failed writing AI-generated script (state=write_failed, slug={})",
+            slug
+        )
+    })?;
+
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=script_written path={} slug={}",
+            path.display(),
+            slug
+        ),
+    );
+
+    Ok(GeneratedScriptOutput {
+        path,
+        slug,
+        model_id: selected_model.id,
+        provider_id: selected_model.provider,
+    })
+}
+
+fn select_generation_model(registry: &ProviderRegistry) -> Result<(ModelInfo, Arc<dyn AiProvider>)> {
+    let models = registry.get_all_models();
+    let selected_model = models
+        .iter()
+        .find(|model| model.provider.eq_ignore_ascii_case("vercel"))
+        .or_else(|| models.first())
+        .cloned()
+        .context("No AI models available in provider registry")?;
+
+    let provider = registry
+        .find_provider_for_model(&selected_model.id)
+        .cloned()
+        .with_context(|| {
+            format!(
+                "No provider found for selected model '{}' (state=provider_missing)",
+                selected_model.id
+            )
+        })?;
+
+    Ok((selected_model, provider))
+}
+
+fn generated_scripts_dir() -> PathBuf {
+    PathBuf::from(shellexpand::tilde(AI_SCRIPT_OUTPUT_DIR).as_ref())
+}
+
+fn split_fence_header_and_body(fence: &str) -> (&str, &str) {
+    match fence.find('\n') {
+        Some(newline_index) => (&fence[..newline_index], &fence[newline_index + 1..]),
+        None => ("", fence),
+    }
+}
+
+fn extract_fenced_code(response: &str, preferred_languages: Option<&[&str]>) -> Option<String> {
+    let mut remaining = response;
+
+    while let Some(start) = remaining.find("```") {
+        let after_start = &remaining[start + 3..];
+        let Some(end) = after_start.find("```") else {
+            break;
+        };
+
+        let fence_contents = &after_start[..end];
+        let (header, body) = split_fence_header_and_body(fence_contents);
+        let language = header
+            .trim()
+            .split(|c: char| c.is_whitespace() || c == '{')
+            .next()
+            .unwrap_or("")
+            .to_ascii_lowercase();
+        let code = body.trim();
+
+        if !code.is_empty() {
+            match preferred_languages {
+                Some(preferred) => {
+                    if preferred.iter().any(|candidate| *candidate == language) {
+                        return Some(code.to_string());
+                    }
+                }
+                None => return Some(code.to_string()),
+            }
+        }
+
+        remaining = &after_start[end + 3..];
+    }
+
+    None
+}
+
+fn extract_script_code(response: &str) -> String {
+    const PREFERRED_LANGUAGES: [&str; 6] = ["typescript", "ts", "javascript", "js", "tsx", "jsx"];
+
+    extract_fenced_code(response, Some(&PREFERRED_LANGUAGES))
+        .or_else(|| extract_fenced_code(response, None))
+        .unwrap_or_else(|| response.trim().to_string())
+}
+
+fn slugify_script_name(prompt: &str) -> String {
+    let mut slug = String::new();
+    let mut last_was_hyphen = false;
+
+    for character in prompt.to_ascii_lowercase().chars() {
+        if character.is_ascii_alphanumeric() {
+            slug.push(character);
+            last_was_hyphen = false;
+        } else if matches!(character, ' ' | '_' | '-') {
+            if !slug.is_empty() && !last_was_hyphen {
+                slug.push('-');
+                last_was_hyphen = true;
+            }
+        }
+    }
+
+    while slug.ends_with('-') {
+        slug.pop();
+    }
+
+    if slug.len() > AI_SCRIPT_MAX_SLUG_LEN {
+        slug.truncate(AI_SCRIPT_MAX_SLUG_LEN);
+        while slug.ends_with('-') {
+            slug.pop();
+        }
+    }
+
+    if slug.is_empty() {
+        AI_SCRIPT_DEFAULT_SLUG.to_string()
+    } else {
+        slug
+    }
+}
+
+fn slug_to_title(slug: &str) -> String {
+    slug.split('-')
+        .filter(|segment| !segment.is_empty())
+        .map(|segment| {
+            let mut chars = segment.chars();
+            match chars.next() {
+                Some(first) => first.to_uppercase().collect::<String>() + chars.as_str(),
+                None => String::new(),
+            }
+        })
+        .collect::<Vec<_>>()
+        .join(" ")
+}
+
+fn description_from_prompt(prompt: &str) -> String {
+    let normalized = prompt.split_whitespace().collect::<Vec<_>>().join(" ");
+    if normalized.is_empty() {
+        return "AI-generated Script Kit script".to_string();
+    }
+
+    let mut shortened = normalized;
+    if shortened.chars().count() > 110 {
+        shortened = format!("{}...", shortened.chars().take(107).collect::<String>());
+    }
+    shortened
+}
+
+fn has_kit_import(script: &str) -> bool {
+    script.contains("import \"@johnlindquist/kit\";")
+        || script.contains("import '@johnlindquist/kit';")
+        || script.contains("import \"@scriptkit/sdk\";")
+        || script.contains("import '@scriptkit/sdk';")
+}
+
+fn enforce_script_kit_conventions(script: &str, prompt: &str, slug: &str) -> String {
+    let mut prefix_lines: Vec<String> = Vec::new();
+    let trimmed_script = script.trim();
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Name:"))
+    {
+        prefix_lines.push(format!("// Name: {}", slug_to_title(slug)));
+    }
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Description:"))
+    {
+        prefix_lines.push(format!("// Description: {}", description_from_prompt(prompt)));
+    }
+
+    if !has_kit_import(trimmed_script) {
+        prefix_lines.push("import \"@johnlindquist/kit\";".to_string());
+    }
+
+    let mut output = String::new();
+    if !prefix_lines.is_empty() {
+        output.push_str(&prefix_lines.join("\n"));
+        output.push_str("\n\n");
+    }
+
+    output.push_str(trimmed_script);
+    if !output.ends_with('\n') {
+        output.push('\n');
+    }
+    output
+}
+
+fn write_generated_script(slug: &str, script_content: &str) -> Result<PathBuf> {
+    write_generated_script_in_dir(&generated_scripts_dir(), slug, script_content)
+}
+
+fn write_generated_script_in_dir(output_dir: &Path, slug: &str, script_content: &str) -> Result<PathBuf> {
+    fs::create_dir_all(output_dir)
+        .with_context(|| format!("Failed to create output dir: {}", output_dir.display()))?;
+
+    for suffix in 0usize.. {
+        let candidate = if suffix == 0 {
+            slug.to_string()
+        } else {
+            format!("{slug}-{suffix}")
+        };
+        let path = output_dir.join(format!("{}.ts", candidate));
+        match OpenOptions::new().write(true).create_new(true).open(&path) {
+            Ok(mut file) => {
+                file.write_all(script_content.as_bytes())
+                    .with_context(|| format!("Failed writing generated script to {}", path.display()))?;
+                return Ok(path);
+            }
+            Err(error) if error.kind() == ErrorKind::AlreadyExists => continue,
+            Err(error) => {
+                return Err(error).with_context(|| {
+                    format!(
+                        "Failed creating generated script file {} (slug={})",
+                        path.display(),
+                        slug
+                    )
+                });
+            }
+        }
+    }
+
+    unreachable!("suffix loop should eventually create a unique script filename")
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+    use tempfile::tempdir;
+
+    #[test]
+    fn test_slugify_script_name_handles_spaces_and_symbols() {
+        assert_eq!(slugify_script_name("Build: API Client!"), "build-api-client");
+        assert_eq!(slugify_script_name("  ___  "), "ai-script");
+    }
+
+    #[test]
+    fn test_extract_script_code_prefers_typescript_fence_when_multiple_blocks_exist() {
+        let response = r#"
+Here's one idea:
+```markdown
+Not code
+```
+```typescript
+await div("hello");
+```
+"#;
+        assert_eq!(extract_script_code(response), "await div(\"hello\");");
+    }
+
+    #[test]
+    fn test_extract_script_code_falls_back_to_first_fenced_block() {
+        let response = r#"
+```python
+print("hello")
+```
+"#;
+        assert_eq!(extract_script_code(response), "print(\"hello\")");
+    }
+
+    #[test]
+    fn test_extract_script_code_returns_trimmed_response_when_no_fence_exists() {
+        let response = "const answer = 42;";
+        assert_eq!(extract_script_code(response), "const answer = 42;");
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_adds_missing_metadata_and_import() {
+        let script = "const name = await arg(\"Name?\");";
+        let output = enforce_script_kit_conventions(script, "Ask for user name", "ask-user-name");
+
+        assert!(output.contains("// Name: Ask User Name"));
+        assert!(output.contains("// Description: Ask for user name"));
+        assert!(output.contains("import \"@johnlindquist/kit\";"));
+        assert!(output.contains("await arg(\"Name?\");"));
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_keeps_existing_metadata_and_import() {
+        let script = r#"// Name: Existing
+// Description: Existing description
+import "@johnlindquist/kit";
+
+await div("ready");
+"#;
+        let output = enforce_script_kit_conventions(script, "ignored", "ignored");
+
+        assert_eq!(
+            output.matches("// Name:").count(),
+            1,
+            "should not duplicate existing Name metadata"
+        );
+        assert_eq!(
+            output.matches("// Description:").count(),
+            1,
+            "should not duplicate existing Description metadata"
+        );
+        assert_eq!(
+            output.matches("import \"@johnlindquist/kit\";").count(),
+            1,
+            "should not duplicate existing import"
+        );
+    }
+
+    #[test]
+    fn test_write_generated_script_in_dir_appends_numeric_suffix_for_collisions() {
+        let temp_dir = tempdir().unwrap();
+        let first = write_generated_script_in_dir(temp_dir.path(), "my-script", "a").unwrap();
+        let second = write_generated_script_in_dir(temp_dir.path(), "my-script", "b").unwrap();
+
+        assert_eq!(first.file_name().unwrap(), "my-script.ts");
+        assert_eq!(second.file_name().unwrap(), "my-script-1.ts");
+    }
+}
diff --git a/src/builtins/part_000.rs b/src/builtins/part_000.rs
index d6b9c2a9b35b40c5005dbb9f65147f528702cb9e..5f6d27d28d72e51126d10d8beccf931c689ef2bb
--- a/src/builtins/part_000.rs
+++ b/src/builtins/part_000.rs
@@ -96,6 +96,8 @@
     OpenAi,
     NewConversation,
     ClearConversation,
+    /// Generate a new Script Kit script from the main prompt text
+    GenerateScript,
     /// Send a screenshot of the entire screen to AI Chat
     SendScreenToAi,
     /// Send a screenshot of the focused window to AI Chat
diff --git a/src/builtins/part_001_entries/entries_002.rs b/src/builtins/part_001_entries/entries_002.rs
index 6d1c9334f0ccaf0aab48582aaf42dcb129e1cb6e..72b318c66aeaf124359f4ecd276dae0350287328
--- a/src/builtins/part_001_entries/entries_002.rs
+++ b/src/builtins/part_001_entries/entries_002.rs
@@ -61,6 +61,17 @@
     ));
 
     entries.push(BuiltInEntry::new_with_icon(
+        "builtin-generate-script-with-ai",
+        "Generate Script with AI",
+        "Generate a Script Kit script from your current prompt text",
+        vec![
+            "generate", "script", "ai", "create", "code", "typescript", "shift", "tab",
+        ],
+        BuiltInFeature::AiCommand(AiCommandType::GenerateScript),
+        "ðŸ§ ",
+    ));
+
+    entries.push(BuiltInEntry::new_with_icon(
         "builtin-send-screen-to-ai",
         "Send Screen to AI Chat",
         "Capture the full screen and send it to AI Chat",


thinking
**Locating core execution code**
exec
/bin/zsh -lc "sed -n '1,220p' src/app_execute.rs" in /Users/johnlindquist/dev/script-kit-gpui succeeded in 50ms:
// App execution methods split into sub-files for maintainability
include!("app_execute/builtin_execution.rs");
include!("app_execute/execution_helpers.rs");
include!("app_execute/utility_views.rs");
include!("app_execute/builtin_confirmation.rs");
file update:
diff --git a/src/ai/mod.rs b/src/ai/mod.rs
index a420b1a5faf59506acdb7caf60681c153a3f9bb6..9a73e9491862633b325b2c52b51a3e20395ff85c
--- a/src/ai/mod.rs
+++ b/src/ai/mod.rs
@@ -37,6 +37,7 @@
 pub(crate) mod providers;
 pub(crate) mod sdk_handlers;
 pub(crate) mod session;
+pub(crate) mod script_generation;
 pub(crate) mod storage;
 pub(crate) mod window;
 
@@ -44,6 +45,7 @@
 pub use self::config::{DetectedKeys, ModelInfo, ProviderConfig};
 pub use self::model::{Chat, ChatId, ChatSource, Message, MessageRole};
 pub use self::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+pub use self::script_generation::{generate_script_from_prompt, GeneratedScriptOutput};
 pub use self::sdk_handlers::try_handle_ai_message;
 pub use self::storage::{
     clear_all_chats, create_chat, delete_chat, get_all_chats, get_chat, get_chat_messages,
diff --git a/src/ai/script_generation.rs b/src/ai/script_generation.rs
new file mode 100644
index 0000000000000000000000000000000000000000..7f2ec8e7576ed50cd10f7aea31a6522875ef667a
--- /dev/null
+++ b/src/ai/script_generation.rs
@@ -0,0 +1,417 @@
+use anyhow::{Context, Result};
+use std::fs::{self, OpenOptions};
+use std::io::{ErrorKind, Write};
+use std::path::{Path, PathBuf};
+use std::sync::Arc;
+
+use super::config::ModelInfo;
+use super::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+
+const AI_SCRIPT_OUTPUT_DIR: &str = "~/.kenv/scripts";
+const AI_SCRIPT_DEFAULT_SLUG: &str = "ai-script";
+const AI_SCRIPT_MAX_SLUG_LEN: usize = 64;
+
+const AI_SCRIPT_GENERATION_SYSTEM_PROMPT: &str = r#"You write production-ready Script Kit scripts.
+
+Return ONLY TypeScript source code for one Script Kit script. Do not include explanations.
+
+Required output conventions:
+1) Include metadata comments at the top:
+   // Name: <clear title>
+   // Description: <one-line summary>
+2) Include: import "@johnlindquist/kit";
+3) Use await arg() for user input when useful.
+4) Use await div() for display output when useful.
+5) Keep the script runnable as-is with sensible defaults and light error handling."#;
+
+#[derive(Debug, Clone)]
+pub struct GeneratedScriptOutput {
+    pub path: PathBuf,
+    pub slug: String,
+    pub model_id: String,
+    pub provider_id: String,
+}
+
+pub fn generate_script_from_prompt(
+    prompt: &str,
+    config: Option<&crate::config::Config>,
+) -> Result<GeneratedScriptOutput> {
+    let normalized_prompt = prompt.trim();
+    if normalized_prompt.is_empty() {
+        anyhow::bail!("AI script generation requires a non-empty prompt");
+    }
+
+    let registry = ProviderRegistry::from_environment_with_config(config);
+    if !registry.has_any_provider() {
+        anyhow::bail!(
+            "No AI providers configured. Configure an API key first (Vercel, OpenAI, Anthropic, etc.)."
+        );
+    }
+
+    let (selected_model, provider) = select_generation_model(&registry)?;
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=provider_ready model_id={} provider_id={} prompt_len={}",
+            selected_model.id,
+            selected_model.provider,
+            normalized_prompt.len()
+        ),
+    );
+
+    let messages = vec![
+        ProviderMessage::system(AI_SCRIPT_GENERATION_SYSTEM_PROMPT),
+        ProviderMessage::user(format!(
+            "Generate a Script Kit script for this user request:\n\n{}",
+            normalized_prompt
+        )),
+    ];
+
+    let raw_response = provider
+        .send_message(&messages, &selected_model.id)
+        .with_context(|| {
+            format!(
+                "AI script generation failed (attempted=send_message, model_id={}, provider_id={})",
+                selected_model.id, selected_model.provider
+            )
+        })?;
+
+    let extracted = extract_script_code(&raw_response);
+    if extracted.trim().is_empty() {
+        anyhow::bail!(
+            "AI returned an empty response for script generation (state=empty_response)"
+        );
+    }
+
+    let slug = slugify_script_name(normalized_prompt);
+    let finalized = enforce_script_kit_conventions(&extracted, normalized_prompt, &slug);
+    let path = write_generated_script(&slug, &finalized).with_context(|| {
+        format!(
+            "Failed writing AI-generated script (state=write_failed, slug={})",
+            slug
+        )
+    })?;
+
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=script_written path={} slug={}",
+            path.display(),
+            slug
+        ),
+    );
+
+    Ok(GeneratedScriptOutput {
+        path,
+        slug,
+        model_id: selected_model.id,
+        provider_id: selected_model.provider,
+    })
+}
+
+fn select_generation_model(registry: &ProviderRegistry) -> Result<(ModelInfo, Arc<dyn AiProvider>)> {
+    let models = registry.get_all_models();
+    let selected_model = models
+        .iter()
+        .find(|model| model.provider.eq_ignore_ascii_case("vercel"))
+        .or_else(|| models.first())
+        .cloned()
+        .context("No AI models available in provider registry")?;
+
+    let provider = registry
+        .find_provider_for_model(&selected_model.id)
+        .cloned()
+        .with_context(|| {
+            format!(
+                "No provider found for selected model '{}' (state=provider_missing)",
+                selected_model.id
+            )
+        })?;
+
+    Ok((selected_model, provider))
+}
+
+fn generated_scripts_dir() -> PathBuf {
+    PathBuf::from(shellexpand::tilde(AI_SCRIPT_OUTPUT_DIR).as_ref())
+}
+
+fn split_fence_header_and_body(fence: &str) -> (&str, &str) {
+    match fence.find('\n') {
+        Some(newline_index) => (&fence[..newline_index], &fence[newline_index + 1..]),
+        None => ("", fence),
+    }
+}
+
+fn extract_fenced_code(response: &str, preferred_languages: Option<&[&str]>) -> Option<String> {
+    let mut remaining = response;
+
+    while let Some(start) = remaining.find("```") {
+        let after_start = &remaining[start + 3..];
+        let Some(end) = after_start.find("```") else {
+            break;
+        };
+
+        let fence_contents = &after_start[..end];
+        let (header, body) = split_fence_header_and_body(fence_contents);
+        let language = header
+            .trim()
+            .split(|c: char| c.is_whitespace() || c == '{')
+            .next()
+            .unwrap_or("")
+            .to_ascii_lowercase();
+        let code = body.trim();
+
+        if !code.is_empty() {
+            match preferred_languages {
+                Some(preferred) => {
+                    if preferred.iter().any(|candidate| *candidate == language) {
+                        return Some(code.to_string());
+                    }
+                }
+                None => return Some(code.to_string()),
+            }
+        }
+
+        remaining = &after_start[end + 3..];
+    }
+
+    None
+}
+
+fn extract_script_code(response: &str) -> String {
+    const PREFERRED_LANGUAGES: [&str; 6] = ["typescript", "ts", "javascript", "js", "tsx", "jsx"];
+
+    extract_fenced_code(response, Some(&PREFERRED_LANGUAGES))
+        .or_else(|| extract_fenced_code(response, None))
+        .unwrap_or_else(|| response.trim().to_string())
+}
+
+fn slugify_script_name(prompt: &str) -> String {
+    let mut slug = String::new();
+    let mut last_was_hyphen = false;
+
+    for character in prompt.to_ascii_lowercase().chars() {
+        if character.is_ascii_alphanumeric() {
+            slug.push(character);
+            last_was_hyphen = false;
+        } else if matches!(character, ' ' | '_' | '-') {
+            if !slug.is_empty() && !last_was_hyphen {
+                slug.push('-');
+                last_was_hyphen = true;
+            }
+        }
+    }
+
+    while slug.ends_with('-') {
+        slug.pop();
+    }
+
+    if slug.len() > AI_SCRIPT_MAX_SLUG_LEN {
+        slug.truncate(AI_SCRIPT_MAX_SLUG_LEN);
+        while slug.ends_with('-') {
+            slug.pop();
+        }
+    }
+
+    if slug.is_empty() {
+        AI_SCRIPT_DEFAULT_SLUG.to_string()
+    } else {
+        slug
+    }
+}
+
+fn slug_to_title(slug: &str) -> String {
+    slug.split('-')
+        .filter(|segment| !segment.is_empty())
+        .map(|segment| {
+            let mut chars = segment.chars();
+            match chars.next() {
+                Some(first) => first.to_uppercase().collect::<String>() + chars.as_str(),
+                None => String::new(),
+            }
+        })
+        .collect::<Vec<_>>()
+        .join(" ")
+}
+
+fn description_from_prompt(prompt: &str) -> String {
+    let normalized = prompt.split_whitespace().collect::<Vec<_>>().join(" ");
+    if normalized.is_empty() {
+        return "AI-generated Script Kit script".to_string();
+    }
+
+    let mut shortened = normalized;
+    if shortened.chars().count() > 110 {
+        shortened = format!("{}...", shortened.chars().take(107).collect::<String>());
+    }
+    shortened
+}
+
+fn has_kit_import(script: &str) -> bool {
+    script.contains("import \"@johnlindquist/kit\";")
+        || script.contains("import '@johnlindquist/kit';")
+        || script.contains("import \"@scriptkit/sdk\";")
+        || script.contains("import '@scriptkit/sdk';")
+}
+
+fn enforce_script_kit_conventions(script: &str, prompt: &str, slug: &str) -> String {
+    let mut prefix_lines: Vec<String> = Vec::new();
+    let trimmed_script = script.trim();
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Name:"))
+    {
+        prefix_lines.push(format!("// Name: {}", slug_to_title(slug)));
+    }
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Description:"))
+    {
+        prefix_lines.push(format!("// Description: {}", description_from_prompt(prompt)));
+    }
+
+    if !has_kit_import(trimmed_script) {
+        prefix_lines.push("import \"@johnlindquist/kit\";".to_string());
+    }
+
+    let mut output = String::new();
+    if !prefix_lines.is_empty() {
+        output.push_str(&prefix_lines.join("\n"));
+        output.push_str("\n\n");
+    }
+
+    output.push_str(trimmed_script);
+    if !output.ends_with('\n') {
+        output.push('\n');
+    }
+    output
+}
+
+fn write_generated_script(slug: &str, script_content: &str) -> Result<PathBuf> {
+    write_generated_script_in_dir(&generated_scripts_dir(), slug, script_content)
+}
+
+fn write_generated_script_in_dir(output_dir: &Path, slug: &str, script_content: &str) -> Result<PathBuf> {
+    fs::create_dir_all(output_dir)
+        .with_context(|| format!("Failed to create output dir: {}", output_dir.display()))?;
+
+    for suffix in 0usize.. {
+        let candidate = if suffix == 0 {
+            slug.to_string()
+        } else {
+            format!("{slug}-{suffix}")
+        };
+        let path = output_dir.join(format!("{}.ts", candidate));
+        match OpenOptions::new().write(true).create_new(true).open(&path) {
+            Ok(mut file) => {
+                file.write_all(script_content.as_bytes())
+                    .with_context(|| format!("Failed writing generated script to {}", path.display()))?;
+                return Ok(path);
+            }
+            Err(error) if error.kind() == ErrorKind::AlreadyExists => continue,
+            Err(error) => {
+                return Err(error).with_context(|| {
+                    format!(
+                        "Failed creating generated script file {} (slug={})",
+                        path.display(),
+                        slug
+                    )
+                });
+            }
+        }
+    }
+
+    unreachable!("suffix loop should eventually create a unique script filename")
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+    use tempfile::tempdir;
+
+    #[test]
+    fn test_slugify_script_name_handles_spaces_and_symbols() {
+        assert_eq!(slugify_script_name("Build: API Client!"), "build-api-client");
+        assert_eq!(slugify_script_name("  ___  "), "ai-script");
+    }
+
+    #[test]
+    fn test_extract_script_code_prefers_typescript_fence_when_multiple_blocks_exist() {
+        let response = r#"
+Here's one idea:
+```markdown
+Not code
+```
+```typescript
+await div("hello");
+```
+"#;
+        assert_eq!(extract_script_code(response), "await div(\"hello\");");
+    }
+
+    #[test]
+    fn test_extract_script_code_falls_back_to_first_fenced_block() {
+        let response = r#"
+```python
+print("hello")
+```
+"#;
+        assert_eq!(extract_script_code(response), "print(\"hello\")");
+    }
+
+    #[test]
+    fn test_extract_script_code_returns_trimmed_response_when_no_fence_exists() {
+        let response = "const answer = 42;";
+        assert_eq!(extract_script_code(response), "const answer = 42;");
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_adds_missing_metadata_and_import() {
+        let script = "const name = await arg(\"Name?\");";
+        let output = enforce_script_kit_conventions(script, "Ask for user name", "ask-user-name");
+
+        assert!(output.contains("// Name: Ask User Name"));
+        assert!(output.contains("// Description: Ask for user name"));
+        assert!(output.contains("import \"@johnlindquist/kit\";"));
+        assert!(output.contains("await arg(\"Name?\");"));
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_keeps_existing_metadata_and_import() {
+        let script = r#"// Name: Existing
+// Description: Existing description
+import "@johnlindquist/kit";
+
+await div("ready");
+"#;
+        let output = enforce_script_kit_conventions(script, "ignored", "ignored");
+
+        assert_eq!(
+            output.matches("// Name:").count(),
+            1,
+            "should not duplicate existing Name metadata"
+        );
+        assert_eq!(
+            output.matches("// Description:").count(),
+            1,
+            "should not duplicate existing Description metadata"
+        );
+        assert_eq!(
+            output.matches("import \"@johnlindquist/kit\";").count(),
+            1,
+            "should not duplicate existing import"
+        );
+    }
+
+    #[test]
+    fn test_write_generated_script_in_dir_appends_numeric_suffix_for_collisions() {
+        let temp_dir = tempdir().unwrap();
+        let first = write_generated_script_in_dir(temp_dir.path(), "my-script", "a").unwrap();
+        let second = write_generated_script_in_dir(temp_dir.path(), "my-script", "b").unwrap();
+
+        assert_eq!(first.file_name().unwrap(), "my-script.ts");
+        assert_eq!(second.file_name().unwrap(), "my-script-1.ts");
+    }
+}
diff --git a/src/builtins/part_000.rs b/src/builtins/part_000.rs
index d6b9c2a9b35b40c5005dbb9f65147f528702cb9e..5f6d27d28d72e51126d10d8beccf931c689ef2bb
--- a/src/builtins/part_000.rs
+++ b/src/builtins/part_000.rs
@@ -96,6 +96,8 @@
     OpenAi,
     NewConversation,
     ClearConversation,
+    /// Generate a new Script Kit script from the main prompt text
+    GenerateScript,
     /// Send a screenshot of the entire screen to AI Chat
     SendScreenToAi,
     /// Send a screenshot of the focused window to AI Chat
diff --git a/src/builtins/part_001_entries/entries_002.rs b/src/builtins/part_001_entries/entries_002.rs
index 6d1c9334f0ccaf0aab48582aaf42dcb129e1cb6e..72b318c66aeaf124359f4ecd276dae0350287328
--- a/src/builtins/part_001_entries/entries_002.rs
+++ b/src/builtins/part_001_entries/entries_002.rs
@@ -61,6 +61,17 @@
     ));
 
     entries.push(BuiltInEntry::new_with_icon(
+        "builtin-generate-script-with-ai",
+        "Generate Script with AI",
+        "Generate a Script Kit script from your current prompt text",
+        vec![
+            "generate", "script", "ai", "create", "code", "typescript", "shift", "tab",
+        ],
+        BuiltInFeature::AiCommand(AiCommandType::GenerateScript),
+        "ðŸ§ ",
+    ));
+
+    entries.push(BuiltInEntry::new_with_icon(
         "builtin-send-screen-to-ai",
         "Send Screen to AI Chat",
         "Capture the full screen and send it to AI Chat",


thinking
**Inspecting import statements in main module**
exec
/bin/zsh -lc 'rg -n "include!'"\\(\\\"app_execute/builtin_execution.rs\\\"\\)|mod app_execute|use crate::ai|use gpui::Context\" src/app.rs src/lib.rs src/main.rs src/* | head -n 80" in /Users/johnlindquist/dev/script-kit-gpui succeeded in 51ms:
rg: src/app.rs: No such file or directory (os error 2)
src/prompt_handler/part_001.rs:1702:                    use crate::ai::ProviderRegistry;
src/app_execute.rs:2:include!("app_execute/builtin_execution.rs");
src/prompt_handler/part_001_arms/arms_004.rs:287:                    use crate::ai::ProviderRegistry;
src/app_impl/prompt_ai.rs:349:        use crate::ai::ProviderRegistry;
src/hotkey_pollers.rs:3:use crate::ai;
src/ai/window/streaming_submit.rs:2:use crate::ai::model::ImageAttachment;
src/ai/window/streaming_submit.rs:3:use crate::ai::providers::{ProviderImage, ProviderMessage};
src/prompts/chat/mod.rs:24:use crate::ai::providers::{ProviderMessage, ProviderRegistry};
src/prompts/chat/mod.rs:25:use crate::ai::{self, Chat, ChatSource, Message, MessageRole, ModelInfo};
file update:
diff --git a/src/ai/mod.rs b/src/ai/mod.rs
index a420b1a5faf59506acdb7caf60681c153a3f9bb6..9a73e9491862633b325b2c52b51a3e20395ff85c
--- a/src/ai/mod.rs
+++ b/src/ai/mod.rs
@@ -37,6 +37,7 @@
 pub(crate) mod providers;
 pub(crate) mod sdk_handlers;
 pub(crate) mod session;
+pub(crate) mod script_generation;
 pub(crate) mod storage;
 pub(crate) mod window;
 
@@ -44,6 +45,7 @@
 pub use self::config::{DetectedKeys, ModelInfo, ProviderConfig};
 pub use self::model::{Chat, ChatId, ChatSource, Message, MessageRole};
 pub use self::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+pub use self::script_generation::{generate_script_from_prompt, GeneratedScriptOutput};
 pub use self::sdk_handlers::try_handle_ai_message;
 pub use self::storage::{
     clear_all_chats, create_chat, delete_chat, get_all_chats, get_chat, get_chat_messages,
diff --git a/src/ai/script_generation.rs b/src/ai/script_generation.rs
new file mode 100644
index 0000000000000000000000000000000000000000..7f2ec8e7576ed50cd10f7aea31a6522875ef667a
--- /dev/null
+++ b/src/ai/script_generation.rs
@@ -0,0 +1,417 @@
+use anyhow::{Context, Result};
+use std::fs::{self, OpenOptions};
+use std::io::{ErrorKind, Write};
+use std::path::{Path, PathBuf};
+use std::sync::Arc;
+
+use super::config::ModelInfo;
+use super::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+
+const AI_SCRIPT_OUTPUT_DIR: &str = "~/.kenv/scripts";
+const AI_SCRIPT_DEFAULT_SLUG: &str = "ai-script";
+const AI_SCRIPT_MAX_SLUG_LEN: usize = 64;
+
+const AI_SCRIPT_GENERATION_SYSTEM_PROMPT: &str = r#"You write production-ready Script Kit scripts.
+
+Return ONLY TypeScript source code for one Script Kit script. Do not include explanations.
+
+Required output conventions:
+1) Include metadata comments at the top:
+   // Name: <clear title>
+   // Description: <one-line summary>
+2) Include: import "@johnlindquist/kit";
+3) Use await arg() for user input when useful.
+4) Use await div() for display output when useful.
+5) Keep the script runnable as-is with sensible defaults and light error handling."#;
+
+#[derive(Debug, Clone)]
+pub struct GeneratedScriptOutput {
+    pub path: PathBuf,
+    pub slug: String,
+    pub model_id: String,
+    pub provider_id: String,
+}
+
+pub fn generate_script_from_prompt(
+    prompt: &str,
+    config: Option<&crate::config::Config>,
+) -> Result<GeneratedScriptOutput> {
+    let normalized_prompt = prompt.trim();
+    if normalized_prompt.is_empty() {
+        anyhow::bail!("AI script generation requires a non-empty prompt");
+    }
+
+    let registry = ProviderRegistry::from_environment_with_config(config);
+    if !registry.has_any_provider() {
+        anyhow::bail!(
+            "No AI providers configured. Configure an API key first (Vercel, OpenAI, Anthropic, etc.)."
+        );
+    }
+
+    let (selected_model, provider) = select_generation_model(&registry)?;
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=provider_ready model_id={} provider_id={} prompt_len={}",
+            selected_model.id,
+            selected_model.provider,
+            normalized_prompt.len()
+        ),
+    );
+
+    let messages = vec![
+        ProviderMessage::system(AI_SCRIPT_GENERATION_SYSTEM_PROMPT),
+        ProviderMessage::user(format!(
+            "Generate a Script Kit script for this user request:\n\n{}",
+            normalized_prompt
+        )),
+    ];
+
+    let raw_response = provider
+        .send_message(&messages, &selected_model.id)
+        .with_context(|| {
+            format!(
+                "AI script generation failed (attempted=send_message, model_id={}, provider_id={})",
+                selected_model.id, selected_model.provider
+            )
+        })?;
+
+    let extracted = extract_script_code(&raw_response);
+    if extracted.trim().is_empty() {
+        anyhow::bail!(
+            "AI returned an empty response for script generation (state=empty_response)"
+        );
+    }
+
+    let slug = slugify_script_name(normalized_prompt);
+    let finalized = enforce_script_kit_conventions(&extracted, normalized_prompt, &slug);
+    let path = write_generated_script(&slug, &finalized).with_context(|| {
+        format!(
+            "Failed writing AI-generated script (state=write_failed, slug={})",
+            slug
+        )
+    })?;
+
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=script_written path={} slug={}",
+            path.display(),
+            slug
+        ),
+    );
+
+    Ok(GeneratedScriptOutput {
+        path,
+        slug,
+        model_id: selected_model.id,
+        provider_id: selected_model.provider,
+    })
+}
+
+fn select_generation_model(registry: &ProviderRegistry) -> Result<(ModelInfo, Arc<dyn AiProvider>)> {
+    let models = registry.get_all_models();
+    let selected_model = models
+        .iter()
+        .find(|model| model.provider.eq_ignore_ascii_case("vercel"))
+        .or_else(|| models.first())
+        .cloned()
+        .context("No AI models available in provider registry")?;
+
+    let provider = registry
+        .find_provider_for_model(&selected_model.id)
+        .cloned()
+        .with_context(|| {
+            format!(
+                "No provider found for selected model '{}' (state=provider_missing)",
+                selected_model.id
+            )
+        })?;
+
+    Ok((selected_model, provider))
+}
+
+fn generated_scripts_dir() -> PathBuf {
+    PathBuf::from(shellexpand::tilde(AI_SCRIPT_OUTPUT_DIR).as_ref())
+}
+
+fn split_fence_header_and_body(fence: &str) -> (&str, &str) {
+    match fence.find('\n') {
+        Some(newline_index) => (&fence[..newline_index], &fence[newline_index + 1..]),
+        None => ("", fence),
+    }
+}
+
+fn extract_fenced_code(response: &str, preferred_languages: Option<&[&str]>) -> Option<String> {
+    let mut remaining = response;
+
+    while let Some(start) = remaining.find("```") {
+        let after_start = &remaining[start + 3..];
+        let Some(end) = after_start.find("```") else {
+            break;
+        };
+
+        let fence_contents = &after_start[..end];
+        let (header, body) = split_fence_header_and_body(fence_contents);
+        let language = header
+            .trim()
+            .split(|c: char| c.is_whitespace() || c == '{')
+            .next()
+            .unwrap_or("")
+            .to_ascii_lowercase();
+        let code = body.trim();
+
+        if !code.is_empty() {
+            match preferred_languages {
+                Some(preferred) => {
+                    if preferred.iter().any(|candidate| *candidate == language) {
+                        return Some(code.to_string());
+                    }
+                }
+                None => return Some(code.to_string()),
+            }
+        }
+
+        remaining = &after_start[end + 3..];
+    }
+
+    None
+}
+
+fn extract_script_code(response: &str) -> String {
+    const PREFERRED_LANGUAGES: [&str; 6] = ["typescript", "ts", "javascript", "js", "tsx", "jsx"];
+
+    extract_fenced_code(response, Some(&PREFERRED_LANGUAGES))
+        .or_else(|| extract_fenced_code(response, None))
+        .unwrap_or_else(|| response.trim().to_string())
+}
+
+fn slugify_script_name(prompt: &str) -> String {
+    let mut slug = String::new();
+    let mut last_was_hyphen = false;
+
+    for character in prompt.to_ascii_lowercase().chars() {
+        if character.is_ascii_alphanumeric() {
+            slug.push(character);
+            last_was_hyphen = false;
+        } else if matches!(character, ' ' | '_' | '-') {
+            if !slug.is_empty() && !last_was_hyphen {
+                slug.push('-');
+                last_was_hyphen = true;
+            }
+        }
+    }
+
+    while slug.ends_with('-') {
+        slug.pop();
+    }
+
+    if slug.len() > AI_SCRIPT_MAX_SLUG_LEN {
+        slug.truncate(AI_SCRIPT_MAX_SLUG_LEN);
+        while slug.ends_with('-') {
+            slug.pop();
+        }
+    }
+
+    if slug.is_empty() {
+        AI_SCRIPT_DEFAULT_SLUG.to_string()
+    } else {
+        slug
+    }
+}
+
+fn slug_to_title(slug: &str) -> String {
+    slug.split('-')
+        .filter(|segment| !segment.is_empty())
+        .map(|segment| {
+            let mut chars = segment.chars();
+            match chars.next() {
+                Some(first) => first.to_uppercase().collect::<String>() + chars.as_str(),
+                None => String::new(),
+            }
+        })
+        .collect::<Vec<_>>()
+        .join(" ")
+}
+
+fn description_from_prompt(prompt: &str) -> String {
+    let normalized = prompt.split_whitespace().collect::<Vec<_>>().join(" ");
+    if normalized.is_empty() {
+        return "AI-generated Script Kit script".to_string();
+    }
+
+    let mut shortened = normalized;
+    if shortened.chars().count() > 110 {
+        shortened = format!("{}...", shortened.chars().take(107).collect::<String>());
+    }
+    shortened
+}
+
+fn has_kit_import(script: &str) -> bool {
+    script.contains("import \"@johnlindquist/kit\";")
+        || script.contains("import '@johnlindquist/kit';")
+        || script.contains("import \"@scriptkit/sdk\";")
+        || script.contains("import '@scriptkit/sdk';")
+}
+
+fn enforce_script_kit_conventions(script: &str, prompt: &str, slug: &str) -> String {
+    let mut prefix_lines: Vec<String> = Vec::new();
+    let trimmed_script = script.trim();
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Name:"))
+    {
+        prefix_lines.push(format!("// Name: {}", slug_to_title(slug)));
+    }
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Description:"))
+    {
+        prefix_lines.push(format!("// Description: {}", description_from_prompt(prompt)));
+    }
+
+    if !has_kit_import(trimmed_script) {
+        prefix_lines.push("import \"@johnlindquist/kit\";".to_string());
+    }
+
+    let mut output = String::new();
+    if !prefix_lines.is_empty() {
+        output.push_str(&prefix_lines.join("\n"));
+        output.push_str("\n\n");
+    }
+
+    output.push_str(trimmed_script);
+    if !output.ends_with('\n') {
+        output.push('\n');
+    }
+    output
+}
+
+fn write_generated_script(slug: &str, script_content: &str) -> Result<PathBuf> {
+    write_generated_script_in_dir(&generated_scripts_dir(), slug, script_content)
+}
+
+fn write_generated_script_in_dir(output_dir: &Path, slug: &str, script_content: &str) -> Result<PathBuf> {
+    fs::create_dir_all(output_dir)
+        .with_context(|| format!("Failed to create output dir: {}", output_dir.display()))?;
+
+    for suffix in 0usize.. {
+        let candidate = if suffix == 0 {
+            slug.to_string()
+        } else {
+            format!("{slug}-{suffix}")
+        };
+        let path = output_dir.join(format!("{}.ts", candidate));
+        match OpenOptions::new().write(true).create_new(true).open(&path) {
+            Ok(mut file) => {
+                file.write_all(script_content.as_bytes())
+                    .with_context(|| format!("Failed writing generated script to {}", path.display()))?;
+                return Ok(path);
+            }
+            Err(error) if error.kind() == ErrorKind::AlreadyExists => continue,
+            Err(error) => {
+                return Err(error).with_context(|| {
+                    format!(
+                        "Failed creating generated script file {} (slug={})",
+                        path.display(),
+                        slug
+                    )
+                });
+            }
+        }
+    }
+
+    unreachable!("suffix loop should eventually create a unique script filename")
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+    use tempfile::tempdir;
+
+    #[test]
+    fn test_slugify_script_name_handles_spaces_and_symbols() {
+        assert_eq!(slugify_script_name("Build: API Client!"), "build-api-client");
+        assert_eq!(slugify_script_name("  ___  "), "ai-script");
+    }
+
+    #[test]
+    fn test_extract_script_code_prefers_typescript_fence_when_multiple_blocks_exist() {
+        let response = r#"
+Here's one idea:
+```markdown
+Not code
+```
+```typescript
+await div("hello");
+```
+"#;
+        assert_eq!(extract_script_code(response), "await div(\"hello\");");
+    }
+
+    #[test]
+    fn test_extract_script_code_falls_back_to_first_fenced_block() {
+        let response = r#"
+```python
+print("hello")
+```
+"#;
+        assert_eq!(extract_script_code(response), "print(\"hello\")");
+    }
+
+    #[test]
+    fn test_extract_script_code_returns_trimmed_response_when_no_fence_exists() {
+        let response = "const answer = 42;";
+        assert_eq!(extract_script_code(response), "const answer = 42;");
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_adds_missing_metadata_and_import() {
+        let script = "const name = await arg(\"Name?\");";
+        let output = enforce_script_kit_conventions(script, "Ask for user name", "ask-user-name");
+
+        assert!(output.contains("// Name: Ask User Name"));
+        assert!(output.contains("// Description: Ask for user name"));
+        assert!(output.contains("import \"@johnlindquist/kit\";"));
+        assert!(output.contains("await arg(\"Name?\");"));
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_keeps_existing_metadata_and_import() {
+        let script = r#"// Name: Existing
+// Description: Existing description
+import "@johnlindquist/kit";
+
+await div("ready");
+"#;
+        let output = enforce_script_kit_conventions(script, "ignored", "ignored");
+
+        assert_eq!(
+            output.matches("// Name:").count(),
+            1,
+            "should not duplicate existing Name metadata"
+        );
+        assert_eq!(
+            output.matches("// Description:").count(),
+            1,
+            "should not duplicate existing Description metadata"
+        );
+        assert_eq!(
+            output.matches("import \"@johnlindquist/kit\";").count(),
+            1,
+            "should not duplicate existing import"
+        );
+    }
+
+    #[test]
+    fn test_write_generated_script_in_dir_appends_numeric_suffix_for_collisions() {
+        let temp_dir = tempdir().unwrap();
+        let first = write_generated_script_in_dir(temp_dir.path(), "my-script", "a").unwrap();
+        let second = write_generated_script_in_dir(temp_dir.path(), "my-script", "b").unwrap();
+
+        assert_eq!(first.file_name().unwrap(), "my-script.ts");
+        assert_eq!(second.file_name().unwrap(), "my-script-1.ts");
+    }
+}
diff --git a/src/builtins/part_000.rs b/src/builtins/part_000.rs
index d6b9c2a9b35b40c5005dbb9f65147f528702cb9e..5f6d27d28d72e51126d10d8beccf931c689ef2bb
--- a/src/builtins/part_000.rs
+++ b/src/builtins/part_000.rs
@@ -96,6 +96,8 @@
     OpenAi,
     NewConversation,
     ClearConversation,
+    /// Generate a new Script Kit script from the main prompt text
+    GenerateScript,
     /// Send a screenshot of the entire screen to AI Chat
     SendScreenToAi,
     /// Send a screenshot of the focused window to AI Chat
diff --git a/src/builtins/part_001_entries/entries_002.rs b/src/builtins/part_001_entries/entries_002.rs
index 6d1c9334f0ccaf0aab48582aaf42dcb129e1cb6e..72b318c66aeaf124359f4ecd276dae0350287328
--- a/src/builtins/part_001_entries/entries_002.rs
+++ b/src/builtins/part_001_entries/entries_002.rs
@@ -61,6 +61,17 @@
     ));
 
     entries.push(BuiltInEntry::new_with_icon(
+        "builtin-generate-script-with-ai",
+        "Generate Script with AI",
+        "Generate a Script Kit script from your current prompt text",
+        vec![
+            "generate", "script", "ai", "create", "code", "typescript", "shift", "tab",
+        ],
+        BuiltInFeature::AiCommand(AiCommandType::GenerateScript),
+        "ðŸ§ ",
+    ));
+
+    entries.push(BuiltInEntry::new_with_icon(
         "builtin-send-screen-to-ai",
         "Send Screen to AI Chat",
         "Capture the full screen and send it to AI Chat",


thinking
**Inspecting top-level lib.rs**
exec
/bin/zsh -lc "sed -n '1,260p' src/lib.rs" in /Users/johnlindquist/dev/script-kit-gpui succeeded in 52ms:
#![allow(unexpected_cfgs)]
#![recursion_limit = "2048"]

//! Script Kit GPUI - A GPUI-based launcher for Script Kit
//!
//! This library provides the core functionality for executing scripts
//! with bidirectional JSONL communication.

// Actions - Reusable action dialog component
// Provides ActionsDialog with configurable layout for script actions, AI command bar, etc.
pub mod actions;

// App Shell - Unified frame and chrome for all prompts
// Provides ShellSpec, HeaderSpec, FooterSpec, ChromeSpec for consistent prompt layout
pub mod app_shell;

#[cfg(target_os = "macos")]
pub mod camera;
pub mod components;
pub mod config;
file update:
diff --git a/src/ai/mod.rs b/src/ai/mod.rs
index a420b1a5faf59506acdb7caf60681c153a3f9bb6..9a73e9491862633b325b2c52b51a3e20395ff85c
--- a/src/ai/mod.rs
+++ b/src/ai/mod.rs
@@ -37,6 +37,7 @@
 pub(crate) mod providers;
 pub(crate) mod sdk_handlers;
 pub(crate) mod session;
+pub(crate) mod script_generation;
 pub(crate) mod storage;
 pub(crate) mod window;
 
@@ -44,6 +45,7 @@
 pub use self::config::{DetectedKeys, ModelInfo, ProviderConfig};
 pub use self::model::{Chat, ChatId, ChatSource, Message, MessageRole};
 pub use self::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+pub use self::script_generation::{generate_script_from_prompt, GeneratedScriptOutput};
 pub use self::sdk_handlers::try_handle_ai_message;
 pub use self::storage::{
     clear_all_chats, create_chat, delete_chat, get_all_chats, get_chat, get_chat_messages,
diff --git a/src/ai/script_generation.rs b/src/ai/script_generation.rs
new file mode 100644
index 0000000000000000000000000000000000000000..7f2ec8e7576ed50cd10f7aea31a6522875ef667a
--- /dev/null
+++ b/src/ai/script_generation.rs
@@ -0,0 +1,417 @@
+use anyhow::{Context, Result};
+use std::fs::{self, OpenOptions};
+use std::io::{ErrorKind, Write};
+use std::path::{Path, PathBuf};
+use std::sync::Arc;
+
+use super::config::ModelInfo;
+use super::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+
+const AI_SCRIPT_OUTPUT_DIR: &str = "~/.kenv/scripts";
+const AI_SCRIPT_DEFAULT_SLUG: &str = "ai-script";
+const AI_SCRIPT_MAX_SLUG_LEN: usize = 64;
+
+const AI_SCRIPT_GENERATION_SYSTEM_PROMPT: &str = r#"You write production-ready Script Kit scripts.
+
+Return ONLY TypeScript source code for one Script Kit script. Do not include explanations.
+
+Required output conventions:
+1) Include metadata comments at the top:
+   // Name: <clear title>
+   // Description: <one-line summary>
+2) Include: import "@johnlindquist/kit";
+3) Use await arg() for user input when useful.
+4) Use await div() for display output when useful.
+5) Keep the script runnable as-is with sensible defaults and light error handling."#;
+
+#[derive(Debug, Clone)]
+pub struct GeneratedScriptOutput {
+    pub path: PathBuf,
+    pub slug: String,
+    pub model_id: String,
+    pub provider_id: String,
+}
+
+pub fn generate_script_from_prompt(
+    prompt: &str,
+    config: Option<&crate::config::Config>,
+) -> Result<GeneratedScriptOutput> {
+    let normalized_prompt = prompt.trim();
+    if normalized_prompt.is_empty() {
+        anyhow::bail!("AI script generation requires a non-empty prompt");
+    }
+
+    let registry = ProviderRegistry::from_environment_with_config(config);
+    if !registry.has_any_provider() {
+        anyhow::bail!(
+            "No AI providers configured. Configure an API key first (Vercel, OpenAI, Anthropic, etc.)."
+        );
+    }
+
+    let (selected_model, provider) = select_generation_model(&registry)?;
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=provider_ready model_id={} provider_id={} prompt_len={}",
+            selected_model.id,
+            selected_model.provider,
+            normalized_prompt.len()
+        ),
+    );
+
+    let messages = vec![
+        ProviderMessage::system(AI_SCRIPT_GENERATION_SYSTEM_PROMPT),
+        ProviderMessage::user(format!(
+            "Generate a Script Kit script for this user request:\n\n{}",
+            normalized_prompt
+        )),
+    ];
+
+    let raw_response = provider
+        .send_message(&messages, &selected_model.id)
+        .with_context(|| {
+            format!(
+                "AI script generation failed (attempted=send_message, model_id={}, provider_id={})",
+                selected_model.id, selected_model.provider
+            )
+        })?;
+
+    let extracted = extract_script_code(&raw_response);
+    if extracted.trim().is_empty() {
+        anyhow::bail!(
+            "AI returned an empty response for script generation (state=empty_response)"
+        );
+    }
+
+    let slug = slugify_script_name(normalized_prompt);
+    let finalized = enforce_script_kit_conventions(&extracted, normalized_prompt, &slug);
+    let path = write_generated_script(&slug, &finalized).with_context(|| {
+        format!(
+            "Failed writing AI-generated script (state=write_failed, slug={})",
+            slug
+        )
+    })?;
+
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=script_written path={} slug={}",
+            path.display(),
+            slug
+        ),
+    );
+
+    Ok(GeneratedScriptOutput {
+        path,
+        slug,
+        model_id: selected_model.id,
+        provider_id: selected_model.provider,
+    })
+}
+
+fn select_generation_model(registry: &ProviderRegistry) -> Result<(ModelInfo, Arc<dyn AiProvider>)> {
+    let models = registry.get_all_models();
+    let selected_model = models
+        .iter()
+        .find(|model| model.provider.eq_ignore_ascii_case("vercel"))
+        .or_else(|| models.first())
+        .cloned()
+        .context("No AI models available in provider registry")?;
+
+    let provider = registry
+        .find_provider_for_model(&selected_model.id)
+        .cloned()
+        .with_context(|| {
+            format!(
+                "No provider found for selected model '{}' (state=provider_missing)",
+                selected_model.id
+            )
+        })?;
+
+    Ok((selected_model, provider))
+}
+
+fn generated_scripts_dir() -> PathBuf {
+    PathBuf::from(shellexpand::tilde(AI_SCRIPT_OUTPUT_DIR).as_ref())
+}
+
+fn split_fence_header_and_body(fence: &str) -> (&str, &str) {
+    match fence.find('\n') {
+        Some(newline_index) => (&fence[..newline_index], &fence[newline_index + 1..]),
+        None => ("", fence),
+    }
+}
+
+fn extract_fenced_code(response: &str, preferred_languages: Option<&[&str]>) -> Option<String> {
+    let mut remaining = response;
+
+    while let Some(start) = remaining.find("```") {
+        let after_start = &remaining[start + 3..];
+        let Some(end) = after_start.find("```") else {
+            break;
+        };
+
+        let fence_contents = &after_start[..end];
+        let (header, body) = split_fence_header_and_body(fence_contents);
+        let language = header
+            .trim()
+            .split(|c: char| c.is_whitespace() || c == '{')
+            .next()
+            .unwrap_or("")
+            .to_ascii_lowercase();
+        let code = body.trim();
+
+        if !code.is_empty() {
+            match preferred_languages {
+                Some(preferred) => {
+                    if preferred.iter().any(|candidate| *candidate == language) {
+                        return Some(code.to_string());
+                    }
+                }
+                None => return Some(code.to_string()),
+            }
+        }
+
+        remaining = &after_start[end + 3..];
+    }
+
+    None
+}
+
+fn extract_script_code(response: &str) -> String {
+    const PREFERRED_LANGUAGES: [&str; 6] = ["typescript", "ts", "javascript", "js", "tsx", "jsx"];
+
+    extract_fenced_code(response, Some(&PREFERRED_LANGUAGES))
+        .or_else(|| extract_fenced_code(response, None))
+        .unwrap_or_else(|| response.trim().to_string())
+}
+
+fn slugify_script_name(prompt: &str) -> String {
+    let mut slug = String::new();
+    let mut last_was_hyphen = false;
+
+    for character in prompt.to_ascii_lowercase().chars() {
+        if character.is_ascii_alphanumeric() {
+            slug.push(character);
+            last_was_hyphen = false;
+        } else if matches!(character, ' ' | '_' | '-') {
+            if !slug.is_empty() && !last_was_hyphen {
+                slug.push('-');
+                last_was_hyphen = true;
+            }
+        }
+    }
+
+    while slug.ends_with('-') {
+        slug.pop();
+    }
+
+    if slug.len() > AI_SCRIPT_MAX_SLUG_LEN {
+        slug.truncate(AI_SCRIPT_MAX_SLUG_LEN);
+        while slug.ends_with('-') {
+            slug.pop();
+        }
+    }
+
+    if slug.is_empty() {
+        AI_SCRIPT_DEFAULT_SLUG.to_string()
+    } else {
+        slug
+    }
+}
+
+fn slug_to_title(slug: &str) -> String {
+    slug.split('-')
+        .filter(|segment| !segment.is_empty())
+        .map(|segment| {
+            let mut chars = segment.chars();
+            match chars.next() {
+                Some(first) => first.to_uppercase().collect::<String>() + chars.as_str(),
+                None => String::new(),
+            }
+        })
+        .collect::<Vec<_>>()
+        .join(" ")
+}
+
+fn description_from_prompt(prompt: &str) -> String {
+    let normalized = prompt.split_whitespace().collect::<Vec<_>>().join(" ");
+    if normalized.is_empty() {
+        return "AI-generated Script Kit script".to_string();
+    }
+
+    let mut shortened = normalized;
+    if shortened.chars().count() > 110 {
+        shortened = format!("{}...", shortened.chars().take(107).collect::<String>());
+    }
+    shortened
+}
+
+fn has_kit_import(script: &str) -> bool {
+    script.contains("import \"@johnlindquist/kit\";")
+        || script.contains("import '@johnlindquist/kit';")
+        || script.contains("import \"@scriptkit/sdk\";")
+        || script.contains("import '@scriptkit/sdk';")
+}
+
+fn enforce_script_kit_conventions(script: &str, prompt: &str, slug: &str) -> String {
+    let mut prefix_lines: Vec<String> = Vec::new();
+    let trimmed_script = script.trim();
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Name:"))
+    {
+        prefix_lines.push(format!("// Name: {}", slug_to_title(slug)));
+    }
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Description:"))
+    {
+        prefix_lines.push(format!("// Description: {}", description_from_prompt(prompt)));
+    }
+
+    if !has_kit_import(trimmed_script) {
+        prefix_lines.push("import \"@johnlindquist/kit\";".to_string());
+    }
+
+    let mut output = String::new();
+    if !prefix_lines.is_empty() {
+        output.push_str(&prefix_lines.join("\n"));
+        output.push_str("\n\n");
+    }
+
+    output.push_str(trimmed_script);
+    if !output.ends_with('\n') {
+        output.push('\n');
+    }
+    output
+}
+
+fn write_generated_script(slug: &str, script_content: &str) -> Result<PathBuf> {
+    write_generated_script_in_dir(&generated_scripts_dir(), slug, script_content)
+}
+
+fn write_generated_script_in_dir(output_dir: &Path, slug: &str, script_content: &str) -> Result<PathBuf> {
+    fs::create_dir_all(output_dir)
+        .with_context(|| format!("Failed to create output dir: {}", output_dir.display()))?;
+
+    for suffix in 0usize.. {
+        let candidate = if suffix == 0 {
+            slug.to_string()
+        } else {
+            format!("{slug}-{suffix}")
+        };
+        let path = output_dir.join(format!("{}.ts", candidate));
+        match OpenOptions::new().write(true).create_new(true).open(&path) {
+            Ok(mut file) => {
+                file.write_all(script_content.as_bytes())
+                    .with_context(|| format!("Failed writing generated script to {}", path.display()))?;
+                return Ok(path);
+            }
+            Err(error) if error.kind() == ErrorKind::AlreadyExists => continue,
+            Err(error) => {
+                return Err(error).with_context(|| {
+                    format!(
+                        "Failed creating generated script file {} (slug={})",
+                        path.display(),
+                        slug
+                    )
+                });
+            }
+        }
+    }
+
+    unreachable!("suffix loop should eventually create a unique script filename")
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+    use tempfile::tempdir;
+
+    #[test]
+    fn test_slugify_script_name_handles_spaces_and_symbols() {
+        assert_eq!(slugify_script_name("Build: API Client!"), "build-api-client");
+        assert_eq!(slugify_script_name("  ___  "), "ai-script");
+    }
+
+    #[test]
+    fn test_extract_script_code_prefers_typescript_fence_when_multiple_blocks_exist() {
+        let response = r#"
+Here's one idea:
+```markdown
+Not code
+```
+```typescript
+await div("hello");
+```
+"#;
+        assert_eq!(extract_script_code(response), "await div(\"hello\");");
+    }
+
+    #[test]
+    fn test_extract_script_code_falls_back_to_first_fenced_block() {
+        let response = r#"
+```python
+print("hello")
+```
+"#;
+        assert_eq!(extract_script_code(response), "print(\"hello\")");
+    }
+
+    #[test]
+    fn test_extract_script_code_returns_trimmed_response_when_no_fence_exists() {
+        let response = "const answer = 42;";
+        assert_eq!(extract_script_code(response), "const answer = 42;");
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_adds_missing_metadata_and_import() {
+        let script = "const name = await arg(\"Name?\");";
+        let output = enforce_script_kit_conventions(script, "Ask for user name", "ask-user-name");
+
+        assert!(output.contains("// Name: Ask User Name"));
+        assert!(output.contains("// Description: Ask for user name"));
+        assert!(output.contains("import \"@johnlindquist/kit\";"));
+        assert!(output.contains("await arg(\"Name?\");"));
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_keeps_existing_metadata_and_import() {
+        let script = r#"// Name: Existing
+// Description: Existing description
+import "@johnlindquist/kit";
+
+await div("ready");
+"#;
+        let output = enforce_script_kit_conventions(script, "ignored", "ignored");
+
+        assert_eq!(
+            output.matches("// Name:").count(),
+            1,
+            "should not duplicate existing Name metadata"
+        );
+        assert_eq!(
+            output.matches("// Description:").count(),
+            1,
+            "should not duplicate existing Description metadata"
+        );
+        assert_eq!(
+            output.matches("import \"@johnlindquist/kit\";").count(),
+            1,
+            "should not duplicate existing import"
+        );
+    }
+
+    #[test]
+    fn test_write_generated_script_in_dir_appends_numeric_suffix_for_collisions() {
+        let temp_dir = tempdir().unwrap();
+        let first = write_generated_script_in_dir(temp_dir.path(), "my-script", "a").unwrap();
+        let second = write_generated_script_in_dir(temp_dir.path(), "my-script", "b").unwrap();
+
+        assert_eq!(first.file_name().unwrap(), "my-script.ts");
+        assert_eq!(second.file_name().unwrap(), "my-script-1.ts");
+    }
+}
diff --git a/src/builtins/part_000.rs b/src/builtins/part_000.rs
index d6b9c2a9b35b40c5005dbb9f65147f528702cb9e..5f6d27d28d72e51126d10d8beccf931c689ef2bb
--- a/src/builtins/part_000.rs
+++ b/src/builtins/part_000.rs
@@ -96,6 +96,8 @@
     OpenAi,
     NewConversation,
     ClearConversation,
+    /// Generate a new Script Kit script from the main prompt text
+    GenerateScript,
     /// Send a screenshot of the entire screen to AI Chat
     SendScreenToAi,
     /// Send a screenshot of the focused window to AI Chat
diff --git a/src/builtins/part_001_entries/entries_002.rs b/src/builtins/part_001_entries/entries_002.rs
index 6d1c9334f0ccaf0aab48582aaf42dcb129e1cb6e..72b318c66aeaf124359f4ecd276dae0350287328
--- a/src/builtins/part_001_entries/entries_002.rs
+++ b/src/builtins/part_001_entries/entries_002.rs
@@ -61,6 +61,17 @@
     ));
 
     entries.push(BuiltInEntry::new_with_icon(
+        "builtin-generate-script-with-ai",
+        "Generate Script with AI",
+        "Generate a Script Kit script from your current prompt text",
+        vec![
+            "generate", "script", "ai", "create", "code", "typescript", "shift", "tab",
+        ],
+        BuiltInFeature::AiCommand(AiCommandType::GenerateScript),
+        "ðŸ§ ",
+    ));
+
+    entries.push(BuiltInEntry::new_with_icon(
         "builtin-send-screen-to-ai",
         "Send Screen to AI Chat",
         "Capture the full screen and send it to AI Chat",


thinking
**Investigating builtin execution inclusion**
exec
/bin/zsh -lc 'rg -n "include!'"\\(\\\"app_execute.rs\\\"\\)|mod app_execute|ScriptListApp\" src | head -n 60" in /Users/johnlindquist/dev/script-kit-gpui succeeded in 52ms:
src/app_actions/sdk_actions.rs:1:impl ScriptListApp {
src/app_actions/handle_action.rs:1:impl ScriptListApp {
src/app_actions/tests/actions_button_visibility.rs:14:            "Expected ScriptListApp::has_actions() helper to exist"
src/app_actions/tests/clipboard_actions_menu_coverage.rs:4:// in `ScriptListApp::handle_action`.
src/app_shell/mod.rs:9://! remain in the window root (ScriptListApp). The shell:
src/app_shell/mod.rs:22://! impl ScriptListApp {
src/main.rs:4://! It defines the `ScriptListApp` runtime, wires stdin protocol handling in `main`,
src/main.rs:267:// Core ScriptListApp implementation extracted to app_impl/mod.rs
src/main.rs:280:include!("app_execute.rs");
src/main.rs:296:// Each file adds render_*_prompt methods to ScriptListApp via impl blocks
src/execute_script/part_001.rs:1:impl ScriptListApp {
src/clipboard_actions_menu_coverage_tests.rs:4://! in `ScriptListApp::handle_action`.
src/app_impl/alias_input.rs:3:impl ScriptListApp {
src/render_script_list/part_000.rs:5:impl ScriptListApp {
src/render_script_list/part_000.rs:285:                                            move |this: &mut ScriptListApp,
src/render_script_list/part_000.rs:318:                                            move |this: &mut ScriptListApp,
src/app_impl/filter_input_change.rs:3:impl ScriptListApp {
src/render_script_list/part_000_body/body_000.rs:279:                                            move |this: &mut ScriptListApp,
src/render_script_list/part_000_body/body_000.rs:312:                                            move |this: &mut ScriptListApp,
src/app_impl/filtering_cache.rs:3:impl ScriptListApp {
file update:
diff --git a/src/ai/mod.rs b/src/ai/mod.rs
index a420b1a5faf59506acdb7caf60681c153a3f9bb6..9a73e9491862633b325b2c52b51a3e20395ff85c
--- a/src/ai/mod.rs
+++ b/src/ai/mod.rs
@@ -37,6 +37,7 @@
 pub(crate) mod providers;
 pub(crate) mod sdk_handlers;
 pub(crate) mod session;
+pub(crate) mod script_generation;
 pub(crate) mod storage;
 pub(crate) mod window;
 
@@ -44,6 +45,7 @@
 pub use self::config::{DetectedKeys, ModelInfo, ProviderConfig};
 pub use self::model::{Chat, ChatId, ChatSource, Message, MessageRole};
 pub use self::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+pub use self::script_generation::{generate_script_from_prompt, GeneratedScriptOutput};
 pub use self::sdk_handlers::try_handle_ai_message;
 pub use self::storage::{
     clear_all_chats, create_chat, delete_chat, get_all_chats, get_chat, get_chat_messages,
diff --git a/src/ai/script_generation.rs b/src/ai/script_generation.rs
new file mode 100644
index 0000000000000000000000000000000000000000..7f2ec8e7576ed50cd10f7aea31a6522875ef667a
--- /dev/null
+++ b/src/ai/script_generation.rs
@@ -0,0 +1,417 @@
+use anyhow::{Context, Result};
+use std::fs::{self, OpenOptions};
+use std::io::{ErrorKind, Write};
+use std::path::{Path, PathBuf};
+use std::sync::Arc;
+
+use super::config::ModelInfo;
+use super::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+
+const AI_SCRIPT_OUTPUT_DIR: &str = "~/.kenv/scripts";
+const AI_SCRIPT_DEFAULT_SLUG: &str = "ai-script";
+const AI_SCRIPT_MAX_SLUG_LEN: usize = 64;
+
+const AI_SCRIPT_GENERATION_SYSTEM_PROMPT: &str = r#"You write production-ready Script Kit scripts.
+
+Return ONLY TypeScript source code for one Script Kit script. Do not include explanations.
+
+Required output conventions:
+1) Include metadata comments at the top:
+   // Name: <clear title>
+   // Description: <one-line summary>
+2) Include: import "@johnlindquist/kit";
+3) Use await arg() for user input when useful.
+4) Use await div() for display output when useful.
+5) Keep the script runnable as-is with sensible defaults and light error handling."#;
+
+#[derive(Debug, Clone)]
+pub struct GeneratedScriptOutput {
+    pub path: PathBuf,
+    pub slug: String,
+    pub model_id: String,
+    pub provider_id: String,
+}
+
+pub fn generate_script_from_prompt(
+    prompt: &str,
+    config: Option<&crate::config::Config>,
+) -> Result<GeneratedScriptOutput> {
+    let normalized_prompt = prompt.trim();
+    if normalized_prompt.is_empty() {
+        anyhow::bail!("AI script generation requires a non-empty prompt");
+    }
+
+    let registry = ProviderRegistry::from_environment_with_config(config);
+    if !registry.has_any_provider() {
+        anyhow::bail!(
+            "No AI providers configured. Configure an API key first (Vercel, OpenAI, Anthropic, etc.)."
+        );
+    }
+
+    let (selected_model, provider) = select_generation_model(&registry)?;
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=provider_ready model_id={} provider_id={} prompt_len={}",
+            selected_model.id,
+            selected_model.provider,
+            normalized_prompt.len()
+        ),
+    );
+
+    let messages = vec![
+        ProviderMessage::system(AI_SCRIPT_GENERATION_SYSTEM_PROMPT),
+        ProviderMessage::user(format!(
+            "Generate a Script Kit script for this user request:\n\n{}",
+            normalized_prompt
+        )),
+    ];
+
+    let raw_response = provider
+        .send_message(&messages, &selected_model.id)
+        .with_context(|| {
+            format!(
+                "AI script generation failed (attempted=send_message, model_id={}, provider_id={})",
+                selected_model.id, selected_model.provider
+            )
+        })?;
+
+    let extracted = extract_script_code(&raw_response);
+    if extracted.trim().is_empty() {
+        anyhow::bail!(
+            "AI returned an empty response for script generation (state=empty_response)"
+        );
+    }
+
+    let slug = slugify_script_name(normalized_prompt);
+    let finalized = enforce_script_kit_conventions(&extracted, normalized_prompt, &slug);
+    let path = write_generated_script(&slug, &finalized).with_context(|| {
+        format!(
+            "Failed writing AI-generated script (state=write_failed, slug={})",
+            slug
+        )
+    })?;
+
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=script_written path={} slug={}",
+            path.display(),
+            slug
+        ),
+    );
+
+    Ok(GeneratedScriptOutput {
+        path,
+        slug,
+        model_id: selected_model.id,
+        provider_id: selected_model.provider,
+    })
+}
+
+fn select_generation_model(registry: &ProviderRegistry) -> Result<(ModelInfo, Arc<dyn AiProvider>)> {
+    let models = registry.get_all_models();
+    let selected_model = models
+        .iter()
+        .find(|model| model.provider.eq_ignore_ascii_case("vercel"))
+        .or_else(|| models.first())
+        .cloned()
+        .context("No AI models available in provider registry")?;
+
+    let provider = registry
+        .find_provider_for_model(&selected_model.id)
+        .cloned()
+        .with_context(|| {
+            format!(
+                "No provider found for selected model '{}' (state=provider_missing)",
+                selected_model.id
+            )
+        })?;
+
+    Ok((selected_model, provider))
+}
+
+fn generated_scripts_dir() -> PathBuf {
+    PathBuf::from(shellexpand::tilde(AI_SCRIPT_OUTPUT_DIR).as_ref())
+}
+
+fn split_fence_header_and_body(fence: &str) -> (&str, &str) {
+    match fence.find('\n') {
+        Some(newline_index) => (&fence[..newline_index], &fence[newline_index + 1..]),
+        None => ("", fence),
+    }
+}
+
+fn extract_fenced_code(response: &str, preferred_languages: Option<&[&str]>) -> Option<String> {
+    let mut remaining = response;
+
+    while let Some(start) = remaining.find("```") {
+        let after_start = &remaining[start + 3..];
+        let Some(end) = after_start.find("```") else {
+            break;
+        };
+
+        let fence_contents = &after_start[..end];
+        let (header, body) = split_fence_header_and_body(fence_contents);
+        let language = header
+            .trim()
+            .split(|c: char| c.is_whitespace() || c == '{')
+            .next()
+            .unwrap_or("")
+            .to_ascii_lowercase();
+        let code = body.trim();
+
+        if !code.is_empty() {
+            match preferred_languages {
+                Some(preferred) => {
+                    if preferred.iter().any(|candidate| *candidate == language) {
+                        return Some(code.to_string());
+                    }
+                }
+                None => return Some(code.to_string()),
+            }
+        }
+
+        remaining = &after_start[end + 3..];
+    }
+
+    None
+}
+
+fn extract_script_code(response: &str) -> String {
+    const PREFERRED_LANGUAGES: [&str; 6] = ["typescript", "ts", "javascript", "js", "tsx", "jsx"];
+
+    extract_fenced_code(response, Some(&PREFERRED_LANGUAGES))
+        .or_else(|| extract_fenced_code(response, None))
+        .unwrap_or_else(|| response.trim().to_string())
+}
+
+fn slugify_script_name(prompt: &str) -> String {
+    let mut slug = String::new();
+    let mut last_was_hyphen = false;
+
+    for character in prompt.to_ascii_lowercase().chars() {
+        if character.is_ascii_alphanumeric() {
+            slug.push(character);
+            last_was_hyphen = false;
+        } else if matches!(character, ' ' | '_' | '-') {
+            if !slug.is_empty() && !last_was_hyphen {
+                slug.push('-');
+                last_was_hyphen = true;
+            }
+        }
+    }
+
+    while slug.ends_with('-') {
+        slug.pop();
+    }
+
+    if slug.len() > AI_SCRIPT_MAX_SLUG_LEN {
+        slug.truncate(AI_SCRIPT_MAX_SLUG_LEN);
+        while slug.ends_with('-') {
+            slug.pop();
+        }
+    }
+
+    if slug.is_empty() {
+        AI_SCRIPT_DEFAULT_SLUG.to_string()
+    } else {
+        slug
+    }
+}
+
+fn slug_to_title(slug: &str) -> String {
+    slug.split('-')
+        .filter(|segment| !segment.is_empty())
+        .map(|segment| {
+            let mut chars = segment.chars();
+            match chars.next() {
+                Some(first) => first.to_uppercase().collect::<String>() + chars.as_str(),
+                None => String::new(),
+            }
+        })
+        .collect::<Vec<_>>()
+        .join(" ")
+}
+
+fn description_from_prompt(prompt: &str) -> String {
+    let normalized = prompt.split_whitespace().collect::<Vec<_>>().join(" ");
+    if normalized.is_empty() {
+        return "AI-generated Script Kit script".to_string();
+    }
+
+    let mut shortened = normalized;
+    if shortened.chars().count() > 110 {
+        shortened = format!("{}...", shortened.chars().take(107).collect::<String>());
+    }
+    shortened
+}
+
+fn has_kit_import(script: &str) -> bool {
+    script.contains("import \"@johnlindquist/kit\";")
+        || script.contains("import '@johnlindquist/kit';")
+        || script.contains("import \"@scriptkit/sdk\";")
+        || script.contains("import '@scriptkit/sdk';")
+}
+
+fn enforce_script_kit_conventions(script: &str, prompt: &str, slug: &str) -> String {
+    let mut prefix_lines: Vec<String> = Vec::new();
+    let trimmed_script = script.trim();
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Name:"))
+    {
+        prefix_lines.push(format!("// Name: {}", slug_to_title(slug)));
+    }
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Description:"))
+    {
+        prefix_lines.push(format!("// Description: {}", description_from_prompt(prompt)));
+    }
+
+    if !has_kit_import(trimmed_script) {
+        prefix_lines.push("import \"@johnlindquist/kit\";".to_string());
+    }
+
+    let mut output = String::new();
+    if !prefix_lines.is_empty() {
+        output.push_str(&prefix_lines.join("\n"));
+        output.push_str("\n\n");
+    }
+
+    output.push_str(trimmed_script);
+    if !output.ends_with('\n') {
+        output.push('\n');
+    }
+    output
+}
+
+fn write_generated_script(slug: &str, script_content: &str) -> Result<PathBuf> {
+    write_generated_script_in_dir(&generated_scripts_dir(), slug, script_content)
+}
+
+fn write_generated_script_in_dir(output_dir: &Path, slug: &str, script_content: &str) -> Result<PathBuf> {
+    fs::create_dir_all(output_dir)
+        .with_context(|| format!("Failed to create output dir: {}", output_dir.display()))?;
+
+    for suffix in 0usize.. {
+        let candidate = if suffix == 0 {
+            slug.to_string()
+        } else {
+            format!("{slug}-{suffix}")
+        };
+        let path = output_dir.join(format!("{}.ts", candidate));
+        match OpenOptions::new().write(true).create_new(true).open(&path) {
+            Ok(mut file) => {
+                file.write_all(script_content.as_bytes())
+                    .with_context(|| format!("Failed writing generated script to {}", path.display()))?;
+                return Ok(path);
+            }
+            Err(error) if error.kind() == ErrorKind::AlreadyExists => continue,
+            Err(error) => {
+                return Err(error).with_context(|| {
+                    format!(
+                        "Failed creating generated script file {} (slug={})",
+                        path.display(),
+                        slug
+                    )
+                });
+            }
+        }
+    }
+
+    unreachable!("suffix loop should eventually create a unique script filename")
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+    use tempfile::tempdir;
+
+    #[test]
+    fn test_slugify_script_name_handles_spaces_and_symbols() {
+        assert_eq!(slugify_script_name("Build: API Client!"), "build-api-client");
+        assert_eq!(slugify_script_name("  ___  "), "ai-script");
+    }
+
+    #[test]
+    fn test_extract_script_code_prefers_typescript_fence_when_multiple_blocks_exist() {
+        let response = r#"
+Here's one idea:
+```markdown
+Not code
+```
+```typescript
+await div("hello");
+```
+"#;
+        assert_eq!(extract_script_code(response), "await div(\"hello\");");
+    }
+
+    #[test]
+    fn test_extract_script_code_falls_back_to_first_fenced_block() {
+        let response = r#"
+```python
+print("hello")
+```
+"#;
+        assert_eq!(extract_script_code(response), "print(\"hello\")");
+    }
+
+    #[test]
+    fn test_extract_script_code_returns_trimmed_response_when_no_fence_exists() {
+        let response = "const answer = 42;";
+        assert_eq!(extract_script_code(response), "const answer = 42;");
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_adds_missing_metadata_and_import() {
+        let script = "const name = await arg(\"Name?\");";
+        let output = enforce_script_kit_conventions(script, "Ask for user name", "ask-user-name");
+
+        assert!(output.contains("// Name: Ask User Name"));
+        assert!(output.contains("// Description: Ask for user name"));
+        assert!(output.contains("import \"@johnlindquist/kit\";"));
+        assert!(output.contains("await arg(\"Name?\");"));
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_keeps_existing_metadata_and_import() {
+        let script = r#"// Name: Existing
+// Description: Existing description
+import "@johnlindquist/kit";
+
+await div("ready");
+"#;
+        let output = enforce_script_kit_conventions(script, "ignored", "ignored");
+
+        assert_eq!(
+            output.matches("// Name:").count(),
+            1,
+            "should not duplicate existing Name metadata"
+        );
+        assert_eq!(
+            output.matches("// Description:").count(),
+            1,
+            "should not duplicate existing Description metadata"
+        );
+        assert_eq!(
+            output.matches("import \"@johnlindquist/kit\";").count(),
+            1,
+            "should not duplicate existing import"
+        );
+    }
+
+    #[test]
+    fn test_write_generated_script_in_dir_appends_numeric_suffix_for_collisions() {
+        let temp_dir = tempdir().unwrap();
+        let first = write_generated_script_in_dir(temp_dir.path(), "my-script", "a").unwrap();
+        let second = write_generated_script_in_dir(temp_dir.path(), "my-script", "b").unwrap();
+
+        assert_eq!(first.file_name().unwrap(), "my-script.ts");
+        assert_eq!(second.file_name().unwrap(), "my-script-1.ts");
+    }
+}
diff --git a/src/builtins/part_000.rs b/src/builtins/part_000.rs
index d6b9c2a9b35b40c5005dbb9f65147f528702cb9e..5f6d27d28d72e51126d10d8beccf931c689ef2bb
--- a/src/builtins/part_000.rs
+++ b/src/builtins/part_000.rs
@@ -96,6 +96,8 @@
     OpenAi,
     NewConversation,
     ClearConversation,
+    /// Generate a new Script Kit script from the main prompt text
+    GenerateScript,
     /// Send a screenshot of the entire screen to AI Chat
     SendScreenToAi,
     /// Send a screenshot of the focused window to AI Chat
diff --git a/src/builtins/part_001_entries/entries_002.rs b/src/builtins/part_001_entries/entries_002.rs
index 6d1c9334f0ccaf0aab48582aaf42dcb129e1cb6e..72b318c66aeaf124359f4ecd276dae0350287328
--- a/src/builtins/part_001_entries/entries_002.rs
+++ b/src/builtins/part_001_entries/entries_002.rs
@@ -61,6 +61,17 @@
     ));
 
     entries.push(BuiltInEntry::new_with_icon(
+        "builtin-generate-script-with-ai",
+        "Generate Script with AI",
+        "Generate a Script Kit script from your current prompt text",
+        vec![
+            "generate", "script", "ai", "create", "code", "typescript", "shift", "tab",
+        ],
+        BuiltInFeature::AiCommand(AiCommandType::GenerateScript),
+        "ðŸ§ ",
+    ));
+
+    entries.push(BuiltInEntry::new_with_icon(
         "builtin-send-screen-to-ai",
         "Send Screen to AI Chat",
         "Capture the full screen and send it to AI Chat",


thinking
**Inspecting main imports**
exec
/bin/zsh -lc "sed -n '220,360p' src/main.rs" in /Users/johnlindquist/dev/script-kit-gpui succeeded in 52ms:
    EMPTY_STATE_GAP, EMPTY_STATE_ICON_SIZE, EMPTY_STATE_MESSAGE_FONT_SIZE,
    EMPTY_STATE_TIPS_MARGIN_TOP, ESTIMATED_LIST_CONTAINER_HEIGHT, FONT_MONO, LIST_ITEM_HEIGHT,
    LOG_PANEL_MAX_HEIGHT, SECTION_HEADER_HEIGHT, TAB_BADGE_PADDING_X, TAB_BADGE_PADDING_Y,
    TAB_BADGE_RADIUS,
};
use scripts::get_grouped_results;
// strip_html_tags removed - DivPrompt now renders HTML properly

use actions::{
    close_actions_window, is_actions_window_open, notify_actions_window, open_actions_window,
    resize_actions_window, ActionsDialog, ScriptInfo,
};
use confirm::{open_confirm_window, ConfirmCallback};
use panel::{
    CURSOR_GAP_X, CURSOR_HEIGHT_LG, CURSOR_MARGIN_Y, CURSOR_WIDTH, DEFAULT_PLACEHOLDER, HEADER_GAP,
    HEADER_PADDING_X, HEADER_PADDING_Y,
};
use parking_lot::Mutex as ParkingMutex;
use protocol::{Choice, Message, ProtocolAction};
use std::sync::{mpsc, Arc, Mutex};
file update:
diff --git a/src/ai/mod.rs b/src/ai/mod.rs
index a420b1a5faf59506acdb7caf60681c153a3f9bb6..9a73e9491862633b325b2c52b51a3e20395ff85c
--- a/src/ai/mod.rs
+++ b/src/ai/mod.rs
@@ -37,6 +37,7 @@
 pub(crate) mod providers;
 pub(crate) mod sdk_handlers;
 pub(crate) mod session;
+pub(crate) mod script_generation;
 pub(crate) mod storage;
 pub(crate) mod window;
 
@@ -44,6 +45,7 @@
 pub use self::config::{DetectedKeys, ModelInfo, ProviderConfig};
 pub use self::model::{Chat, ChatId, ChatSource, Message, MessageRole};
 pub use self::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+pub use self::script_generation::{generate_script_from_prompt, GeneratedScriptOutput};
 pub use self::sdk_handlers::try_handle_ai_message;
 pub use self::storage::{
     clear_all_chats, create_chat, delete_chat, get_all_chats, get_chat, get_chat_messages,
diff --git a/src/ai/script_generation.rs b/src/ai/script_generation.rs
new file mode 100644
index 0000000000000000000000000000000000000000..7f2ec8e7576ed50cd10f7aea31a6522875ef667a
--- /dev/null
+++ b/src/ai/script_generation.rs
@@ -0,0 +1,417 @@
+use anyhow::{Context, Result};
+use std::fs::{self, OpenOptions};
+use std::io::{ErrorKind, Write};
+use std::path::{Path, PathBuf};
+use std::sync::Arc;
+
+use super::config::ModelInfo;
+use super::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+
+const AI_SCRIPT_OUTPUT_DIR: &str = "~/.kenv/scripts";
+const AI_SCRIPT_DEFAULT_SLUG: &str = "ai-script";
+const AI_SCRIPT_MAX_SLUG_LEN: usize = 64;
+
+const AI_SCRIPT_GENERATION_SYSTEM_PROMPT: &str = r#"You write production-ready Script Kit scripts.
+
+Return ONLY TypeScript source code for one Script Kit script. Do not include explanations.
+
+Required output conventions:
+1) Include metadata comments at the top:
+   // Name: <clear title>
+   // Description: <one-line summary>
+2) Include: import "@johnlindquist/kit";
+3) Use await arg() for user input when useful.
+4) Use await div() for display output when useful.
+5) Keep the script runnable as-is with sensible defaults and light error handling."#;
+
+#[derive(Debug, Clone)]
+pub struct GeneratedScriptOutput {
+    pub path: PathBuf,
+    pub slug: String,
+    pub model_id: String,
+    pub provider_id: String,
+}
+
+pub fn generate_script_from_prompt(
+    prompt: &str,
+    config: Option<&crate::config::Config>,
+) -> Result<GeneratedScriptOutput> {
+    let normalized_prompt = prompt.trim();
+    if normalized_prompt.is_empty() {
+        anyhow::bail!("AI script generation requires a non-empty prompt");
+    }
+
+    let registry = ProviderRegistry::from_environment_with_config(config);
+    if !registry.has_any_provider() {
+        anyhow::bail!(
+            "No AI providers configured. Configure an API key first (Vercel, OpenAI, Anthropic, etc.)."
+        );
+    }
+
+    let (selected_model, provider) = select_generation_model(&registry)?;
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=provider_ready model_id={} provider_id={} prompt_len={}",
+            selected_model.id,
+            selected_model.provider,
+            normalized_prompt.len()
+        ),
+    );
+
+    let messages = vec![
+        ProviderMessage::system(AI_SCRIPT_GENERATION_SYSTEM_PROMPT),
+        ProviderMessage::user(format!(
+            "Generate a Script Kit script for this user request:\n\n{}",
+            normalized_prompt
+        )),
+    ];
+
+    let raw_response = provider
+        .send_message(&messages, &selected_model.id)
+        .with_context(|| {
+            format!(
+                "AI script generation failed (attempted=send_message, model_id={}, provider_id={})",
+                selected_model.id, selected_model.provider
+            )
+        })?;
+
+    let extracted = extract_script_code(&raw_response);
+    if extracted.trim().is_empty() {
+        anyhow::bail!(
+            "AI returned an empty response for script generation (state=empty_response)"
+        );
+    }
+
+    let slug = slugify_script_name(normalized_prompt);
+    let finalized = enforce_script_kit_conventions(&extracted, normalized_prompt, &slug);
+    let path = write_generated_script(&slug, &finalized).with_context(|| {
+        format!(
+            "Failed writing AI-generated script (state=write_failed, slug={})",
+            slug
+        )
+    })?;
+
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=script_written path={} slug={}",
+            path.display(),
+            slug
+        ),
+    );
+
+    Ok(GeneratedScriptOutput {
+        path,
+        slug,
+        model_id: selected_model.id,
+        provider_id: selected_model.provider,
+    })
+}
+
+fn select_generation_model(registry: &ProviderRegistry) -> Result<(ModelInfo, Arc<dyn AiProvider>)> {
+    let models = registry.get_all_models();
+    let selected_model = models
+        .iter()
+        .find(|model| model.provider.eq_ignore_ascii_case("vercel"))
+        .or_else(|| models.first())
+        .cloned()
+        .context("No AI models available in provider registry")?;
+
+    let provider = registry
+        .find_provider_for_model(&selected_model.id)
+        .cloned()
+        .with_context(|| {
+            format!(
+                "No provider found for selected model '{}' (state=provider_missing)",
+                selected_model.id
+            )
+        })?;
+
+    Ok((selected_model, provider))
+}
+
+fn generated_scripts_dir() -> PathBuf {
+    PathBuf::from(shellexpand::tilde(AI_SCRIPT_OUTPUT_DIR).as_ref())
+}
+
+fn split_fence_header_and_body(fence: &str) -> (&str, &str) {
+    match fence.find('\n') {
+        Some(newline_index) => (&fence[..newline_index], &fence[newline_index + 1..]),
+        None => ("", fence),
+    }
+}
+
+fn extract_fenced_code(response: &str, preferred_languages: Option<&[&str]>) -> Option<String> {
+    let mut remaining = response;
+
+    while let Some(start) = remaining.find("```") {
+        let after_start = &remaining[start + 3..];
+        let Some(end) = after_start.find("```") else {
+            break;
+        };
+
+        let fence_contents = &after_start[..end];
+        let (header, body) = split_fence_header_and_body(fence_contents);
+        let language = header
+            .trim()
+            .split(|c: char| c.is_whitespace() || c == '{')
+            .next()
+            .unwrap_or("")
+            .to_ascii_lowercase();
+        let code = body.trim();
+
+        if !code.is_empty() {
+            match preferred_languages {
+                Some(preferred) => {
+                    if preferred.iter().any(|candidate| *candidate == language) {
+                        return Some(code.to_string());
+                    }
+                }
+                None => return Some(code.to_string()),
+            }
+        }
+
+        remaining = &after_start[end + 3..];
+    }
+
+    None
+}
+
+fn extract_script_code(response: &str) -> String {
+    const PREFERRED_LANGUAGES: [&str; 6] = ["typescript", "ts", "javascript", "js", "tsx", "jsx"];
+
+    extract_fenced_code(response, Some(&PREFERRED_LANGUAGES))
+        .or_else(|| extract_fenced_code(response, None))
+        .unwrap_or_else(|| response.trim().to_string())
+}
+
+fn slugify_script_name(prompt: &str) -> String {
+    let mut slug = String::new();
+    let mut last_was_hyphen = false;
+
+    for character in prompt.to_ascii_lowercase().chars() {
+        if character.is_ascii_alphanumeric() {
+            slug.push(character);
+            last_was_hyphen = false;
+        } else if matches!(character, ' ' | '_' | '-') {
+            if !slug.is_empty() && !last_was_hyphen {
+                slug.push('-');
+                last_was_hyphen = true;
+            }
+        }
+    }
+
+    while slug.ends_with('-') {
+        slug.pop();
+    }
+
+    if slug.len() > AI_SCRIPT_MAX_SLUG_LEN {
+        slug.truncate(AI_SCRIPT_MAX_SLUG_LEN);
+        while slug.ends_with('-') {
+            slug.pop();
+        }
+    }
+
+    if slug.is_empty() {
+        AI_SCRIPT_DEFAULT_SLUG.to_string()
+    } else {
+        slug
+    }
+}
+
+fn slug_to_title(slug: &str) -> String {
+    slug.split('-')
+        .filter(|segment| !segment.is_empty())
+        .map(|segment| {
+            let mut chars = segment.chars();
+            match chars.next() {
+                Some(first) => first.to_uppercase().collect::<String>() + chars.as_str(),
+                None => String::new(),
+            }
+        })
+        .collect::<Vec<_>>()
+        .join(" ")
+}
+
+fn description_from_prompt(prompt: &str) -> String {
+    let normalized = prompt.split_whitespace().collect::<Vec<_>>().join(" ");
+    if normalized.is_empty() {
+        return "AI-generated Script Kit script".to_string();
+    }
+
+    let mut shortened = normalized;
+    if shortened.chars().count() > 110 {
+        shortened = format!("{}...", shortened.chars().take(107).collect::<String>());
+    }
+    shortened
+}
+
+fn has_kit_import(script: &str) -> bool {
+    script.contains("import \"@johnlindquist/kit\";")
+        || script.contains("import '@johnlindquist/kit';")
+        || script.contains("import \"@scriptkit/sdk\";")
+        || script.contains("import '@scriptkit/sdk';")
+}
+
+fn enforce_script_kit_conventions(script: &str, prompt: &str, slug: &str) -> String {
+    let mut prefix_lines: Vec<String> = Vec::new();
+    let trimmed_script = script.trim();
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Name:"))
+    {
+        prefix_lines.push(format!("// Name: {}", slug_to_title(slug)));
+    }
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Description:"))
+    {
+        prefix_lines.push(format!("// Description: {}", description_from_prompt(prompt)));
+    }
+
+    if !has_kit_import(trimmed_script) {
+        prefix_lines.push("import \"@johnlindquist/kit\";".to_string());
+    }
+
+    let mut output = String::new();
+    if !prefix_lines.is_empty() {
+        output.push_str(&prefix_lines.join("\n"));
+        output.push_str("\n\n");
+    }
+
+    output.push_str(trimmed_script);
+    if !output.ends_with('\n') {
+        output.push('\n');
+    }
+    output
+}
+
+fn write_generated_script(slug: &str, script_content: &str) -> Result<PathBuf> {
+    write_generated_script_in_dir(&generated_scripts_dir(), slug, script_content)
+}
+
+fn write_generated_script_in_dir(output_dir: &Path, slug: &str, script_content: &str) -> Result<PathBuf> {
+    fs::create_dir_all(output_dir)
+        .with_context(|| format!("Failed to create output dir: {}", output_dir.display()))?;
+
+    for suffix in 0usize.. {
+        let candidate = if suffix == 0 {
+            slug.to_string()
+        } else {
+            format!("{slug}-{suffix}")
+        };
+        let path = output_dir.join(format!("{}.ts", candidate));
+        match OpenOptions::new().write(true).create_new(true).open(&path) {
+            Ok(mut file) => {
+                file.write_all(script_content.as_bytes())
+                    .with_context(|| format!("Failed writing generated script to {}", path.display()))?;
+                return Ok(path);
+            }
+            Err(error) if error.kind() == ErrorKind::AlreadyExists => continue,
+            Err(error) => {
+                return Err(error).with_context(|| {
+                    format!(
+                        "Failed creating generated script file {} (slug={})",
+                        path.display(),
+                        slug
+                    )
+                });
+            }
+        }
+    }
+
+    unreachable!("suffix loop should eventually create a unique script filename")
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+    use tempfile::tempdir;
+
+    #[test]
+    fn test_slugify_script_name_handles_spaces_and_symbols() {
+        assert_eq!(slugify_script_name("Build: API Client!"), "build-api-client");
+        assert_eq!(slugify_script_name("  ___  "), "ai-script");
+    }
+
+    #[test]
+    fn test_extract_script_code_prefers_typescript_fence_when_multiple_blocks_exist() {
+        let response = r#"
+Here's one idea:
+```markdown
+Not code
+```
+```typescript
+await div("hello");
+```
+"#;
+        assert_eq!(extract_script_code(response), "await div(\"hello\");");
+    }
+
+    #[test]
+    fn test_extract_script_code_falls_back_to_first_fenced_block() {
+        let response = r#"
+```python
+print("hello")
+```
+"#;
+        assert_eq!(extract_script_code(response), "print(\"hello\")");
+    }
+
+    #[test]
+    fn test_extract_script_code_returns_trimmed_response_when_no_fence_exists() {
+        let response = "const answer = 42;";
+        assert_eq!(extract_script_code(response), "const answer = 42;");
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_adds_missing_metadata_and_import() {
+        let script = "const name = await arg(\"Name?\");";
+        let output = enforce_script_kit_conventions(script, "Ask for user name", "ask-user-name");
+
+        assert!(output.contains("// Name: Ask User Name"));
+        assert!(output.contains("// Description: Ask for user name"));
+        assert!(output.contains("import \"@johnlindquist/kit\";"));
+        assert!(output.contains("await arg(\"Name?\");"));
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_keeps_existing_metadata_and_import() {
+        let script = r#"// Name: Existing
+// Description: Existing description
+import "@johnlindquist/kit";
+
+await div("ready");
+"#;
+        let output = enforce_script_kit_conventions(script, "ignored", "ignored");
+
+        assert_eq!(
+            output.matches("// Name:").count(),
+            1,
+            "should not duplicate existing Name metadata"
+        );
+        assert_eq!(
+            output.matches("// Description:").count(),
+            1,
+            "should not duplicate existing Description metadata"
+        );
+        assert_eq!(
+            output.matches("import \"@johnlindquist/kit\";").count(),
+            1,
+            "should not duplicate existing import"
+        );
+    }
+
+    #[test]
+    fn test_write_generated_script_in_dir_appends_numeric_suffix_for_collisions() {
+        let temp_dir = tempdir().unwrap();
+        let first = write_generated_script_in_dir(temp_dir.path(), "my-script", "a").unwrap();
+        let second = write_generated_script_in_dir(temp_dir.path(), "my-script", "b").unwrap();
+
+        assert_eq!(first.file_name().unwrap(), "my-script.ts");
+        assert_eq!(second.file_name().unwrap(), "my-script-1.ts");
+    }
+}
diff --git a/src/builtins/part_000.rs b/src/builtins/part_000.rs
index d6b9c2a9b35b40c5005dbb9f65147f528702cb9e..5f6d27d28d72e51126d10d8beccf931c689ef2bb
--- a/src/builtins/part_000.rs
+++ b/src/builtins/part_000.rs
@@ -96,6 +96,8 @@
     OpenAi,
     NewConversation,
     ClearConversation,
+    /// Generate a new Script Kit script from the main prompt text
+    GenerateScript,
     /// Send a screenshot of the entire screen to AI Chat
     SendScreenToAi,
     /// Send a screenshot of the focused window to AI Chat
diff --git a/src/builtins/part_001_entries/entries_002.rs b/src/builtins/part_001_entries/entries_002.rs
index 6d1c9334f0ccaf0aab48582aaf42dcb129e1cb6e..72b318c66aeaf124359f4ecd276dae0350287328
--- a/src/builtins/part_001_entries/entries_002.rs
+++ b/src/builtins/part_001_entries/entries_002.rs
@@ -61,6 +61,17 @@
     ));
 
     entries.push(BuiltInEntry::new_with_icon(
+        "builtin-generate-script-with-ai",
+        "Generate Script with AI",
+        "Generate a Script Kit script from your current prompt text",
+        vec![
+            "generate", "script", "ai", "create", "code", "typescript", "shift", "tab",
+        ],
+        BuiltInFeature::AiCommand(AiCommandType::GenerateScript),
+        "ðŸ§ ",
+    ));
+
+    entries.push(BuiltInEntry::new_with_icon(
         "builtin-send-screen-to-ai",
         "Send Screen to AI Chat",
         "Capture the full screen and send it to AI Chat",


thinking
**Inspecting main.rs imports**
exec
/bin/zsh -lc 'rg -n "use std::thread|thread::spawn|std::sync::mpsc|mpsc::channel|open_in_editor|script_creation" src/main.rs src/app_execute/builtin_execution.rs | head -n 80' in /Users/johnlindquist/dev/script-kit-gpui succeeded in 51ms:
src/main.rs:112:mod script_creation;
src/app_execute/builtin_execution.rs:857:                        (script_creation::create_new_script("untitled"), "script")
src/app_execute/builtin_execution.rs:863:                        (script_creation::create_new_extension(&name), "extension")
src/app_execute/builtin_execution.rs:870:                        if let Err(e) = script_creation::open_in_editor(&path, &self.config) {
file update:
diff --git a/src/ai/mod.rs b/src/ai/mod.rs
index a420b1a5faf59506acdb7caf60681c153a3f9bb6..9a73e9491862633b325b2c52b51a3e20395ff85c
--- a/src/ai/mod.rs
+++ b/src/ai/mod.rs
@@ -37,6 +37,7 @@
 pub(crate) mod providers;
 pub(crate) mod sdk_handlers;
 pub(crate) mod session;
+pub(crate) mod script_generation;
 pub(crate) mod storage;
 pub(crate) mod window;
 
@@ -44,6 +45,7 @@
 pub use self::config::{DetectedKeys, ModelInfo, ProviderConfig};
 pub use self::model::{Chat, ChatId, ChatSource, Message, MessageRole};
 pub use self::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+pub use self::script_generation::{generate_script_from_prompt, GeneratedScriptOutput};
 pub use self::sdk_handlers::try_handle_ai_message;
 pub use self::storage::{
     clear_all_chats, create_chat, delete_chat, get_all_chats, get_chat, get_chat_messages,
diff --git a/src/ai/script_generation.rs b/src/ai/script_generation.rs
new file mode 100644
index 0000000000000000000000000000000000000000..7f2ec8e7576ed50cd10f7aea31a6522875ef667a
--- /dev/null
+++ b/src/ai/script_generation.rs
@@ -0,0 +1,417 @@
+use anyhow::{Context, Result};
+use std::fs::{self, OpenOptions};
+use std::io::{ErrorKind, Write};
+use std::path::{Path, PathBuf};
+use std::sync::Arc;
+
+use super::config::ModelInfo;
+use super::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+
+const AI_SCRIPT_OUTPUT_DIR: &str = "~/.kenv/scripts";
+const AI_SCRIPT_DEFAULT_SLUG: &str = "ai-script";
+const AI_SCRIPT_MAX_SLUG_LEN: usize = 64;
+
+const AI_SCRIPT_GENERATION_SYSTEM_PROMPT: &str = r#"You write production-ready Script Kit scripts.
+
+Return ONLY TypeScript source code for one Script Kit script. Do not include explanations.
+
+Required output conventions:
+1) Include metadata comments at the top:
+   // Name: <clear title>
+   // Description: <one-line summary>
+2) Include: import "@johnlindquist/kit";
+3) Use await arg() for user input when useful.
+4) Use await div() for display output when useful.
+5) Keep the script runnable as-is with sensible defaults and light error handling."#;
+
+#[derive(Debug, Clone)]
+pub struct GeneratedScriptOutput {
+    pub path: PathBuf,
+    pub slug: String,
+    pub model_id: String,
+    pub provider_id: String,
+}
+
+pub fn generate_script_from_prompt(
+    prompt: &str,
+    config: Option<&crate::config::Config>,
+) -> Result<GeneratedScriptOutput> {
+    let normalized_prompt = prompt.trim();
+    if normalized_prompt.is_empty() {
+        anyhow::bail!("AI script generation requires a non-empty prompt");
+    }
+
+    let registry = ProviderRegistry::from_environment_with_config(config);
+    if !registry.has_any_provider() {
+        anyhow::bail!(
+            "No AI providers configured. Configure an API key first (Vercel, OpenAI, Anthropic, etc.)."
+        );
+    }
+
+    let (selected_model, provider) = select_generation_model(&registry)?;
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=provider_ready model_id={} provider_id={} prompt_len={}",
+            selected_model.id,
+            selected_model.provider,
+            normalized_prompt.len()
+        ),
+    );
+
+    let messages = vec![
+        ProviderMessage::system(AI_SCRIPT_GENERATION_SYSTEM_PROMPT),
+        ProviderMessage::user(format!(
+            "Generate a Script Kit script for this user request:\n\n{}",
+            normalized_prompt
+        )),
+    ];
+
+    let raw_response = provider
+        .send_message(&messages, &selected_model.id)
+        .with_context(|| {
+            format!(
+                "AI script generation failed (attempted=send_message, model_id={}, provider_id={})",
+                selected_model.id, selected_model.provider
+            )
+        })?;
+
+    let extracted = extract_script_code(&raw_response);
+    if extracted.trim().is_empty() {
+        anyhow::bail!(
+            "AI returned an empty response for script generation (state=empty_response)"
+        );
+    }
+
+    let slug = slugify_script_name(normalized_prompt);
+    let finalized = enforce_script_kit_conventions(&extracted, normalized_prompt, &slug);
+    let path = write_generated_script(&slug, &finalized).with_context(|| {
+        format!(
+            "Failed writing AI-generated script (state=write_failed, slug={})",
+            slug
+        )
+    })?;
+
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=script_written path={} slug={}",
+            path.display(),
+            slug
+        ),
+    );
+
+    Ok(GeneratedScriptOutput {
+        path,
+        slug,
+        model_id: selected_model.id,
+        provider_id: selected_model.provider,
+    })
+}
+
+fn select_generation_model(registry: &ProviderRegistry) -> Result<(ModelInfo, Arc<dyn AiProvider>)> {
+    let models = registry.get_all_models();
+    let selected_model = models
+        .iter()
+        .find(|model| model.provider.eq_ignore_ascii_case("vercel"))
+        .or_else(|| models.first())
+        .cloned()
+        .context("No AI models available in provider registry")?;
+
+    let provider = registry
+        .find_provider_for_model(&selected_model.id)
+        .cloned()
+        .with_context(|| {
+            format!(
+                "No provider found for selected model '{}' (state=provider_missing)",
+                selected_model.id
+            )
+        })?;
+
+    Ok((selected_model, provider))
+}
+
+fn generated_scripts_dir() -> PathBuf {
+    PathBuf::from(shellexpand::tilde(AI_SCRIPT_OUTPUT_DIR).as_ref())
+}
+
+fn split_fence_header_and_body(fence: &str) -> (&str, &str) {
+    match fence.find('\n') {
+        Some(newline_index) => (&fence[..newline_index], &fence[newline_index + 1..]),
+        None => ("", fence),
+    }
+}
+
+fn extract_fenced_code(response: &str, preferred_languages: Option<&[&str]>) -> Option<String> {
+    let mut remaining = response;
+
+    while let Some(start) = remaining.find("```") {
+        let after_start = &remaining[start + 3..];
+        let Some(end) = after_start.find("```") else {
+            break;
+        };
+
+        let fence_contents = &after_start[..end];
+        let (header, body) = split_fence_header_and_body(fence_contents);
+        let language = header
+            .trim()
+            .split(|c: char| c.is_whitespace() || c == '{')
+            .next()
+            .unwrap_or("")
+            .to_ascii_lowercase();
+        let code = body.trim();
+
+        if !code.is_empty() {
+            match preferred_languages {
+                Some(preferred) => {
+                    if preferred.iter().any(|candidate| *candidate == language) {
+                        return Some(code.to_string());
+                    }
+                }
+                None => return Some(code.to_string()),
+            }
+        }
+
+        remaining = &after_start[end + 3..];
+    }
+
+    None
+}
+
+fn extract_script_code(response: &str) -> String {
+    const PREFERRED_LANGUAGES: [&str; 6] = ["typescript", "ts", "javascript", "js", "tsx", "jsx"];
+
+    extract_fenced_code(response, Some(&PREFERRED_LANGUAGES))
+        .or_else(|| extract_fenced_code(response, None))
+        .unwrap_or_else(|| response.trim().to_string())
+}
+
+fn slugify_script_name(prompt: &str) -> String {
+    let mut slug = String::new();
+    let mut last_was_hyphen = false;
+
+    for character in prompt.to_ascii_lowercase().chars() {
+        if character.is_ascii_alphanumeric() {
+            slug.push(character);
+            last_was_hyphen = false;
+        } else if matches!(character, ' ' | '_' | '-') {
+            if !slug.is_empty() && !last_was_hyphen {
+                slug.push('-');
+                last_was_hyphen = true;
+            }
+        }
+    }
+
+    while slug.ends_with('-') {
+        slug.pop();
+    }
+
+    if slug.len() > AI_SCRIPT_MAX_SLUG_LEN {
+        slug.truncate(AI_SCRIPT_MAX_SLUG_LEN);
+        while slug.ends_with('-') {
+            slug.pop();
+        }
+    }
+
+    if slug.is_empty() {
+        AI_SCRIPT_DEFAULT_SLUG.to_string()
+    } else {
+        slug
+    }
+}
+
+fn slug_to_title(slug: &str) -> String {
+    slug.split('-')
+        .filter(|segment| !segment.is_empty())
+        .map(|segment| {
+            let mut chars = segment.chars();
+            match chars.next() {
+                Some(first) => first.to_uppercase().collect::<String>() + chars.as_str(),
+                None => String::new(),
+            }
+        })
+        .collect::<Vec<_>>()
+        .join(" ")
+}
+
+fn description_from_prompt(prompt: &str) -> String {
+    let normalized = prompt.split_whitespace().collect::<Vec<_>>().join(" ");
+    if normalized.is_empty() {
+        return "AI-generated Script Kit script".to_string();
+    }
+
+    let mut shortened = normalized;
+    if shortened.chars().count() > 110 {
+        shortened = format!("{}...", shortened.chars().take(107).collect::<String>());
+    }
+    shortened
+}
+
+fn has_kit_import(script: &str) -> bool {
+    script.contains("import \"@johnlindquist/kit\";")
+        || script.contains("import '@johnlindquist/kit';")
+        || script.contains("import \"@scriptkit/sdk\";")
+        || script.contains("import '@scriptkit/sdk';")
+}
+
+fn enforce_script_kit_conventions(script: &str, prompt: &str, slug: &str) -> String {
+    let mut prefix_lines: Vec<String> = Vec::new();
+    let trimmed_script = script.trim();
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Name:"))
+    {
+        prefix_lines.push(format!("// Name: {}", slug_to_title(slug)));
+    }
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Description:"))
+    {
+        prefix_lines.push(format!("// Description: {}", description_from_prompt(prompt)));
+    }
+
+    if !has_kit_import(trimmed_script) {
+        prefix_lines.push("import \"@johnlindquist/kit\";".to_string());
+    }
+
+    let mut output = String::new();
+    if !prefix_lines.is_empty() {
+        output.push_str(&prefix_lines.join("\n"));
+        output.push_str("\n\n");
+    }
+
+    output.push_str(trimmed_script);
+    if !output.ends_with('\n') {
+        output.push('\n');
+    }
+    output
+}
+
+fn write_generated_script(slug: &str, script_content: &str) -> Result<PathBuf> {
+    write_generated_script_in_dir(&generated_scripts_dir(), slug, script_content)
+}
+
+fn write_generated_script_in_dir(output_dir: &Path, slug: &str, script_content: &str) -> Result<PathBuf> {
+    fs::create_dir_all(output_dir)
+        .with_context(|| format!("Failed to create output dir: {}", output_dir.display()))?;
+
+    for suffix in 0usize.. {
+        let candidate = if suffix == 0 {
+            slug.to_string()
+        } else {
+            format!("{slug}-{suffix}")
+        };
+        let path = output_dir.join(format!("{}.ts", candidate));
+        match OpenOptions::new().write(true).create_new(true).open(&path) {
+            Ok(mut file) => {
+                file.write_all(script_content.as_bytes())
+                    .with_context(|| format!("Failed writing generated script to {}", path.display()))?;
+                return Ok(path);
+            }
+            Err(error) if error.kind() == ErrorKind::AlreadyExists => continue,
+            Err(error) => {
+                return Err(error).with_context(|| {
+                    format!(
+                        "Failed creating generated script file {} (slug={})",
+                        path.display(),
+                        slug
+                    )
+                });
+            }
+        }
+    }
+
+    unreachable!("suffix loop should eventually create a unique script filename")
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+    use tempfile::tempdir;
+
+    #[test]
+    fn test_slugify_script_name_handles_spaces_and_symbols() {
+        assert_eq!(slugify_script_name("Build: API Client!"), "build-api-client");
+        assert_eq!(slugify_script_name("  ___  "), "ai-script");
+    }
+
+    #[test]
+    fn test_extract_script_code_prefers_typescript_fence_when_multiple_blocks_exist() {
+        let response = r#"
+Here's one idea:
+```markdown
+Not code
+```
+```typescript
+await div("hello");
+```
+"#;
+        assert_eq!(extract_script_code(response), "await div(\"hello\");");
+    }
+
+    #[test]
+    fn test_extract_script_code_falls_back_to_first_fenced_block() {
+        let response = r#"
+```python
+print("hello")
+```
+"#;
+        assert_eq!(extract_script_code(response), "print(\"hello\")");
+    }
+
+    #[test]
+    fn test_extract_script_code_returns_trimmed_response_when_no_fence_exists() {
+        let response = "const answer = 42;";
+        assert_eq!(extract_script_code(response), "const answer = 42;");
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_adds_missing_metadata_and_import() {
+        let script = "const name = await arg(\"Name?\");";
+        let output = enforce_script_kit_conventions(script, "Ask for user name", "ask-user-name");
+
+        assert!(output.contains("// Name: Ask User Name"));
+        assert!(output.contains("// Description: Ask for user name"));
+        assert!(output.contains("import \"@johnlindquist/kit\";"));
+        assert!(output.contains("await arg(\"Name?\");"));
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_keeps_existing_metadata_and_import() {
+        let script = r#"// Name: Existing
+// Description: Existing description
+import "@johnlindquist/kit";
+
+await div("ready");
+"#;
+        let output = enforce_script_kit_conventions(script, "ignored", "ignored");
+
+        assert_eq!(
+            output.matches("// Name:").count(),
+            1,
+            "should not duplicate existing Name metadata"
+        );
+        assert_eq!(
+            output.matches("// Description:").count(),
+            1,
+            "should not duplicate existing Description metadata"
+        );
+        assert_eq!(
+            output.matches("import \"@johnlindquist/kit\";").count(),
+            1,
+            "should not duplicate existing import"
+        );
+    }
+
+    #[test]
+    fn test_write_generated_script_in_dir_appends_numeric_suffix_for_collisions() {
+        let temp_dir = tempdir().unwrap();
+        let first = write_generated_script_in_dir(temp_dir.path(), "my-script", "a").unwrap();
+        let second = write_generated_script_in_dir(temp_dir.path(), "my-script", "b").unwrap();
+
+        assert_eq!(first.file_name().unwrap(), "my-script.ts");
+        assert_eq!(second.file_name().unwrap(), "my-script-1.ts");
+    }
+}
diff --git a/src/builtins/part_000.rs b/src/builtins/part_000.rs
index d6b9c2a9b35b40c5005dbb9f65147f528702cb9e..5f6d27d28d72e51126d10d8beccf931c689ef2bb
--- a/src/builtins/part_000.rs
+++ b/src/builtins/part_000.rs
@@ -96,6 +96,8 @@
     OpenAi,
     NewConversation,
     ClearConversation,
+    /// Generate a new Script Kit script from the main prompt text
+    GenerateScript,
     /// Send a screenshot of the entire screen to AI Chat
     SendScreenToAi,
     /// Send a screenshot of the focused window to AI Chat
diff --git a/src/builtins/part_001_entries/entries_002.rs b/src/builtins/part_001_entries/entries_002.rs
index 6d1c9334f0ccaf0aab48582aaf42dcb129e1cb6e..72b318c66aeaf124359f4ecd276dae0350287328
--- a/src/builtins/part_001_entries/entries_002.rs
+++ b/src/builtins/part_001_entries/entries_002.rs
@@ -61,6 +61,17 @@
     ));
 
     entries.push(BuiltInEntry::new_with_icon(
+        "builtin-generate-script-with-ai",
+        "Generate Script with AI",
+        "Generate a Script Kit script from your current prompt text",
+        vec![
+            "generate", "script", "ai", "create", "code", "typescript", "shift", "tab",
+        ],
+        BuiltInFeature::AiCommand(AiCommandType::GenerateScript),
+        "ðŸ§ ",
+    ));
+
+    entries.push(BuiltInEntry::new_with_icon(
         "builtin-send-screen-to-ai",
         "Send Screen to AI Chat",
         "Capture the full screen and send it to AI Chat",


thinking
**Inspecting provider traits and sync semantics**
exec
/bin/zsh -lc "sed -n '1,260p' src/ai/providers.rs" in /Users/johnlindquist/dev/script-kit-gpui succeeded in 51ms:
//! AI provider abstraction layer.
//!
//! This module provides a trait-based abstraction for AI providers, allowing
//! Script Kit to work with multiple AI services (OpenAI, Anthropic, etc.) through
//! a unified interface.
//!
//! # Architecture
//!
//! - `AiProvider` trait defines the interface all providers must implement
//! - `ProviderRegistry` manages available providers based on detected API keys
//! - Individual provider implementations (OpenAI, Anthropic, etc.) implement the trait
//!

use anyhow::{anyhow, Context, Result};
use std::collections::HashMap;
use std::io::{BufRead, BufReader};
use std::sync::Arc;
use std::time::Duration;

use super::config::{default_models, DetectedKeys, ModelInfo, ProviderConfig};
file update:
diff --git a/src/ai/mod.rs b/src/ai/mod.rs
index a420b1a5faf59506acdb7caf60681c153a3f9bb6..9a73e9491862633b325b2c52b51a3e20395ff85c
--- a/src/ai/mod.rs
+++ b/src/ai/mod.rs
@@ -37,6 +37,7 @@
 pub(crate) mod providers;
 pub(crate) mod sdk_handlers;
 pub(crate) mod session;
+pub(crate) mod script_generation;
 pub(crate) mod storage;
 pub(crate) mod window;
 
@@ -44,6 +45,7 @@
 pub use self::config::{DetectedKeys, ModelInfo, ProviderConfig};
 pub use self::model::{Chat, ChatId, ChatSource, Message, MessageRole};
 pub use self::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+pub use self::script_generation::{generate_script_from_prompt, GeneratedScriptOutput};
 pub use self::sdk_handlers::try_handle_ai_message;
 pub use self::storage::{
     clear_all_chats, create_chat, delete_chat, get_all_chats, get_chat, get_chat_messages,
diff --git a/src/ai/script_generation.rs b/src/ai/script_generation.rs
new file mode 100644
index 0000000000000000000000000000000000000000..7f2ec8e7576ed50cd10f7aea31a6522875ef667a
--- /dev/null
+++ b/src/ai/script_generation.rs
@@ -0,0 +1,417 @@
+use anyhow::{Context, Result};
+use std::fs::{self, OpenOptions};
+use std::io::{ErrorKind, Write};
+use std::path::{Path, PathBuf};
+use std::sync::Arc;
+
+use super::config::ModelInfo;
+use super::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+
+const AI_SCRIPT_OUTPUT_DIR: &str = "~/.kenv/scripts";
+const AI_SCRIPT_DEFAULT_SLUG: &str = "ai-script";
+const AI_SCRIPT_MAX_SLUG_LEN: usize = 64;
+
+const AI_SCRIPT_GENERATION_SYSTEM_PROMPT: &str = r#"You write production-ready Script Kit scripts.
+
+Return ONLY TypeScript source code for one Script Kit script. Do not include explanations.
+
+Required output conventions:
+1) Include metadata comments at the top:
+   // Name: <clear title>
+   // Description: <one-line summary>
+2) Include: import "@johnlindquist/kit";
+3) Use await arg() for user input when useful.
+4) Use await div() for display output when useful.
+5) Keep the script runnable as-is with sensible defaults and light error handling."#;
+
+#[derive(Debug, Clone)]
+pub struct GeneratedScriptOutput {
+    pub path: PathBuf,
+    pub slug: String,
+    pub model_id: String,
+    pub provider_id: String,
+}
+
+pub fn generate_script_from_prompt(
+    prompt: &str,
+    config: Option<&crate::config::Config>,
+) -> Result<GeneratedScriptOutput> {
+    let normalized_prompt = prompt.trim();
+    if normalized_prompt.is_empty() {
+        anyhow::bail!("AI script generation requires a non-empty prompt");
+    }
+
+    let registry = ProviderRegistry::from_environment_with_config(config);
+    if !registry.has_any_provider() {
+        anyhow::bail!(
+            "No AI providers configured. Configure an API key first (Vercel, OpenAI, Anthropic, etc.)."
+        );
+    }
+
+    let (selected_model, provider) = select_generation_model(&registry)?;
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=provider_ready model_id={} provider_id={} prompt_len={}",
+            selected_model.id,
+            selected_model.provider,
+            normalized_prompt.len()
+        ),
+    );
+
+    let messages = vec![
+        ProviderMessage::system(AI_SCRIPT_GENERATION_SYSTEM_PROMPT),
+        ProviderMessage::user(format!(
+            "Generate a Script Kit script for this user request:\n\n{}",
+            normalized_prompt
+        )),
+    ];
+
+    let raw_response = provider
+        .send_message(&messages, &selected_model.id)
+        .with_context(|| {
+            format!(
+                "AI script generation failed (attempted=send_message, model_id={}, provider_id={})",
+                selected_model.id, selected_model.provider
+            )
+        })?;
+
+    let extracted = extract_script_code(&raw_response);
+    if extracted.trim().is_empty() {
+        anyhow::bail!(
+            "AI returned an empty response for script generation (state=empty_response)"
+        );
+    }
+
+    let slug = slugify_script_name(normalized_prompt);
+    let finalized = enforce_script_kit_conventions(&extracted, normalized_prompt, &slug);
+    let path = write_generated_script(&slug, &finalized).with_context(|| {
+        format!(
+            "Failed writing AI-generated script (state=write_failed, slug={})",
+            slug
+        )
+    })?;
+
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=script_written path={} slug={}",
+            path.display(),
+            slug
+        ),
+    );
+
+    Ok(GeneratedScriptOutput {
+        path,
+        slug,
+        model_id: selected_model.id,
+        provider_id: selected_model.provider,
+    })
+}
+
+fn select_generation_model(registry: &ProviderRegistry) -> Result<(ModelInfo, Arc<dyn AiProvider>)> {
+    let models = registry.get_all_models();
+    let selected_model = models
+        .iter()
+        .find(|model| model.provider.eq_ignore_ascii_case("vercel"))
+        .or_else(|| models.first())
+        .cloned()
+        .context("No AI models available in provider registry")?;
+
+    let provider = registry
+        .find_provider_for_model(&selected_model.id)
+        .cloned()
+        .with_context(|| {
+            format!(
+                "No provider found for selected model '{}' (state=provider_missing)",
+                selected_model.id
+            )
+        })?;
+
+    Ok((selected_model, provider))
+}
+
+fn generated_scripts_dir() -> PathBuf {
+    PathBuf::from(shellexpand::tilde(AI_SCRIPT_OUTPUT_DIR).as_ref())
+}
+
+fn split_fence_header_and_body(fence: &str) -> (&str, &str) {
+    match fence.find('\n') {
+        Some(newline_index) => (&fence[..newline_index], &fence[newline_index + 1..]),
+        None => ("", fence),
+    }
+}
+
+fn extract_fenced_code(response: &str, preferred_languages: Option<&[&str]>) -> Option<String> {
+    let mut remaining = response;
+
+    while let Some(start) = remaining.find("```") {
+        let after_start = &remaining[start + 3..];
+        let Some(end) = after_start.find("```") else {
+            break;
+        };
+
+        let fence_contents = &after_start[..end];
+        let (header, body) = split_fence_header_and_body(fence_contents);
+        let language = header
+            .trim()
+            .split(|c: char| c.is_whitespace() || c == '{')
+            .next()
+            .unwrap_or("")
+            .to_ascii_lowercase();
+        let code = body.trim();
+
+        if !code.is_empty() {
+            match preferred_languages {
+                Some(preferred) => {
+                    if preferred.iter().any(|candidate| *candidate == language) {
+                        return Some(code.to_string());
+                    }
+                }
+                None => return Some(code.to_string()),
+            }
+        }
+
+        remaining = &after_start[end + 3..];
+    }
+
+    None
+}
+
+fn extract_script_code(response: &str) -> String {
+    const PREFERRED_LANGUAGES: [&str; 6] = ["typescript", "ts", "javascript", "js", "tsx", "jsx"];
+
+    extract_fenced_code(response, Some(&PREFERRED_LANGUAGES))
+        .or_else(|| extract_fenced_code(response, None))
+        .unwrap_or_else(|| response.trim().to_string())
+}
+
+fn slugify_script_name(prompt: &str) -> String {
+    let mut slug = String::new();
+    let mut last_was_hyphen = false;
+
+    for character in prompt.to_ascii_lowercase().chars() {
+        if character.is_ascii_alphanumeric() {
+            slug.push(character);
+            last_was_hyphen = false;
+        } else if matches!(character, ' ' | '_' | '-') {
+            if !slug.is_empty() && !last_was_hyphen {
+                slug.push('-');
+                last_was_hyphen = true;
+            }
+        }
+    }
+
+    while slug.ends_with('-') {
+        slug.pop();
+    }
+
+    if slug.len() > AI_SCRIPT_MAX_SLUG_LEN {
+        slug.truncate(AI_SCRIPT_MAX_SLUG_LEN);
+        while slug.ends_with('-') {
+            slug.pop();
+        }
+    }
+
+    if slug.is_empty() {
+        AI_SCRIPT_DEFAULT_SLUG.to_string()
+    } else {
+        slug
+    }
+}
+
+fn slug_to_title(slug: &str) -> String {
+    slug.split('-')
+        .filter(|segment| !segment.is_empty())
+        .map(|segment| {
+            let mut chars = segment.chars();
+            match chars.next() {
+                Some(first) => first.to_uppercase().collect::<String>() + chars.as_str(),
+                None => String::new(),
+            }
+        })
+        .collect::<Vec<_>>()
+        .join(" ")
+}
+
+fn description_from_prompt(prompt: &str) -> String {
+    let normalized = prompt.split_whitespace().collect::<Vec<_>>().join(" ");
+    if normalized.is_empty() {
+        return "AI-generated Script Kit script".to_string();
+    }
+
+    let mut shortened = normalized;
+    if shortened.chars().count() > 110 {
+        shortened = format!("{}...", shortened.chars().take(107).collect::<String>());
+    }
+    shortened
+}
+
+fn has_kit_import(script: &str) -> bool {
+    script.contains("import \"@johnlindquist/kit\";")
+        || script.contains("import '@johnlindquist/kit';")
+        || script.contains("import \"@scriptkit/sdk\";")
+        || script.contains("import '@scriptkit/sdk';")
+}
+
+fn enforce_script_kit_conventions(script: &str, prompt: &str, slug: &str) -> String {
+    let mut prefix_lines: Vec<String> = Vec::new();
+    let trimmed_script = script.trim();
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Name:"))
+    {
+        prefix_lines.push(format!("// Name: {}", slug_to_title(slug)));
+    }
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Description:"))
+    {
+        prefix_lines.push(format!("// Description: {}", description_from_prompt(prompt)));
+    }
+
+    if !has_kit_import(trimmed_script) {
+        prefix_lines.push("import \"@johnlindquist/kit\";".to_string());
+    }
+
+    let mut output = String::new();
+    if !prefix_lines.is_empty() {
+        output.push_str(&prefix_lines.join("\n"));
+        output.push_str("\n\n");
+    }
+
+    output.push_str(trimmed_script);
+    if !output.ends_with('\n') {
+        output.push('\n');
+    }
+    output
+}
+
+fn write_generated_script(slug: &str, script_content: &str) -> Result<PathBuf> {
+    write_generated_script_in_dir(&generated_scripts_dir(), slug, script_content)
+}
+
+fn write_generated_script_in_dir(output_dir: &Path, slug: &str, script_content: &str) -> Result<PathBuf> {
+    fs::create_dir_all(output_dir)
+        .with_context(|| format!("Failed to create output dir: {}", output_dir.display()))?;
+
+    for suffix in 0usize.. {
+        let candidate = if suffix == 0 {
+            slug.to_string()
+        } else {
+            format!("{slug}-{suffix}")
+        };
+        let path = output_dir.join(format!("{}.ts", candidate));
+        match OpenOptions::new().write(true).create_new(true).open(&path) {
+            Ok(mut file) => {
+                file.write_all(script_content.as_bytes())
+                    .with_context(|| format!("Failed writing generated script to {}", path.display()))?;
+                return Ok(path);
+            }
+            Err(error) if error.kind() == ErrorKind::AlreadyExists => continue,
+            Err(error) => {
+                return Err(error).with_context(|| {
+                    format!(
+                        "Failed creating generated script file {} (slug={})",
+                        path.display(),
+                        slug
+                    )
+                });
+            }
+        }
+    }
+
+    unreachable!("suffix loop should eventually create a unique script filename")
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+    use tempfile::tempdir;
+
+    #[test]
+    fn test_slugify_script_name_handles_spaces_and_symbols() {
+        assert_eq!(slugify_script_name("Build: API Client!"), "build-api-client");
+        assert_eq!(slugify_script_name("  ___  "), "ai-script");
+    }
+
+    #[test]
+    fn test_extract_script_code_prefers_typescript_fence_when_multiple_blocks_exist() {
+        let response = r#"
+Here's one idea:
+```markdown
+Not code
+```
+```typescript
+await div("hello");
+```
+"#;
+        assert_eq!(extract_script_code(response), "await div(\"hello\");");
+    }
+
+    #[test]
+    fn test_extract_script_code_falls_back_to_first_fenced_block() {
+        let response = r#"
+```python
+print("hello")
+```
+"#;
+        assert_eq!(extract_script_code(response), "print(\"hello\")");
+    }
+
+    #[test]
+    fn test_extract_script_code_returns_trimmed_response_when_no_fence_exists() {
+        let response = "const answer = 42;";
+        assert_eq!(extract_script_code(response), "const answer = 42;");
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_adds_missing_metadata_and_import() {
+        let script = "const name = await arg(\"Name?\");";
+        let output = enforce_script_kit_conventions(script, "Ask for user name", "ask-user-name");
+
+        assert!(output.contains("// Name: Ask User Name"));
+        assert!(output.contains("// Description: Ask for user name"));
+        assert!(output.contains("import \"@johnlindquist/kit\";"));
+        assert!(output.contains("await arg(\"Name?\");"));
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_keeps_existing_metadata_and_import() {
+        let script = r#"// Name: Existing
+// Description: Existing description
+import "@johnlindquist/kit";
+
+await div("ready");
+"#;
+        let output = enforce_script_kit_conventions(script, "ignored", "ignored");
+
+        assert_eq!(
+            output.matches("// Name:").count(),
+            1,
+            "should not duplicate existing Name metadata"
+        );
+        assert_eq!(
+            output.matches("// Description:").count(),
+            1,
+            "should not duplicate existing Description metadata"
+        );
+        assert_eq!(
+            output.matches("import \"@johnlindquist/kit\";").count(),
+            1,
+            "should not duplicate existing import"
+        );
+    }
+
+    #[test]
+    fn test_write_generated_script_in_dir_appends_numeric_suffix_for_collisions() {
+        let temp_dir = tempdir().unwrap();
+        let first = write_generated_script_in_dir(temp_dir.path(), "my-script", "a").unwrap();
+        let second = write_generated_script_in_dir(temp_dir.path(), "my-script", "b").unwrap();
+
+        assert_eq!(first.file_name().unwrap(), "my-script.ts");
+        assert_eq!(second.file_name().unwrap(), "my-script-1.ts");
+    }
+}
diff --git a/src/builtins/part_000.rs b/src/builtins/part_000.rs
index d6b9c2a9b35b40c5005dbb9f65147f528702cb9e..5f6d27d28d72e51126d10d8beccf931c689ef2bb
--- a/src/builtins/part_000.rs
+++ b/src/builtins/part_000.rs
@@ -96,6 +96,8 @@
     OpenAi,
     NewConversation,
     ClearConversation,
+    /// Generate a new Script Kit script from the main prompt text
+    GenerateScript,
     /// Send a screenshot of the entire screen to AI Chat
     SendScreenToAi,
     /// Send a screenshot of the focused window to AI Chat
diff --git a/src/builtins/part_001_entries/entries_002.rs b/src/builtins/part_001_entries/entries_002.rs
index 6d1c9334f0ccaf0aab48582aaf42dcb129e1cb6e..72b318c66aeaf124359f4ecd276dae0350287328
--- a/src/builtins/part_001_entries/entries_002.rs
+++ b/src/builtins/part_001_entries/entries_002.rs
@@ -61,6 +61,17 @@
     ));
 
     entries.push(BuiltInEntry::new_with_icon(
+        "builtin-generate-script-with-ai",
+        "Generate Script with AI",
+        "Generate a Script Kit script from your current prompt text",
+        vec![
+            "generate", "script", "ai", "create", "code", "typescript", "shift", "tab",
+        ],
+        BuiltInFeature::AiCommand(AiCommandType::GenerateScript),
+        "ðŸ§ ",
+    ));
+
+    entries.push(BuiltInEntry::new_with_icon(
         "builtin-send-screen-to-ai",
         "Send Screen to AI Chat",
         "Capture the full screen and send it to AI Chat",


thinking
**Reviewing provider registry APIs**
exec
/bin/zsh -lc "sed -n '1,200p' src/ai/mod.rs" in /Users/johnlindquist/dev/script-kit-gpui succeeded in 51ms:
//! AI Chat Module
//!
//! This module provides the data layer for the AI chat window feature.
//! It includes data models, SQLite storage with FTS5 search support,
//! and provider abstraction for BYOK (Bring Your Own Key) AI integration.
//!
//! # Architecture
//!
//! ```text
//! src/ai/
//! â”œâ”€â”€ mod.rs       - Module exports and documentation
//! â”œâ”€â”€ model.rs     - Data models (Chat, Message, ChatId, MessageRole)
//! â”œâ”€â”€ storage.rs   - SQLite persistence layer
//! â”œâ”€â”€ config.rs    - Environment variable detection and model configuration
//! â””â”€â”€ providers.rs - Provider trait and implementations (OpenAI, Anthropic, etc.)
//! ```
//!
//! # Database Location
//!
//! The AI chats database is stored at `~/.scriptkit/ai-chats.db`.
file update:
diff --git a/src/ai/mod.rs b/src/ai/mod.rs
index a420b1a5faf59506acdb7caf60681c153a3f9bb6..9a73e9491862633b325b2c52b51a3e20395ff85c
--- a/src/ai/mod.rs
+++ b/src/ai/mod.rs
@@ -37,6 +37,7 @@
 pub(crate) mod providers;
 pub(crate) mod sdk_handlers;
 pub(crate) mod session;
+pub(crate) mod script_generation;
 pub(crate) mod storage;
 pub(crate) mod window;
 
@@ -44,6 +45,7 @@
 pub use self::config::{DetectedKeys, ModelInfo, ProviderConfig};
 pub use self::model::{Chat, ChatId, ChatSource, Message, MessageRole};
 pub use self::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+pub use self::script_generation::{generate_script_from_prompt, GeneratedScriptOutput};
 pub use self::sdk_handlers::try_handle_ai_message;
 pub use self::storage::{
     clear_all_chats, create_chat, delete_chat, get_all_chats, get_chat, get_chat_messages,
diff --git a/src/ai/script_generation.rs b/src/ai/script_generation.rs
new file mode 100644
index 0000000000000000000000000000000000000000..7f2ec8e7576ed50cd10f7aea31a6522875ef667a
--- /dev/null
+++ b/src/ai/script_generation.rs
@@ -0,0 +1,417 @@
+use anyhow::{Context, Result};
+use std::fs::{self, OpenOptions};
+use std::io::{ErrorKind, Write};
+use std::path::{Path, PathBuf};
+use std::sync::Arc;
+
+use super::config::ModelInfo;
+use super::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+
+const AI_SCRIPT_OUTPUT_DIR: &str = "~/.kenv/scripts";
+const AI_SCRIPT_DEFAULT_SLUG: &str = "ai-script";
+const AI_SCRIPT_MAX_SLUG_LEN: usize = 64;
+
+const AI_SCRIPT_GENERATION_SYSTEM_PROMPT: &str = r#"You write production-ready Script Kit scripts.
+
+Return ONLY TypeScript source code for one Script Kit script. Do not include explanations.
+
+Required output conventions:
+1) Include metadata comments at the top:
+   // Name: <clear title>
+   // Description: <one-line summary>
+2) Include: import "@johnlindquist/kit";
+3) Use await arg() for user input when useful.
+4) Use await div() for display output when useful.
+5) Keep the script runnable as-is with sensible defaults and light error handling."#;
+
+#[derive(Debug, Clone)]
+pub struct GeneratedScriptOutput {
+    pub path: PathBuf,
+    pub slug: String,
+    pub model_id: String,
+    pub provider_id: String,
+}
+
+pub fn generate_script_from_prompt(
+    prompt: &str,
+    config: Option<&crate::config::Config>,
+) -> Result<GeneratedScriptOutput> {
+    let normalized_prompt = prompt.trim();
+    if normalized_prompt.is_empty() {
+        anyhow::bail!("AI script generation requires a non-empty prompt");
+    }
+
+    let registry = ProviderRegistry::from_environment_with_config(config);
+    if !registry.has_any_provider() {
+        anyhow::bail!(
+            "No AI providers configured. Configure an API key first (Vercel, OpenAI, Anthropic, etc.)."
+        );
+    }
+
+    let (selected_model, provider) = select_generation_model(&registry)?;
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=provider_ready model_id={} provider_id={} prompt_len={}",
+            selected_model.id,
+            selected_model.provider,
+            normalized_prompt.len()
+        ),
+    );
+
+    let messages = vec![
+        ProviderMessage::system(AI_SCRIPT_GENERATION_SYSTEM_PROMPT),
+        ProviderMessage::user(format!(
+            "Generate a Script Kit script for this user request:\n\n{}",
+            normalized_prompt
+        )),
+    ];
+
+    let raw_response = provider
+        .send_message(&messages, &selected_model.id)
+        .with_context(|| {
+            format!(
+                "AI script generation failed (attempted=send_message, model_id={}, provider_id={})",
+                selected_model.id, selected_model.provider
+            )
+        })?;
+
+    let extracted = extract_script_code(&raw_response);
+    if extracted.trim().is_empty() {
+        anyhow::bail!(
+            "AI returned an empty response for script generation (state=empty_response)"
+        );
+    }
+
+    let slug = slugify_script_name(normalized_prompt);
+    let finalized = enforce_script_kit_conventions(&extracted, normalized_prompt, &slug);
+    let path = write_generated_script(&slug, &finalized).with_context(|| {
+        format!(
+            "Failed writing AI-generated script (state=write_failed, slug={})",
+            slug
+        )
+    })?;
+
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=script_written path={} slug={}",
+            path.display(),
+            slug
+        ),
+    );
+
+    Ok(GeneratedScriptOutput {
+        path,
+        slug,
+        model_id: selected_model.id,
+        provider_id: selected_model.provider,
+    })
+}
+
+fn select_generation_model(registry: &ProviderRegistry) -> Result<(ModelInfo, Arc<dyn AiProvider>)> {
+    let models = registry.get_all_models();
+    let selected_model = models
+        .iter()
+        .find(|model| model.provider.eq_ignore_ascii_case("vercel"))
+        .or_else(|| models.first())
+        .cloned()
+        .context("No AI models available in provider registry")?;
+
+    let provider = registry
+        .find_provider_for_model(&selected_model.id)
+        .cloned()
+        .with_context(|| {
+            format!(
+                "No provider found for selected model '{}' (state=provider_missing)",
+                selected_model.id
+            )
+        })?;
+
+    Ok((selected_model, provider))
+}
+
+fn generated_scripts_dir() -> PathBuf {
+    PathBuf::from(shellexpand::tilde(AI_SCRIPT_OUTPUT_DIR).as_ref())
+}
+
+fn split_fence_header_and_body(fence: &str) -> (&str, &str) {
+    match fence.find('\n') {
+        Some(newline_index) => (&fence[..newline_index], &fence[newline_index + 1..]),
+        None => ("", fence),
+    }
+}
+
+fn extract_fenced_code(response: &str, preferred_languages: Option<&[&str]>) -> Option<String> {
+    let mut remaining = response;
+
+    while let Some(start) = remaining.find("```") {
+        let after_start = &remaining[start + 3..];
+        let Some(end) = after_start.find("```") else {
+            break;
+        };
+
+        let fence_contents = &after_start[..end];
+        let (header, body) = split_fence_header_and_body(fence_contents);
+        let language = header
+            .trim()
+            .split(|c: char| c.is_whitespace() || c == '{')
+            .next()
+            .unwrap_or("")
+            .to_ascii_lowercase();
+        let code = body.trim();
+
+        if !code.is_empty() {
+            match preferred_languages {
+                Some(preferred) => {
+                    if preferred.iter().any(|candidate| *candidate == language) {
+                        return Some(code.to_string());
+                    }
+                }
+                None => return Some(code.to_string()),
+            }
+        }
+
+        remaining = &after_start[end + 3..];
+    }
+
+    None
+}
+
+fn extract_script_code(response: &str) -> String {
+    const PREFERRED_LANGUAGES: [&str; 6] = ["typescript", "ts", "javascript", "js", "tsx", "jsx"];
+
+    extract_fenced_code(response, Some(&PREFERRED_LANGUAGES))
+        .or_else(|| extract_fenced_code(response, None))
+        .unwrap_or_else(|| response.trim().to_string())
+}
+
+fn slugify_script_name(prompt: &str) -> String {
+    let mut slug = String::new();
+    let mut last_was_hyphen = false;
+
+    for character in prompt.to_ascii_lowercase().chars() {
+        if character.is_ascii_alphanumeric() {
+            slug.push(character);
+            last_was_hyphen = false;
+        } else if matches!(character, ' ' | '_' | '-') {
+            if !slug.is_empty() && !last_was_hyphen {
+                slug.push('-');
+                last_was_hyphen = true;
+            }
+        }
+    }
+
+    while slug.ends_with('-') {
+        slug.pop();
+    }
+
+    if slug.len() > AI_SCRIPT_MAX_SLUG_LEN {
+        slug.truncate(AI_SCRIPT_MAX_SLUG_LEN);
+        while slug.ends_with('-') {
+            slug.pop();
+        }
+    }
+
+    if slug.is_empty() {
+        AI_SCRIPT_DEFAULT_SLUG.to_string()
+    } else {
+        slug
+    }
+}
+
+fn slug_to_title(slug: &str) -> String {
+    slug.split('-')
+        .filter(|segment| !segment.is_empty())
+        .map(|segment| {
+            let mut chars = segment.chars();
+            match chars.next() {
+                Some(first) => first.to_uppercase().collect::<String>() + chars.as_str(),
+                None => String::new(),
+            }
+        })
+        .collect::<Vec<_>>()
+        .join(" ")
+}
+
+fn description_from_prompt(prompt: &str) -> String {
+    let normalized = prompt.split_whitespace().collect::<Vec<_>>().join(" ");
+    if normalized.is_empty() {
+        return "AI-generated Script Kit script".to_string();
+    }
+
+    let mut shortened = normalized;
+    if shortened.chars().count() > 110 {
+        shortened = format!("{}...", shortened.chars().take(107).collect::<String>());
+    }
+    shortened
+}
+
+fn has_kit_import(script: &str) -> bool {
+    script.contains("import \"@johnlindquist/kit\";")
+        || script.contains("import '@johnlindquist/kit';")
+        || script.contains("import \"@scriptkit/sdk\";")
+        || script.contains("import '@scriptkit/sdk';")
+}
+
+fn enforce_script_kit_conventions(script: &str, prompt: &str, slug: &str) -> String {
+    let mut prefix_lines: Vec<String> = Vec::new();
+    let trimmed_script = script.trim();
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Name:"))
+    {
+        prefix_lines.push(format!("// Name: {}", slug_to_title(slug)));
+    }
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Description:"))
+    {
+        prefix_lines.push(format!("// Description: {}", description_from_prompt(prompt)));
+    }
+
+    if !has_kit_import(trimmed_script) {
+        prefix_lines.push("import \"@johnlindquist/kit\";".to_string());
+    }
+
+    let mut output = String::new();
+    if !prefix_lines.is_empty() {
+        output.push_str(&prefix_lines.join("\n"));
+        output.push_str("\n\n");
+    }
+
+    output.push_str(trimmed_script);
+    if !output.ends_with('\n') {
+        output.push('\n');
+    }
+    output
+}
+
+fn write_generated_script(slug: &str, script_content: &str) -> Result<PathBuf> {
+    write_generated_script_in_dir(&generated_scripts_dir(), slug, script_content)
+}
+
+fn write_generated_script_in_dir(output_dir: &Path, slug: &str, script_content: &str) -> Result<PathBuf> {
+    fs::create_dir_all(output_dir)
+        .with_context(|| format!("Failed to create output dir: {}", output_dir.display()))?;
+
+    for suffix in 0usize.. {
+        let candidate = if suffix == 0 {
+            slug.to_string()
+        } else {
+            format!("{slug}-{suffix}")
+        };
+        let path = output_dir.join(format!("{}.ts", candidate));
+        match OpenOptions::new().write(true).create_new(true).open(&path) {
+            Ok(mut file) => {
+                file.write_all(script_content.as_bytes())
+                    .with_context(|| format!("Failed writing generated script to {}", path.display()))?;
+                return Ok(path);
+            }
+            Err(error) if error.kind() == ErrorKind::AlreadyExists => continue,
+            Err(error) => {
+                return Err(error).with_context(|| {
+                    format!(
+                        "Failed creating generated script file {} (slug={})",
+                        path.display(),
+                        slug
+                    )
+                });
+            }
+        }
+    }
+
+    unreachable!("suffix loop should eventually create a unique script filename")
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+    use tempfile::tempdir;
+
+    #[test]
+    fn test_slugify_script_name_handles_spaces_and_symbols() {
+        assert_eq!(slugify_script_name("Build: API Client!"), "build-api-client");
+        assert_eq!(slugify_script_name("  ___  "), "ai-script");
+    }
+
+    #[test]
+    fn test_extract_script_code_prefers_typescript_fence_when_multiple_blocks_exist() {
+        let response = r#"
+Here's one idea:
+```markdown
+Not code
+```
+```typescript
+await div("hello");
+```
+"#;
+        assert_eq!(extract_script_code(response), "await div(\"hello\");");
+    }
+
+    #[test]
+    fn test_extract_script_code_falls_back_to_first_fenced_block() {
+        let response = r#"
+```python
+print("hello")
+```
+"#;
+        assert_eq!(extract_script_code(response), "print(\"hello\")");
+    }
+
+    #[test]
+    fn test_extract_script_code_returns_trimmed_response_when_no_fence_exists() {
+        let response = "const answer = 42;";
+        assert_eq!(extract_script_code(response), "const answer = 42;");
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_adds_missing_metadata_and_import() {
+        let script = "const name = await arg(\"Name?\");";
+        let output = enforce_script_kit_conventions(script, "Ask for user name", "ask-user-name");
+
+        assert!(output.contains("// Name: Ask User Name"));
+        assert!(output.contains("// Description: Ask for user name"));
+        assert!(output.contains("import \"@johnlindquist/kit\";"));
+        assert!(output.contains("await arg(\"Name?\");"));
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_keeps_existing_metadata_and_import() {
+        let script = r#"// Name: Existing
+// Description: Existing description
+import "@johnlindquist/kit";
+
+await div("ready");
+"#;
+        let output = enforce_script_kit_conventions(script, "ignored", "ignored");
+
+        assert_eq!(
+            output.matches("// Name:").count(),
+            1,
+            "should not duplicate existing Name metadata"
+        );
+        assert_eq!(
+            output.matches("// Description:").count(),
+            1,
+            "should not duplicate existing Description metadata"
+        );
+        assert_eq!(
+            output.matches("import \"@johnlindquist/kit\";").count(),
+            1,
+            "should not duplicate existing import"
+        );
+    }
+
+    #[test]
+    fn test_write_generated_script_in_dir_appends_numeric_suffix_for_collisions() {
+        let temp_dir = tempdir().unwrap();
+        let first = write_generated_script_in_dir(temp_dir.path(), "my-script", "a").unwrap();
+        let second = write_generated_script_in_dir(temp_dir.path(), "my-script", "b").unwrap();
+
+        assert_eq!(first.file_name().unwrap(), "my-script.ts");
+        assert_eq!(second.file_name().unwrap(), "my-script-1.ts");
+    }
+}
diff --git a/src/builtins/part_000.rs b/src/builtins/part_000.rs
index d6b9c2a9b35b40c5005dbb9f65147f528702cb9e..5f6d27d28d72e51126d10d8beccf931c689ef2bb
--- a/src/builtins/part_000.rs
+++ b/src/builtins/part_000.rs
@@ -96,6 +96,8 @@
     OpenAi,
     NewConversation,
     ClearConversation,
+    /// Generate a new Script Kit script from the main prompt text
+    GenerateScript,
     /// Send a screenshot of the entire screen to AI Chat
     SendScreenToAi,
     /// Send a screenshot of the focused window to AI Chat
diff --git a/src/builtins/part_001_entries/entries_002.rs b/src/builtins/part_001_entries/entries_002.rs
index 6d1c9334f0ccaf0aab48582aaf42dcb129e1cb6e..72b318c66aeaf124359f4ecd276dae0350287328
--- a/src/builtins/part_001_entries/entries_002.rs
+++ b/src/builtins/part_001_entries/entries_002.rs
@@ -61,6 +61,17 @@
     ));
 
     entries.push(BuiltInEntry::new_with_icon(
+        "builtin-generate-script-with-ai",
+        "Generate Script with AI",
+        "Generate a Script Kit script from your current prompt text",
+        vec![
+            "generate", "script", "ai", "create", "code", "typescript", "shift", "tab",
+        ],
+        BuiltInFeature::AiCommand(AiCommandType::GenerateScript),
+        "ðŸ§ ",
+    ));
+
+    entries.push(BuiltInEntry::new_with_icon(
         "builtin-send-screen-to-ai",
         "Send Screen to AI Chat",
         "Capture the full screen and send it to AI Chat",


thinking
**Reviewing builtins and test impacts**
exec
/bin/zsh -lc 'rg -n "builtin-open-ai|builtin-new-conversation|builtin-send-screen-to-ai|AI commands|AiCommandType::GenerateScript|builtin-generate-script-with-ai" src/builtins/tests src | head -n 200' in /Users/johnlindquist/dev/script-kit-gpui succeeded in 52ms:
src/builtins/tests/part_000.rs:27:        // Plus: system actions (28), window actions (6), notes commands (3), AI commands (1),
src/builtins/tests/part_000.rs:299:        let open_ai = entries.iter().find(|e| e.id == "builtin-open-ai");
src/builtins/tests/part_000.rs:300:        assert!(open_ai.is_some(), "builtin-open-ai should exist");
src/builtins/part_001_entries/entries_002.rs:46:        "builtin-open-ai",
src/builtins/part_001_entries/entries_002.rs:55:        "builtin-new-conversation",
src/builtins/part_001_entries/entries_002.rs:64:        "builtin-generate-script-with-ai",
src/builtins/part_001_entries/entries_002.rs:70:        BuiltInFeature::AiCommand(AiCommandType::GenerateScript),
src/builtins/part_001_entries/entries_002.rs:75:        "builtin-send-screen-to-ai",
src/builtins/tests/part_000.rs:27:        // Plus: system actions (28), window actions (6), notes commands (3), AI commands (1),
src/builtins/tests/part_000.rs:299:        let open_ai = entries.iter().find(|e| e.id == "builtin-open-ai");
src/builtins/tests/part_000.rs:300:        assert!(open_ai.is_some(), "builtin-open-ai should exist");
src/app_impl/execution_scripts.rs:5:    "builtin-open-ai",
src/app_impl/execution_scripts.rs:11:    "builtin-new-conversation",
src/app_impl/execution_scripts.rs:24:        assert!(!builtin_needs_main_window_for_command_id("builtin-open-ai"));
src/ai/window/window_api.rs:373:/// Used by AI commands like "Send Screen to AI Chat".
src/app_execute/builtin_execution.rs:547:                // All AI commands: reset state, hide main window
src/app_execute/builtin_execution/feature_02.rs:39:                // All AI commands: reset state, hide main window
file update:
diff --git a/src/ai/mod.rs b/src/ai/mod.rs
index a420b1a5faf59506acdb7caf60681c153a3f9bb6..9a73e9491862633b325b2c52b51a3e20395ff85c
--- a/src/ai/mod.rs
+++ b/src/ai/mod.rs
@@ -37,6 +37,7 @@
 pub(crate) mod providers;
 pub(crate) mod sdk_handlers;
 pub(crate) mod session;
+pub(crate) mod script_generation;
 pub(crate) mod storage;
 pub(crate) mod window;
 
@@ -44,6 +45,7 @@
 pub use self::config::{DetectedKeys, ModelInfo, ProviderConfig};
 pub use self::model::{Chat, ChatId, ChatSource, Message, MessageRole};
 pub use self::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+pub use self::script_generation::{generate_script_from_prompt, GeneratedScriptOutput};
 pub use self::sdk_handlers::try_handle_ai_message;
 pub use self::storage::{
     clear_all_chats, create_chat, delete_chat, get_all_chats, get_chat, get_chat_messages,
diff --git a/src/ai/script_generation.rs b/src/ai/script_generation.rs
new file mode 100644
index 0000000000000000000000000000000000000000..7f2ec8e7576ed50cd10f7aea31a6522875ef667a
--- /dev/null
+++ b/src/ai/script_generation.rs
@@ -0,0 +1,417 @@
+use anyhow::{Context, Result};
+use std::fs::{self, OpenOptions};
+use std::io::{ErrorKind, Write};
+use std::path::{Path, PathBuf};
+use std::sync::Arc;
+
+use super::config::ModelInfo;
+use super::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+
+const AI_SCRIPT_OUTPUT_DIR: &str = "~/.kenv/scripts";
+const AI_SCRIPT_DEFAULT_SLUG: &str = "ai-script";
+const AI_SCRIPT_MAX_SLUG_LEN: usize = 64;
+
+const AI_SCRIPT_GENERATION_SYSTEM_PROMPT: &str = r#"You write production-ready Script Kit scripts.
+
+Return ONLY TypeScript source code for one Script Kit script. Do not include explanations.
+
+Required output conventions:
+1) Include metadata comments at the top:
+   // Name: <clear title>
+   // Description: <one-line summary>
+2) Include: import "@johnlindquist/kit";
+3) Use await arg() for user input when useful.
+4) Use await div() for display output when useful.
+5) Keep the script runnable as-is with sensible defaults and light error handling."#;
+
+#[derive(Debug, Clone)]
+pub struct GeneratedScriptOutput {
+    pub path: PathBuf,
+    pub slug: String,
+    pub model_id: String,
+    pub provider_id: String,
+}
+
+pub fn generate_script_from_prompt(
+    prompt: &str,
+    config: Option<&crate::config::Config>,
+) -> Result<GeneratedScriptOutput> {
+    let normalized_prompt = prompt.trim();
+    if normalized_prompt.is_empty() {
+        anyhow::bail!("AI script generation requires a non-empty prompt");
+    }
+
+    let registry = ProviderRegistry::from_environment_with_config(config);
+    if !registry.has_any_provider() {
+        anyhow::bail!(
+            "No AI providers configured. Configure an API key first (Vercel, OpenAI, Anthropic, etc.)."
+        );
+    }
+
+    let (selected_model, provider) = select_generation_model(&registry)?;
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=provider_ready model_id={} provider_id={} prompt_len={}",
+            selected_model.id,
+            selected_model.provider,
+            normalized_prompt.len()
+        ),
+    );
+
+    let messages = vec![
+        ProviderMessage::system(AI_SCRIPT_GENERATION_SYSTEM_PROMPT),
+        ProviderMessage::user(format!(
+            "Generate a Script Kit script for this user request:\n\n{}",
+            normalized_prompt
+        )),
+    ];
+
+    let raw_response = provider
+        .send_message(&messages, &selected_model.id)
+        .with_context(|| {
+            format!(
+                "AI script generation failed (attempted=send_message, model_id={}, provider_id={})",
+                selected_model.id, selected_model.provider
+            )
+        })?;
+
+    let extracted = extract_script_code(&raw_response);
+    if extracted.trim().is_empty() {
+        anyhow::bail!(
+            "AI returned an empty response for script generation (state=empty_response)"
+        );
+    }
+
+    let slug = slugify_script_name(normalized_prompt);
+    let finalized = enforce_script_kit_conventions(&extracted, normalized_prompt, &slug);
+    let path = write_generated_script(&slug, &finalized).with_context(|| {
+        format!(
+            "Failed writing AI-generated script (state=write_failed, slug={})",
+            slug
+        )
+    })?;
+
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=script_written path={} slug={}",
+            path.display(),
+            slug
+        ),
+    );
+
+    Ok(GeneratedScriptOutput {
+        path,
+        slug,
+        model_id: selected_model.id,
+        provider_id: selected_model.provider,
+    })
+}
+
+fn select_generation_model(registry: &ProviderRegistry) -> Result<(ModelInfo, Arc<dyn AiProvider>)> {
+    let models = registry.get_all_models();
+    let selected_model = models
+        .iter()
+        .find(|model| model.provider.eq_ignore_ascii_case("vercel"))
+        .or_else(|| models.first())
+        .cloned()
+        .context("No AI models available in provider registry")?;
+
+    let provider = registry
+        .find_provider_for_model(&selected_model.id)
+        .cloned()
+        .with_context(|| {
+            format!(
+                "No provider found for selected model '{}' (state=provider_missing)",
+                selected_model.id
+            )
+        })?;
+
+    Ok((selected_model, provider))
+}
+
+fn generated_scripts_dir() -> PathBuf {
+    PathBuf::from(shellexpand::tilde(AI_SCRIPT_OUTPUT_DIR).as_ref())
+}
+
+fn split_fence_header_and_body(fence: &str) -> (&str, &str) {
+    match fence.find('\n') {
+        Some(newline_index) => (&fence[..newline_index], &fence[newline_index + 1..]),
+        None => ("", fence),
+    }
+}
+
+fn extract_fenced_code(response: &str, preferred_languages: Option<&[&str]>) -> Option<String> {
+    let mut remaining = response;
+
+    while let Some(start) = remaining.find("```") {
+        let after_start = &remaining[start + 3..];
+        let Some(end) = after_start.find("```") else {
+            break;
+        };
+
+        let fence_contents = &after_start[..end];
+        let (header, body) = split_fence_header_and_body(fence_contents);
+        let language = header
+            .trim()
+            .split(|c: char| c.is_whitespace() || c == '{')
+            .next()
+            .unwrap_or("")
+            .to_ascii_lowercase();
+        let code = body.trim();
+
+        if !code.is_empty() {
+            match preferred_languages {
+                Some(preferred) => {
+                    if preferred.iter().any(|candidate| *candidate == language) {
+                        return Some(code.to_string());
+                    }
+                }
+                None => return Some(code.to_string()),
+            }
+        }
+
+        remaining = &after_start[end + 3..];
+    }
+
+    None
+}
+
+fn extract_script_code(response: &str) -> String {
+    const PREFERRED_LANGUAGES: [&str; 6] = ["typescript", "ts", "javascript", "js", "tsx", "jsx"];
+
+    extract_fenced_code(response, Some(&PREFERRED_LANGUAGES))
+        .or_else(|| extract_fenced_code(response, None))
+        .unwrap_or_else(|| response.trim().to_string())
+}
+
+fn slugify_script_name(prompt: &str) -> String {
+    let mut slug = String::new();
+    let mut last_was_hyphen = false;
+
+    for character in prompt.to_ascii_lowercase().chars() {
+        if character.is_ascii_alphanumeric() {
+            slug.push(character);
+            last_was_hyphen = false;
+        } else if matches!(character, ' ' | '_' | '-') {
+            if !slug.is_empty() && !last_was_hyphen {
+                slug.push('-');
+                last_was_hyphen = true;
+            }
+        }
+    }
+
+    while slug.ends_with('-') {
+        slug.pop();
+    }
+
+    if slug.len() > AI_SCRIPT_MAX_SLUG_LEN {
+        slug.truncate(AI_SCRIPT_MAX_SLUG_LEN);
+        while slug.ends_with('-') {
+            slug.pop();
+        }
+    }
+
+    if slug.is_empty() {
+        AI_SCRIPT_DEFAULT_SLUG.to_string()
+    } else {
+        slug
+    }
+}
+
+fn slug_to_title(slug: &str) -> String {
+    slug.split('-')
+        .filter(|segment| !segment.is_empty())
+        .map(|segment| {
+            let mut chars = segment.chars();
+            match chars.next() {
+                Some(first) => first.to_uppercase().collect::<String>() + chars.as_str(),
+                None => String::new(),
+            }
+        })
+        .collect::<Vec<_>>()
+        .join(" ")
+}
+
+fn description_from_prompt(prompt: &str) -> String {
+    let normalized = prompt.split_whitespace().collect::<Vec<_>>().join(" ");
+    if normalized.is_empty() {
+        return "AI-generated Script Kit script".to_string();
+    }
+
+    let mut shortened = normalized;
+    if shortened.chars().count() > 110 {
+        shortened = format!("{}...", shortened.chars().take(107).collect::<String>());
+    }
+    shortened
+}
+
+fn has_kit_import(script: &str) -> bool {
+    script.contains("import \"@johnlindquist/kit\";")
+        || script.contains("import '@johnlindquist/kit';")
+        || script.contains("import \"@scriptkit/sdk\";")
+        || script.contains("import '@scriptkit/sdk';")
+}
+
+fn enforce_script_kit_conventions(script: &str, prompt: &str, slug: &str) -> String {
+    let mut prefix_lines: Vec<String> = Vec::new();
+    let trimmed_script = script.trim();
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Name:"))
+    {
+        prefix_lines.push(format!("// Name: {}", slug_to_title(slug)));
+    }
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Description:"))
+    {
+        prefix_lines.push(format!("// Description: {}", description_from_prompt(prompt)));
+    }
+
+    if !has_kit_import(trimmed_script) {
+        prefix_lines.push("import \"@johnlindquist/kit\";".to_string());
+    }
+
+    let mut output = String::new();
+    if !prefix_lines.is_empty() {
+        output.push_str(&prefix_lines.join("\n"));
+        output.push_str("\n\n");
+    }
+
+    output.push_str(trimmed_script);
+    if !output.ends_with('\n') {
+        output.push('\n');
+    }
+    output
+}
+
+fn write_generated_script(slug: &str, script_content: &str) -> Result<PathBuf> {
+    write_generated_script_in_dir(&generated_scripts_dir(), slug, script_content)
+}
+
+fn write_generated_script_in_dir(output_dir: &Path, slug: &str, script_content: &str) -> Result<PathBuf> {
+    fs::create_dir_all(output_dir)
+        .with_context(|| format!("Failed to create output dir: {}", output_dir.display()))?;
+
+    for suffix in 0usize.. {
+        let candidate = if suffix == 0 {
+            slug.to_string()
+        } else {
+            format!("{slug}-{suffix}")
+        };
+        let path = output_dir.join(format!("{}.ts", candidate));
+        match OpenOptions::new().write(true).create_new(true).open(&path) {
+            Ok(mut file) => {
+                file.write_all(script_content.as_bytes())
+                    .with_context(|| format!("Failed writing generated script to {}", path.display()))?;
+                return Ok(path);
+            }
+            Err(error) if error.kind() == ErrorKind::AlreadyExists => continue,
+            Err(error) => {
+                return Err(error).with_context(|| {
+                    format!(
+                        "Failed creating generated script file {} (slug={})",
+                        path.display(),
+                        slug
+                    )
+                });
+            }
+        }
+    }
+
+    unreachable!("suffix loop should eventually create a unique script filename")
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+    use tempfile::tempdir;
+
+    #[test]
+    fn test_slugify_script_name_handles_spaces_and_symbols() {
+        assert_eq!(slugify_script_name("Build: API Client!"), "build-api-client");
+        assert_eq!(slugify_script_name("  ___  "), "ai-script");
+    }
+
+    #[test]
+    fn test_extract_script_code_prefers_typescript_fence_when_multiple_blocks_exist() {
+        let response = r#"
+Here's one idea:
+```markdown
+Not code
+```
+```typescript
+await div("hello");
+```
+"#;
+        assert_eq!(extract_script_code(response), "await div(\"hello\");");
+    }
+
+    #[test]
+    fn test_extract_script_code_falls_back_to_first_fenced_block() {
+        let response = r#"
+```python
+print("hello")
+```
+"#;
+        assert_eq!(extract_script_code(response), "print(\"hello\")");
+    }
+
+    #[test]
+    fn test_extract_script_code_returns_trimmed_response_when_no_fence_exists() {
+        let response = "const answer = 42;";
+        assert_eq!(extract_script_code(response), "const answer = 42;");
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_adds_missing_metadata_and_import() {
+        let script = "const name = await arg(\"Name?\");";
+        let output = enforce_script_kit_conventions(script, "Ask for user name", "ask-user-name");
+
+        assert!(output.contains("// Name: Ask User Name"));
+        assert!(output.contains("// Description: Ask for user name"));
+        assert!(output.contains("import \"@johnlindquist/kit\";"));
+        assert!(output.contains("await arg(\"Name?\");"));
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_keeps_existing_metadata_and_import() {
+        let script = r#"// Name: Existing
+// Description: Existing description
+import "@johnlindquist/kit";
+
+await div("ready");
+"#;
+        let output = enforce_script_kit_conventions(script, "ignored", "ignored");
+
+        assert_eq!(
+            output.matches("// Name:").count(),
+            1,
+            "should not duplicate existing Name metadata"
+        );
+        assert_eq!(
+            output.matches("// Description:").count(),
+            1,
+            "should not duplicate existing Description metadata"
+        );
+        assert_eq!(
+            output.matches("import \"@johnlindquist/kit\";").count(),
+            1,
+            "should not duplicate existing import"
+        );
+    }
+
+    #[test]
+    fn test_write_generated_script_in_dir_appends_numeric_suffix_for_collisions() {
+        let temp_dir = tempdir().unwrap();
+        let first = write_generated_script_in_dir(temp_dir.path(), "my-script", "a").unwrap();
+        let second = write_generated_script_in_dir(temp_dir.path(), "my-script", "b").unwrap();
+
+        assert_eq!(first.file_name().unwrap(), "my-script.ts");
+        assert_eq!(second.file_name().unwrap(), "my-script-1.ts");
+    }
+}
diff --git a/src/builtins/part_000.rs b/src/builtins/part_000.rs
index d6b9c2a9b35b40c5005dbb9f65147f528702cb9e..5f6d27d28d72e51126d10d8beccf931c689ef2bb
--- a/src/builtins/part_000.rs
+++ b/src/builtins/part_000.rs
@@ -96,6 +96,8 @@
     OpenAi,
     NewConversation,
     ClearConversation,
+    /// Generate a new Script Kit script from the main prompt text
+    GenerateScript,
     /// Send a screenshot of the entire screen to AI Chat
     SendScreenToAi,
     /// Send a screenshot of the focused window to AI Chat
diff --git a/src/builtins/part_001_entries/entries_002.rs b/src/builtins/part_001_entries/entries_002.rs
index 6d1c9334f0ccaf0aab48582aaf42dcb129e1cb6e..72b318c66aeaf124359f4ecd276dae0350287328
--- a/src/builtins/part_001_entries/entries_002.rs
+++ b/src/builtins/part_001_entries/entries_002.rs
@@ -61,6 +61,17 @@
     ));
 
     entries.push(BuiltInEntry::new_with_icon(
+        "builtin-generate-script-with-ai",
+        "Generate Script with AI",
+        "Generate a Script Kit script from your current prompt text",
+        vec![
+            "generate", "script", "ai", "create", "code", "typescript", "shift", "tab",
+        ],
+        BuiltInFeature::AiCommand(AiCommandType::GenerateScript),
+        "ðŸ§ ",
+    ));
+
+    entries.push(BuiltInEntry::new_with_icon(
         "builtin-send-screen-to-ai",
         "Send Screen to AI Chat",
         "Capture the full screen and send it to AI Chat",


thinking
**Planning AI command tests**
exec
/bin/zsh -lc "sed -n '240,380p' src/builtins/tests/part_000.rs" in /Users/johnlindquist/dev/script-kit-gpui succeeded in 51ms:
        assert_eq!(entry.name, cloned.name);
        assert_eq!(entry.description, cloned.description);
        assert_eq!(entry.keywords, cloned.keywords);
        assert_eq!(entry.feature, cloned.feature);
        assert_eq!(entry.icon, cloned.icon);
    }
    #[test]
    fn test_builtin_config_clone() {
        let config = BuiltInConfig {
            clipboard_history: true,
            app_launcher: false,
            window_switcher: true,
        };

        let cloned = config.clone();
        assert_eq!(config.clipboard_history, cloned.clipboard_history);
        assert_eq!(config.app_launcher, cloned.app_launcher);
        assert_eq!(config.window_switcher, cloned.window_switcher);
    }
    #[test]
file update:
diff --git a/src/ai/mod.rs b/src/ai/mod.rs
index a420b1a5faf59506acdb7caf60681c153a3f9bb6..9a73e9491862633b325b2c52b51a3e20395ff85c
--- a/src/ai/mod.rs
+++ b/src/ai/mod.rs
@@ -37,6 +37,7 @@
 pub(crate) mod providers;
 pub(crate) mod sdk_handlers;
 pub(crate) mod session;
+pub(crate) mod script_generation;
 pub(crate) mod storage;
 pub(crate) mod window;
 
@@ -44,6 +45,7 @@
 pub use self::config::{DetectedKeys, ModelInfo, ProviderConfig};
 pub use self::model::{Chat, ChatId, ChatSource, Message, MessageRole};
 pub use self::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+pub use self::script_generation::{generate_script_from_prompt, GeneratedScriptOutput};
 pub use self::sdk_handlers::try_handle_ai_message;
 pub use self::storage::{
     clear_all_chats, create_chat, delete_chat, get_all_chats, get_chat, get_chat_messages,
diff --git a/src/ai/script_generation.rs b/src/ai/script_generation.rs
new file mode 100644
index 0000000000000000000000000000000000000000..7f2ec8e7576ed50cd10f7aea31a6522875ef667a
--- /dev/null
+++ b/src/ai/script_generation.rs
@@ -0,0 +1,417 @@
+use anyhow::{Context, Result};
+use std::fs::{self, OpenOptions};
+use std::io::{ErrorKind, Write};
+use std::path::{Path, PathBuf};
+use std::sync::Arc;
+
+use super::config::ModelInfo;
+use super::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+
+const AI_SCRIPT_OUTPUT_DIR: &str = "~/.kenv/scripts";
+const AI_SCRIPT_DEFAULT_SLUG: &str = "ai-script";
+const AI_SCRIPT_MAX_SLUG_LEN: usize = 64;
+
+const AI_SCRIPT_GENERATION_SYSTEM_PROMPT: &str = r#"You write production-ready Script Kit scripts.
+
+Return ONLY TypeScript source code for one Script Kit script. Do not include explanations.
+
+Required output conventions:
+1) Include metadata comments at the top:
+   // Name: <clear title>
+   // Description: <one-line summary>
+2) Include: import "@johnlindquist/kit";
+3) Use await arg() for user input when useful.
+4) Use await div() for display output when useful.
+5) Keep the script runnable as-is with sensible defaults and light error handling."#;
+
+#[derive(Debug, Clone)]
+pub struct GeneratedScriptOutput {
+    pub path: PathBuf,
+    pub slug: String,
+    pub model_id: String,
+    pub provider_id: String,
+}
+
+pub fn generate_script_from_prompt(
+    prompt: &str,
+    config: Option<&crate::config::Config>,
+) -> Result<GeneratedScriptOutput> {
+    let normalized_prompt = prompt.trim();
+    if normalized_prompt.is_empty() {
+        anyhow::bail!("AI script generation requires a non-empty prompt");
+    }
+
+    let registry = ProviderRegistry::from_environment_with_config(config);
+    if !registry.has_any_provider() {
+        anyhow::bail!(
+            "No AI providers configured. Configure an API key first (Vercel, OpenAI, Anthropic, etc.)."
+        );
+    }
+
+    let (selected_model, provider) = select_generation_model(&registry)?;
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=provider_ready model_id={} provider_id={} prompt_len={}",
+            selected_model.id,
+            selected_model.provider,
+            normalized_prompt.len()
+        ),
+    );
+
+    let messages = vec![
+        ProviderMessage::system(AI_SCRIPT_GENERATION_SYSTEM_PROMPT),
+        ProviderMessage::user(format!(
+            "Generate a Script Kit script for this user request:\n\n{}",
+            normalized_prompt
+        )),
+    ];
+
+    let raw_response = provider
+        .send_message(&messages, &selected_model.id)
+        .with_context(|| {
+            format!(
+                "AI script generation failed (attempted=send_message, model_id={}, provider_id={})",
+                selected_model.id, selected_model.provider
+            )
+        })?;
+
+    let extracted = extract_script_code(&raw_response);
+    if extracted.trim().is_empty() {
+        anyhow::bail!(
+            "AI returned an empty response for script generation (state=empty_response)"
+        );
+    }
+
+    let slug = slugify_script_name(normalized_prompt);
+    let finalized = enforce_script_kit_conventions(&extracted, normalized_prompt, &slug);
+    let path = write_generated_script(&slug, &finalized).with_context(|| {
+        format!(
+            "Failed writing AI-generated script (state=write_failed, slug={})",
+            slug
+        )
+    })?;
+
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=script_written path={} slug={}",
+            path.display(),
+            slug
+        ),
+    );
+
+    Ok(GeneratedScriptOutput {
+        path,
+        slug,
+        model_id: selected_model.id,
+        provider_id: selected_model.provider,
+    })
+}
+
+fn select_generation_model(registry: &ProviderRegistry) -> Result<(ModelInfo, Arc<dyn AiProvider>)> {
+    let models = registry.get_all_models();
+    let selected_model = models
+        .iter()
+        .find(|model| model.provider.eq_ignore_ascii_case("vercel"))
+        .or_else(|| models.first())
+        .cloned()
+        .context("No AI models available in provider registry")?;
+
+    let provider = registry
+        .find_provider_for_model(&selected_model.id)
+        .cloned()
+        .with_context(|| {
+            format!(
+                "No provider found for selected model '{}' (state=provider_missing)",
+                selected_model.id
+            )
+        })?;
+
+    Ok((selected_model, provider))
+}
+
+fn generated_scripts_dir() -> PathBuf {
+    PathBuf::from(shellexpand::tilde(AI_SCRIPT_OUTPUT_DIR).as_ref())
+}
+
+fn split_fence_header_and_body(fence: &str) -> (&str, &str) {
+    match fence.find('\n') {
+        Some(newline_index) => (&fence[..newline_index], &fence[newline_index + 1..]),
+        None => ("", fence),
+    }
+}
+
+fn extract_fenced_code(response: &str, preferred_languages: Option<&[&str]>) -> Option<String> {
+    let mut remaining = response;
+
+    while let Some(start) = remaining.find("```") {
+        let after_start = &remaining[start + 3..];
+        let Some(end) = after_start.find("```") else {
+            break;
+        };
+
+        let fence_contents = &after_start[..end];
+        let (header, body) = split_fence_header_and_body(fence_contents);
+        let language = header
+            .trim()
+            .split(|c: char| c.is_whitespace() || c == '{')
+            .next()
+            .unwrap_or("")
+            .to_ascii_lowercase();
+        let code = body.trim();
+
+        if !code.is_empty() {
+            match preferred_languages {
+                Some(preferred) => {
+                    if preferred.iter().any(|candidate| *candidate == language) {
+                        return Some(code.to_string());
+                    }
+                }
+                None => return Some(code.to_string()),
+            }
+        }
+
+        remaining = &after_start[end + 3..];
+    }
+
+    None
+}
+
+fn extract_script_code(response: &str) -> String {
+    const PREFERRED_LANGUAGES: [&str; 6] = ["typescript", "ts", "javascript", "js", "tsx", "jsx"];
+
+    extract_fenced_code(response, Some(&PREFERRED_LANGUAGES))
+        .or_else(|| extract_fenced_code(response, None))
+        .unwrap_or_else(|| response.trim().to_string())
+}
+
+fn slugify_script_name(prompt: &str) -> String {
+    let mut slug = String::new();
+    let mut last_was_hyphen = false;
+
+    for character in prompt.to_ascii_lowercase().chars() {
+        if character.is_ascii_alphanumeric() {
+            slug.push(character);
+            last_was_hyphen = false;
+        } else if matches!(character, ' ' | '_' | '-') {
+            if !slug.is_empty() && !last_was_hyphen {
+                slug.push('-');
+                last_was_hyphen = true;
+            }
+        }
+    }
+
+    while slug.ends_with('-') {
+        slug.pop();
+    }
+
+    if slug.len() > AI_SCRIPT_MAX_SLUG_LEN {
+        slug.truncate(AI_SCRIPT_MAX_SLUG_LEN);
+        while slug.ends_with('-') {
+            slug.pop();
+        }
+    }
+
+    if slug.is_empty() {
+        AI_SCRIPT_DEFAULT_SLUG.to_string()
+    } else {
+        slug
+    }
+}
+
+fn slug_to_title(slug: &str) -> String {
+    slug.split('-')
+        .filter(|segment| !segment.is_empty())
+        .map(|segment| {
+            let mut chars = segment.chars();
+            match chars.next() {
+                Some(first) => first.to_uppercase().collect::<String>() + chars.as_str(),
+                None => String::new(),
+            }
+        })
+        .collect::<Vec<_>>()
+        .join(" ")
+}
+
+fn description_from_prompt(prompt: &str) -> String {
+    let normalized = prompt.split_whitespace().collect::<Vec<_>>().join(" ");
+    if normalized.is_empty() {
+        return "AI-generated Script Kit script".to_string();
+    }
+
+    let mut shortened = normalized;
+    if shortened.chars().count() > 110 {
+        shortened = format!("{}...", shortened.chars().take(107).collect::<String>());
+    }
+    shortened
+}
+
+fn has_kit_import(script: &str) -> bool {
+    script.contains("import \"@johnlindquist/kit\";")
+        || script.contains("import '@johnlindquist/kit';")
+        || script.contains("import \"@scriptkit/sdk\";")
+        || script.contains("import '@scriptkit/sdk';")
+}
+
+fn enforce_script_kit_conventions(script: &str, prompt: &str, slug: &str) -> String {
+    let mut prefix_lines: Vec<String> = Vec::new();
+    let trimmed_script = script.trim();
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Name:"))
+    {
+        prefix_lines.push(format!("// Name: {}", slug_to_title(slug)));
+    }
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Description:"))
+    {
+        prefix_lines.push(format!("// Description: {}", description_from_prompt(prompt)));
+    }
+
+    if !has_kit_import(trimmed_script) {
+        prefix_lines.push("import \"@johnlindquist/kit\";".to_string());
+    }
+
+    let mut output = String::new();
+    if !prefix_lines.is_empty() {
+        output.push_str(&prefix_lines.join("\n"));
+        output.push_str("\n\n");
+    }
+
+    output.push_str(trimmed_script);
+    if !output.ends_with('\n') {
+        output.push('\n');
+    }
+    output
+}
+
+fn write_generated_script(slug: &str, script_content: &str) -> Result<PathBuf> {
+    write_generated_script_in_dir(&generated_scripts_dir(), slug, script_content)
+}
+
+fn write_generated_script_in_dir(output_dir: &Path, slug: &str, script_content: &str) -> Result<PathBuf> {
+    fs::create_dir_all(output_dir)
+        .with_context(|| format!("Failed to create output dir: {}", output_dir.display()))?;
+
+    for suffix in 0usize.. {
+        let candidate = if suffix == 0 {
+            slug.to_string()
+        } else {
+            format!("{slug}-{suffix}")
+        };
+        let path = output_dir.join(format!("{}.ts", candidate));
+        match OpenOptions::new().write(true).create_new(true).open(&path) {
+            Ok(mut file) => {
+                file.write_all(script_content.as_bytes())
+                    .with_context(|| format!("Failed writing generated script to {}", path.display()))?;
+                return Ok(path);
+            }
+            Err(error) if error.kind() == ErrorKind::AlreadyExists => continue,
+            Err(error) => {
+                return Err(error).with_context(|| {
+                    format!(
+                        "Failed creating generated script file {} (slug={})",
+                        path.display(),
+                        slug
+                    )
+                });
+            }
+        }
+    }
+
+    unreachable!("suffix loop should eventually create a unique script filename")
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+    use tempfile::tempdir;
+
+    #[test]
+    fn test_slugify_script_name_handles_spaces_and_symbols() {
+        assert_eq!(slugify_script_name("Build: API Client!"), "build-api-client");
+        assert_eq!(slugify_script_name("  ___  "), "ai-script");
+    }
+
+    #[test]
+    fn test_extract_script_code_prefers_typescript_fence_when_multiple_blocks_exist() {
+        let response = r#"
+Here's one idea:
+```markdown
+Not code
+```
+```typescript
+await div("hello");
+```
+"#;
+        assert_eq!(extract_script_code(response), "await div(\"hello\");");
+    }
+
+    #[test]
+    fn test_extract_script_code_falls_back_to_first_fenced_block() {
+        let response = r#"
+```python
+print("hello")
+```
+"#;
+        assert_eq!(extract_script_code(response), "print(\"hello\")");
+    }
+
+    #[test]
+    fn test_extract_script_code_returns_trimmed_response_when_no_fence_exists() {
+        let response = "const answer = 42;";
+        assert_eq!(extract_script_code(response), "const answer = 42;");
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_adds_missing_metadata_and_import() {
+        let script = "const name = await arg(\"Name?\");";
+        let output = enforce_script_kit_conventions(script, "Ask for user name", "ask-user-name");
+
+        assert!(output.contains("// Name: Ask User Name"));
+        assert!(output.contains("// Description: Ask for user name"));
+        assert!(output.contains("import \"@johnlindquist/kit\";"));
+        assert!(output.contains("await arg(\"Name?\");"));
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_keeps_existing_metadata_and_import() {
+        let script = r#"// Name: Existing
+// Description: Existing description
+import "@johnlindquist/kit";
+
+await div("ready");
+"#;
+        let output = enforce_script_kit_conventions(script, "ignored", "ignored");
+
+        assert_eq!(
+            output.matches("// Name:").count(),
+            1,
+            "should not duplicate existing Name metadata"
+        );
+        assert_eq!(
+            output.matches("// Description:").count(),
+            1,
+            "should not duplicate existing Description metadata"
+        );
+        assert_eq!(
+            output.matches("import \"@johnlindquist/kit\";").count(),
+            1,
+            "should not duplicate existing import"
+        );
+    }
+
+    #[test]
+    fn test_write_generated_script_in_dir_appends_numeric_suffix_for_collisions() {
+        let temp_dir = tempdir().unwrap();
+        let first = write_generated_script_in_dir(temp_dir.path(), "my-script", "a").unwrap();
+        let second = write_generated_script_in_dir(temp_dir.path(), "my-script", "b").unwrap();
+
+        assert_eq!(first.file_name().unwrap(), "my-script.ts");
+        assert_eq!(second.file_name().unwrap(), "my-script-1.ts");
+    }
+}
diff --git a/src/builtins/part_000.rs b/src/builtins/part_000.rs
index d6b9c2a9b35b40c5005dbb9f65147f528702cb9e..5f6d27d28d72e51126d10d8beccf931c689ef2bb
--- a/src/builtins/part_000.rs
+++ b/src/builtins/part_000.rs
@@ -96,6 +96,8 @@
     OpenAi,
     NewConversation,
     ClearConversation,
+    /// Generate a new Script Kit script from the main prompt text
+    GenerateScript,
     /// Send a screenshot of the entire screen to AI Chat
     SendScreenToAi,
     /// Send a screenshot of the focused window to AI Chat
diff --git a/src/builtins/part_001_entries/entries_002.rs b/src/builtins/part_001_entries/entries_002.rs
index 6d1c9334f0ccaf0aab48582aaf42dcb129e1cb6e..72b318c66aeaf124359f4ecd276dae0350287328
--- a/src/builtins/part_001_entries/entries_002.rs
+++ b/src/builtins/part_001_entries/entries_002.rs
@@ -61,6 +61,17 @@
     ));
 
     entries.push(BuiltInEntry::new_with_icon(
+        "builtin-generate-script-with-ai",
+        "Generate Script with AI",
+        "Generate a Script Kit script from your current prompt text",
+        vec![
+            "generate", "script", "ai", "create", "code", "typescript", "shift", "tab",
+        ],
+        BuiltInFeature::AiCommand(AiCommandType::GenerateScript),
+        "ðŸ§ ",
+    ));
+
+    entries.push(BuiltInEntry::new_with_icon(
         "builtin-send-screen-to-ai",
         "Send Screen to AI Chat",
         "Capture the full screen and send it to AI Chat",


thinking
**Assessing builtin-generate-script test scope**
exec
/bin/zsh -lc "sed -n '1,120p' src/app_impl/execution_scripts.rs" in /Users/johnlindquist/dev/script-kit-gpui succeeded in 52ms:
use super::*;

const NO_MAIN_WINDOW_BUILTINS: &[&str] = &[
    "builtin-ai-chat",
    "builtin-open-ai",
    "builtin-notes",
    "builtin-open-notes",
    "builtin-new-note",
    "builtin-search-notes",
    "builtin-quick-capture",
    "builtin-new-conversation",
];

fn builtin_needs_main_window_for_command_id(identifier: &str) -> bool {
    !NO_MAIN_WINDOW_BUILTINS.contains(&identifier)
}

#[cfg(test)]
mod builtin_command_window_visibility_tests {
    use super::builtin_needs_main_window_for_command_id;
file update:
diff --git a/src/ai/mod.rs b/src/ai/mod.rs
index a420b1a5faf59506acdb7caf60681c153a3f9bb6..9a73e9491862633b325b2c52b51a3e20395ff85c
--- a/src/ai/mod.rs
+++ b/src/ai/mod.rs
@@ -37,6 +37,7 @@
 pub(crate) mod providers;
 pub(crate) mod sdk_handlers;
 pub(crate) mod session;
+pub(crate) mod script_generation;
 pub(crate) mod storage;
 pub(crate) mod window;
 
@@ -44,6 +45,7 @@
 pub use self::config::{DetectedKeys, ModelInfo, ProviderConfig};
 pub use self::model::{Chat, ChatId, ChatSource, Message, MessageRole};
 pub use self::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+pub use self::script_generation::{generate_script_from_prompt, GeneratedScriptOutput};
 pub use self::sdk_handlers::try_handle_ai_message;
 pub use self::storage::{
     clear_all_chats, create_chat, delete_chat, get_all_chats, get_chat, get_chat_messages,
diff --git a/src/ai/script_generation.rs b/src/ai/script_generation.rs
new file mode 100644
index 0000000000000000000000000000000000000000..7f2ec8e7576ed50cd10f7aea31a6522875ef667a
--- /dev/null
+++ b/src/ai/script_generation.rs
@@ -0,0 +1,417 @@
+use anyhow::{Context, Result};
+use std::fs::{self, OpenOptions};
+use std::io::{ErrorKind, Write};
+use std::path::{Path, PathBuf};
+use std::sync::Arc;
+
+use super::config::ModelInfo;
+use super::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+
+const AI_SCRIPT_OUTPUT_DIR: &str = "~/.kenv/scripts";
+const AI_SCRIPT_DEFAULT_SLUG: &str = "ai-script";
+const AI_SCRIPT_MAX_SLUG_LEN: usize = 64;
+
+const AI_SCRIPT_GENERATION_SYSTEM_PROMPT: &str = r#"You write production-ready Script Kit scripts.
+
+Return ONLY TypeScript source code for one Script Kit script. Do not include explanations.
+
+Required output conventions:
+1) Include metadata comments at the top:
+   // Name: <clear title>
+   // Description: <one-line summary>
+2) Include: import "@johnlindquist/kit";
+3) Use await arg() for user input when useful.
+4) Use await div() for display output when useful.
+5) Keep the script runnable as-is with sensible defaults and light error handling."#;
+
+#[derive(Debug, Clone)]
+pub struct GeneratedScriptOutput {
+    pub path: PathBuf,
+    pub slug: String,
+    pub model_id: String,
+    pub provider_id: String,
+}
+
+pub fn generate_script_from_prompt(
+    prompt: &str,
+    config: Option<&crate::config::Config>,
+) -> Result<GeneratedScriptOutput> {
+    let normalized_prompt = prompt.trim();
+    if normalized_prompt.is_empty() {
+        anyhow::bail!("AI script generation requires a non-empty prompt");
+    }
+
+    let registry = ProviderRegistry::from_environment_with_config(config);
+    if !registry.has_any_provider() {
+        anyhow::bail!(
+            "No AI providers configured. Configure an API key first (Vercel, OpenAI, Anthropic, etc.)."
+        );
+    }
+
+    let (selected_model, provider) = select_generation_model(&registry)?;
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=provider_ready model_id={} provider_id={} prompt_len={}",
+            selected_model.id,
+            selected_model.provider,
+            normalized_prompt.len()
+        ),
+    );
+
+    let messages = vec![
+        ProviderMessage::system(AI_SCRIPT_GENERATION_SYSTEM_PROMPT),
+        ProviderMessage::user(format!(
+            "Generate a Script Kit script for this user request:\n\n{}",
+            normalized_prompt
+        )),
+    ];
+
+    let raw_response = provider
+        .send_message(&messages, &selected_model.id)
+        .with_context(|| {
+            format!(
+                "AI script generation failed (attempted=send_message, model_id={}, provider_id={})",
+                selected_model.id, selected_model.provider
+            )
+        })?;
+
+    let extracted = extract_script_code(&raw_response);
+    if extracted.trim().is_empty() {
+        anyhow::bail!(
+            "AI returned an empty response for script generation (state=empty_response)"
+        );
+    }
+
+    let slug = slugify_script_name(normalized_prompt);
+    let finalized = enforce_script_kit_conventions(&extracted, normalized_prompt, &slug);
+    let path = write_generated_script(&slug, &finalized).with_context(|| {
+        format!(
+            "Failed writing AI-generated script (state=write_failed, slug={})",
+            slug
+        )
+    })?;
+
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=script_written path={} slug={}",
+            path.display(),
+            slug
+        ),
+    );
+
+    Ok(GeneratedScriptOutput {
+        path,
+        slug,
+        model_id: selected_model.id,
+        provider_id: selected_model.provider,
+    })
+}
+
+fn select_generation_model(registry: &ProviderRegistry) -> Result<(ModelInfo, Arc<dyn AiProvider>)> {
+    let models = registry.get_all_models();
+    let selected_model = models
+        .iter()
+        .find(|model| model.provider.eq_ignore_ascii_case("vercel"))
+        .or_else(|| models.first())
+        .cloned()
+        .context("No AI models available in provider registry")?;
+
+    let provider = registry
+        .find_provider_for_model(&selected_model.id)
+        .cloned()
+        .with_context(|| {
+            format!(
+                "No provider found for selected model '{}' (state=provider_missing)",
+                selected_model.id
+            )
+        })?;
+
+    Ok((selected_model, provider))
+}
+
+fn generated_scripts_dir() -> PathBuf {
+    PathBuf::from(shellexpand::tilde(AI_SCRIPT_OUTPUT_DIR).as_ref())
+}
+
+fn split_fence_header_and_body(fence: &str) -> (&str, &str) {
+    match fence.find('\n') {
+        Some(newline_index) => (&fence[..newline_index], &fence[newline_index + 1..]),
+        None => ("", fence),
+    }
+}
+
+fn extract_fenced_code(response: &str, preferred_languages: Option<&[&str]>) -> Option<String> {
+    let mut remaining = response;
+
+    while let Some(start) = remaining.find("```") {
+        let after_start = &remaining[start + 3..];
+        let Some(end) = after_start.find("```") else {
+            break;
+        };
+
+        let fence_contents = &after_start[..end];
+        let (header, body) = split_fence_header_and_body(fence_contents);
+        let language = header
+            .trim()
+            .split(|c: char| c.is_whitespace() || c == '{')
+            .next()
+            .unwrap_or("")
+            .to_ascii_lowercase();
+        let code = body.trim();
+
+        if !code.is_empty() {
+            match preferred_languages {
+                Some(preferred) => {
+                    if preferred.iter().any(|candidate| *candidate == language) {
+                        return Some(code.to_string());
+                    }
+                }
+                None => return Some(code.to_string()),
+            }
+        }
+
+        remaining = &after_start[end + 3..];
+    }
+
+    None
+}
+
+fn extract_script_code(response: &str) -> String {
+    const PREFERRED_LANGUAGES: [&str; 6] = ["typescript", "ts", "javascript", "js", "tsx", "jsx"];
+
+    extract_fenced_code(response, Some(&PREFERRED_LANGUAGES))
+        .or_else(|| extract_fenced_code(response, None))
+        .unwrap_or_else(|| response.trim().to_string())
+}
+
+fn slugify_script_name(prompt: &str) -> String {
+    let mut slug = String::new();
+    let mut last_was_hyphen = false;
+
+    for character in prompt.to_ascii_lowercase().chars() {
+        if character.is_ascii_alphanumeric() {
+            slug.push(character);
+            last_was_hyphen = false;
+        } else if matches!(character, ' ' | '_' | '-') {
+            if !slug.is_empty() && !last_was_hyphen {
+                slug.push('-');
+                last_was_hyphen = true;
+            }
+        }
+    }
+
+    while slug.ends_with('-') {
+        slug.pop();
+    }
+
+    if slug.len() > AI_SCRIPT_MAX_SLUG_LEN {
+        slug.truncate(AI_SCRIPT_MAX_SLUG_LEN);
+        while slug.ends_with('-') {
+            slug.pop();
+        }
+    }
+
+    if slug.is_empty() {
+        AI_SCRIPT_DEFAULT_SLUG.to_string()
+    } else {
+        slug
+    }
+}
+
+fn slug_to_title(slug: &str) -> String {
+    slug.split('-')
+        .filter(|segment| !segment.is_empty())
+        .map(|segment| {
+            let mut chars = segment.chars();
+            match chars.next() {
+                Some(first) => first.to_uppercase().collect::<String>() + chars.as_str(),
+                None => String::new(),
+            }
+        })
+        .collect::<Vec<_>>()
+        .join(" ")
+}
+
+fn description_from_prompt(prompt: &str) -> String {
+    let normalized = prompt.split_whitespace().collect::<Vec<_>>().join(" ");
+    if normalized.is_empty() {
+        return "AI-generated Script Kit script".to_string();
+    }
+
+    let mut shortened = normalized;
+    if shortened.chars().count() > 110 {
+        shortened = format!("{}...", shortened.chars().take(107).collect::<String>());
+    }
+    shortened
+}
+
+fn has_kit_import(script: &str) -> bool {
+    script.contains("import \"@johnlindquist/kit\";")
+        || script.contains("import '@johnlindquist/kit';")
+        || script.contains("import \"@scriptkit/sdk\";")
+        || script.contains("import '@scriptkit/sdk';")
+}
+
+fn enforce_script_kit_conventions(script: &str, prompt: &str, slug: &str) -> String {
+    let mut prefix_lines: Vec<String> = Vec::new();
+    let trimmed_script = script.trim();
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Name:"))
+    {
+        prefix_lines.push(format!("// Name: {}", slug_to_title(slug)));
+    }
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Description:"))
+    {
+        prefix_lines.push(format!("// Description: {}", description_from_prompt(prompt)));
+    }
+
+    if !has_kit_import(trimmed_script) {
+        prefix_lines.push("import \"@johnlindquist/kit\";".to_string());
+    }
+
+    let mut output = String::new();
+    if !prefix_lines.is_empty() {
+        output.push_str(&prefix_lines.join("\n"));
+        output.push_str("\n\n");
+    }
+
+    output.push_str(trimmed_script);
+    if !output.ends_with('\n') {
+        output.push('\n');
+    }
+    output
+}
+
+fn write_generated_script(slug: &str, script_content: &str) -> Result<PathBuf> {
+    write_generated_script_in_dir(&generated_scripts_dir(), slug, script_content)
+}
+
+fn write_generated_script_in_dir(output_dir: &Path, slug: &str, script_content: &str) -> Result<PathBuf> {
+    fs::create_dir_all(output_dir)
+        .with_context(|| format!("Failed to create output dir: {}", output_dir.display()))?;
+
+    for suffix in 0usize.. {
+        let candidate = if suffix == 0 {
+            slug.to_string()
+        } else {
+            format!("{slug}-{suffix}")
+        };
+        let path = output_dir.join(format!("{}.ts", candidate));
+        match OpenOptions::new().write(true).create_new(true).open(&path) {
+            Ok(mut file) => {
+                file.write_all(script_content.as_bytes())
+                    .with_context(|| format!("Failed writing generated script to {}", path.display()))?;
+                return Ok(path);
+            }
+            Err(error) if error.kind() == ErrorKind::AlreadyExists => continue,
+            Err(error) => {
+                return Err(error).with_context(|| {
+                    format!(
+                        "Failed creating generated script file {} (slug={})",
+                        path.display(),
+                        slug
+                    )
+                });
+            }
+        }
+    }
+
+    unreachable!("suffix loop should eventually create a unique script filename")
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+    use tempfile::tempdir;
+
+    #[test]
+    fn test_slugify_script_name_handles_spaces_and_symbols() {
+        assert_eq!(slugify_script_name("Build: API Client!"), "build-api-client");
+        assert_eq!(slugify_script_name("  ___  "), "ai-script");
+    }
+
+    #[test]
+    fn test_extract_script_code_prefers_typescript_fence_when_multiple_blocks_exist() {
+        let response = r#"
+Here's one idea:
+```markdown
+Not code
+```
+```typescript
+await div("hello");
+```
+"#;
+        assert_eq!(extract_script_code(response), "await div(\"hello\");");
+    }
+
+    #[test]
+    fn test_extract_script_code_falls_back_to_first_fenced_block() {
+        let response = r#"
+```python
+print("hello")
+```
+"#;
+        assert_eq!(extract_script_code(response), "print(\"hello\")");
+    }
+
+    #[test]
+    fn test_extract_script_code_returns_trimmed_response_when_no_fence_exists() {
+        let response = "const answer = 42;";
+        assert_eq!(extract_script_code(response), "const answer = 42;");
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_adds_missing_metadata_and_import() {
+        let script = "const name = await arg(\"Name?\");";
+        let output = enforce_script_kit_conventions(script, "Ask for user name", "ask-user-name");
+
+        assert!(output.contains("// Name: Ask User Name"));
+        assert!(output.contains("// Description: Ask for user name"));
+        assert!(output.contains("import \"@johnlindquist/kit\";"));
+        assert!(output.contains("await arg(\"Name?\");"));
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_keeps_existing_metadata_and_import() {
+        let script = r#"// Name: Existing
+// Description: Existing description
+import "@johnlindquist/kit";
+
+await div("ready");
+"#;
+        let output = enforce_script_kit_conventions(script, "ignored", "ignored");
+
+        assert_eq!(
+            output.matches("// Name:").count(),
+            1,
+            "should not duplicate existing Name metadata"
+        );
+        assert_eq!(
+            output.matches("// Description:").count(),
+            1,
+            "should not duplicate existing Description metadata"
+        );
+        assert_eq!(
+            output.matches("import \"@johnlindquist/kit\";").count(),
+            1,
+            "should not duplicate existing import"
+        );
+    }
+
+    #[test]
+    fn test_write_generated_script_in_dir_appends_numeric_suffix_for_collisions() {
+        let temp_dir = tempdir().unwrap();
+        let first = write_generated_script_in_dir(temp_dir.path(), "my-script", "a").unwrap();
+        let second = write_generated_script_in_dir(temp_dir.path(), "my-script", "b").unwrap();
+
+        assert_eq!(first.file_name().unwrap(), "my-script.ts");
+        assert_eq!(second.file_name().unwrap(), "my-script-1.ts");
+    }
+}
diff --git a/src/builtins/part_000.rs b/src/builtins/part_000.rs
index d6b9c2a9b35b40c5005dbb9f65147f528702cb9e..5f6d27d28d72e51126d10d8beccf931c689ef2bb
--- a/src/builtins/part_000.rs
+++ b/src/builtins/part_000.rs
@@ -96,6 +96,8 @@
     OpenAi,
     NewConversation,
     ClearConversation,
+    /// Generate a new Script Kit script from the main prompt text
+    GenerateScript,
     /// Send a screenshot of the entire screen to AI Chat
     SendScreenToAi,
     /// Send a screenshot of the focused window to AI Chat
diff --git a/src/builtins/part_001_entries/entries_002.rs b/src/builtins/part_001_entries/entries_002.rs
index 6d1c9334f0ccaf0aab48582aaf42dcb129e1cb6e..72b318c66aeaf124359f4ecd276dae0350287328
--- a/src/builtins/part_001_entries/entries_002.rs
+++ b/src/builtins/part_001_entries/entries_002.rs
@@ -61,6 +61,17 @@
     ));
 
     entries.push(BuiltInEntry::new_with_icon(
+        "builtin-generate-script-with-ai",
+        "Generate Script with AI",
+        "Generate a Script Kit script from your current prompt text",
+        vec![
+            "generate", "script", "ai", "create", "code", "typescript", "shift", "tab",
+        ],
+        BuiltInFeature::AiCommand(AiCommandType::GenerateScript),
+        "ðŸ§ ",
+    ));
+
+    entries.push(BuiltInEntry::new_with_icon(
         "builtin-send-screen-to-ai",
         "Send Screen to AI Chat",
         "Capture the full screen and send it to AI Chat",


thinking
**Planning async script open**
exec
/bin/zsh -lc "rg -n \"mpsc::channel\\(|std::thread::spawn|thread::spawn|try_recv\\(|cx.spawn\\(|Toast::success\\(|show_hud\\(\" src/app_execute src/app_impl src/main_sections src/main.rs | head -n 200" in /Users/johnlindquist/dev/script-kit-gpui succeeded in 51ms:
src/app_execute/builtin_confirmation.rs:78:                                components::toast::Toast::success(
src/app_execute/builtin_confirmation.rs:167:                                self.show_hud(message, Some(2000), cx);
src/main_sections/fallbacks.rs:77:                        hud_manager::show_hud(
src/main_sections/fallbacks.rs:114:                            hud_manager::show_hud(format!("= {}", result_str), Some(2000), cx);
src/main_sections/fallbacks.rs:118:                            hud_manager::show_hud(format!("Error: {}", e), Some(3000), cx);
src/app_impl/alias_input.rs:85:                    self.show_hud("Alias removed".to_string(), Some(2000), cx);
src/app_impl/alias_input.rs:89:                    self.show_hud(format!("Failed to remove alias: {}", e), Some(4000), cx);
src/app_impl/alias_input.rs:98:                self.show_hud(
src/app_impl/alias_input.rs:117:                    self.show_hud(
src/app_impl/alias_input.rs:127:                    self.show_hud(format!("Failed to save alias: {}", e), Some(4000), cx);
src/app_impl/alias_input.rs:198:                    cx.spawn(async move |_this, cx| {
src/app_impl/alias_input.rs:218:                    cx.spawn(async move |_this, cx| {
src/app_execute/utility_views.rs:37:                cx.spawn(async move |_this, _cx| {
src/app_execute/utility_views.rs:299:                cx.spawn(async move |_this, _cx| {
src/app_execute/utility_views.rs:353:                cx.spawn(async move |_this, cx| {
src/app_execute/utility_views.rs:381:        cx.spawn(async move |_this, cx| {
src/app_execute/utility_views.rs:388:                    match frame_rx.try_recv() {
src/app_execute/execution_helpers.rs:152:                components::toast::Toast::success(
src/app_execute/execution_helpers.rs:291:                components::toast::Toast::success(
src/app_execute/execution_helpers.rs:419:        cx.spawn(async move |_this, cx| {
file update:
diff --git a/src/ai/mod.rs b/src/ai/mod.rs
index a420b1a5faf59506acdb7caf60681c153a3f9bb6..9a73e9491862633b325b2c52b51a3e20395ff85c
--- a/src/ai/mod.rs
+++ b/src/ai/mod.rs
@@ -37,6 +37,7 @@
 pub(crate) mod providers;
 pub(crate) mod sdk_handlers;
 pub(crate) mod session;
+pub(crate) mod script_generation;
 pub(crate) mod storage;
 pub(crate) mod window;
 
@@ -44,6 +45,7 @@
 pub use self::config::{DetectedKeys, ModelInfo, ProviderConfig};
 pub use self::model::{Chat, ChatId, ChatSource, Message, MessageRole};
 pub use self::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+pub use self::script_generation::{generate_script_from_prompt, GeneratedScriptOutput};
 pub use self::sdk_handlers::try_handle_ai_message;
 pub use self::storage::{
     clear_all_chats, create_chat, delete_chat, get_all_chats, get_chat, get_chat_messages,
diff --git a/src/ai/script_generation.rs b/src/ai/script_generation.rs
new file mode 100644
index 0000000000000000000000000000000000000000..7f2ec8e7576ed50cd10f7aea31a6522875ef667a
--- /dev/null
+++ b/src/ai/script_generation.rs
@@ -0,0 +1,417 @@
+use anyhow::{Context, Result};
+use std::fs::{self, OpenOptions};
+use std::io::{ErrorKind, Write};
+use std::path::{Path, PathBuf};
+use std::sync::Arc;
+
+use super::config::ModelInfo;
+use super::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+
+const AI_SCRIPT_OUTPUT_DIR: &str = "~/.kenv/scripts";
+const AI_SCRIPT_DEFAULT_SLUG: &str = "ai-script";
+const AI_SCRIPT_MAX_SLUG_LEN: usize = 64;
+
+const AI_SCRIPT_GENERATION_SYSTEM_PROMPT: &str = r#"You write production-ready Script Kit scripts.
+
+Return ONLY TypeScript source code for one Script Kit script. Do not include explanations.
+
+Required output conventions:
+1) Include metadata comments at the top:
+   // Name: <clear title>
+   // Description: <one-line summary>
+2) Include: import "@johnlindquist/kit";
+3) Use await arg() for user input when useful.
+4) Use await div() for display output when useful.
+5) Keep the script runnable as-is with sensible defaults and light error handling."#;
+
+#[derive(Debug, Clone)]
+pub struct GeneratedScriptOutput {
+    pub path: PathBuf,
+    pub slug: String,
+    pub model_id: String,
+    pub provider_id: String,
+}
+
+pub fn generate_script_from_prompt(
+    prompt: &str,
+    config: Option<&crate::config::Config>,
+) -> Result<GeneratedScriptOutput> {
+    let normalized_prompt = prompt.trim();
+    if normalized_prompt.is_empty() {
+        anyhow::bail!("AI script generation requires a non-empty prompt");
+    }
+
+    let registry = ProviderRegistry::from_environment_with_config(config);
+    if !registry.has_any_provider() {
+        anyhow::bail!(
+            "No AI providers configured. Configure an API key first (Vercel, OpenAI, Anthropic, etc.)."
+        );
+    }
+
+    let (selected_model, provider) = select_generation_model(&registry)?;
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=provider_ready model_id={} provider_id={} prompt_len={}",
+            selected_model.id,
+            selected_model.provider,
+            normalized_prompt.len()
+        ),
+    );
+
+    let messages = vec![
+        ProviderMessage::system(AI_SCRIPT_GENERATION_SYSTEM_PROMPT),
+        ProviderMessage::user(format!(
+            "Generate a Script Kit script for this user request:\n\n{}",
+            normalized_prompt
+        )),
+    ];
+
+    let raw_response = provider
+        .send_message(&messages, &selected_model.id)
+        .with_context(|| {
+            format!(
+                "AI script generation failed (attempted=send_message, model_id={}, provider_id={})",
+                selected_model.id, selected_model.provider
+            )
+        })?;
+
+    let extracted = extract_script_code(&raw_response);
+    if extracted.trim().is_empty() {
+        anyhow::bail!(
+            "AI returned an empty response for script generation (state=empty_response)"
+        );
+    }
+
+    let slug = slugify_script_name(normalized_prompt);
+    let finalized = enforce_script_kit_conventions(&extracted, normalized_prompt, &slug);
+    let path = write_generated_script(&slug, &finalized).with_context(|| {
+        format!(
+            "Failed writing AI-generated script (state=write_failed, slug={})",
+            slug
+        )
+    })?;
+
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=script_written path={} slug={}",
+            path.display(),
+            slug
+        ),
+    );
+
+    Ok(GeneratedScriptOutput {
+        path,
+        slug,
+        model_id: selected_model.id,
+        provider_id: selected_model.provider,
+    })
+}
+
+fn select_generation_model(registry: &ProviderRegistry) -> Result<(ModelInfo, Arc<dyn AiProvider>)> {
+    let models = registry.get_all_models();
+    let selected_model = models
+        .iter()
+        .find(|model| model.provider.eq_ignore_ascii_case("vercel"))
+        .or_else(|| models.first())
+        .cloned()
+        .context("No AI models available in provider registry")?;
+
+    let provider = registry
+        .find_provider_for_model(&selected_model.id)
+        .cloned()
+        .with_context(|| {
+            format!(
+                "No provider found for selected model '{}' (state=provider_missing)",
+                selected_model.id
+            )
+        })?;
+
+    Ok((selected_model, provider))
+}
+
+fn generated_scripts_dir() -> PathBuf {
+    PathBuf::from(shellexpand::tilde(AI_SCRIPT_OUTPUT_DIR).as_ref())
+}
+
+fn split_fence_header_and_body(fence: &str) -> (&str, &str) {
+    match fence.find('\n') {
+        Some(newline_index) => (&fence[..newline_index], &fence[newline_index + 1..]),
+        None => ("", fence),
+    }
+}
+
+fn extract_fenced_code(response: &str, preferred_languages: Option<&[&str]>) -> Option<String> {
+    let mut remaining = response;
+
+    while let Some(start) = remaining.find("```") {
+        let after_start = &remaining[start + 3..];
+        let Some(end) = after_start.find("```") else {
+            break;
+        };
+
+        let fence_contents = &after_start[..end];
+        let (header, body) = split_fence_header_and_body(fence_contents);
+        let language = header
+            .trim()
+            .split(|c: char| c.is_whitespace() || c == '{')
+            .next()
+            .unwrap_or("")
+            .to_ascii_lowercase();
+        let code = body.trim();
+
+        if !code.is_empty() {
+            match preferred_languages {
+                Some(preferred) => {
+                    if preferred.iter().any(|candidate| *candidate == language) {
+                        return Some(code.to_string());
+                    }
+                }
+                None => return Some(code.to_string()),
+            }
+        }
+
+        remaining = &after_start[end + 3..];
+    }
+
+    None
+}
+
+fn extract_script_code(response: &str) -> String {
+    const PREFERRED_LANGUAGES: [&str; 6] = ["typescript", "ts", "javascript", "js", "tsx", "jsx"];
+
+    extract_fenced_code(response, Some(&PREFERRED_LANGUAGES))
+        .or_else(|| extract_fenced_code(response, None))
+        .unwrap_or_else(|| response.trim().to_string())
+}
+
+fn slugify_script_name(prompt: &str) -> String {
+    let mut slug = String::new();
+    let mut last_was_hyphen = false;
+
+    for character in prompt.to_ascii_lowercase().chars() {
+        if character.is_ascii_alphanumeric() {
+            slug.push(character);
+            last_was_hyphen = false;
+        } else if matches!(character, ' ' | '_' | '-') {
+            if !slug.is_empty() && !last_was_hyphen {
+                slug.push('-');
+                last_was_hyphen = true;
+            }
+        }
+    }
+
+    while slug.ends_with('-') {
+        slug.pop();
+    }
+
+    if slug.len() > AI_SCRIPT_MAX_SLUG_LEN {
+        slug.truncate(AI_SCRIPT_MAX_SLUG_LEN);
+        while slug.ends_with('-') {
+            slug.pop();
+        }
+    }
+
+    if slug.is_empty() {
+        AI_SCRIPT_DEFAULT_SLUG.to_string()
+    } else {
+        slug
+    }
+}
+
+fn slug_to_title(slug: &str) -> String {
+    slug.split('-')
+        .filter(|segment| !segment.is_empty())
+        .map(|segment| {
+            let mut chars = segment.chars();
+            match chars.next() {
+                Some(first) => first.to_uppercase().collect::<String>() + chars.as_str(),
+                None => String::new(),
+            }
+        })
+        .collect::<Vec<_>>()
+        .join(" ")
+}
+
+fn description_from_prompt(prompt: &str) -> String {
+    let normalized = prompt.split_whitespace().collect::<Vec<_>>().join(" ");
+    if normalized.is_empty() {
+        return "AI-generated Script Kit script".to_string();
+    }
+
+    let mut shortened = normalized;
+    if shortened.chars().count() > 110 {
+        shortened = format!("{}...", shortened.chars().take(107).collect::<String>());
+    }
+    shortened
+}
+
+fn has_kit_import(script: &str) -> bool {
+    script.contains("import \"@johnlindquist/kit\";")
+        || script.contains("import '@johnlindquist/kit';")
+        || script.contains("import \"@scriptkit/sdk\";")
+        || script.contains("import '@scriptkit/sdk';")
+}
+
+fn enforce_script_kit_conventions(script: &str, prompt: &str, slug: &str) -> String {
+    let mut prefix_lines: Vec<String> = Vec::new();
+    let trimmed_script = script.trim();
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Name:"))
+    {
+        prefix_lines.push(format!("// Name: {}", slug_to_title(slug)));
+    }
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Description:"))
+    {
+        prefix_lines.push(format!("// Description: {}", description_from_prompt(prompt)));
+    }
+
+    if !has_kit_import(trimmed_script) {
+        prefix_lines.push("import \"@johnlindquist/kit\";".to_string());
+    }
+
+    let mut output = String::new();
+    if !prefix_lines.is_empty() {
+        output.push_str(&prefix_lines.join("\n"));
+        output.push_str("\n\n");
+    }
+
+    output.push_str(trimmed_script);
+    if !output.ends_with('\n') {
+        output.push('\n');
+    }
+    output
+}
+
+fn write_generated_script(slug: &str, script_content: &str) -> Result<PathBuf> {
+    write_generated_script_in_dir(&generated_scripts_dir(), slug, script_content)
+}
+
+fn write_generated_script_in_dir(output_dir: &Path, slug: &str, script_content: &str) -> Result<PathBuf> {
+    fs::create_dir_all(output_dir)
+        .with_context(|| format!("Failed to create output dir: {}", output_dir.display()))?;
+
+    for suffix in 0usize.. {
+        let candidate = if suffix == 0 {
+            slug.to_string()
+        } else {
+            format!("{slug}-{suffix}")
+        };
+        let path = output_dir.join(format!("{}.ts", candidate));
+        match OpenOptions::new().write(true).create_new(true).open(&path) {
+            Ok(mut file) => {
+                file.write_all(script_content.as_bytes())
+                    .with_context(|| format!("Failed writing generated script to {}", path.display()))?;
+                return Ok(path);
+            }
+            Err(error) if error.kind() == ErrorKind::AlreadyExists => continue,
+            Err(error) => {
+                return Err(error).with_context(|| {
+                    format!(
+                        "Failed creating generated script file {} (slug={})",
+                        path.display(),
+                        slug
+                    )
+                });
+            }
+        }
+    }
+
+    unreachable!("suffix loop should eventually create a unique script filename")
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+    use tempfile::tempdir;
+
+    #[test]
+    fn test_slugify_script_name_handles_spaces_and_symbols() {
+        assert_eq!(slugify_script_name("Build: API Client!"), "build-api-client");
+        assert_eq!(slugify_script_name("  ___  "), "ai-script");
+    }
+
+    #[test]
+    fn test_extract_script_code_prefers_typescript_fence_when_multiple_blocks_exist() {
+        let response = r#"
+Here's one idea:
+```markdown
+Not code
+```
+```typescript
+await div("hello");
+```
+"#;
+        assert_eq!(extract_script_code(response), "await div(\"hello\");");
+    }
+
+    #[test]
+    fn test_extract_script_code_falls_back_to_first_fenced_block() {
+        let response = r#"
+```python
+print("hello")
+```
+"#;
+        assert_eq!(extract_script_code(response), "print(\"hello\")");
+    }
+
+    #[test]
+    fn test_extract_script_code_returns_trimmed_response_when_no_fence_exists() {
+        let response = "const answer = 42;";
+        assert_eq!(extract_script_code(response), "const answer = 42;");
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_adds_missing_metadata_and_import() {
+        let script = "const name = await arg(\"Name?\");";
+        let output = enforce_script_kit_conventions(script, "Ask for user name", "ask-user-name");
+
+        assert!(output.contains("// Name: Ask User Name"));
+        assert!(output.contains("// Description: Ask for user name"));
+        assert!(output.contains("import \"@johnlindquist/kit\";"));
+        assert!(output.contains("await arg(\"Name?\");"));
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_keeps_existing_metadata_and_import() {
+        let script = r#"// Name: Existing
+// Description: Existing description
+import "@johnlindquist/kit";
+
+await div("ready");
+"#;
+        let output = enforce_script_kit_conventions(script, "ignored", "ignored");
+
+        assert_eq!(
+            output.matches("// Name:").count(),
+            1,
+            "should not duplicate existing Name metadata"
+        );
+        assert_eq!(
+            output.matches("// Description:").count(),
+            1,
+            "should not duplicate existing Description metadata"
+        );
+        assert_eq!(
+            output.matches("import \"@johnlindquist/kit\";").count(),
+            1,
+            "should not duplicate existing import"
+        );
+    }
+
+    #[test]
+    fn test_write_generated_script_in_dir_appends_numeric_suffix_for_collisions() {
+        let temp_dir = tempdir().unwrap();
+        let first = write_generated_script_in_dir(temp_dir.path(), "my-script", "a").unwrap();
+        let second = write_generated_script_in_dir(temp_dir.path(), "my-script", "b").unwrap();
+
+        assert_eq!(first.file_name().unwrap(), "my-script.ts");
+        assert_eq!(second.file_name().unwrap(), "my-script-1.ts");
+    }
+}
diff --git a/src/builtins/part_000.rs b/src/builtins/part_000.rs
index d6b9c2a9b35b40c5005dbb9f65147f528702cb9e..5f6d27d28d72e51126d10d8beccf931c689ef2bb
--- a/src/builtins/part_000.rs
+++ b/src/builtins/part_000.rs
@@ -96,6 +96,8 @@
     OpenAi,
     NewConversation,
     ClearConversation,
+    /// Generate a new Script Kit script from the main prompt text
+    GenerateScript,
     /// Send a screenshot of the entire screen to AI Chat
     SendScreenToAi,
     /// Send a screenshot of the focused window to AI Chat
diff --git a/src/builtins/part_001_entries/entries_002.rs b/src/builtins/part_001_entries/entries_002.rs
index 6d1c9334f0ccaf0aab48582aaf42dcb129e1cb6e..72b318c66aeaf124359f4ecd276dae0350287328
--- a/src/builtins/part_001_entries/entries_002.rs
+++ b/src/builtins/part_001_entries/entries_002.rs
@@ -61,6 +61,17 @@
     ));
 
     entries.push(BuiltInEntry::new_with_icon(
+        "builtin-generate-script-with-ai",
+        "Generate Script with AI",
+        "Generate a Script Kit script from your current prompt text",
+        vec![
+            "generate", "script", "ai", "create", "code", "typescript", "shift", "tab",
+        ],
+        BuiltInFeature::AiCommand(AiCommandType::GenerateScript),
+        "ðŸ§ ",
+    ));
+
+    entries.push(BuiltInEntry::new_with_icon(
         "builtin-send-screen-to-ai",
         "Send Screen to AI Chat",
         "Capture the full screen and send it to AI Chat",


thinking
**Inspecting existing AI generation**
codex
I discovered there is already a script-generation flow in `app_impl/prompt_ai.rs`; Iâ€™m checking it to avoid duplicating logic and to ensure the new built-in path reuses the same backend helper cleanly.
exec
/bin/zsh -lc "sed -n '480,700p' src/app_impl/prompt_ai.rs" in /Users/johnlindquist/dev/script-kit-gpui succeeded in 52ms:
            crate::ai::ProviderRegistry::from_environment_with_config(Some(&self.config))
        });

        if !registry.has_any_provider() {
            self.toast_manager.push(
                components::toast::Toast::error("No AI providers configured for script generation", &self.theme)
                    .duration_ms(Some(5000)),
            );
            cx.notify();
            return;
        }

        let selected_model = match select_default_ai_script_model(&registry) {
            Some(model) => model,
            None => {
                let stage = AiScriptGenerationStage::SelectModel.as_str();
                logging::log(
                    "AI_SCRIPT_GEN",
                    &format!(
                        "state={} attempted=select_default_model failure=no_available_models",
file update:
diff --git a/src/ai/mod.rs b/src/ai/mod.rs
index a420b1a5faf59506acdb7caf60681c153a3f9bb6..9a73e9491862633b325b2c52b51a3e20395ff85c
--- a/src/ai/mod.rs
+++ b/src/ai/mod.rs
@@ -37,6 +37,7 @@
 pub(crate) mod providers;
 pub(crate) mod sdk_handlers;
 pub(crate) mod session;
+pub(crate) mod script_generation;
 pub(crate) mod storage;
 pub(crate) mod window;
 
@@ -44,6 +45,7 @@
 pub use self::config::{DetectedKeys, ModelInfo, ProviderConfig};
 pub use self::model::{Chat, ChatId, ChatSource, Message, MessageRole};
 pub use self::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+pub use self::script_generation::{generate_script_from_prompt, GeneratedScriptOutput};
 pub use self::sdk_handlers::try_handle_ai_message;
 pub use self::storage::{
     clear_all_chats, create_chat, delete_chat, get_all_chats, get_chat, get_chat_messages,
diff --git a/src/ai/script_generation.rs b/src/ai/script_generation.rs
new file mode 100644
index 0000000000000000000000000000000000000000..7f2ec8e7576ed50cd10f7aea31a6522875ef667a
--- /dev/null
+++ b/src/ai/script_generation.rs
@@ -0,0 +1,417 @@
+use anyhow::{Context, Result};
+use std::fs::{self, OpenOptions};
+use std::io::{ErrorKind, Write};
+use std::path::{Path, PathBuf};
+use std::sync::Arc;
+
+use super::config::ModelInfo;
+use super::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+
+const AI_SCRIPT_OUTPUT_DIR: &str = "~/.kenv/scripts";
+const AI_SCRIPT_DEFAULT_SLUG: &str = "ai-script";
+const AI_SCRIPT_MAX_SLUG_LEN: usize = 64;
+
+const AI_SCRIPT_GENERATION_SYSTEM_PROMPT: &str = r#"You write production-ready Script Kit scripts.
+
+Return ONLY TypeScript source code for one Script Kit script. Do not include explanations.
+
+Required output conventions:
+1) Include metadata comments at the top:
+   // Name: <clear title>
+   // Description: <one-line summary>
+2) Include: import "@johnlindquist/kit";
+3) Use await arg() for user input when useful.
+4) Use await div() for display output when useful.
+5) Keep the script runnable as-is with sensible defaults and light error handling."#;
+
+#[derive(Debug, Clone)]
+pub struct GeneratedScriptOutput {
+    pub path: PathBuf,
+    pub slug: String,
+    pub model_id: String,
+    pub provider_id: String,
+}
+
+pub fn generate_script_from_prompt(
+    prompt: &str,
+    config: Option<&crate::config::Config>,
+) -> Result<GeneratedScriptOutput> {
+    let normalized_prompt = prompt.trim();
+    if normalized_prompt.is_empty() {
+        anyhow::bail!("AI script generation requires a non-empty prompt");
+    }
+
+    let registry = ProviderRegistry::from_environment_with_config(config);
+    if !registry.has_any_provider() {
+        anyhow::bail!(
+            "No AI providers configured. Configure an API key first (Vercel, OpenAI, Anthropic, etc.)."
+        );
+    }
+
+    let (selected_model, provider) = select_generation_model(&registry)?;
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=provider_ready model_id={} provider_id={} prompt_len={}",
+            selected_model.id,
+            selected_model.provider,
+            normalized_prompt.len()
+        ),
+    );
+
+    let messages = vec![
+        ProviderMessage::system(AI_SCRIPT_GENERATION_SYSTEM_PROMPT),
+        ProviderMessage::user(format!(
+            "Generate a Script Kit script for this user request:\n\n{}",
+            normalized_prompt
+        )),
+    ];
+
+    let raw_response = provider
+        .send_message(&messages, &selected_model.id)
+        .with_context(|| {
+            format!(
+                "AI script generation failed (attempted=send_message, model_id={}, provider_id={})",
+                selected_model.id, selected_model.provider
+            )
+        })?;
+
+    let extracted = extract_script_code(&raw_response);
+    if extracted.trim().is_empty() {
+        anyhow::bail!(
+            "AI returned an empty response for script generation (state=empty_response)"
+        );
+    }
+
+    let slug = slugify_script_name(normalized_prompt);
+    let finalized = enforce_script_kit_conventions(&extracted, normalized_prompt, &slug);
+    let path = write_generated_script(&slug, &finalized).with_context(|| {
+        format!(
+            "Failed writing AI-generated script (state=write_failed, slug={})",
+            slug
+        )
+    })?;
+
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=script_written path={} slug={}",
+            path.display(),
+            slug
+        ),
+    );
+
+    Ok(GeneratedScriptOutput {
+        path,
+        slug,
+        model_id: selected_model.id,
+        provider_id: selected_model.provider,
+    })
+}
+
+fn select_generation_model(registry: &ProviderRegistry) -> Result<(ModelInfo, Arc<dyn AiProvider>)> {
+    let models = registry.get_all_models();
+    let selected_model = models
+        .iter()
+        .find(|model| model.provider.eq_ignore_ascii_case("vercel"))
+        .or_else(|| models.first())
+        .cloned()
+        .context("No AI models available in provider registry")?;
+
+    let provider = registry
+        .find_provider_for_model(&selected_model.id)
+        .cloned()
+        .with_context(|| {
+            format!(
+                "No provider found for selected model '{}' (state=provider_missing)",
+                selected_model.id
+            )
+        })?;
+
+    Ok((selected_model, provider))
+}
+
+fn generated_scripts_dir() -> PathBuf {
+    PathBuf::from(shellexpand::tilde(AI_SCRIPT_OUTPUT_DIR).as_ref())
+}
+
+fn split_fence_header_and_body(fence: &str) -> (&str, &str) {
+    match fence.find('\n') {
+        Some(newline_index) => (&fence[..newline_index], &fence[newline_index + 1..]),
+        None => ("", fence),
+    }
+}
+
+fn extract_fenced_code(response: &str, preferred_languages: Option<&[&str]>) -> Option<String> {
+    let mut remaining = response;
+
+    while let Some(start) = remaining.find("```") {
+        let after_start = &remaining[start + 3..];
+        let Some(end) = after_start.find("```") else {
+            break;
+        };
+
+        let fence_contents = &after_start[..end];
+        let (header, body) = split_fence_header_and_body(fence_contents);
+        let language = header
+            .trim()
+            .split(|c: char| c.is_whitespace() || c == '{')
+            .next()
+            .unwrap_or("")
+            .to_ascii_lowercase();
+        let code = body.trim();
+
+        if !code.is_empty() {
+            match preferred_languages {
+                Some(preferred) => {
+                    if preferred.iter().any(|candidate| *candidate == language) {
+                        return Some(code.to_string());
+                    }
+                }
+                None => return Some(code.to_string()),
+            }
+        }
+
+        remaining = &after_start[end + 3..];
+    }
+
+    None
+}
+
+fn extract_script_code(response: &str) -> String {
+    const PREFERRED_LANGUAGES: [&str; 6] = ["typescript", "ts", "javascript", "js", "tsx", "jsx"];
+
+    extract_fenced_code(response, Some(&PREFERRED_LANGUAGES))
+        .or_else(|| extract_fenced_code(response, None))
+        .unwrap_or_else(|| response.trim().to_string())
+}
+
+fn slugify_script_name(prompt: &str) -> String {
+    let mut slug = String::new();
+    let mut last_was_hyphen = false;
+
+    for character in prompt.to_ascii_lowercase().chars() {
+        if character.is_ascii_alphanumeric() {
+            slug.push(character);
+            last_was_hyphen = false;
+        } else if matches!(character, ' ' | '_' | '-') {
+            if !slug.is_empty() && !last_was_hyphen {
+                slug.push('-');
+                last_was_hyphen = true;
+            }
+        }
+    }
+
+    while slug.ends_with('-') {
+        slug.pop();
+    }
+
+    if slug.len() > AI_SCRIPT_MAX_SLUG_LEN {
+        slug.truncate(AI_SCRIPT_MAX_SLUG_LEN);
+        while slug.ends_with('-') {
+            slug.pop();
+        }
+    }
+
+    if slug.is_empty() {
+        AI_SCRIPT_DEFAULT_SLUG.to_string()
+    } else {
+        slug
+    }
+}
+
+fn slug_to_title(slug: &str) -> String {
+    slug.split('-')
+        .filter(|segment| !segment.is_empty())
+        .map(|segment| {
+            let mut chars = segment.chars();
+            match chars.next() {
+                Some(first) => first.to_uppercase().collect::<String>() + chars.as_str(),
+                None => String::new(),
+            }
+        })
+        .collect::<Vec<_>>()
+        .join(" ")
+}
+
+fn description_from_prompt(prompt: &str) -> String {
+    let normalized = prompt.split_whitespace().collect::<Vec<_>>().join(" ");
+    if normalized.is_empty() {
+        return "AI-generated Script Kit script".to_string();
+    }
+
+    let mut shortened = normalized;
+    if shortened.chars().count() > 110 {
+        shortened = format!("{}...", shortened.chars().take(107).collect::<String>());
+    }
+    shortened
+}
+
+fn has_kit_import(script: &str) -> bool {
+    script.contains("import \"@johnlindquist/kit\";")
+        || script.contains("import '@johnlindquist/kit';")
+        || script.contains("import \"@scriptkit/sdk\";")
+        || script.contains("import '@scriptkit/sdk';")
+}
+
+fn enforce_script_kit_conventions(script: &str, prompt: &str, slug: &str) -> String {
+    let mut prefix_lines: Vec<String> = Vec::new();
+    let trimmed_script = script.trim();
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Name:"))
+    {
+        prefix_lines.push(format!("// Name: {}", slug_to_title(slug)));
+    }
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Description:"))
+    {
+        prefix_lines.push(format!("// Description: {}", description_from_prompt(prompt)));
+    }
+
+    if !has_kit_import(trimmed_script) {
+        prefix_lines.push("import \"@johnlindquist/kit\";".to_string());
+    }
+
+    let mut output = String::new();
+    if !prefix_lines.is_empty() {
+        output.push_str(&prefix_lines.join("\n"));
+        output.push_str("\n\n");
+    }
+
+    output.push_str(trimmed_script);
+    if !output.ends_with('\n') {
+        output.push('\n');
+    }
+    output
+}
+
+fn write_generated_script(slug: &str, script_content: &str) -> Result<PathBuf> {
+    write_generated_script_in_dir(&generated_scripts_dir(), slug, script_content)
+}
+
+fn write_generated_script_in_dir(output_dir: &Path, slug: &str, script_content: &str) -> Result<PathBuf> {
+    fs::create_dir_all(output_dir)
+        .with_context(|| format!("Failed to create output dir: {}", output_dir.display()))?;
+
+    for suffix in 0usize.. {
+        let candidate = if suffix == 0 {
+            slug.to_string()
+        } else {
+            format!("{slug}-{suffix}")
+        };
+        let path = output_dir.join(format!("{}.ts", candidate));
+        match OpenOptions::new().write(true).create_new(true).open(&path) {
+            Ok(mut file) => {
+                file.write_all(script_content.as_bytes())
+                    .with_context(|| format!("Failed writing generated script to {}", path.display()))?;
+                return Ok(path);
+            }
+            Err(error) if error.kind() == ErrorKind::AlreadyExists => continue,
+            Err(error) => {
+                return Err(error).with_context(|| {
+                    format!(
+                        "Failed creating generated script file {} (slug={})",
+                        path.display(),
+                        slug
+                    )
+                });
+            }
+        }
+    }
+
+    unreachable!("suffix loop should eventually create a unique script filename")
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+    use tempfile::tempdir;
+
+    #[test]
+    fn test_slugify_script_name_handles_spaces_and_symbols() {
+        assert_eq!(slugify_script_name("Build: API Client!"), "build-api-client");
+        assert_eq!(slugify_script_name("  ___  "), "ai-script");
+    }
+
+    #[test]
+    fn test_extract_script_code_prefers_typescript_fence_when_multiple_blocks_exist() {
+        let response = r#"
+Here's one idea:
+```markdown
+Not code
+```
+```typescript
+await div("hello");
+```
+"#;
+        assert_eq!(extract_script_code(response), "await div(\"hello\");");
+    }
+
+    #[test]
+    fn test_extract_script_code_falls_back_to_first_fenced_block() {
+        let response = r#"
+```python
+print("hello")
+```
+"#;
+        assert_eq!(extract_script_code(response), "print(\"hello\")");
+    }
+
+    #[test]
+    fn test_extract_script_code_returns_trimmed_response_when_no_fence_exists() {
+        let response = "const answer = 42;";
+        assert_eq!(extract_script_code(response), "const answer = 42;");
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_adds_missing_metadata_and_import() {
+        let script = "const name = await arg(\"Name?\");";
+        let output = enforce_script_kit_conventions(script, "Ask for user name", "ask-user-name");
+
+        assert!(output.contains("// Name: Ask User Name"));
+        assert!(output.contains("// Description: Ask for user name"));
+        assert!(output.contains("import \"@johnlindquist/kit\";"));
+        assert!(output.contains("await arg(\"Name?\");"));
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_keeps_existing_metadata_and_import() {
+        let script = r#"// Name: Existing
+// Description: Existing description
+import "@johnlindquist/kit";
+
+await div("ready");
+"#;
+        let output = enforce_script_kit_conventions(script, "ignored", "ignored");
+
+        assert_eq!(
+            output.matches("// Name:").count(),
+            1,
+            "should not duplicate existing Name metadata"
+        );
+        assert_eq!(
+            output.matches("// Description:").count(),
+            1,
+            "should not duplicate existing Description metadata"
+        );
+        assert_eq!(
+            output.matches("import \"@johnlindquist/kit\";").count(),
+            1,
+            "should not duplicate existing import"
+        );
+    }
+
+    #[test]
+    fn test_write_generated_script_in_dir_appends_numeric_suffix_for_collisions() {
+        let temp_dir = tempdir().unwrap();
+        let first = write_generated_script_in_dir(temp_dir.path(), "my-script", "a").unwrap();
+        let second = write_generated_script_in_dir(temp_dir.path(), "my-script", "b").unwrap();
+
+        assert_eq!(first.file_name().unwrap(), "my-script.ts");
+        assert_eq!(second.file_name().unwrap(), "my-script-1.ts");
+    }
+}
diff --git a/src/builtins/part_000.rs b/src/builtins/part_000.rs
index d6b9c2a9b35b40c5005dbb9f65147f528702cb9e..5f6d27d28d72e51126d10d8beccf931c689ef2bb
--- a/src/builtins/part_000.rs
+++ b/src/builtins/part_000.rs
@@ -96,6 +96,8 @@
     OpenAi,
     NewConversation,
     ClearConversation,
+    /// Generate a new Script Kit script from the main prompt text
+    GenerateScript,
     /// Send a screenshot of the entire screen to AI Chat
     SendScreenToAi,
     /// Send a screenshot of the focused window to AI Chat
diff --git a/src/builtins/part_001_entries/entries_002.rs b/src/builtins/part_001_entries/entries_002.rs
index 6d1c9334f0ccaf0aab48582aaf42dcb129e1cb6e..72b318c66aeaf124359f4ecd276dae0350287328
--- a/src/builtins/part_001_entries/entries_002.rs
+++ b/src/builtins/part_001_entries/entries_002.rs
@@ -61,6 +61,17 @@
     ));
 
     entries.push(BuiltInEntry::new_with_icon(
+        "builtin-generate-script-with-ai",
+        "Generate Script with AI",
+        "Generate a Script Kit script from your current prompt text",
+        vec![
+            "generate", "script", "ai", "create", "code", "typescript", "shift", "tab",
+        ],
+        BuiltInFeature::AiCommand(AiCommandType::GenerateScript),
+        "ðŸ§ ",
+    ));
+
+    entries.push(BuiltInEntry::new_with_icon(
         "builtin-send-screen-to-ai",
         "Send Screen to AI Chat",
         "Capture the full screen and send it to AI Chat",


thinking
**Assessing AI script generation integration**
exec
/bin/zsh -lc "sed -n '1080,1230p' src/app_execute/builtin_execution.rs" in /Users/johnlindquist/dev/script-kit-gpui succeeded in 51ms:
                            cx,
                        );
                    }
                    SettingsCommandType::ConfigureAnthropicApiKey => {
                        self.show_api_key_prompt(
                            "SCRIPT_KIT_ANTHROPIC_API_KEY",
                            "Enter your Anthropic API key",
                            "Anthropic",
                            cx,
                        );
                    }
                    SettingsCommandType::ChooseTheme => {
                        logging::log("EXEC", "Opening Theme Chooser");
                        // Back up current theme for cancel/restore
                        self.theme_before_chooser = Some(self.theme.clone());
                        // Clear the shared input for fresh search (sync on next render)
                        self.filter_text = String::new();
                        self.pending_filter_sync = true;
                        self.pending_placeholder = Some("Search themes...".to_string());
                        // Start at the currently active theme
file update:
diff --git a/src/ai/mod.rs b/src/ai/mod.rs
index a420b1a5faf59506acdb7caf60681c153a3f9bb6..9a73e9491862633b325b2c52b51a3e20395ff85c
--- a/src/ai/mod.rs
+++ b/src/ai/mod.rs
@@ -37,6 +37,7 @@
 pub(crate) mod providers;
 pub(crate) mod sdk_handlers;
 pub(crate) mod session;
+pub(crate) mod script_generation;
 pub(crate) mod storage;
 pub(crate) mod window;
 
@@ -44,6 +45,7 @@
 pub use self::config::{DetectedKeys, ModelInfo, ProviderConfig};
 pub use self::model::{Chat, ChatId, ChatSource, Message, MessageRole};
 pub use self::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+pub use self::script_generation::{generate_script_from_prompt, GeneratedScriptOutput};
 pub use self::sdk_handlers::try_handle_ai_message;
 pub use self::storage::{
     clear_all_chats, create_chat, delete_chat, get_all_chats, get_chat, get_chat_messages,
diff --git a/src/ai/script_generation.rs b/src/ai/script_generation.rs
new file mode 100644
index 0000000000000000000000000000000000000000..7f2ec8e7576ed50cd10f7aea31a6522875ef667a
--- /dev/null
+++ b/src/ai/script_generation.rs
@@ -0,0 +1,417 @@
+use anyhow::{Context, Result};
+use std::fs::{self, OpenOptions};
+use std::io::{ErrorKind, Write};
+use std::path::{Path, PathBuf};
+use std::sync::Arc;
+
+use super::config::ModelInfo;
+use super::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+
+const AI_SCRIPT_OUTPUT_DIR: &str = "~/.kenv/scripts";
+const AI_SCRIPT_DEFAULT_SLUG: &str = "ai-script";
+const AI_SCRIPT_MAX_SLUG_LEN: usize = 64;
+
+const AI_SCRIPT_GENERATION_SYSTEM_PROMPT: &str = r#"You write production-ready Script Kit scripts.
+
+Return ONLY TypeScript source code for one Script Kit script. Do not include explanations.
+
+Required output conventions:
+1) Include metadata comments at the top:
+   // Name: <clear title>
+   // Description: <one-line summary>
+2) Include: import "@johnlindquist/kit";
+3) Use await arg() for user input when useful.
+4) Use await div() for display output when useful.
+5) Keep the script runnable as-is with sensible defaults and light error handling."#;
+
+#[derive(Debug, Clone)]
+pub struct GeneratedScriptOutput {
+    pub path: PathBuf,
+    pub slug: String,
+    pub model_id: String,
+    pub provider_id: String,
+}
+
+pub fn generate_script_from_prompt(
+    prompt: &str,
+    config: Option<&crate::config::Config>,
+) -> Result<GeneratedScriptOutput> {
+    let normalized_prompt = prompt.trim();
+    if normalized_prompt.is_empty() {
+        anyhow::bail!("AI script generation requires a non-empty prompt");
+    }
+
+    let registry = ProviderRegistry::from_environment_with_config(config);
+    if !registry.has_any_provider() {
+        anyhow::bail!(
+            "No AI providers configured. Configure an API key first (Vercel, OpenAI, Anthropic, etc.)."
+        );
+    }
+
+    let (selected_model, provider) = select_generation_model(&registry)?;
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=provider_ready model_id={} provider_id={} prompt_len={}",
+            selected_model.id,
+            selected_model.provider,
+            normalized_prompt.len()
+        ),
+    );
+
+    let messages = vec![
+        ProviderMessage::system(AI_SCRIPT_GENERATION_SYSTEM_PROMPT),
+        ProviderMessage::user(format!(
+            "Generate a Script Kit script for this user request:\n\n{}",
+            normalized_prompt
+        )),
+    ];
+
+    let raw_response = provider
+        .send_message(&messages, &selected_model.id)
+        .with_context(|| {
+            format!(
+                "AI script generation failed (attempted=send_message, model_id={}, provider_id={})",
+                selected_model.id, selected_model.provider
+            )
+        })?;
+
+    let extracted = extract_script_code(&raw_response);
+    if extracted.trim().is_empty() {
+        anyhow::bail!(
+            "AI returned an empty response for script generation (state=empty_response)"
+        );
+    }
+
+    let slug = slugify_script_name(normalized_prompt);
+    let finalized = enforce_script_kit_conventions(&extracted, normalized_prompt, &slug);
+    let path = write_generated_script(&slug, &finalized).with_context(|| {
+        format!(
+            "Failed writing AI-generated script (state=write_failed, slug={})",
+            slug
+        )
+    })?;
+
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=script_written path={} slug={}",
+            path.display(),
+            slug
+        ),
+    );
+
+    Ok(GeneratedScriptOutput {
+        path,
+        slug,
+        model_id: selected_model.id,
+        provider_id: selected_model.provider,
+    })
+}
+
+fn select_generation_model(registry: &ProviderRegistry) -> Result<(ModelInfo, Arc<dyn AiProvider>)> {
+    let models = registry.get_all_models();
+    let selected_model = models
+        .iter()
+        .find(|model| model.provider.eq_ignore_ascii_case("vercel"))
+        .or_else(|| models.first())
+        .cloned()
+        .context("No AI models available in provider registry")?;
+
+    let provider = registry
+        .find_provider_for_model(&selected_model.id)
+        .cloned()
+        .with_context(|| {
+            format!(
+                "No provider found for selected model '{}' (state=provider_missing)",
+                selected_model.id
+            )
+        })?;
+
+    Ok((selected_model, provider))
+}
+
+fn generated_scripts_dir() -> PathBuf {
+    PathBuf::from(shellexpand::tilde(AI_SCRIPT_OUTPUT_DIR).as_ref())
+}
+
+fn split_fence_header_and_body(fence: &str) -> (&str, &str) {
+    match fence.find('\n') {
+        Some(newline_index) => (&fence[..newline_index], &fence[newline_index + 1..]),
+        None => ("", fence),
+    }
+}
+
+fn extract_fenced_code(response: &str, preferred_languages: Option<&[&str]>) -> Option<String> {
+    let mut remaining = response;
+
+    while let Some(start) = remaining.find("```") {
+        let after_start = &remaining[start + 3..];
+        let Some(end) = after_start.find("```") else {
+            break;
+        };
+
+        let fence_contents = &after_start[..end];
+        let (header, body) = split_fence_header_and_body(fence_contents);
+        let language = header
+            .trim()
+            .split(|c: char| c.is_whitespace() || c == '{')
+            .next()
+            .unwrap_or("")
+            .to_ascii_lowercase();
+        let code = body.trim();
+
+        if !code.is_empty() {
+            match preferred_languages {
+                Some(preferred) => {
+                    if preferred.iter().any(|candidate| *candidate == language) {
+                        return Some(code.to_string());
+                    }
+                }
+                None => return Some(code.to_string()),
+            }
+        }
+
+        remaining = &after_start[end + 3..];
+    }
+
+    None
+}
+
+fn extract_script_code(response: &str) -> String {
+    const PREFERRED_LANGUAGES: [&str; 6] = ["typescript", "ts", "javascript", "js", "tsx", "jsx"];
+
+    extract_fenced_code(response, Some(&PREFERRED_LANGUAGES))
+        .or_else(|| extract_fenced_code(response, None))
+        .unwrap_or_else(|| response.trim().to_string())
+}
+
+fn slugify_script_name(prompt: &str) -> String {
+    let mut slug = String::new();
+    let mut last_was_hyphen = false;
+
+    for character in prompt.to_ascii_lowercase().chars() {
+        if character.is_ascii_alphanumeric() {
+            slug.push(character);
+            last_was_hyphen = false;
+        } else if matches!(character, ' ' | '_' | '-') {
+            if !slug.is_empty() && !last_was_hyphen {
+                slug.push('-');
+                last_was_hyphen = true;
+            }
+        }
+    }
+
+    while slug.ends_with('-') {
+        slug.pop();
+    }
+
+    if slug.len() > AI_SCRIPT_MAX_SLUG_LEN {
+        slug.truncate(AI_SCRIPT_MAX_SLUG_LEN);
+        while slug.ends_with('-') {
+            slug.pop();
+        }
+    }
+
+    if slug.is_empty() {
+        AI_SCRIPT_DEFAULT_SLUG.to_string()
+    } else {
+        slug
+    }
+}
+
+fn slug_to_title(slug: &str) -> String {
+    slug.split('-')
+        .filter(|segment| !segment.is_empty())
+        .map(|segment| {
+            let mut chars = segment.chars();
+            match chars.next() {
+                Some(first) => first.to_uppercase().collect::<String>() + chars.as_str(),
+                None => String::new(),
+            }
+        })
+        .collect::<Vec<_>>()
+        .join(" ")
+}
+
+fn description_from_prompt(prompt: &str) -> String {
+    let normalized = prompt.split_whitespace().collect::<Vec<_>>().join(" ");
+    if normalized.is_empty() {
+        return "AI-generated Script Kit script".to_string();
+    }
+
+    let mut shortened = normalized;
+    if shortened.chars().count() > 110 {
+        shortened = format!("{}...", shortened.chars().take(107).collect::<String>());
+    }
+    shortened
+}
+
+fn has_kit_import(script: &str) -> bool {
+    script.contains("import \"@johnlindquist/kit\";")
+        || script.contains("import '@johnlindquist/kit';")
+        || script.contains("import \"@scriptkit/sdk\";")
+        || script.contains("import '@scriptkit/sdk';")
+}
+
+fn enforce_script_kit_conventions(script: &str, prompt: &str, slug: &str) -> String {
+    let mut prefix_lines: Vec<String> = Vec::new();
+    let trimmed_script = script.trim();
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Name:"))
+    {
+        prefix_lines.push(format!("// Name: {}", slug_to_title(slug)));
+    }
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Description:"))
+    {
+        prefix_lines.push(format!("// Description: {}", description_from_prompt(prompt)));
+    }
+
+    if !has_kit_import(trimmed_script) {
+        prefix_lines.push("import \"@johnlindquist/kit\";".to_string());
+    }
+
+    let mut output = String::new();
+    if !prefix_lines.is_empty() {
+        output.push_str(&prefix_lines.join("\n"));
+        output.push_str("\n\n");
+    }
+
+    output.push_str(trimmed_script);
+    if !output.ends_with('\n') {
+        output.push('\n');
+    }
+    output
+}
+
+fn write_generated_script(slug: &str, script_content: &str) -> Result<PathBuf> {
+    write_generated_script_in_dir(&generated_scripts_dir(), slug, script_content)
+}
+
+fn write_generated_script_in_dir(output_dir: &Path, slug: &str, script_content: &str) -> Result<PathBuf> {
+    fs::create_dir_all(output_dir)
+        .with_context(|| format!("Failed to create output dir: {}", output_dir.display()))?;
+
+    for suffix in 0usize.. {
+        let candidate = if suffix == 0 {
+            slug.to_string()
+        } else {
+            format!("{slug}-{suffix}")
+        };
+        let path = output_dir.join(format!("{}.ts", candidate));
+        match OpenOptions::new().write(true).create_new(true).open(&path) {
+            Ok(mut file) => {
+                file.write_all(script_content.as_bytes())
+                    .with_context(|| format!("Failed writing generated script to {}", path.display()))?;
+                return Ok(path);
+            }
+            Err(error) if error.kind() == ErrorKind::AlreadyExists => continue,
+            Err(error) => {
+                return Err(error).with_context(|| {
+                    format!(
+                        "Failed creating generated script file {} (slug={})",
+                        path.display(),
+                        slug
+                    )
+                });
+            }
+        }
+    }
+
+    unreachable!("suffix loop should eventually create a unique script filename")
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+    use tempfile::tempdir;
+
+    #[test]
+    fn test_slugify_script_name_handles_spaces_and_symbols() {
+        assert_eq!(slugify_script_name("Build: API Client!"), "build-api-client");
+        assert_eq!(slugify_script_name("  ___  "), "ai-script");
+    }
+
+    #[test]
+    fn test_extract_script_code_prefers_typescript_fence_when_multiple_blocks_exist() {
+        let response = r#"
+Here's one idea:
+```markdown
+Not code
+```
+```typescript
+await div("hello");
+```
+"#;
+        assert_eq!(extract_script_code(response), "await div(\"hello\");");
+    }
+
+    #[test]
+    fn test_extract_script_code_falls_back_to_first_fenced_block() {
+        let response = r#"
+```python
+print("hello")
+```
+"#;
+        assert_eq!(extract_script_code(response), "print(\"hello\")");
+    }
+
+    #[test]
+    fn test_extract_script_code_returns_trimmed_response_when_no_fence_exists() {
+        let response = "const answer = 42;";
+        assert_eq!(extract_script_code(response), "const answer = 42;");
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_adds_missing_metadata_and_import() {
+        let script = "const name = await arg(\"Name?\");";
+        let output = enforce_script_kit_conventions(script, "Ask for user name", "ask-user-name");
+
+        assert!(output.contains("// Name: Ask User Name"));
+        assert!(output.contains("// Description: Ask for user name"));
+        assert!(output.contains("import \"@johnlindquist/kit\";"));
+        assert!(output.contains("await arg(\"Name?\");"));
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_keeps_existing_metadata_and_import() {
+        let script = r#"// Name: Existing
+// Description: Existing description
+import "@johnlindquist/kit";
+
+await div("ready");
+"#;
+        let output = enforce_script_kit_conventions(script, "ignored", "ignored");
+
+        assert_eq!(
+            output.matches("// Name:").count(),
+            1,
+            "should not duplicate existing Name metadata"
+        );
+        assert_eq!(
+            output.matches("// Description:").count(),
+            1,
+            "should not duplicate existing Description metadata"
+        );
+        assert_eq!(
+            output.matches("import \"@johnlindquist/kit\";").count(),
+            1,
+            "should not duplicate existing import"
+        );
+    }
+
+    #[test]
+    fn test_write_generated_script_in_dir_appends_numeric_suffix_for_collisions() {
+        let temp_dir = tempdir().unwrap();
+        let first = write_generated_script_in_dir(temp_dir.path(), "my-script", "a").unwrap();
+        let second = write_generated_script_in_dir(temp_dir.path(), "my-script", "b").unwrap();
+
+        assert_eq!(first.file_name().unwrap(), "my-script.ts");
+        assert_eq!(second.file_name().unwrap(), "my-script-1.ts");
+    }
+}
diff --git a/src/builtins/part_000.rs b/src/builtins/part_000.rs
index d6b9c2a9b35b40c5005dbb9f65147f528702cb9e..5f6d27d28d72e51126d10d8beccf931c689ef2bb
--- a/src/builtins/part_000.rs
+++ b/src/builtins/part_000.rs
@@ -96,6 +96,8 @@
     OpenAi,
     NewConversation,
     ClearConversation,
+    /// Generate a new Script Kit script from the main prompt text
+    GenerateScript,
     /// Send a screenshot of the entire screen to AI Chat
     SendScreenToAi,
     /// Send a screenshot of the focused window to AI Chat
diff --git a/src/builtins/part_001_entries/entries_002.rs b/src/builtins/part_001_entries/entries_002.rs
index 6d1c9334f0ccaf0aab48582aaf42dcb129e1cb6e..72b318c66aeaf124359f4ecd276dae0350287328
--- a/src/builtins/part_001_entries/entries_002.rs
+++ b/src/builtins/part_001_entries/entries_002.rs
@@ -61,6 +61,17 @@
     ));
 
     entries.push(BuiltInEntry::new_with_icon(
+        "builtin-generate-script-with-ai",
+        "Generate Script with AI",
+        "Generate a Script Kit script from your current prompt text",
+        vec![
+            "generate", "script", "ai", "create", "code", "typescript", "shift", "tab",
+        ],
+        BuiltInFeature::AiCommand(AiCommandType::GenerateScript),
+        "ðŸ§ ",
+    ));
+
+    entries.push(BuiltInEntry::new_with_icon(
         "builtin-send-screen-to-ai",
         "Send Screen to AI Chat",
         "Capture the full screen and send it to AI Chat",


thinking
**Assessing AI helper integration**
exec
/bin/zsh -lc "rg -n \"fn open_in_editor\" -n src/script_creation -S && sed -n '1,220p' src/script_creation/mod.rs" in /Users/johnlindquist/dev/script-kit-gpui succeeded in 51ms:
src/script_creation/part_000.rs:403:pub fn open_in_editor(path: &Path, config: &Config) -> Result<()> {
//! Script and Extension Creation Module
//!
//! This module provides functions to create new scripts and extensions
//! in the Script Kit environment, as well as opening files in the configured editor.
//!
//! # Usage
//!
//! ```rust,ignore
//! use script_kit_gpui::script_creation::{create_new_script, create_new_extension, open_in_editor};
//! use script_kit_gpui::config::Config;
//!
//! // Create a new script
//! let script_path = create_new_script("my-script")?;
//!
//! // Create a new extension
//! let extension_path = create_new_extension("my-extension")?;
//!
//! // Open in editor
//! let config = Config::default();
file update:
diff --git a/src/ai/mod.rs b/src/ai/mod.rs
index a420b1a5faf59506acdb7caf60681c153a3f9bb6..9a73e9491862633b325b2c52b51a3e20395ff85c
--- a/src/ai/mod.rs
+++ b/src/ai/mod.rs
@@ -37,6 +37,7 @@
 pub(crate) mod providers;
 pub(crate) mod sdk_handlers;
 pub(crate) mod session;
+pub(crate) mod script_generation;
 pub(crate) mod storage;
 pub(crate) mod window;
 
@@ -44,6 +45,7 @@
 pub use self::config::{DetectedKeys, ModelInfo, ProviderConfig};
 pub use self::model::{Chat, ChatId, ChatSource, Message, MessageRole};
 pub use self::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+pub use self::script_generation::{generate_script_from_prompt, GeneratedScriptOutput};
 pub use self::sdk_handlers::try_handle_ai_message;
 pub use self::storage::{
     clear_all_chats, create_chat, delete_chat, get_all_chats, get_chat, get_chat_messages,
diff --git a/src/ai/script_generation.rs b/src/ai/script_generation.rs
new file mode 100644
index 0000000000000000000000000000000000000000..7f2ec8e7576ed50cd10f7aea31a6522875ef667a
--- /dev/null
+++ b/src/ai/script_generation.rs
@@ -0,0 +1,417 @@
+use anyhow::{Context, Result};
+use std::fs::{self, OpenOptions};
+use std::io::{ErrorKind, Write};
+use std::path::{Path, PathBuf};
+use std::sync::Arc;
+
+use super::config::ModelInfo;
+use super::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+
+const AI_SCRIPT_OUTPUT_DIR: &str = "~/.kenv/scripts";
+const AI_SCRIPT_DEFAULT_SLUG: &str = "ai-script";
+const AI_SCRIPT_MAX_SLUG_LEN: usize = 64;
+
+const AI_SCRIPT_GENERATION_SYSTEM_PROMPT: &str = r#"You write production-ready Script Kit scripts.
+
+Return ONLY TypeScript source code for one Script Kit script. Do not include explanations.
+
+Required output conventions:
+1) Include metadata comments at the top:
+   // Name: <clear title>
+   // Description: <one-line summary>
+2) Include: import "@johnlindquist/kit";
+3) Use await arg() for user input when useful.
+4) Use await div() for display output when useful.
+5) Keep the script runnable as-is with sensible defaults and light error handling."#;
+
+#[derive(Debug, Clone)]
+pub struct GeneratedScriptOutput {
+    pub path: PathBuf,
+    pub slug: String,
+    pub model_id: String,
+    pub provider_id: String,
+}
+
+pub fn generate_script_from_prompt(
+    prompt: &str,
+    config: Option<&crate::config::Config>,
+) -> Result<GeneratedScriptOutput> {
+    let normalized_prompt = prompt.trim();
+    if normalized_prompt.is_empty() {
+        anyhow::bail!("AI script generation requires a non-empty prompt");
+    }
+
+    let registry = ProviderRegistry::from_environment_with_config(config);
+    if !registry.has_any_provider() {
+        anyhow::bail!(
+            "No AI providers configured. Configure an API key first (Vercel, OpenAI, Anthropic, etc.)."
+        );
+    }
+
+    let (selected_model, provider) = select_generation_model(&registry)?;
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=provider_ready model_id={} provider_id={} prompt_len={}",
+            selected_model.id,
+            selected_model.provider,
+            normalized_prompt.len()
+        ),
+    );
+
+    let messages = vec![
+        ProviderMessage::system(AI_SCRIPT_GENERATION_SYSTEM_PROMPT),
+        ProviderMessage::user(format!(
+            "Generate a Script Kit script for this user request:\n\n{}",
+            normalized_prompt
+        )),
+    ];
+
+    let raw_response = provider
+        .send_message(&messages, &selected_model.id)
+        .with_context(|| {
+            format!(
+                "AI script generation failed (attempted=send_message, model_id={}, provider_id={})",
+                selected_model.id, selected_model.provider
+            )
+        })?;
+
+    let extracted = extract_script_code(&raw_response);
+    if extracted.trim().is_empty() {
+        anyhow::bail!(
+            "AI returned an empty response for script generation (state=empty_response)"
+        );
+    }
+
+    let slug = slugify_script_name(normalized_prompt);
+    let finalized = enforce_script_kit_conventions(&extracted, normalized_prompt, &slug);
+    let path = write_generated_script(&slug, &finalized).with_context(|| {
+        format!(
+            "Failed writing AI-generated script (state=write_failed, slug={})",
+            slug
+        )
+    })?;
+
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=script_written path={} slug={}",
+            path.display(),
+            slug
+        ),
+    );
+
+    Ok(GeneratedScriptOutput {
+        path,
+        slug,
+        model_id: selected_model.id,
+        provider_id: selected_model.provider,
+    })
+}
+
+fn select_generation_model(registry: &ProviderRegistry) -> Result<(ModelInfo, Arc<dyn AiProvider>)> {
+    let models = registry.get_all_models();
+    let selected_model = models
+        .iter()
+        .find(|model| model.provider.eq_ignore_ascii_case("vercel"))
+        .or_else(|| models.first())
+        .cloned()
+        .context("No AI models available in provider registry")?;
+
+    let provider = registry
+        .find_provider_for_model(&selected_model.id)
+        .cloned()
+        .with_context(|| {
+            format!(
+                "No provider found for selected model '{}' (state=provider_missing)",
+                selected_model.id
+            )
+        })?;
+
+    Ok((selected_model, provider))
+}
+
+fn generated_scripts_dir() -> PathBuf {
+    PathBuf::from(shellexpand::tilde(AI_SCRIPT_OUTPUT_DIR).as_ref())
+}
+
+fn split_fence_header_and_body(fence: &str) -> (&str, &str) {
+    match fence.find('\n') {
+        Some(newline_index) => (&fence[..newline_index], &fence[newline_index + 1..]),
+        None => ("", fence),
+    }
+}
+
+fn extract_fenced_code(response: &str, preferred_languages: Option<&[&str]>) -> Option<String> {
+    let mut remaining = response;
+
+    while let Some(start) = remaining.find("```") {
+        let after_start = &remaining[start + 3..];
+        let Some(end) = after_start.find("```") else {
+            break;
+        };
+
+        let fence_contents = &after_start[..end];
+        let (header, body) = split_fence_header_and_body(fence_contents);
+        let language = header
+            .trim()
+            .split(|c: char| c.is_whitespace() || c == '{')
+            .next()
+            .unwrap_or("")
+            .to_ascii_lowercase();
+        let code = body.trim();
+
+        if !code.is_empty() {
+            match preferred_languages {
+                Some(preferred) => {
+                    if preferred.iter().any(|candidate| *candidate == language) {
+                        return Some(code.to_string());
+                    }
+                }
+                None => return Some(code.to_string()),
+            }
+        }
+
+        remaining = &after_start[end + 3..];
+    }
+
+    None
+}
+
+fn extract_script_code(response: &str) -> String {
+    const PREFERRED_LANGUAGES: [&str; 6] = ["typescript", "ts", "javascript", "js", "tsx", "jsx"];
+
+    extract_fenced_code(response, Some(&PREFERRED_LANGUAGES))
+        .or_else(|| extract_fenced_code(response, None))
+        .unwrap_or_else(|| response.trim().to_string())
+}
+
+fn slugify_script_name(prompt: &str) -> String {
+    let mut slug = String::new();
+    let mut last_was_hyphen = false;
+
+    for character in prompt.to_ascii_lowercase().chars() {
+        if character.is_ascii_alphanumeric() {
+            slug.push(character);
+            last_was_hyphen = false;
+        } else if matches!(character, ' ' | '_' | '-') {
+            if !slug.is_empty() && !last_was_hyphen {
+                slug.push('-');
+                last_was_hyphen = true;
+            }
+        }
+    }
+
+    while slug.ends_with('-') {
+        slug.pop();
+    }
+
+    if slug.len() > AI_SCRIPT_MAX_SLUG_LEN {
+        slug.truncate(AI_SCRIPT_MAX_SLUG_LEN);
+        while slug.ends_with('-') {
+            slug.pop();
+        }
+    }
+
+    if slug.is_empty() {
+        AI_SCRIPT_DEFAULT_SLUG.to_string()
+    } else {
+        slug
+    }
+}
+
+fn slug_to_title(slug: &str) -> String {
+    slug.split('-')
+        .filter(|segment| !segment.is_empty())
+        .map(|segment| {
+            let mut chars = segment.chars();
+            match chars.next() {
+                Some(first) => first.to_uppercase().collect::<String>() + chars.as_str(),
+                None => String::new(),
+            }
+        })
+        .collect::<Vec<_>>()
+        .join(" ")
+}
+
+fn description_from_prompt(prompt: &str) -> String {
+    let normalized = prompt.split_whitespace().collect::<Vec<_>>().join(" ");
+    if normalized.is_empty() {
+        return "AI-generated Script Kit script".to_string();
+    }
+
+    let mut shortened = normalized;
+    if shortened.chars().count() > 110 {
+        shortened = format!("{}...", shortened.chars().take(107).collect::<String>());
+    }
+    shortened
+}
+
+fn has_kit_import(script: &str) -> bool {
+    script.contains("import \"@johnlindquist/kit\";")
+        || script.contains("import '@johnlindquist/kit';")
+        || script.contains("import \"@scriptkit/sdk\";")
+        || script.contains("import '@scriptkit/sdk';")
+}
+
+fn enforce_script_kit_conventions(script: &str, prompt: &str, slug: &str) -> String {
+    let mut prefix_lines: Vec<String> = Vec::new();
+    let trimmed_script = script.trim();
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Name:"))
+    {
+        prefix_lines.push(format!("// Name: {}", slug_to_title(slug)));
+    }
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Description:"))
+    {
+        prefix_lines.push(format!("// Description: {}", description_from_prompt(prompt)));
+    }
+
+    if !has_kit_import(trimmed_script) {
+        prefix_lines.push("import \"@johnlindquist/kit\";".to_string());
+    }
+
+    let mut output = String::new();
+    if !prefix_lines.is_empty() {
+        output.push_str(&prefix_lines.join("\n"));
+        output.push_str("\n\n");
+    }
+
+    output.push_str(trimmed_script);
+    if !output.ends_with('\n') {
+        output.push('\n');
+    }
+    output
+}
+
+fn write_generated_script(slug: &str, script_content: &str) -> Result<PathBuf> {
+    write_generated_script_in_dir(&generated_scripts_dir(), slug, script_content)
+}
+
+fn write_generated_script_in_dir(output_dir: &Path, slug: &str, script_content: &str) -> Result<PathBuf> {
+    fs::create_dir_all(output_dir)
+        .with_context(|| format!("Failed to create output dir: {}", output_dir.display()))?;
+
+    for suffix in 0usize.. {
+        let candidate = if suffix == 0 {
+            slug.to_string()
+        } else {
+            format!("{slug}-{suffix}")
+        };
+        let path = output_dir.join(format!("{}.ts", candidate));
+        match OpenOptions::new().write(true).create_new(true).open(&path) {
+            Ok(mut file) => {
+                file.write_all(script_content.as_bytes())
+                    .with_context(|| format!("Failed writing generated script to {}", path.display()))?;
+                return Ok(path);
+            }
+            Err(error) if error.kind() == ErrorKind::AlreadyExists => continue,
+            Err(error) => {
+                return Err(error).with_context(|| {
+                    format!(
+                        "Failed creating generated script file {} (slug={})",
+                        path.display(),
+                        slug
+                    )
+                });
+            }
+        }
+    }
+
+    unreachable!("suffix loop should eventually create a unique script filename")
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+    use tempfile::tempdir;
+
+    #[test]
+    fn test_slugify_script_name_handles_spaces_and_symbols() {
+        assert_eq!(slugify_script_name("Build: API Client!"), "build-api-client");
+        assert_eq!(slugify_script_name("  ___  "), "ai-script");
+    }
+
+    #[test]
+    fn test_extract_script_code_prefers_typescript_fence_when_multiple_blocks_exist() {
+        let response = r#"
+Here's one idea:
+```markdown
+Not code
+```
+```typescript
+await div("hello");
+```
+"#;
+        assert_eq!(extract_script_code(response), "await div(\"hello\");");
+    }
+
+    #[test]
+    fn test_extract_script_code_falls_back_to_first_fenced_block() {
+        let response = r#"
+```python
+print("hello")
+```
+"#;
+        assert_eq!(extract_script_code(response), "print(\"hello\")");
+    }
+
+    #[test]
+    fn test_extract_script_code_returns_trimmed_response_when_no_fence_exists() {
+        let response = "const answer = 42;";
+        assert_eq!(extract_script_code(response), "const answer = 42;");
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_adds_missing_metadata_and_import() {
+        let script = "const name = await arg(\"Name?\");";
+        let output = enforce_script_kit_conventions(script, "Ask for user name", "ask-user-name");
+
+        assert!(output.contains("// Name: Ask User Name"));
+        assert!(output.contains("// Description: Ask for user name"));
+        assert!(output.contains("import \"@johnlindquist/kit\";"));
+        assert!(output.contains("await arg(\"Name?\");"));
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_keeps_existing_metadata_and_import() {
+        let script = r#"// Name: Existing
+// Description: Existing description
+import "@johnlindquist/kit";
+
+await div("ready");
+"#;
+        let output = enforce_script_kit_conventions(script, "ignored", "ignored");
+
+        assert_eq!(
+            output.matches("// Name:").count(),
+            1,
+            "should not duplicate existing Name metadata"
+        );
+        assert_eq!(
+            output.matches("// Description:").count(),
+            1,
+            "should not duplicate existing Description metadata"
+        );
+        assert_eq!(
+            output.matches("import \"@johnlindquist/kit\";").count(),
+            1,
+            "should not duplicate existing import"
+        );
+    }
+
+    #[test]
+    fn test_write_generated_script_in_dir_appends_numeric_suffix_for_collisions() {
+        let temp_dir = tempdir().unwrap();
+        let first = write_generated_script_in_dir(temp_dir.path(), "my-script", "a").unwrap();
+        let second = write_generated_script_in_dir(temp_dir.path(), "my-script", "b").unwrap();
+
+        assert_eq!(first.file_name().unwrap(), "my-script.ts");
+        assert_eq!(second.file_name().unwrap(), "my-script-1.ts");
+    }
+}
diff --git a/src/builtins/part_000.rs b/src/builtins/part_000.rs
index d6b9c2a9b35b40c5005dbb9f65147f528702cb9e..5f6d27d28d72e51126d10d8beccf931c689ef2bb
--- a/src/builtins/part_000.rs
+++ b/src/builtins/part_000.rs
@@ -96,6 +96,8 @@
     OpenAi,
     NewConversation,
     ClearConversation,
+    /// Generate a new Script Kit script from the main prompt text
+    GenerateScript,
     /// Send a screenshot of the entire screen to AI Chat
     SendScreenToAi,
     /// Send a screenshot of the focused window to AI Chat
diff --git a/src/builtins/part_001_entries/entries_002.rs b/src/builtins/part_001_entries/entries_002.rs
index 6d1c9334f0ccaf0aab48582aaf42dcb129e1cb6e..72b318c66aeaf124359f4ecd276dae0350287328
--- a/src/builtins/part_001_entries/entries_002.rs
+++ b/src/builtins/part_001_entries/entries_002.rs
@@ -61,6 +61,17 @@
     ));
 
     entries.push(BuiltInEntry::new_with_icon(
+        "builtin-generate-script-with-ai",
+        "Generate Script with AI",
+        "Generate a Script Kit script from your current prompt text",
+        vec![
+            "generate", "script", "ai", "create", "code", "typescript", "shift", "tab",
+        ],
+        BuiltInFeature::AiCommand(AiCommandType::GenerateScript),
+        "ðŸ§ ",
+    ));
+
+    entries.push(BuiltInEntry::new_with_icon(
         "builtin-send-screen-to-ai",
         "Send Screen to AI Chat",
         "Capture the full screen and send it to AI Chat",


thinking
**Considering function body contents**
exec
/bin/zsh -lc "sed -n '360,500p' src/script_creation/part_000.rs" in /Users/johnlindquist/dev/script-kit-gpui succeeded in 51ms:
                    if let Some(next) = chars.next() {
                        current.push(next);
                    } else {
                        current.push(ch);
                    }
                } else {
                    current.push(ch);
                }
            }
            None => match ch {
                '\'' | '"' => quote = Some(ch),
                '\\' => {
                    if let Some(next) = chars.next() {
                        current.push(next);
                    } else {
                        current.push(ch);
                    }
                }
                c if c.is_whitespace() => {
                    if !current.is_empty() {
file update:
diff --git a/src/ai/mod.rs b/src/ai/mod.rs
index a420b1a5faf59506acdb7caf60681c153a3f9bb6..9a73e9491862633b325b2c52b51a3e20395ff85c
--- a/src/ai/mod.rs
+++ b/src/ai/mod.rs
@@ -37,6 +37,7 @@
 pub(crate) mod providers;
 pub(crate) mod sdk_handlers;
 pub(crate) mod session;
+pub(crate) mod script_generation;
 pub(crate) mod storage;
 pub(crate) mod window;
 
@@ -44,6 +45,7 @@
 pub use self::config::{DetectedKeys, ModelInfo, ProviderConfig};
 pub use self::model::{Chat, ChatId, ChatSource, Message, MessageRole};
 pub use self::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+pub use self::script_generation::{generate_script_from_prompt, GeneratedScriptOutput};
 pub use self::sdk_handlers::try_handle_ai_message;
 pub use self::storage::{
     clear_all_chats, create_chat, delete_chat, get_all_chats, get_chat, get_chat_messages,
diff --git a/src/ai/script_generation.rs b/src/ai/script_generation.rs
new file mode 100644
index 0000000000000000000000000000000000000000..7f2ec8e7576ed50cd10f7aea31a6522875ef667a
--- /dev/null
+++ b/src/ai/script_generation.rs
@@ -0,0 +1,417 @@
+use anyhow::{Context, Result};
+use std::fs::{self, OpenOptions};
+use std::io::{ErrorKind, Write};
+use std::path::{Path, PathBuf};
+use std::sync::Arc;
+
+use super::config::ModelInfo;
+use super::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+
+const AI_SCRIPT_OUTPUT_DIR: &str = "~/.kenv/scripts";
+const AI_SCRIPT_DEFAULT_SLUG: &str = "ai-script";
+const AI_SCRIPT_MAX_SLUG_LEN: usize = 64;
+
+const AI_SCRIPT_GENERATION_SYSTEM_PROMPT: &str = r#"You write production-ready Script Kit scripts.
+
+Return ONLY TypeScript source code for one Script Kit script. Do not include explanations.
+
+Required output conventions:
+1) Include metadata comments at the top:
+   // Name: <clear title>
+   // Description: <one-line summary>
+2) Include: import "@johnlindquist/kit";
+3) Use await arg() for user input when useful.
+4) Use await div() for display output when useful.
+5) Keep the script runnable as-is with sensible defaults and light error handling."#;
+
+#[derive(Debug, Clone)]
+pub struct GeneratedScriptOutput {
+    pub path: PathBuf,
+    pub slug: String,
+    pub model_id: String,
+    pub provider_id: String,
+}
+
+pub fn generate_script_from_prompt(
+    prompt: &str,
+    config: Option<&crate::config::Config>,
+) -> Result<GeneratedScriptOutput> {
+    let normalized_prompt = prompt.trim();
+    if normalized_prompt.is_empty() {
+        anyhow::bail!("AI script generation requires a non-empty prompt");
+    }
+
+    let registry = ProviderRegistry::from_environment_with_config(config);
+    if !registry.has_any_provider() {
+        anyhow::bail!(
+            "No AI providers configured. Configure an API key first (Vercel, OpenAI, Anthropic, etc.)."
+        );
+    }
+
+    let (selected_model, provider) = select_generation_model(&registry)?;
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=provider_ready model_id={} provider_id={} prompt_len={}",
+            selected_model.id,
+            selected_model.provider,
+            normalized_prompt.len()
+        ),
+    );
+
+    let messages = vec![
+        ProviderMessage::system(AI_SCRIPT_GENERATION_SYSTEM_PROMPT),
+        ProviderMessage::user(format!(
+            "Generate a Script Kit script for this user request:\n\n{}",
+            normalized_prompt
+        )),
+    ];
+
+    let raw_response = provider
+        .send_message(&messages, &selected_model.id)
+        .with_context(|| {
+            format!(
+                "AI script generation failed (attempted=send_message, model_id={}, provider_id={})",
+                selected_model.id, selected_model.provider
+            )
+        })?;
+
+    let extracted = extract_script_code(&raw_response);
+    if extracted.trim().is_empty() {
+        anyhow::bail!(
+            "AI returned an empty response for script generation (state=empty_response)"
+        );
+    }
+
+    let slug = slugify_script_name(normalized_prompt);
+    let finalized = enforce_script_kit_conventions(&extracted, normalized_prompt, &slug);
+    let path = write_generated_script(&slug, &finalized).with_context(|| {
+        format!(
+            "Failed writing AI-generated script (state=write_failed, slug={})",
+            slug
+        )
+    })?;
+
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=script_written path={} slug={}",
+            path.display(),
+            slug
+        ),
+    );
+
+    Ok(GeneratedScriptOutput {
+        path,
+        slug,
+        model_id: selected_model.id,
+        provider_id: selected_model.provider,
+    })
+}
+
+fn select_generation_model(registry: &ProviderRegistry) -> Result<(ModelInfo, Arc<dyn AiProvider>)> {
+    let models = registry.get_all_models();
+    let selected_model = models
+        .iter()
+        .find(|model| model.provider.eq_ignore_ascii_case("vercel"))
+        .or_else(|| models.first())
+        .cloned()
+        .context("No AI models available in provider registry")?;
+
+    let provider = registry
+        .find_provider_for_model(&selected_model.id)
+        .cloned()
+        .with_context(|| {
+            format!(
+                "No provider found for selected model '{}' (state=provider_missing)",
+                selected_model.id
+            )
+        })?;
+
+    Ok((selected_model, provider))
+}
+
+fn generated_scripts_dir() -> PathBuf {
+    PathBuf::from(shellexpand::tilde(AI_SCRIPT_OUTPUT_DIR).as_ref())
+}
+
+fn split_fence_header_and_body(fence: &str) -> (&str, &str) {
+    match fence.find('\n') {
+        Some(newline_index) => (&fence[..newline_index], &fence[newline_index + 1..]),
+        None => ("", fence),
+    }
+}
+
+fn extract_fenced_code(response: &str, preferred_languages: Option<&[&str]>) -> Option<String> {
+    let mut remaining = response;
+
+    while let Some(start) = remaining.find("```") {
+        let after_start = &remaining[start + 3..];
+        let Some(end) = after_start.find("```") else {
+            break;
+        };
+
+        let fence_contents = &after_start[..end];
+        let (header, body) = split_fence_header_and_body(fence_contents);
+        let language = header
+            .trim()
+            .split(|c: char| c.is_whitespace() || c == '{')
+            .next()
+            .unwrap_or("")
+            .to_ascii_lowercase();
+        let code = body.trim();
+
+        if !code.is_empty() {
+            match preferred_languages {
+                Some(preferred) => {
+                    if preferred.iter().any(|candidate| *candidate == language) {
+                        return Some(code.to_string());
+                    }
+                }
+                None => return Some(code.to_string()),
+            }
+        }
+
+        remaining = &after_start[end + 3..];
+    }
+
+    None
+}
+
+fn extract_script_code(response: &str) -> String {
+    const PREFERRED_LANGUAGES: [&str; 6] = ["typescript", "ts", "javascript", "js", "tsx", "jsx"];
+
+    extract_fenced_code(response, Some(&PREFERRED_LANGUAGES))
+        .or_else(|| extract_fenced_code(response, None))
+        .unwrap_or_else(|| response.trim().to_string())
+}
+
+fn slugify_script_name(prompt: &str) -> String {
+    let mut slug = String::new();
+    let mut last_was_hyphen = false;
+
+    for character in prompt.to_ascii_lowercase().chars() {
+        if character.is_ascii_alphanumeric() {
+            slug.push(character);
+            last_was_hyphen = false;
+        } else if matches!(character, ' ' | '_' | '-') {
+            if !slug.is_empty() && !last_was_hyphen {
+                slug.push('-');
+                last_was_hyphen = true;
+            }
+        }
+    }
+
+    while slug.ends_with('-') {
+        slug.pop();
+    }
+
+    if slug.len() > AI_SCRIPT_MAX_SLUG_LEN {
+        slug.truncate(AI_SCRIPT_MAX_SLUG_LEN);
+        while slug.ends_with('-') {
+            slug.pop();
+        }
+    }
+
+    if slug.is_empty() {
+        AI_SCRIPT_DEFAULT_SLUG.to_string()
+    } else {
+        slug
+    }
+}
+
+fn slug_to_title(slug: &str) -> String {
+    slug.split('-')
+        .filter(|segment| !segment.is_empty())
+        .map(|segment| {
+            let mut chars = segment.chars();
+            match chars.next() {
+                Some(first) => first.to_uppercase().collect::<String>() + chars.as_str(),
+                None => String::new(),
+            }
+        })
+        .collect::<Vec<_>>()
+        .join(" ")
+}
+
+fn description_from_prompt(prompt: &str) -> String {
+    let normalized = prompt.split_whitespace().collect::<Vec<_>>().join(" ");
+    if normalized.is_empty() {
+        return "AI-generated Script Kit script".to_string();
+    }
+
+    let mut shortened = normalized;
+    if shortened.chars().count() > 110 {
+        shortened = format!("{}...", shortened.chars().take(107).collect::<String>());
+    }
+    shortened
+}
+
+fn has_kit_import(script: &str) -> bool {
+    script.contains("import \"@johnlindquist/kit\";")
+        || script.contains("import '@johnlindquist/kit';")
+        || script.contains("import \"@scriptkit/sdk\";")
+        || script.contains("import '@scriptkit/sdk';")
+}
+
+fn enforce_script_kit_conventions(script: &str, prompt: &str, slug: &str) -> String {
+    let mut prefix_lines: Vec<String> = Vec::new();
+    let trimmed_script = script.trim();
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Name:"))
+    {
+        prefix_lines.push(format!("// Name: {}", slug_to_title(slug)));
+    }
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Description:"))
+    {
+        prefix_lines.push(format!("// Description: {}", description_from_prompt(prompt)));
+    }
+
+    if !has_kit_import(trimmed_script) {
+        prefix_lines.push("import \"@johnlindquist/kit\";".to_string());
+    }
+
+    let mut output = String::new();
+    if !prefix_lines.is_empty() {
+        output.push_str(&prefix_lines.join("\n"));
+        output.push_str("\n\n");
+    }
+
+    output.push_str(trimmed_script);
+    if !output.ends_with('\n') {
+        output.push('\n');
+    }
+    output
+}
+
+fn write_generated_script(slug: &str, script_content: &str) -> Result<PathBuf> {
+    write_generated_script_in_dir(&generated_scripts_dir(), slug, script_content)
+}
+
+fn write_generated_script_in_dir(output_dir: &Path, slug: &str, script_content: &str) -> Result<PathBuf> {
+    fs::create_dir_all(output_dir)
+        .with_context(|| format!("Failed to create output dir: {}", output_dir.display()))?;
+
+    for suffix in 0usize.. {
+        let candidate = if suffix == 0 {
+            slug.to_string()
+        } else {
+            format!("{slug}-{suffix}")
+        };
+        let path = output_dir.join(format!("{}.ts", candidate));
+        match OpenOptions::new().write(true).create_new(true).open(&path) {
+            Ok(mut file) => {
+                file.write_all(script_content.as_bytes())
+                    .with_context(|| format!("Failed writing generated script to {}", path.display()))?;
+                return Ok(path);
+            }
+            Err(error) if error.kind() == ErrorKind::AlreadyExists => continue,
+            Err(error) => {
+                return Err(error).with_context(|| {
+                    format!(
+                        "Failed creating generated script file {} (slug={})",
+                        path.display(),
+                        slug
+                    )
+                });
+            }
+        }
+    }
+
+    unreachable!("suffix loop should eventually create a unique script filename")
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+    use tempfile::tempdir;
+
+    #[test]
+    fn test_slugify_script_name_handles_spaces_and_symbols() {
+        assert_eq!(slugify_script_name("Build: API Client!"), "build-api-client");
+        assert_eq!(slugify_script_name("  ___  "), "ai-script");
+    }
+
+    #[test]
+    fn test_extract_script_code_prefers_typescript_fence_when_multiple_blocks_exist() {
+        let response = r#"
+Here's one idea:
+```markdown
+Not code
+```
+```typescript
+await div("hello");
+```
+"#;
+        assert_eq!(extract_script_code(response), "await div(\"hello\");");
+    }
+
+    #[test]
+    fn test_extract_script_code_falls_back_to_first_fenced_block() {
+        let response = r#"
+```python
+print("hello")
+```
+"#;
+        assert_eq!(extract_script_code(response), "print(\"hello\")");
+    }
+
+    #[test]
+    fn test_extract_script_code_returns_trimmed_response_when_no_fence_exists() {
+        let response = "const answer = 42;";
+        assert_eq!(extract_script_code(response), "const answer = 42;");
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_adds_missing_metadata_and_import() {
+        let script = "const name = await arg(\"Name?\");";
+        let output = enforce_script_kit_conventions(script, "Ask for user name", "ask-user-name");
+
+        assert!(output.contains("// Name: Ask User Name"));
+        assert!(output.contains("// Description: Ask for user name"));
+        assert!(output.contains("import \"@johnlindquist/kit\";"));
+        assert!(output.contains("await arg(\"Name?\");"));
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_keeps_existing_metadata_and_import() {
+        let script = r#"// Name: Existing
+// Description: Existing description
+import "@johnlindquist/kit";
+
+await div("ready");
+"#;
+        let output = enforce_script_kit_conventions(script, "ignored", "ignored");
+
+        assert_eq!(
+            output.matches("// Name:").count(),
+            1,
+            "should not duplicate existing Name metadata"
+        );
+        assert_eq!(
+            output.matches("// Description:").count(),
+            1,
+            "should not duplicate existing Description metadata"
+        );
+        assert_eq!(
+            output.matches("import \"@johnlindquist/kit\";").count(),
+            1,
+            "should not duplicate existing import"
+        );
+    }
+
+    #[test]
+    fn test_write_generated_script_in_dir_appends_numeric_suffix_for_collisions() {
+        let temp_dir = tempdir().unwrap();
+        let first = write_generated_script_in_dir(temp_dir.path(), "my-script", "a").unwrap();
+        let second = write_generated_script_in_dir(temp_dir.path(), "my-script", "b").unwrap();
+
+        assert_eq!(first.file_name().unwrap(), "my-script.ts");
+        assert_eq!(second.file_name().unwrap(), "my-script-1.ts");
+    }
+}
diff --git a/src/builtins/part_000.rs b/src/builtins/part_000.rs
index d6b9c2a9b35b40c5005dbb9f65147f528702cb9e..5f6d27d28d72e51126d10d8beccf931c689ef2bb
--- a/src/builtins/part_000.rs
+++ b/src/builtins/part_000.rs
@@ -96,6 +96,8 @@
     OpenAi,
     NewConversation,
     ClearConversation,
+    /// Generate a new Script Kit script from the main prompt text
+    GenerateScript,
     /// Send a screenshot of the entire screen to AI Chat
     SendScreenToAi,
     /// Send a screenshot of the focused window to AI Chat
diff --git a/src/builtins/part_001_entries/entries_002.rs b/src/builtins/part_001_entries/entries_002.rs
index 6d1c9334f0ccaf0aab48582aaf42dcb129e1cb6e..72b318c66aeaf124359f4ecd276dae0350287328
--- a/src/builtins/part_001_entries/entries_002.rs
+++ b/src/builtins/part_001_entries/entries_002.rs
@@ -61,6 +61,17 @@
     ));
 
     entries.push(BuiltInEntry::new_with_icon(
+        "builtin-generate-script-with-ai",
+        "Generate Script with AI",
+        "Generate a Script Kit script from your current prompt text",
+        vec![
+            "generate", "script", "ai", "create", "code", "typescript", "shift", "tab",
+        ],
+        BuiltInFeature::AiCommand(AiCommandType::GenerateScript),
+        "ðŸ§ ",
+    ));
+
+    entries.push(BuiltInEntry::new_with_icon(
         "builtin-send-screen-to-ai",
         "Send Screen to AI Chat",
         "Capture the full screen and send it to AI Chat",


thinking
**Assessing thread safety and state reset**
exec
/bin/zsh -lc "rg -n \"filter_text|reset_to_script_list\\(cx\\)|hide_main_window\\(|show_hud\\(\" src/app_execute/builtin_execution.rs | sed -n '1,200p'" in /Users/johnlindquist/dev/script-kit-gpui succeeded in 51ms:
143:                self.filter_text = String::new();
174:                self.filter_text = String::new();
222:                        self.filter_text = String::new();
254:                self.filter_text = String::new();
275:                self.reset_to_script_list(cx);
276:                platform::hide_main_window();
310:                self.reset_to_script_list(cx);
311:                platform::hide_main_window();
468:                                self.show_hud(message, Some(2000), cx);
516:                self.reset_to_script_list(cx);
517:                platform::hide_main_window();
549:                self.reset_to_script_list(cx);
550:                platform::hide_main_window();
593:                                    self.show_hud(
1017:                            self.reset_to_script_list(cx);
1096:                        self.filter_text = String::new();
1157:                            self.show_hud(
1163:                            self.show_hud(
1184:                            self.show_hud("No running scripts to stop.".to_string(), Some(2200), cx);
1187:                            self.show_hud(
file update:
diff --git a/src/ai/mod.rs b/src/ai/mod.rs
index a420b1a5faf59506acdb7caf60681c153a3f9bb6..9a73e9491862633b325b2c52b51a3e20395ff85c
--- a/src/ai/mod.rs
+++ b/src/ai/mod.rs
@@ -37,6 +37,7 @@
 pub(crate) mod providers;
 pub(crate) mod sdk_handlers;
 pub(crate) mod session;
+pub(crate) mod script_generation;
 pub(crate) mod storage;
 pub(crate) mod window;
 
@@ -44,6 +45,7 @@
 pub use self::config::{DetectedKeys, ModelInfo, ProviderConfig};
 pub use self::model::{Chat, ChatId, ChatSource, Message, MessageRole};
 pub use self::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+pub use self::script_generation::{generate_script_from_prompt, GeneratedScriptOutput};
 pub use self::sdk_handlers::try_handle_ai_message;
 pub use self::storage::{
     clear_all_chats, create_chat, delete_chat, get_all_chats, get_chat, get_chat_messages,
diff --git a/src/ai/script_generation.rs b/src/ai/script_generation.rs
new file mode 100644
index 0000000000000000000000000000000000000000..7f2ec8e7576ed50cd10f7aea31a6522875ef667a
--- /dev/null
+++ b/src/ai/script_generation.rs
@@ -0,0 +1,417 @@
+use anyhow::{Context, Result};
+use std::fs::{self, OpenOptions};
+use std::io::{ErrorKind, Write};
+use std::path::{Path, PathBuf};
+use std::sync::Arc;
+
+use super::config::ModelInfo;
+use super::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+
+const AI_SCRIPT_OUTPUT_DIR: &str = "~/.kenv/scripts";
+const AI_SCRIPT_DEFAULT_SLUG: &str = "ai-script";
+const AI_SCRIPT_MAX_SLUG_LEN: usize = 64;
+
+const AI_SCRIPT_GENERATION_SYSTEM_PROMPT: &str = r#"You write production-ready Script Kit scripts.
+
+Return ONLY TypeScript source code for one Script Kit script. Do not include explanations.
+
+Required output conventions:
+1) Include metadata comments at the top:
+   // Name: <clear title>
+   // Description: <one-line summary>
+2) Include: import "@johnlindquist/kit";
+3) Use await arg() for user input when useful.
+4) Use await div() for display output when useful.
+5) Keep the script runnable as-is with sensible defaults and light error handling."#;
+
+#[derive(Debug, Clone)]
+pub struct GeneratedScriptOutput {
+    pub path: PathBuf,
+    pub slug: String,
+    pub model_id: String,
+    pub provider_id: String,
+}
+
+pub fn generate_script_from_prompt(
+    prompt: &str,
+    config: Option<&crate::config::Config>,
+) -> Result<GeneratedScriptOutput> {
+    let normalized_prompt = prompt.trim();
+    if normalized_prompt.is_empty() {
+        anyhow::bail!("AI script generation requires a non-empty prompt");
+    }
+
+    let registry = ProviderRegistry::from_environment_with_config(config);
+    if !registry.has_any_provider() {
+        anyhow::bail!(
+            "No AI providers configured. Configure an API key first (Vercel, OpenAI, Anthropic, etc.)."
+        );
+    }
+
+    let (selected_model, provider) = select_generation_model(&registry)?;
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=provider_ready model_id={} provider_id={} prompt_len={}",
+            selected_model.id,
+            selected_model.provider,
+            normalized_prompt.len()
+        ),
+    );
+
+    let messages = vec![
+        ProviderMessage::system(AI_SCRIPT_GENERATION_SYSTEM_PROMPT),
+        ProviderMessage::user(format!(
+            "Generate a Script Kit script for this user request:\n\n{}",
+            normalized_prompt
+        )),
+    ];
+
+    let raw_response = provider
+        .send_message(&messages, &selected_model.id)
+        .with_context(|| {
+            format!(
+                "AI script generation failed (attempted=send_message, model_id={}, provider_id={})",
+                selected_model.id, selected_model.provider
+            )
+        })?;
+
+    let extracted = extract_script_code(&raw_response);
+    if extracted.trim().is_empty() {
+        anyhow::bail!(
+            "AI returned an empty response for script generation (state=empty_response)"
+        );
+    }
+
+    let slug = slugify_script_name(normalized_prompt);
+    let finalized = enforce_script_kit_conventions(&extracted, normalized_prompt, &slug);
+    let path = write_generated_script(&slug, &finalized).with_context(|| {
+        format!(
+            "Failed writing AI-generated script (state=write_failed, slug={})",
+            slug
+        )
+    })?;
+
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=script_written path={} slug={}",
+            path.display(),
+            slug
+        ),
+    );
+
+    Ok(GeneratedScriptOutput {
+        path,
+        slug,
+        model_id: selected_model.id,
+        provider_id: selected_model.provider,
+    })
+}
+
+fn select_generation_model(registry: &ProviderRegistry) -> Result<(ModelInfo, Arc<dyn AiProvider>)> {
+    let models = registry.get_all_models();
+    let selected_model = models
+        .iter()
+        .find(|model| model.provider.eq_ignore_ascii_case("vercel"))
+        .or_else(|| models.first())
+        .cloned()
+        .context("No AI models available in provider registry")?;
+
+    let provider = registry
+        .find_provider_for_model(&selected_model.id)
+        .cloned()
+        .with_context(|| {
+            format!(
+                "No provider found for selected model '{}' (state=provider_missing)",
+                selected_model.id
+            )
+        })?;
+
+    Ok((selected_model, provider))
+}
+
+fn generated_scripts_dir() -> PathBuf {
+    PathBuf::from(shellexpand::tilde(AI_SCRIPT_OUTPUT_DIR).as_ref())
+}
+
+fn split_fence_header_and_body(fence: &str) -> (&str, &str) {
+    match fence.find('\n') {
+        Some(newline_index) => (&fence[..newline_index], &fence[newline_index + 1..]),
+        None => ("", fence),
+    }
+}
+
+fn extract_fenced_code(response: &str, preferred_languages: Option<&[&str]>) -> Option<String> {
+    let mut remaining = response;
+
+    while let Some(start) = remaining.find("```") {
+        let after_start = &remaining[start + 3..];
+        let Some(end) = after_start.find("```") else {
+            break;
+        };
+
+        let fence_contents = &after_start[..end];
+        let (header, body) = split_fence_header_and_body(fence_contents);
+        let language = header
+            .trim()
+            .split(|c: char| c.is_whitespace() || c == '{')
+            .next()
+            .unwrap_or("")
+            .to_ascii_lowercase();
+        let code = body.trim();
+
+        if !code.is_empty() {
+            match preferred_languages {
+                Some(preferred) => {
+                    if preferred.iter().any(|candidate| *candidate == language) {
+                        return Some(code.to_string());
+                    }
+                }
+                None => return Some(code.to_string()),
+            }
+        }
+
+        remaining = &after_start[end + 3..];
+    }
+
+    None
+}
+
+fn extract_script_code(response: &str) -> String {
+    const PREFERRED_LANGUAGES: [&str; 6] = ["typescript", "ts", "javascript", "js", "tsx", "jsx"];
+
+    extract_fenced_code(response, Some(&PREFERRED_LANGUAGES))
+        .or_else(|| extract_fenced_code(response, None))
+        .unwrap_or_else(|| response.trim().to_string())
+}
+
+fn slugify_script_name(prompt: &str) -> String {
+    let mut slug = String::new();
+    let mut last_was_hyphen = false;
+
+    for character in prompt.to_ascii_lowercase().chars() {
+        if character.is_ascii_alphanumeric() {
+            slug.push(character);
+            last_was_hyphen = false;
+        } else if matches!(character, ' ' | '_' | '-') {
+            if !slug.is_empty() && !last_was_hyphen {
+                slug.push('-');
+                last_was_hyphen = true;
+            }
+        }
+    }
+
+    while slug.ends_with('-') {
+        slug.pop();
+    }
+
+    if slug.len() > AI_SCRIPT_MAX_SLUG_LEN {
+        slug.truncate(AI_SCRIPT_MAX_SLUG_LEN);
+        while slug.ends_with('-') {
+            slug.pop();
+        }
+    }
+
+    if slug.is_empty() {
+        AI_SCRIPT_DEFAULT_SLUG.to_string()
+    } else {
+        slug
+    }
+}
+
+fn slug_to_title(slug: &str) -> String {
+    slug.split('-')
+        .filter(|segment| !segment.is_empty())
+        .map(|segment| {
+            let mut chars = segment.chars();
+            match chars.next() {
+                Some(first) => first.to_uppercase().collect::<String>() + chars.as_str(),
+                None => String::new(),
+            }
+        })
+        .collect::<Vec<_>>()
+        .join(" ")
+}
+
+fn description_from_prompt(prompt: &str) -> String {
+    let normalized = prompt.split_whitespace().collect::<Vec<_>>().join(" ");
+    if normalized.is_empty() {
+        return "AI-generated Script Kit script".to_string();
+    }
+
+    let mut shortened = normalized;
+    if shortened.chars().count() > 110 {
+        shortened = format!("{}...", shortened.chars().take(107).collect::<String>());
+    }
+    shortened
+}
+
+fn has_kit_import(script: &str) -> bool {
+    script.contains("import \"@johnlindquist/kit\";")
+        || script.contains("import '@johnlindquist/kit';")
+        || script.contains("import \"@scriptkit/sdk\";")
+        || script.contains("import '@scriptkit/sdk';")
+}
+
+fn enforce_script_kit_conventions(script: &str, prompt: &str, slug: &str) -> String {
+    let mut prefix_lines: Vec<String> = Vec::new();
+    let trimmed_script = script.trim();
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Name:"))
+    {
+        prefix_lines.push(format!("// Name: {}", slug_to_title(slug)));
+    }
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Description:"))
+    {
+        prefix_lines.push(format!("// Description: {}", description_from_prompt(prompt)));
+    }
+
+    if !has_kit_import(trimmed_script) {
+        prefix_lines.push("import \"@johnlindquist/kit\";".to_string());
+    }
+
+    let mut output = String::new();
+    if !prefix_lines.is_empty() {
+        output.push_str(&prefix_lines.join("\n"));
+        output.push_str("\n\n");
+    }
+
+    output.push_str(trimmed_script);
+    if !output.ends_with('\n') {
+        output.push('\n');
+    }
+    output
+}
+
+fn write_generated_script(slug: &str, script_content: &str) -> Result<PathBuf> {
+    write_generated_script_in_dir(&generated_scripts_dir(), slug, script_content)
+}
+
+fn write_generated_script_in_dir(output_dir: &Path, slug: &str, script_content: &str) -> Result<PathBuf> {
+    fs::create_dir_all(output_dir)
+        .with_context(|| format!("Failed to create output dir: {}", output_dir.display()))?;
+
+    for suffix in 0usize.. {
+        let candidate = if suffix == 0 {
+            slug.to_string()
+        } else {
+            format!("{slug}-{suffix}")
+        };
+        let path = output_dir.join(format!("{}.ts", candidate));
+        match OpenOptions::new().write(true).create_new(true).open(&path) {
+            Ok(mut file) => {
+                file.write_all(script_content.as_bytes())
+                    .with_context(|| format!("Failed writing generated script to {}", path.display()))?;
+                return Ok(path);
+            }
+            Err(error) if error.kind() == ErrorKind::AlreadyExists => continue,
+            Err(error) => {
+                return Err(error).with_context(|| {
+                    format!(
+                        "Failed creating generated script file {} (slug={})",
+                        path.display(),
+                        slug
+                    )
+                });
+            }
+        }
+    }
+
+    unreachable!("suffix loop should eventually create a unique script filename")
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+    use tempfile::tempdir;
+
+    #[test]
+    fn test_slugify_script_name_handles_spaces_and_symbols() {
+        assert_eq!(slugify_script_name("Build: API Client!"), "build-api-client");
+        assert_eq!(slugify_script_name("  ___  "), "ai-script");
+    }
+
+    #[test]
+    fn test_extract_script_code_prefers_typescript_fence_when_multiple_blocks_exist() {
+        let response = r#"
+Here's one idea:
+```markdown
+Not code
+```
+```typescript
+await div("hello");
+```
+"#;
+        assert_eq!(extract_script_code(response), "await div(\"hello\");");
+    }
+
+    #[test]
+    fn test_extract_script_code_falls_back_to_first_fenced_block() {
+        let response = r#"
+```python
+print("hello")
+```
+"#;
+        assert_eq!(extract_script_code(response), "print(\"hello\")");
+    }
+
+    #[test]
+    fn test_extract_script_code_returns_trimmed_response_when_no_fence_exists() {
+        let response = "const answer = 42;";
+        assert_eq!(extract_script_code(response), "const answer = 42;");
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_adds_missing_metadata_and_import() {
+        let script = "const name = await arg(\"Name?\");";
+        let output = enforce_script_kit_conventions(script, "Ask for user name", "ask-user-name");
+
+        assert!(output.contains("// Name: Ask User Name"));
+        assert!(output.contains("// Description: Ask for user name"));
+        assert!(output.contains("import \"@johnlindquist/kit\";"));
+        assert!(output.contains("await arg(\"Name?\");"));
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_keeps_existing_metadata_and_import() {
+        let script = r#"// Name: Existing
+// Description: Existing description
+import "@johnlindquist/kit";
+
+await div("ready");
+"#;
+        let output = enforce_script_kit_conventions(script, "ignored", "ignored");
+
+        assert_eq!(
+            output.matches("// Name:").count(),
+            1,
+            "should not duplicate existing Name metadata"
+        );
+        assert_eq!(
+            output.matches("// Description:").count(),
+            1,
+            "should not duplicate existing Description metadata"
+        );
+        assert_eq!(
+            output.matches("import \"@johnlindquist/kit\";").count(),
+            1,
+            "should not duplicate existing import"
+        );
+    }
+
+    #[test]
+    fn test_write_generated_script_in_dir_appends_numeric_suffix_for_collisions() {
+        let temp_dir = tempdir().unwrap();
+        let first = write_generated_script_in_dir(temp_dir.path(), "my-script", "a").unwrap();
+        let second = write_generated_script_in_dir(temp_dir.path(), "my-script", "b").unwrap();
+
+        assert_eq!(first.file_name().unwrap(), "my-script.ts");
+        assert_eq!(second.file_name().unwrap(), "my-script-1.ts");
+    }
+}
diff --git a/src/builtins/part_000.rs b/src/builtins/part_000.rs
index d6b9c2a9b35b40c5005dbb9f65147f528702cb9e..5f6d27d28d72e51126d10d8beccf931c689ef2bb
--- a/src/builtins/part_000.rs
+++ b/src/builtins/part_000.rs
@@ -96,6 +96,8 @@
     OpenAi,
     NewConversation,
     ClearConversation,
+    /// Generate a new Script Kit script from the main prompt text
+    GenerateScript,
     /// Send a screenshot of the entire screen to AI Chat
     SendScreenToAi,
     /// Send a screenshot of the focused window to AI Chat
diff --git a/src/builtins/part_001_entries/entries_002.rs b/src/builtins/part_001_entries/entries_002.rs
index 6d1c9334f0ccaf0aab48582aaf42dcb129e1cb6e..72b318c66aeaf124359f4ecd276dae0350287328
--- a/src/builtins/part_001_entries/entries_002.rs
+++ b/src/builtins/part_001_entries/entries_002.rs
@@ -61,6 +61,17 @@
     ));
 
     entries.push(BuiltInEntry::new_with_icon(
+        "builtin-generate-script-with-ai",
+        "Generate Script with AI",
+        "Generate a Script Kit script from your current prompt text",
+        vec![
+            "generate", "script", "ai", "create", "code", "typescript", "shift", "tab",
+        ],
+        BuiltInFeature::AiCommand(AiCommandType::GenerateScript),
+        "ðŸ§ ",
+    ));
+
+    entries.push(BuiltInEntry::new_with_icon(
         "builtin-send-screen-to-ai",
         "Send Screen to AI Chat",
         "Capture the full screen and send it to AI Chat",


thinking
**Refining AI script generation flow**
codex
I identified the key fix: capture `filter_text` before the AI-command reset/hide path, then add an async `GenerateScript` branch that calls the new AI helper and opens the created file in the editor. Iâ€™m applying that edit now, then Iâ€™ll update built-in tests for the new entry.

thinking
**Planning AI command patch**
exec
/bin/zsh -lc "nl -ba src/app_execute/builtin_execution.rs | sed -n '528,910p'" in /Users/johnlindquist/dev/script-kit-gpui succeeded in 52ms:
   528	                    self.toast_manager.push(
   529	                        components::toast::Toast::error(
   530	                            format!("Notes command failed: {}", e),
   531	                            &self.theme,
   532	                        )
   533	                        .duration_ms(Some(5000)),
   534	                    );
   535	                    cx.notify();
   536	                }
   537	            }
   538	
   539	            // =========================================================================
   540	            // AI Commands
   541	            // =========================================================================
   542	            builtins::BuiltInFeature::AiCommand(cmd_type) => {
   543	                logging::log("EXEC", &format!("Executing AI command: {:?}", cmd_type));
   544	
   545	                use builtins::AiCommandType;
   546	
   547	                // All AI commands: reset state, hide main window
file update:
diff --git a/src/ai/mod.rs b/src/ai/mod.rs
index a420b1a5faf59506acdb7caf60681c153a3f9bb6..9a73e9491862633b325b2c52b51a3e20395ff85c
--- a/src/ai/mod.rs
+++ b/src/ai/mod.rs
@@ -37,6 +37,7 @@
 pub(crate) mod providers;
 pub(crate) mod sdk_handlers;
 pub(crate) mod session;
+pub(crate) mod script_generation;
 pub(crate) mod storage;
 pub(crate) mod window;
 
@@ -44,6 +45,7 @@
 pub use self::config::{DetectedKeys, ModelInfo, ProviderConfig};
 pub use self::model::{Chat, ChatId, ChatSource, Message, MessageRole};
 pub use self::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+pub use self::script_generation::{generate_script_from_prompt, GeneratedScriptOutput};
 pub use self::sdk_handlers::try_handle_ai_message;
 pub use self::storage::{
     clear_all_chats, create_chat, delete_chat, get_all_chats, get_chat, get_chat_messages,
diff --git a/src/ai/script_generation.rs b/src/ai/script_generation.rs
new file mode 100644
index 0000000000000000000000000000000000000000..7f2ec8e7576ed50cd10f7aea31a6522875ef667a
--- /dev/null
+++ b/src/ai/script_generation.rs
@@ -0,0 +1,417 @@
+use anyhow::{Context, Result};
+use std::fs::{self, OpenOptions};
+use std::io::{ErrorKind, Write};
+use std::path::{Path, PathBuf};
+use std::sync::Arc;
+
+use super::config::ModelInfo;
+use super::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+
+const AI_SCRIPT_OUTPUT_DIR: &str = "~/.kenv/scripts";
+const AI_SCRIPT_DEFAULT_SLUG: &str = "ai-script";
+const AI_SCRIPT_MAX_SLUG_LEN: usize = 64;
+
+const AI_SCRIPT_GENERATION_SYSTEM_PROMPT: &str = r#"You write production-ready Script Kit scripts.
+
+Return ONLY TypeScript source code for one Script Kit script. Do not include explanations.
+
+Required output conventions:
+1) Include metadata comments at the top:
+   // Name: <clear title>
+   // Description: <one-line summary>
+2) Include: import "@johnlindquist/kit";
+3) Use await arg() for user input when useful.
+4) Use await div() for display output when useful.
+5) Keep the script runnable as-is with sensible defaults and light error handling."#;
+
+#[derive(Debug, Clone)]
+pub struct GeneratedScriptOutput {
+    pub path: PathBuf,
+    pub slug: String,
+    pub model_id: String,
+    pub provider_id: String,
+}
+
+pub fn generate_script_from_prompt(
+    prompt: &str,
+    config: Option<&crate::config::Config>,
+) -> Result<GeneratedScriptOutput> {
+    let normalized_prompt = prompt.trim();
+    if normalized_prompt.is_empty() {
+        anyhow::bail!("AI script generation requires a non-empty prompt");
+    }
+
+    let registry = ProviderRegistry::from_environment_with_config(config);
+    if !registry.has_any_provider() {
+        anyhow::bail!(
+            "No AI providers configured. Configure an API key first (Vercel, OpenAI, Anthropic, etc.)."
+        );
+    }
+
+    let (selected_model, provider) = select_generation_model(&registry)?;
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=provider_ready model_id={} provider_id={} prompt_len={}",
+            selected_model.id,
+            selected_model.provider,
+            normalized_prompt.len()
+        ),
+    );
+
+    let messages = vec![
+        ProviderMessage::system(AI_SCRIPT_GENERATION_SYSTEM_PROMPT),
+        ProviderMessage::user(format!(
+            "Generate a Script Kit script for this user request:\n\n{}",
+            normalized_prompt
+        )),
+    ];
+
+    let raw_response = provider
+        .send_message(&messages, &selected_model.id)
+        .with_context(|| {
+            format!(
+                "AI script generation failed (attempted=send_message, model_id={}, provider_id={})",
+                selected_model.id, selected_model.provider
+            )
+        })?;
+
+    let extracted = extract_script_code(&raw_response);
+    if extracted.trim().is_empty() {
+        anyhow::bail!(
+            "AI returned an empty response for script generation (state=empty_response)"
+        );
+    }
+
+    let slug = slugify_script_name(normalized_prompt);
+    let finalized = enforce_script_kit_conventions(&extracted, normalized_prompt, &slug);
+    let path = write_generated_script(&slug, &finalized).with_context(|| {
+        format!(
+            "Failed writing AI-generated script (state=write_failed, slug={})",
+            slug
+        )
+    })?;
+
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=script_written path={} slug={}",
+            path.display(),
+            slug
+        ),
+    );
+
+    Ok(GeneratedScriptOutput {
+        path,
+        slug,
+        model_id: selected_model.id,
+        provider_id: selected_model.provider,
+    })
+}
+
+fn select_generation_model(registry: &ProviderRegistry) -> Result<(ModelInfo, Arc<dyn AiProvider>)> {
+    let models = registry.get_all_models();
+    let selected_model = models
+        .iter()
+        .find(|model| model.provider.eq_ignore_ascii_case("vercel"))
+        .or_else(|| models.first())
+        .cloned()
+        .context("No AI models available in provider registry")?;
+
+    let provider = registry
+        .find_provider_for_model(&selected_model.id)
+        .cloned()
+        .with_context(|| {
+            format!(
+                "No provider found for selected model '{}' (state=provider_missing)",
+                selected_model.id
+            )
+        })?;
+
+    Ok((selected_model, provider))
+}
+
+fn generated_scripts_dir() -> PathBuf {
+    PathBuf::from(shellexpand::tilde(AI_SCRIPT_OUTPUT_DIR).as_ref())
+}
+
+fn split_fence_header_and_body(fence: &str) -> (&str, &str) {
+    match fence.find('\n') {
+        Some(newline_index) => (&fence[..newline_index], &fence[newline_index + 1..]),
+        None => ("", fence),
+    }
+}
+
+fn extract_fenced_code(response: &str, preferred_languages: Option<&[&str]>) -> Option<String> {
+    let mut remaining = response;
+
+    while let Some(start) = remaining.find("```") {
+        let after_start = &remaining[start + 3..];
+        let Some(end) = after_start.find("```") else {
+            break;
+        };
+
+        let fence_contents = &after_start[..end];
+        let (header, body) = split_fence_header_and_body(fence_contents);
+        let language = header
+            .trim()
+            .split(|c: char| c.is_whitespace() || c == '{')
+            .next()
+            .unwrap_or("")
+            .to_ascii_lowercase();
+        let code = body.trim();
+
+        if !code.is_empty() {
+            match preferred_languages {
+                Some(preferred) => {
+                    if preferred.iter().any(|candidate| *candidate == language) {
+                        return Some(code.to_string());
+                    }
+                }
+                None => return Some(code.to_string()),
+            }
+        }
+
+        remaining = &after_start[end + 3..];
+    }
+
+    None
+}
+
+fn extract_script_code(response: &str) -> String {
+    const PREFERRED_LANGUAGES: [&str; 6] = ["typescript", "ts", "javascript", "js", "tsx", "jsx"];
+
+    extract_fenced_code(response, Some(&PREFERRED_LANGUAGES))
+        .or_else(|| extract_fenced_code(response, None))
+        .unwrap_or_else(|| response.trim().to_string())
+}
+
+fn slugify_script_name(prompt: &str) -> String {
+    let mut slug = String::new();
+    let mut last_was_hyphen = false;
+
+    for character in prompt.to_ascii_lowercase().chars() {
+        if character.is_ascii_alphanumeric() {
+            slug.push(character);
+            last_was_hyphen = false;
+        } else if matches!(character, ' ' | '_' | '-') {
+            if !slug.is_empty() && !last_was_hyphen {
+                slug.push('-');
+                last_was_hyphen = true;
+            }
+        }
+    }
+
+    while slug.ends_with('-') {
+        slug.pop();
+    }
+
+    if slug.len() > AI_SCRIPT_MAX_SLUG_LEN {
+        slug.truncate(AI_SCRIPT_MAX_SLUG_LEN);
+        while slug.ends_with('-') {
+            slug.pop();
+        }
+    }
+
+    if slug.is_empty() {
+        AI_SCRIPT_DEFAULT_SLUG.to_string()
+    } else {
+        slug
+    }
+}
+
+fn slug_to_title(slug: &str) -> String {
+    slug.split('-')
+        .filter(|segment| !segment.is_empty())
+        .map(|segment| {
+            let mut chars = segment.chars();
+            match chars.next() {
+                Some(first) => first.to_uppercase().collect::<String>() + chars.as_str(),
+                None => String::new(),
+            }
+        })
+        .collect::<Vec<_>>()
+        .join(" ")
+}
+
+fn description_from_prompt(prompt: &str) -> String {
+    let normalized = prompt.split_whitespace().collect::<Vec<_>>().join(" ");
+    if normalized.is_empty() {
+        return "AI-generated Script Kit script".to_string();
+    }
+
+    let mut shortened = normalized;
+    if shortened.chars().count() > 110 {
+        shortened = format!("{}...", shortened.chars().take(107).collect::<String>());
+    }
+    shortened
+}
+
+fn has_kit_import(script: &str) -> bool {
+    script.contains("import \"@johnlindquist/kit\";")
+        || script.contains("import '@johnlindquist/kit';")
+        || script.contains("import \"@scriptkit/sdk\";")
+        || script.contains("import '@scriptkit/sdk';")
+}
+
+fn enforce_script_kit_conventions(script: &str, prompt: &str, slug: &str) -> String {
+    let mut prefix_lines: Vec<String> = Vec::new();
+    let trimmed_script = script.trim();
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Name:"))
+    {
+        prefix_lines.push(format!("// Name: {}", slug_to_title(slug)));
+    }
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Description:"))
+    {
+        prefix_lines.push(format!("// Description: {}", description_from_prompt(prompt)));
+    }
+
+    if !has_kit_import(trimmed_script) {
+        prefix_lines.push("import \"@johnlindquist/kit\";".to_string());
+    }
+
+    let mut output = String::new();
+    if !prefix_lines.is_empty() {
+        output.push_str(&prefix_lines.join("\n"));
+        output.push_str("\n\n");
+    }
+
+    output.push_str(trimmed_script);
+    if !output.ends_with('\n') {
+        output.push('\n');
+    }
+    output
+}
+
+fn write_generated_script(slug: &str, script_content: &str) -> Result<PathBuf> {
+    write_generated_script_in_dir(&generated_scripts_dir(), slug, script_content)
+}
+
+fn write_generated_script_in_dir(output_dir: &Path, slug: &str, script_content: &str) -> Result<PathBuf> {
+    fs::create_dir_all(output_dir)
+        .with_context(|| format!("Failed to create output dir: {}", output_dir.display()))?;
+
+    for suffix in 0usize.. {
+        let candidate = if suffix == 0 {
+            slug.to_string()
+        } else {
+            format!("{slug}-{suffix}")
+        };
+        let path = output_dir.join(format!("{}.ts", candidate));
+        match OpenOptions::new().write(true).create_new(true).open(&path) {
+            Ok(mut file) => {
+                file.write_all(script_content.as_bytes())
+                    .with_context(|| format!("Failed writing generated script to {}", path.display()))?;
+                return Ok(path);
+            }
+            Err(error) if error.kind() == ErrorKind::AlreadyExists => continue,
+            Err(error) => {
+                return Err(error).with_context(|| {
+                    format!(
+                        "Failed creating generated script file {} (slug={})",
+                        path.display(),
+                        slug
+                    )
+                });
+            }
+        }
+    }
+
+    unreachable!("suffix loop should eventually create a unique script filename")
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+    use tempfile::tempdir;
+
+    #[test]
+    fn test_slugify_script_name_handles_spaces_and_symbols() {
+        assert_eq!(slugify_script_name("Build: API Client!"), "build-api-client");
+        assert_eq!(slugify_script_name("  ___  "), "ai-script");
+    }
+
+    #[test]
+    fn test_extract_script_code_prefers_typescript_fence_when_multiple_blocks_exist() {
+        let response = r#"
+Here's one idea:
+```markdown
+Not code
+```
+```typescript
+await div("hello");
+```
+"#;
+        assert_eq!(extract_script_code(response), "await div(\"hello\");");
+    }
+
+    #[test]
+    fn test_extract_script_code_falls_back_to_first_fenced_block() {
+        let response = r#"
+```python
+print("hello")
+```
+"#;
+        assert_eq!(extract_script_code(response), "print(\"hello\")");
+    }
+
+    #[test]
+    fn test_extract_script_code_returns_trimmed_response_when_no_fence_exists() {
+        let response = "const answer = 42;";
+        assert_eq!(extract_script_code(response), "const answer = 42;");
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_adds_missing_metadata_and_import() {
+        let script = "const name = await arg(\"Name?\");";
+        let output = enforce_script_kit_conventions(script, "Ask for user name", "ask-user-name");
+
+        assert!(output.contains("// Name: Ask User Name"));
+        assert!(output.contains("// Description: Ask for user name"));
+        assert!(output.contains("import \"@johnlindquist/kit\";"));
+        assert!(output.contains("await arg(\"Name?\");"));
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_keeps_existing_metadata_and_import() {
+        let script = r#"// Name: Existing
+// Description: Existing description
+import "@johnlindquist/kit";
+
+await div("ready");
+"#;
+        let output = enforce_script_kit_conventions(script, "ignored", "ignored");
+
+        assert_eq!(
+            output.matches("// Name:").count(),
+            1,
+            "should not duplicate existing Name metadata"
+        );
+        assert_eq!(
+            output.matches("// Description:").count(),
+            1,
+            "should not duplicate existing Description metadata"
+        );
+        assert_eq!(
+            output.matches("import \"@johnlindquist/kit\";").count(),
+            1,
+            "should not duplicate existing import"
+        );
+    }
+
+    #[test]
+    fn test_write_generated_script_in_dir_appends_numeric_suffix_for_collisions() {
+        let temp_dir = tempdir().unwrap();
+        let first = write_generated_script_in_dir(temp_dir.path(), "my-script", "a").unwrap();
+        let second = write_generated_script_in_dir(temp_dir.path(), "my-script", "b").unwrap();
+
+        assert_eq!(first.file_name().unwrap(), "my-script.ts");
+        assert_eq!(second.file_name().unwrap(), "my-script-1.ts");
+    }
+}
diff --git a/src/builtins/part_000.rs b/src/builtins/part_000.rs
index d6b9c2a9b35b40c5005dbb9f65147f528702cb9e..5f6d27d28d72e51126d10d8beccf931c689ef2bb
--- a/src/builtins/part_000.rs
+++ b/src/builtins/part_000.rs
@@ -96,6 +96,8 @@
     OpenAi,
     NewConversation,
     ClearConversation,
+    /// Generate a new Script Kit script from the main prompt text
+    GenerateScript,
     /// Send a screenshot of the entire screen to AI Chat
     SendScreenToAi,
     /// Send a screenshot of the focused window to AI Chat
diff --git a/src/builtins/part_001_entries/entries_002.rs b/src/builtins/part_001_entries/entries_002.rs
index 6d1c9334f0ccaf0aab48582aaf42dcb129e1cb6e..72b318c66aeaf124359f4ecd276dae0350287328
--- a/src/builtins/part_001_entries/entries_002.rs
+++ b/src/builtins/part_001_entries/entries_002.rs
@@ -61,6 +61,17 @@
     ));
 
     entries.push(BuiltInEntry::new_with_icon(
+        "builtin-generate-script-with-ai",
+        "Generate Script with AI",
+        "Generate a Script Kit script from your current prompt text",
+        vec![
+            "generate", "script", "ai", "create", "code", "typescript", "shift", "tab",
+        ],
+        BuiltInFeature::AiCommand(AiCommandType::GenerateScript),
+        "ðŸ§ ",
+    ));
+
+    entries.push(BuiltInEntry::new_with_icon(
         "builtin-send-screen-to-ai",
         "Send Screen to AI Chat",
         "Capture the full screen and send it to AI Chat",


thinking
**Designing AI script generation patch**
exec
/bin/zsh -lc "rg -n \"show_main_window\\(|set_main_window_visible\\(true\\)|reopen\" src/main.rs src/app_impl src/app_execute | head -n 80" in /Users/johnlindquist/dev/script-kit-gpui succeeded in 51ms:
src/main.rs:320:        set_main_window_visible(true);
src/app_execute/builtin_execution.rs:577:                                            "AI history cleared but failed to reopen AI window: {}",
src/app_execute/builtin_execution/feature_02.rs:69:                                            "AI history cleared but failed to reopen AI window: {}",
src/app_impl/registries_state.rs:271:        self.hovered_index = None; // Reset hover state to prevent stale highlight on reopen
file update:
diff --git a/src/ai/mod.rs b/src/ai/mod.rs
index a420b1a5faf59506acdb7caf60681c153a3f9bb6..9a73e9491862633b325b2c52b51a3e20395ff85c
--- a/src/ai/mod.rs
+++ b/src/ai/mod.rs
@@ -37,6 +37,7 @@
 pub(crate) mod providers;
 pub(crate) mod sdk_handlers;
 pub(crate) mod session;
+pub(crate) mod script_generation;
 pub(crate) mod storage;
 pub(crate) mod window;
 
@@ -44,6 +45,7 @@
 pub use self::config::{DetectedKeys, ModelInfo, ProviderConfig};
 pub use self::model::{Chat, ChatId, ChatSource, Message, MessageRole};
 pub use self::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+pub use self::script_generation::{generate_script_from_prompt, GeneratedScriptOutput};
 pub use self::sdk_handlers::try_handle_ai_message;
 pub use self::storage::{
     clear_all_chats, create_chat, delete_chat, get_all_chats, get_chat, get_chat_messages,
diff --git a/src/ai/script_generation.rs b/src/ai/script_generation.rs
new file mode 100644
index 0000000000000000000000000000000000000000..7f2ec8e7576ed50cd10f7aea31a6522875ef667a
--- /dev/null
+++ b/src/ai/script_generation.rs
@@ -0,0 +1,417 @@
+use anyhow::{Context, Result};
+use std::fs::{self, OpenOptions};
+use std::io::{ErrorKind, Write};
+use std::path::{Path, PathBuf};
+use std::sync::Arc;
+
+use super::config::ModelInfo;
+use super::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+
+const AI_SCRIPT_OUTPUT_DIR: &str = "~/.kenv/scripts";
+const AI_SCRIPT_DEFAULT_SLUG: &str = "ai-script";
+const AI_SCRIPT_MAX_SLUG_LEN: usize = 64;
+
+const AI_SCRIPT_GENERATION_SYSTEM_PROMPT: &str = r#"You write production-ready Script Kit scripts.
+
+Return ONLY TypeScript source code for one Script Kit script. Do not include explanations.
+
+Required output conventions:
+1) Include metadata comments at the top:
+   // Name: <clear title>
+   // Description: <one-line summary>
+2) Include: import "@johnlindquist/kit";
+3) Use await arg() for user input when useful.
+4) Use await div() for display output when useful.
+5) Keep the script runnable as-is with sensible defaults and light error handling."#;
+
+#[derive(Debug, Clone)]
+pub struct GeneratedScriptOutput {
+    pub path: PathBuf,
+    pub slug: String,
+    pub model_id: String,
+    pub provider_id: String,
+}
+
+pub fn generate_script_from_prompt(
+    prompt: &str,
+    config: Option<&crate::config::Config>,
+) -> Result<GeneratedScriptOutput> {
+    let normalized_prompt = prompt.trim();
+    if normalized_prompt.is_empty() {
+        anyhow::bail!("AI script generation requires a non-empty prompt");
+    }
+
+    let registry = ProviderRegistry::from_environment_with_config(config);
+    if !registry.has_any_provider() {
+        anyhow::bail!(
+            "No AI providers configured. Configure an API key first (Vercel, OpenAI, Anthropic, etc.)."
+        );
+    }
+
+    let (selected_model, provider) = select_generation_model(&registry)?;
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=provider_ready model_id={} provider_id={} prompt_len={}",
+            selected_model.id,
+            selected_model.provider,
+            normalized_prompt.len()
+        ),
+    );
+
+    let messages = vec![
+        ProviderMessage::system(AI_SCRIPT_GENERATION_SYSTEM_PROMPT),
+        ProviderMessage::user(format!(
+            "Generate a Script Kit script for this user request:\n\n{}",
+            normalized_prompt
+        )),
+    ];
+
+    let raw_response = provider
+        .send_message(&messages, &selected_model.id)
+        .with_context(|| {
+            format!(
+                "AI script generation failed (attempted=send_message, model_id={}, provider_id={})",
+                selected_model.id, selected_model.provider
+            )
+        })?;
+
+    let extracted = extract_script_code(&raw_response);
+    if extracted.trim().is_empty() {
+        anyhow::bail!(
+            "AI returned an empty response for script generation (state=empty_response)"
+        );
+    }
+
+    let slug = slugify_script_name(normalized_prompt);
+    let finalized = enforce_script_kit_conventions(&extracted, normalized_prompt, &slug);
+    let path = write_generated_script(&slug, &finalized).with_context(|| {
+        format!(
+            "Failed writing AI-generated script (state=write_failed, slug={})",
+            slug
+        )
+    })?;
+
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=script_written path={} slug={}",
+            path.display(),
+            slug
+        ),
+    );
+
+    Ok(GeneratedScriptOutput {
+        path,
+        slug,
+        model_id: selected_model.id,
+        provider_id: selected_model.provider,
+    })
+}
+
+fn select_generation_model(registry: &ProviderRegistry) -> Result<(ModelInfo, Arc<dyn AiProvider>)> {
+    let models = registry.get_all_models();
+    let selected_model = models
+        .iter()
+        .find(|model| model.provider.eq_ignore_ascii_case("vercel"))
+        .or_else(|| models.first())
+        .cloned()
+        .context("No AI models available in provider registry")?;
+
+    let provider = registry
+        .find_provider_for_model(&selected_model.id)
+        .cloned()
+        .with_context(|| {
+            format!(
+                "No provider found for selected model '{}' (state=provider_missing)",
+                selected_model.id
+            )
+        })?;
+
+    Ok((selected_model, provider))
+}
+
+fn generated_scripts_dir() -> PathBuf {
+    PathBuf::from(shellexpand::tilde(AI_SCRIPT_OUTPUT_DIR).as_ref())
+}
+
+fn split_fence_header_and_body(fence: &str) -> (&str, &str) {
+    match fence.find('\n') {
+        Some(newline_index) => (&fence[..newline_index], &fence[newline_index + 1..]),
+        None => ("", fence),
+    }
+}
+
+fn extract_fenced_code(response: &str, preferred_languages: Option<&[&str]>) -> Option<String> {
+    let mut remaining = response;
+
+    while let Some(start) = remaining.find("```") {
+        let after_start = &remaining[start + 3..];
+        let Some(end) = after_start.find("```") else {
+            break;
+        };
+
+        let fence_contents = &after_start[..end];
+        let (header, body) = split_fence_header_and_body(fence_contents);
+        let language = header
+            .trim()
+            .split(|c: char| c.is_whitespace() || c == '{')
+            .next()
+            .unwrap_or("")
+            .to_ascii_lowercase();
+        let code = body.trim();
+
+        if !code.is_empty() {
+            match preferred_languages {
+                Some(preferred) => {
+                    if preferred.iter().any(|candidate| *candidate == language) {
+                        return Some(code.to_string());
+                    }
+                }
+                None => return Some(code.to_string()),
+            }
+        }
+
+        remaining = &after_start[end + 3..];
+    }
+
+    None
+}
+
+fn extract_script_code(response: &str) -> String {
+    const PREFERRED_LANGUAGES: [&str; 6] = ["typescript", "ts", "javascript", "js", "tsx", "jsx"];
+
+    extract_fenced_code(response, Some(&PREFERRED_LANGUAGES))
+        .or_else(|| extract_fenced_code(response, None))
+        .unwrap_or_else(|| response.trim().to_string())
+}
+
+fn slugify_script_name(prompt: &str) -> String {
+    let mut slug = String::new();
+    let mut last_was_hyphen = false;
+
+    for character in prompt.to_ascii_lowercase().chars() {
+        if character.is_ascii_alphanumeric() {
+            slug.push(character);
+            last_was_hyphen = false;
+        } else if matches!(character, ' ' | '_' | '-') {
+            if !slug.is_empty() && !last_was_hyphen {
+                slug.push('-');
+                last_was_hyphen = true;
+            }
+        }
+    }
+
+    while slug.ends_with('-') {
+        slug.pop();
+    }
+
+    if slug.len() > AI_SCRIPT_MAX_SLUG_LEN {
+        slug.truncate(AI_SCRIPT_MAX_SLUG_LEN);
+        while slug.ends_with('-') {
+            slug.pop();
+        }
+    }
+
+    if slug.is_empty() {
+        AI_SCRIPT_DEFAULT_SLUG.to_string()
+    } else {
+        slug
+    }
+}
+
+fn slug_to_title(slug: &str) -> String {
+    slug.split('-')
+        .filter(|segment| !segment.is_empty())
+        .map(|segment| {
+            let mut chars = segment.chars();
+            match chars.next() {
+                Some(first) => first.to_uppercase().collect::<String>() + chars.as_str(),
+                None => String::new(),
+            }
+        })
+        .collect::<Vec<_>>()
+        .join(" ")
+}
+
+fn description_from_prompt(prompt: &str) -> String {
+    let normalized = prompt.split_whitespace().collect::<Vec<_>>().join(" ");
+    if normalized.is_empty() {
+        return "AI-generated Script Kit script".to_string();
+    }
+
+    let mut shortened = normalized;
+    if shortened.chars().count() > 110 {
+        shortened = format!("{}...", shortened.chars().take(107).collect::<String>());
+    }
+    shortened
+}
+
+fn has_kit_import(script: &str) -> bool {
+    script.contains("import \"@johnlindquist/kit\";")
+        || script.contains("import '@johnlindquist/kit';")
+        || script.contains("import \"@scriptkit/sdk\";")
+        || script.contains("import '@scriptkit/sdk';")
+}
+
+fn enforce_script_kit_conventions(script: &str, prompt: &str, slug: &str) -> String {
+    let mut prefix_lines: Vec<String> = Vec::new();
+    let trimmed_script = script.trim();
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Name:"))
+    {
+        prefix_lines.push(format!("// Name: {}", slug_to_title(slug)));
+    }
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Description:"))
+    {
+        prefix_lines.push(format!("// Description: {}", description_from_prompt(prompt)));
+    }
+
+    if !has_kit_import(trimmed_script) {
+        prefix_lines.push("import \"@johnlindquist/kit\";".to_string());
+    }
+
+    let mut output = String::new();
+    if !prefix_lines.is_empty() {
+        output.push_str(&prefix_lines.join("\n"));
+        output.push_str("\n\n");
+    }
+
+    output.push_str(trimmed_script);
+    if !output.ends_with('\n') {
+        output.push('\n');
+    }
+    output
+}
+
+fn write_generated_script(slug: &str, script_content: &str) -> Result<PathBuf> {
+    write_generated_script_in_dir(&generated_scripts_dir(), slug, script_content)
+}
+
+fn write_generated_script_in_dir(output_dir: &Path, slug: &str, script_content: &str) -> Result<PathBuf> {
+    fs::create_dir_all(output_dir)
+        .with_context(|| format!("Failed to create output dir: {}", output_dir.display()))?;
+
+    for suffix in 0usize.. {
+        let candidate = if suffix == 0 {
+            slug.to_string()
+        } else {
+            format!("{slug}-{suffix}")
+        };
+        let path = output_dir.join(format!("{}.ts", candidate));
+        match OpenOptions::new().write(true).create_new(true).open(&path) {
+            Ok(mut file) => {
+                file.write_all(script_content.as_bytes())
+                    .with_context(|| format!("Failed writing generated script to {}", path.display()))?;
+                return Ok(path);
+            }
+            Err(error) if error.kind() == ErrorKind::AlreadyExists => continue,
+            Err(error) => {
+                return Err(error).with_context(|| {
+                    format!(
+                        "Failed creating generated script file {} (slug={})",
+                        path.display(),
+                        slug
+                    )
+                });
+            }
+        }
+    }
+
+    unreachable!("suffix loop should eventually create a unique script filename")
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+    use tempfile::tempdir;
+
+    #[test]
+    fn test_slugify_script_name_handles_spaces_and_symbols() {
+        assert_eq!(slugify_script_name("Build: API Client!"), "build-api-client");
+        assert_eq!(slugify_script_name("  ___  "), "ai-script");
+    }
+
+    #[test]
+    fn test_extract_script_code_prefers_typescript_fence_when_multiple_blocks_exist() {
+        let response = r#"
+Here's one idea:
+```markdown
+Not code
+```
+```typescript
+await div("hello");
+```
+"#;
+        assert_eq!(extract_script_code(response), "await div(\"hello\");");
+    }
+
+    #[test]
+    fn test_extract_script_code_falls_back_to_first_fenced_block() {
+        let response = r#"
+```python
+print("hello")
+```
+"#;
+        assert_eq!(extract_script_code(response), "print(\"hello\")");
+    }
+
+    #[test]
+    fn test_extract_script_code_returns_trimmed_response_when_no_fence_exists() {
+        let response = "const answer = 42;";
+        assert_eq!(extract_script_code(response), "const answer = 42;");
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_adds_missing_metadata_and_import() {
+        let script = "const name = await arg(\"Name?\");";
+        let output = enforce_script_kit_conventions(script, "Ask for user name", "ask-user-name");
+
+        assert!(output.contains("// Name: Ask User Name"));
+        assert!(output.contains("// Description: Ask for user name"));
+        assert!(output.contains("import \"@johnlindquist/kit\";"));
+        assert!(output.contains("await arg(\"Name?\");"));
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_keeps_existing_metadata_and_import() {
+        let script = r#"// Name: Existing
+// Description: Existing description
+import "@johnlindquist/kit";
+
+await div("ready");
+"#;
+        let output = enforce_script_kit_conventions(script, "ignored", "ignored");
+
+        assert_eq!(
+            output.matches("// Name:").count(),
+            1,
+            "should not duplicate existing Name metadata"
+        );
+        assert_eq!(
+            output.matches("// Description:").count(),
+            1,
+            "should not duplicate existing Description metadata"
+        );
+        assert_eq!(
+            output.matches("import \"@johnlindquist/kit\";").count(),
+            1,
+            "should not duplicate existing import"
+        );
+    }
+
+    #[test]
+    fn test_write_generated_script_in_dir_appends_numeric_suffix_for_collisions() {
+        let temp_dir = tempdir().unwrap();
+        let first = write_generated_script_in_dir(temp_dir.path(), "my-script", "a").unwrap();
+        let second = write_generated_script_in_dir(temp_dir.path(), "my-script", "b").unwrap();
+
+        assert_eq!(first.file_name().unwrap(), "my-script.ts");
+        assert_eq!(second.file_name().unwrap(), "my-script-1.ts");
+    }
+}
diff --git a/src/builtins/part_000.rs b/src/builtins/part_000.rs
index d6b9c2a9b35b40c5005dbb9f65147f528702cb9e..5f6d27d28d72e51126d10d8beccf931c689ef2bb
--- a/src/builtins/part_000.rs
+++ b/src/builtins/part_000.rs
@@ -96,6 +96,8 @@
     OpenAi,
     NewConversation,
     ClearConversation,
+    /// Generate a new Script Kit script from the main prompt text
+    GenerateScript,
     /// Send a screenshot of the entire screen to AI Chat
     SendScreenToAi,
     /// Send a screenshot of the focused window to AI Chat
diff --git a/src/builtins/part_001_entries/entries_002.rs b/src/builtins/part_001_entries/entries_002.rs
index 6d1c9334f0ccaf0aab48582aaf42dcb129e1cb6e..72b318c66aeaf124359f4ecd276dae0350287328
--- a/src/builtins/part_001_entries/entries_002.rs
+++ b/src/builtins/part_001_entries/entries_002.rs
@@ -61,6 +61,17 @@
     ));
 
     entries.push(BuiltInEntry::new_with_icon(
+        "builtin-generate-script-with-ai",
+        "Generate Script with AI",
+        "Generate a Script Kit script from your current prompt text",
+        vec![
+            "generate", "script", "ai", "create", "code", "typescript", "shift", "tab",
+        ],
+        BuiltInFeature::AiCommand(AiCommandType::GenerateScript),
+        "ðŸ§ ",
+    ));
+
+    entries.push(BuiltInEntry::new_with_icon(
         "builtin-send-screen-to-ai",
         "Send Screen to AI Chat",
         "Capture the full screen and send it to AI Chat",


thinking
**Planning user feedback improvements**
file update
M /Users/johnlindquist/dev/script-kit-gpui/src/app_execute/builtin_execution.rs
@@ -546,2 +546,26 @@
 
+                // Capture prompt text before reset for Shift+Tab/script-generation flows.
+                let script_generation_prompt = if matches!(cmd_type, AiCommandType::GenerateScript)
+                {
+                    Some(self.filter_text.trim().to_string())
+                } else {
+                    None
+                };
+
+                if matches!(cmd_type, AiCommandType::GenerateScript)
+                    && script_generation_prompt
+                        .as_ref()
+                        .is_some_and(|prompt| prompt.is_empty())
+                {
+                    self.toast_manager.push(
+                        components::toast::Toast::warning(
+                            "Type a prompt first, then run Generate Script with AI.",
+                            &self.theme,
+                        )
+                        .duration_ms(Some(3500)),
+                    );
+                    cx.notify();
+                    return;
+                }
+
                 // All AI commands: reset state, hide main window
@@ -616,2 +640,128 @@
 
+                    AiCommandType::GenerateScript => {
+                        let Some(prompt_description) = script_generation_prompt.clone() else {
+                            logging::log(
+                                "AI_SCRIPT_GEN",
+                                "state=failed attempted=capture_prompt failure=missing_prompt",
+                            );
+                            self.toast_manager.push(
+                                components::toast::Toast::error(
+                                    "No prompt available for AI script generation",
+                                    &self.theme,
+                                )
+                                .duration_ms(Some(5000)),
+                            );
+                            cx.notify();
+                            return;
+                        };
+
+                        let config = self.config.clone();
+                        let (tx, rx) = async_channel::bounded::<
+                            std::result::Result<ai::GeneratedScriptOutput, String>,
+                        >(1);
+
+                        logging::log(
+                            "AI_SCRIPT_GEN",
+                            &format!(
+                                "state=queued attempted=builtin_generate_script prompt_len={}",
+                                prompt_description.len()
+                            ),
+                        );
+
+                        std::thread::spawn(move || {
+                            let generation_result =
+                                ai::generate_script_from_prompt(&prompt_description, Some(&config))
+                                    .map_err(|error| error.to_string());
+
+                            if tx.send_blocking(generation_result).is_err() {
+                                logging::log(
+                                    "AI_SCRIPT_GEN",
+                                    "state=aborted attempted=send_result failure=result_channel_closed",
+                                );
+                            }
+                        });
+
+                        cx.spawn(async move |this, cx| {
+                            let Ok(result) = rx.recv().await else {
+                                logging::log(
+                                    "AI_SCRIPT_GEN",
+                                    "state=aborted attempted=recv_result failure=result_channel_closed",
+                                );
+                                return;
+                            };
+
+                            let _ = cx.update(|cx| {
+                                this.update(cx, |app, cx| match result {
+                                    Ok(generated) => {
+                                        let script_name = generated
+                                            .path
+                                            .file_name()
+                                            .and_then(|name| name.to_str())
+                                            .unwrap_or("generated script");
+
+                                        if let Err(error) =
+                                            script_creation::open_in_editor(&generated.path, &app.config)
+                                        {
+                                            logging::log(
+                                                "AI_SCRIPT_GEN",
+                                                &format!(
+                                                    "state=failed attempted=open_editor path={} error={}",
+                                                    generated.path.display(),
+                                                    error
+                                                ),
+                                            );
+                                            app.toast_manager.push(
+                                                components::toast::Toast::error(
+                                                    format!(
+                                                        "Generated {}, but failed to open editor: {}",
+                                                        script_name, error
+                                                    ),
+                                                    &app.theme,
+                                                )
+                                                .duration_ms(Some(7000)),
+                                            );
+                                            cx.notify();
+                                        } else {
+                                            logging::log(
+                                                "AI_SCRIPT_GEN",
+                                                &format!(
+                                                    "state=completed attempted=builtin_generate_script path={} model_id={} provider_id={}",
+                                                    generated.path.display(),
+                                                    generated.model_id,
+                                                    generated.provider_id
+                                                ),
+                                            );
+                                            app.toast_manager.push(
+                                                components::toast::Toast::success(
+                                                    format!("Generated and opened {}", script_name),
+                                                    &app.theme,
+                                                )
+                                                .duration_ms(Some(3500)),
+                                            );
+                                            app.close_and_reset_window(cx);
+                                        }
+                                    }
+                                    Err(error) => {
+                                        logging::log(
+                                            "AI_SCRIPT_GEN",
+                                            &format!(
+                                                "state=failed attempted=builtin_generate_script error={}",
+                                                error
+                                            ),
+                                        );
+                                        app.toast_manager.push(
+                                            components::toast::Toast::error(
+                                                format!("Failed to generate script: {}", error),
+                                                &app.theme,
+                                            )
+                                            .duration_ms(Some(7000)),
+                                        );
+                                        cx.notify();
+                                    }
+                                })
+                            });
+                        })
+                        .detach();
+                    }
+
                     AiCommandType::SendScreenToAi => {
apply_patch(auto_approved=true) exited 0 in 30ms:
Success. Updated the following files:
M src/app_execute/builtin_execution.rs
file update:
diff --git a/src/ai/mod.rs b/src/ai/mod.rs
index a420b1a5faf59506acdb7caf60681c153a3f9bb6..9a73e9491862633b325b2c52b51a3e20395ff85c
--- a/src/ai/mod.rs
+++ b/src/ai/mod.rs
@@ -37,6 +37,7 @@
 pub(crate) mod providers;
 pub(crate) mod sdk_handlers;
 pub(crate) mod session;
+pub(crate) mod script_generation;
 pub(crate) mod storage;
 pub(crate) mod window;
 
@@ -44,6 +45,7 @@
 pub use self::config::{DetectedKeys, ModelInfo, ProviderConfig};
 pub use self::model::{Chat, ChatId, ChatSource, Message, MessageRole};
 pub use self::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+pub use self::script_generation::{generate_script_from_prompt, GeneratedScriptOutput};
 pub use self::sdk_handlers::try_handle_ai_message;
 pub use self::storage::{
     clear_all_chats, create_chat, delete_chat, get_all_chats, get_chat, get_chat_messages,
diff --git a/src/ai/script_generation.rs b/src/ai/script_generation.rs
new file mode 100644
index 0000000000000000000000000000000000000000..7f2ec8e7576ed50cd10f7aea31a6522875ef667a
--- /dev/null
+++ b/src/ai/script_generation.rs
@@ -0,0 +1,417 @@
+use anyhow::{Context, Result};
+use std::fs::{self, OpenOptions};
+use std::io::{ErrorKind, Write};
+use std::path::{Path, PathBuf};
+use std::sync::Arc;
+
+use super::config::ModelInfo;
+use super::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+
+const AI_SCRIPT_OUTPUT_DIR: &str = "~/.kenv/scripts";
+const AI_SCRIPT_DEFAULT_SLUG: &str = "ai-script";
+const AI_SCRIPT_MAX_SLUG_LEN: usize = 64;
+
+const AI_SCRIPT_GENERATION_SYSTEM_PROMPT: &str = r#"You write production-ready Script Kit scripts.
+
+Return ONLY TypeScript source code for one Script Kit script. Do not include explanations.
+
+Required output conventions:
+1) Include metadata comments at the top:
+   // Name: <clear title>
+   // Description: <one-line summary>
+2) Include: import "@johnlindquist/kit";
+3) Use await arg() for user input when useful.
+4) Use await div() for display output when useful.
+5) Keep the script runnable as-is with sensible defaults and light error handling."#;
+
+#[derive(Debug, Clone)]
+pub struct GeneratedScriptOutput {
+    pub path: PathBuf,
+    pub slug: String,
+    pub model_id: String,
+    pub provider_id: String,
+}
+
+pub fn generate_script_from_prompt(
+    prompt: &str,
+    config: Option<&crate::config::Config>,
+) -> Result<GeneratedScriptOutput> {
+    let normalized_prompt = prompt.trim();
+    if normalized_prompt.is_empty() {
+        anyhow::bail!("AI script generation requires a non-empty prompt");
+    }
+
+    let registry = ProviderRegistry::from_environment_with_config(config);
+    if !registry.has_any_provider() {
+        anyhow::bail!(
+            "No AI providers configured. Configure an API key first (Vercel, OpenAI, Anthropic, etc.)."
+        );
+    }
+
+    let (selected_model, provider) = select_generation_model(&registry)?;
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=provider_ready model_id={} provider_id={} prompt_len={}",
+            selected_model.id,
+            selected_model.provider,
+            normalized_prompt.len()
+        ),
+    );
+
+    let messages = vec![
+        ProviderMessage::system(AI_SCRIPT_GENERATION_SYSTEM_PROMPT),
+        ProviderMessage::user(format!(
+            "Generate a Script Kit script for this user request:\n\n{}",
+            normalized_prompt
+        )),
+    ];
+
+    let raw_response = provider
+        .send_message(&messages, &selected_model.id)
+        .with_context(|| {
+            format!(
+                "AI script generation failed (attempted=send_message, model_id={}, provider_id={})",
+                selected_model.id, selected_model.provider
+            )
+        })?;
+
+    let extracted = extract_script_code(&raw_response);
+    if extracted.trim().is_empty() {
+        anyhow::bail!(
+            "AI returned an empty response for script generation (state=empty_response)"
+        );
+    }
+
+    let slug = slugify_script_name(normalized_prompt);
+    let finalized = enforce_script_kit_conventions(&extracted, normalized_prompt, &slug);
+    let path = write_generated_script(&slug, &finalized).with_context(|| {
+        format!(
+            "Failed writing AI-generated script (state=write_failed, slug={})",
+            slug
+        )
+    })?;
+
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=script_written path={} slug={}",
+            path.display(),
+            slug
+        ),
+    );
+
+    Ok(GeneratedScriptOutput {
+        path,
+        slug,
+        model_id: selected_model.id,
+        provider_id: selected_model.provider,
+    })
+}
+
+fn select_generation_model(registry: &ProviderRegistry) -> Result<(ModelInfo, Arc<dyn AiProvider>)> {
+    let models = registry.get_all_models();
+    let selected_model = models
+        .iter()
+        .find(|model| model.provider.eq_ignore_ascii_case("vercel"))
+        .or_else(|| models.first())
+        .cloned()
+        .context("No AI models available in provider registry")?;
+
+    let provider = registry
+        .find_provider_for_model(&selected_model.id)
+        .cloned()
+        .with_context(|| {
+            format!(
+                "No provider found for selected model '{}' (state=provider_missing)",
+                selected_model.id
+            )
+        })?;
+
+    Ok((selected_model, provider))
+}
+
+fn generated_scripts_dir() -> PathBuf {
+    PathBuf::from(shellexpand::tilde(AI_SCRIPT_OUTPUT_DIR).as_ref())
+}
+
+fn split_fence_header_and_body(fence: &str) -> (&str, &str) {
+    match fence.find('\n') {
+        Some(newline_index) => (&fence[..newline_index], &fence[newline_index + 1..]),
+        None => ("", fence),
+    }
+}
+
+fn extract_fenced_code(response: &str, preferred_languages: Option<&[&str]>) -> Option<String> {
+    let mut remaining = response;
+
+    while let Some(start) = remaining.find("```") {
+        let after_start = &remaining[start + 3..];
+        let Some(end) = after_start.find("```") else {
+            break;
+        };
+
+        let fence_contents = &after_start[..end];
+        let (header, body) = split_fence_header_and_body(fence_contents);
+        let language = header
+            .trim()
+            .split(|c: char| c.is_whitespace() || c == '{')
+            .next()
+            .unwrap_or("")
+            .to_ascii_lowercase();
+        let code = body.trim();
+
+        if !code.is_empty() {
+            match preferred_languages {
+                Some(preferred) => {
+                    if preferred.iter().any(|candidate| *candidate == language) {
+                        return Some(code.to_string());
+                    }
+                }
+                None => return Some(code.to_string()),
+            }
+        }
+
+        remaining = &after_start[end + 3..];
+    }
+
+    None
+}
+
+fn extract_script_code(response: &str) -> String {
+    const PREFERRED_LANGUAGES: [&str; 6] = ["typescript", "ts", "javascript", "js", "tsx", "jsx"];
+
+    extract_fenced_code(response, Some(&PREFERRED_LANGUAGES))
+        .or_else(|| extract_fenced_code(response, None))
+        .unwrap_or_else(|| response.trim().to_string())
+}
+
+fn slugify_script_name(prompt: &str) -> String {
+    let mut slug = String::new();
+    let mut last_was_hyphen = false;
+
+    for character in prompt.to_ascii_lowercase().chars() {
+        if character.is_ascii_alphanumeric() {
+            slug.push(character);
+            last_was_hyphen = false;
+        } else if matches!(character, ' ' | '_' | '-') {
+            if !slug.is_empty() && !last_was_hyphen {
+                slug.push('-');
+                last_was_hyphen = true;
+            }
+        }
+    }
+
+    while slug.ends_with('-') {
+        slug.pop();
+    }
+
+    if slug.len() > AI_SCRIPT_MAX_SLUG_LEN {
+        slug.truncate(AI_SCRIPT_MAX_SLUG_LEN);
+        while slug.ends_with('-') {
+            slug.pop();
+        }
+    }
+
+    if slug.is_empty() {
+        AI_SCRIPT_DEFAULT_SLUG.to_string()
+    } else {
+        slug
+    }
+}
+
+fn slug_to_title(slug: &str) -> String {
+    slug.split('-')
+        .filter(|segment| !segment.is_empty())
+        .map(|segment| {
+            let mut chars = segment.chars();
+            match chars.next() {
+                Some(first) => first.to_uppercase().collect::<String>() + chars.as_str(),
+                None => String::new(),
+            }
+        })
+        .collect::<Vec<_>>()
+        .join(" ")
+}
+
+fn description_from_prompt(prompt: &str) -> String {
+    let normalized = prompt.split_whitespace().collect::<Vec<_>>().join(" ");
+    if normalized.is_empty() {
+        return "AI-generated Script Kit script".to_string();
+    }
+
+    let mut shortened = normalized;
+    if shortened.chars().count() > 110 {
+        shortened = format!("{}...", shortened.chars().take(107).collect::<String>());
+    }
+    shortened
+}
+
+fn has_kit_import(script: &str) -> bool {
+    script.contains("import \"@johnlindquist/kit\";")
+        || script.contains("import '@johnlindquist/kit';")
+        || script.contains("import \"@scriptkit/sdk\";")
+        || script.contains("import '@scriptkit/sdk';")
+}
+
+fn enforce_script_kit_conventions(script: &str, prompt: &str, slug: &str) -> String {
+    let mut prefix_lines: Vec<String> = Vec::new();
+    let trimmed_script = script.trim();
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Name:"))
+    {
+        prefix_lines.push(format!("// Name: {}", slug_to_title(slug)));
+    }
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Description:"))
+    {
+        prefix_lines.push(format!("// Description: {}", description_from_prompt(prompt)));
+    }
+
+    if !has_kit_import(trimmed_script) {
+        prefix_lines.push("import \"@johnlindquist/kit\";".to_string());
+    }
+
+    let mut output = String::new();
+    if !prefix_lines.is_empty() {
+        output.push_str(&prefix_lines.join("\n"));
+        output.push_str("\n\n");
+    }
+
+    output.push_str(trimmed_script);
+    if !output.ends_with('\n') {
+        output.push('\n');
+    }
+    output
+}
+
+fn write_generated_script(slug: &str, script_content: &str) -> Result<PathBuf> {
+    write_generated_script_in_dir(&generated_scripts_dir(), slug, script_content)
+}
+
+fn write_generated_script_in_dir(output_dir: &Path, slug: &str, script_content: &str) -> Result<PathBuf> {
+    fs::create_dir_all(output_dir)
+        .with_context(|| format!("Failed to create output dir: {}", output_dir.display()))?;
+
+    for suffix in 0usize.. {
+        let candidate = if suffix == 0 {
+            slug.to_string()
+        } else {
+            format!("{slug}-{suffix}")
+        };
+        let path = output_dir.join(format!("{}.ts", candidate));
+        match OpenOptions::new().write(true).create_new(true).open(&path) {
+            Ok(mut file) => {
+                file.write_all(script_content.as_bytes())
+                    .with_context(|| format!("Failed writing generated script to {}", path.display()))?;
+                return Ok(path);
+            }
+            Err(error) if error.kind() == ErrorKind::AlreadyExists => continue,
+            Err(error) => {
+                return Err(error).with_context(|| {
+                    format!(
+                        "Failed creating generated script file {} (slug={})",
+                        path.display(),
+                        slug
+                    )
+                });
+            }
+        }
+    }
+
+    unreachable!("suffix loop should eventually create a unique script filename")
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+    use tempfile::tempdir;
+
+    #[test]
+    fn test_slugify_script_name_handles_spaces_and_symbols() {
+        assert_eq!(slugify_script_name("Build: API Client!"), "build-api-client");
+        assert_eq!(slugify_script_name("  ___  "), "ai-script");
+    }
+
+    #[test]
+    fn test_extract_script_code_prefers_typescript_fence_when_multiple_blocks_exist() {
+        let response = r#"
+Here's one idea:
+```markdown
+Not code
+```
+```typescript
+await div("hello");
+```
+"#;
+        assert_eq!(extract_script_code(response), "await div(\"hello\");");
+    }
+
+    #[test]
+    fn test_extract_script_code_falls_back_to_first_fenced_block() {
+        let response = r#"
+```python
+print("hello")
+```
+"#;
+        assert_eq!(extract_script_code(response), "print(\"hello\")");
+    }
+
+    #[test]
+    fn test_extract_script_code_returns_trimmed_response_when_no_fence_exists() {
+        let response = "const answer = 42;";
+        assert_eq!(extract_script_code(response), "const answer = 42;");
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_adds_missing_metadata_and_import() {
+        let script = "const name = await arg(\"Name?\");";
+        let output = enforce_script_kit_conventions(script, "Ask for user name", "ask-user-name");
+
+        assert!(output.contains("// Name: Ask User Name"));
+        assert!(output.contains("// Description: Ask for user name"));
+        assert!(output.contains("import \"@johnlindquist/kit\";"));
+        assert!(output.contains("await arg(\"Name?\");"));
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_keeps_existing_metadata_and_import() {
+        let script = r#"// Name: Existing
+// Description: Existing description
+import "@johnlindquist/kit";
+
+await div("ready");
+"#;
+        let output = enforce_script_kit_conventions(script, "ignored", "ignored");
+
+        assert_eq!(
+            output.matches("// Name:").count(),
+            1,
+            "should not duplicate existing Name metadata"
+        );
+        assert_eq!(
+            output.matches("// Description:").count(),
+            1,
+            "should not duplicate existing Description metadata"
+        );
+        assert_eq!(
+            output.matches("import \"@johnlindquist/kit\";").count(),
+            1,
+            "should not duplicate existing import"
+        );
+    }
+
+    #[test]
+    fn test_write_generated_script_in_dir_appends_numeric_suffix_for_collisions() {
+        let temp_dir = tempdir().unwrap();
+        let first = write_generated_script_in_dir(temp_dir.path(), "my-script", "a").unwrap();
+        let second = write_generated_script_in_dir(temp_dir.path(), "my-script", "b").unwrap();
+
+        assert_eq!(first.file_name().unwrap(), "my-script.ts");
+        assert_eq!(second.file_name().unwrap(), "my-script-1.ts");
+    }
+}
diff --git a/src/app_execute/builtin_execution.rs b/src/app_execute/builtin_execution.rs
index c2ec833eff5ada1847787967c7b1195720fa43db..beb3a48c404f463d5edf049315cbbb188d07d3a9
--- a/src/app_execute/builtin_execution.rs
+++ b/src/app_execute/builtin_execution.rs
@@ -544,6 +544,30 @@
 
                 use builtins::AiCommandType;
 
+                // Capture prompt text before reset for Shift+Tab/script-generation flows.
+                let script_generation_prompt = if matches!(cmd_type, AiCommandType::GenerateScript)
+                {
+                    Some(self.filter_text.trim().to_string())
+                } else {
+                    None
+                };
+
+                if matches!(cmd_type, AiCommandType::GenerateScript)
+                    && script_generation_prompt
+                        .as_ref()
+                        .is_some_and(|prompt| prompt.is_empty())
+                {
+                    self.toast_manager.push(
+                        components::toast::Toast::warning(
+                            "Type a prompt first, then run Generate Script with AI.",
+                            &self.theme,
+                        )
+                        .duration_ms(Some(3500)),
+                    );
+                    cx.notify();
+                    return;
+                }
+
                 // All AI commands: reset state, hide main window
                 script_kit_gpui::set_main_window_visible(false);
                 self.reset_to_script_list(cx);
@@ -614,6 +638,132 @@
                         }
                     }
 
+                    AiCommandType::GenerateScript => {
+                        let Some(prompt_description) = script_generation_prompt.clone() else {
+                            logging::log(
+                                "AI_SCRIPT_GEN",
+                                "state=failed attempted=capture_prompt failure=missing_prompt",
+                            );
+                            self.toast_manager.push(
+                                components::toast::Toast::error(
+                                    "No prompt available for AI script generation",
+                                    &self.theme,
+                                )
+                                .duration_ms(Some(5000)),
+                            );
+                            cx.notify();
+                            return;
+                        };
+
+                        let config = self.config.clone();
+                        let (tx, rx) = async_channel::bounded::<
+                            std::result::Result<ai::GeneratedScriptOutput, String>,
+                        >(1);
+
+                        logging::log(
+                            "AI_SCRIPT_GEN",
+                            &format!(
+                                "state=queued attempted=builtin_generate_script prompt_len={}",
+                                prompt_description.len()
+                            ),
+                        );
+
+                        std::thread::spawn(move || {
+                            let generation_result =
+                                ai::generate_script_from_prompt(&prompt_description, Some(&config))
+                                    .map_err(|error| error.to_string());
+
+                            if tx.send_blocking(generation_result).is_err() {
+                                logging::log(
+                                    "AI_SCRIPT_GEN",
+                                    "state=aborted attempted=send_result failure=result_channel_closed",
+                                );
+                            }
+                        });
+
+                        cx.spawn(async move |this, cx| {
+                            let Ok(result) = rx.recv().await else {
+                                logging::log(
+                                    "AI_SCRIPT_GEN",
+                                    "state=aborted attempted=recv_result failure=result_channel_closed",
+                                );
+                                return;
+                            };
+
+                            let _ = cx.update(|cx| {
+                                this.update(cx, |app, cx| match result {
+                                    Ok(generated) => {
+                                        let script_name = generated
+                                            .path
+                                            .file_name()
+                                            .and_then(|name| name.to_str())
+                                            .unwrap_or("generated script");
+
+                                        if let Err(error) =
+                                            script_creation::open_in_editor(&generated.path, &app.config)
+                                        {
+                                            logging::log(
+                                                "AI_SCRIPT_GEN",
+                                                &format!(
+                                                    "state=failed attempted=open_editor path={} error={}",
+                                                    generated.path.display(),
+                                                    error
+                                                ),
+                                            );
+                                            app.toast_manager.push(
+                                                components::toast::Toast::error(
+                                                    format!(
+                                                        "Generated {}, but failed to open editor: {}",
+                                                        script_name, error
+                                                    ),
+                                                    &app.theme,
+                                                )
+                                                .duration_ms(Some(7000)),
+                                            );
+                                            cx.notify();
+                                        } else {
+                                            logging::log(
+                                                "AI_SCRIPT_GEN",
+                                                &format!(
+                                                    "state=completed attempted=builtin_generate_script path={} model_id={} provider_id={}",
+                                                    generated.path.display(),
+                                                    generated.model_id,
+                                                    generated.provider_id
+                                                ),
+                                            );
+                                            app.toast_manager.push(
+                                                components::toast::Toast::success(
+                                                    format!("Generated and opened {}", script_name),
+                                                    &app.theme,
+                                                )
+                                                .duration_ms(Some(3500)),
+                                            );
+                                            app.close_and_reset_window(cx);
+                                        }
+                                    }
+                                    Err(error) => {
+                                        logging::log(
+                                            "AI_SCRIPT_GEN",
+                                            &format!(
+                                                "state=failed attempted=builtin_generate_script error={}",
+                                                error
+                                            ),
+                                        );
+                                        app.toast_manager.push(
+                                            components::toast::Toast::error(
+                                                format!("Failed to generate script: {}", error),
+                                                &app.theme,
+                                            )
+                                            .duration_ms(Some(7000)),
+                                        );
+                                        cx.notify();
+                                    }
+                                })
+                            });
+                        })
+                        .detach();
+                    }
+
                     AiCommandType::SendScreenToAi => {
                         // Capture entire screen and send to AI
                         match platform::capture_screen_screenshot() {
diff --git a/src/builtins/part_000.rs b/src/builtins/part_000.rs
index d6b9c2a9b35b40c5005dbb9f65147f528702cb9e..5f6d27d28d72e51126d10d8beccf931c689ef2bb
--- a/src/builtins/part_000.rs
+++ b/src/builtins/part_000.rs
@@ -96,6 +96,8 @@
     OpenAi,
     NewConversation,
     ClearConversation,
+    /// Generate a new Script Kit script from the main prompt text
+    GenerateScript,
     /// Send a screenshot of the entire screen to AI Chat
     SendScreenToAi,
     /// Send a screenshot of the focused window to AI Chat
diff --git a/src/builtins/part_001_entries/entries_002.rs b/src/builtins/part_001_entries/entries_002.rs
index 6d1c9334f0ccaf0aab48582aaf42dcb129e1cb6e..72b318c66aeaf124359f4ecd276dae0350287328
--- a/src/builtins/part_001_entries/entries_002.rs
+++ b/src/builtins/part_001_entries/entries_002.rs
@@ -61,6 +61,17 @@
     ));
 
     entries.push(BuiltInEntry::new_with_icon(
+        "builtin-generate-script-with-ai",
+        "Generate Script with AI",
+        "Generate a Script Kit script from your current prompt text",
+        vec![
+            "generate", "script", "ai", "create", "code", "typescript", "shift", "tab",
+        ],
+        BuiltInFeature::AiCommand(AiCommandType::GenerateScript),
+        "ðŸ§ ",
+    ));
+
+    entries.push(BuiltInEntry::new_with_icon(
         "builtin-send-screen-to-ai",
         "Send Screen to AI Chat",
         "Capture the full screen and send it to AI Chat",

file update:
diff --git a/src/ai/mod.rs b/src/ai/mod.rs
index a420b1a5faf59506acdb7caf60681c153a3f9bb6..9a73e9491862633b325b2c52b51a3e20395ff85c
--- a/src/ai/mod.rs
+++ b/src/ai/mod.rs
@@ -37,6 +37,7 @@
 pub(crate) mod providers;
 pub(crate) mod sdk_handlers;
 pub(crate) mod session;
+pub(crate) mod script_generation;
 pub(crate) mod storage;
 pub(crate) mod window;
 
@@ -44,6 +45,7 @@
 pub use self::config::{DetectedKeys, ModelInfo, ProviderConfig};
 pub use self::model::{Chat, ChatId, ChatSource, Message, MessageRole};
 pub use self::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+pub use self::script_generation::{generate_script_from_prompt, GeneratedScriptOutput};
 pub use self::sdk_handlers::try_handle_ai_message;
 pub use self::storage::{
     clear_all_chats, create_chat, delete_chat, get_all_chats, get_chat, get_chat_messages,
diff --git a/src/ai/script_generation.rs b/src/ai/script_generation.rs
new file mode 100644
index 0000000000000000000000000000000000000000..7f2ec8e7576ed50cd10f7aea31a6522875ef667a
--- /dev/null
+++ b/src/ai/script_generation.rs
@@ -0,0 +1,417 @@
+use anyhow::{Context, Result};
+use std::fs::{self, OpenOptions};
+use std::io::{ErrorKind, Write};
+use std::path::{Path, PathBuf};
+use std::sync::Arc;
+
+use super::config::ModelInfo;
+use super::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+
+const AI_SCRIPT_OUTPUT_DIR: &str = "~/.kenv/scripts";
+const AI_SCRIPT_DEFAULT_SLUG: &str = "ai-script";
+const AI_SCRIPT_MAX_SLUG_LEN: usize = 64;
+
+const AI_SCRIPT_GENERATION_SYSTEM_PROMPT: &str = r#"You write production-ready Script Kit scripts.
+
+Return ONLY TypeScript source code for one Script Kit script. Do not include explanations.
+
+Required output conventions:
+1) Include metadata comments at the top:
+   // Name: <clear title>
+   // Description: <one-line summary>
+2) Include: import "@johnlindquist/kit";
+3) Use await arg() for user input when useful.
+4) Use await div() for display output when useful.
+5) Keep the script runnable as-is with sensible defaults and light error handling."#;
+
+#[derive(Debug, Clone)]
+pub struct GeneratedScriptOutput {
+    pub path: PathBuf,
+    pub slug: String,
+    pub model_id: String,
+    pub provider_id: String,
+}
+
+pub fn generate_script_from_prompt(
+    prompt: &str,
+    config: Option<&crate::config::Config>,
+) -> Result<GeneratedScriptOutput> {
+    let normalized_prompt = prompt.trim();
+    if normalized_prompt.is_empty() {
+        anyhow::bail!("AI script generation requires a non-empty prompt");
+    }
+
+    let registry = ProviderRegistry::from_environment_with_config(config);
+    if !registry.has_any_provider() {
+        anyhow::bail!(
+            "No AI providers configured. Configure an API key first (Vercel, OpenAI, Anthropic, etc.)."
+        );
+    }
+
+    let (selected_model, provider) = select_generation_model(&registry)?;
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=provider_ready model_id={} provider_id={} prompt_len={}",
+            selected_model.id,
+            selected_model.provider,
+            normalized_prompt.len()
+        ),
+    );
+
+    let messages = vec![
+        ProviderMessage::system(AI_SCRIPT_GENERATION_SYSTEM_PROMPT),
+        ProviderMessage::user(format!(
+            "Generate a Script Kit script for this user request:\n\n{}",
+            normalized_prompt
+        )),
+    ];
+
+    let raw_response = provider
+        .send_message(&messages, &selected_model.id)
+        .with_context(|| {
+            format!(
+                "AI script generation failed (attempted=send_message, model_id={}, provider_id={})",
+                selected_model.id, selected_model.provider
+            )
+        })?;
+
+    let extracted = extract_script_code(&raw_response);
+    if extracted.trim().is_empty() {
+        anyhow::bail!(
+            "AI returned an empty response for script generation (state=empty_response)"
+        );
+    }
+
+    let slug = slugify_script_name(normalized_prompt);
+    let finalized = enforce_script_kit_conventions(&extracted, normalized_prompt, &slug);
+    let path = write_generated_script(&slug, &finalized).with_context(|| {
+        format!(
+            "Failed writing AI-generated script (state=write_failed, slug={})",
+            slug
+        )
+    })?;
+
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=script_written path={} slug={}",
+            path.display(),
+            slug
+        ),
+    );
+
+    Ok(GeneratedScriptOutput {
+        path,
+        slug,
+        model_id: selected_model.id,
+        provider_id: selected_model.provider,
+    })
+}
+
+fn select_generation_model(registry: &ProviderRegistry) -> Result<(ModelInfo, Arc<dyn AiProvider>)> {
+    let models = registry.get_all_models();
+    let selected_model = models
+        .iter()
+        .find(|model| model.provider.eq_ignore_ascii_case("vercel"))
+        .or_else(|| models.first())
+        .cloned()
+        .context("No AI models available in provider registry")?;
+
+    let provider = registry
+        .find_provider_for_model(&selected_model.id)
+        .cloned()
+        .with_context(|| {
+            format!(
+                "No provider found for selected model '{}' (state=provider_missing)",
+                selected_model.id
+            )
+        })?;
+
+    Ok((selected_model, provider))
+}
+
+fn generated_scripts_dir() -> PathBuf {
+    PathBuf::from(shellexpand::tilde(AI_SCRIPT_OUTPUT_DIR).as_ref())
+}
+
+fn split_fence_header_and_body(fence: &str) -> (&str, &str) {
+    match fence.find('\n') {
+        Some(newline_index) => (&fence[..newline_index], &fence[newline_index + 1..]),
+        None => ("", fence),
+    }
+}
+
+fn extract_fenced_code(response: &str, preferred_languages: Option<&[&str]>) -> Option<String> {
+    let mut remaining = response;
+
+    while let Some(start) = remaining.find("```") {
+        let after_start = &remaining[start + 3..];
+        let Some(end) = after_start.find("```") else {
+            break;
+        };
+
+        let fence_contents = &after_start[..end];
+        let (header, body) = split_fence_header_and_body(fence_contents);
+        let language = header
+            .trim()
+            .split(|c: char| c.is_whitespace() || c == '{')
+            .next()
+            .unwrap_or("")
+            .to_ascii_lowercase();
+        let code = body.trim();
+
+        if !code.is_empty() {
+            match preferred_languages {
+                Some(preferred) => {
+                    if preferred.iter().any(|candidate| *candidate == language) {
+                        return Some(code.to_string());
+                    }
+                }
+                None => return Some(code.to_string()),
+            }
+        }
+
+        remaining = &after_start[end + 3..];
+    }
+
+    None
+}
+
+fn extract_script_code(response: &str) -> String {
+    const PREFERRED_LANGUAGES: [&str; 6] = ["typescript", "ts", "javascript", "js", "tsx", "jsx"];
+
+    extract_fenced_code(response, Some(&PREFERRED_LANGUAGES))
+        .or_else(|| extract_fenced_code(response, None))
+        .unwrap_or_else(|| response.trim().to_string())
+}
+
+fn slugify_script_name(prompt: &str) -> String {
+    let mut slug = String::new();
+    let mut last_was_hyphen = false;
+
+    for character in prompt.to_ascii_lowercase().chars() {
+        if character.is_ascii_alphanumeric() {
+            slug.push(character);
+            last_was_hyphen = false;
+        } else if matches!(character, ' ' | '_' | '-') {
+            if !slug.is_empty() && !last_was_hyphen {
+                slug.push('-');
+                last_was_hyphen = true;
+            }
+        }
+    }
+
+    while slug.ends_with('-') {
+        slug.pop();
+    }
+
+    if slug.len() > AI_SCRIPT_MAX_SLUG_LEN {
+        slug.truncate(AI_SCRIPT_MAX_SLUG_LEN);
+        while slug.ends_with('-') {
+            slug.pop();
+        }
+    }
+
+    if slug.is_empty() {
+        AI_SCRIPT_DEFAULT_SLUG.to_string()
+    } else {
+        slug
+    }
+}
+
+fn slug_to_title(slug: &str) -> String {
+    slug.split('-')
+        .filter(|segment| !segment.is_empty())
+        .map(|segment| {
+            let mut chars = segment.chars();
+            match chars.next() {
+                Some(first) => first.to_uppercase().collect::<String>() + chars.as_str(),
+                None => String::new(),
+            }
+        })
+        .collect::<Vec<_>>()
+        .join(" ")
+}
+
+fn description_from_prompt(prompt: &str) -> String {
+    let normalized = prompt.split_whitespace().collect::<Vec<_>>().join(" ");
+    if normalized.is_empty() {
+        return "AI-generated Script Kit script".to_string();
+    }
+
+    let mut shortened = normalized;
+    if shortened.chars().count() > 110 {
+        shortened = format!("{}...", shortened.chars().take(107).collect::<String>());
+    }
+    shortened
+}
+
+fn has_kit_import(script: &str) -> bool {
+    script.contains("import \"@johnlindquist/kit\";")
+        || script.contains("import '@johnlindquist/kit';")
+        || script.contains("import \"@scriptkit/sdk\";")
+        || script.contains("import '@scriptkit/sdk';")
+}
+
+fn enforce_script_kit_conventions(script: &str, prompt: &str, slug: &str) -> String {
+    let mut prefix_lines: Vec<String> = Vec::new();
+    let trimmed_script = script.trim();
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Name:"))
+    {
+        prefix_lines.push(format!("// Name: {}", slug_to_title(slug)));
+    }
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Description:"))
+    {
+        prefix_lines.push(format!("// Description: {}", description_from_prompt(prompt)));
+    }
+
+    if !has_kit_import(trimmed_script) {
+        prefix_lines.push("import \"@johnlindquist/kit\";".to_string());
+    }
+
+    let mut output = String::new();
+    if !prefix_lines.is_empty() {
+        output.push_str(&prefix_lines.join("\n"));
+        output.push_str("\n\n");
+    }
+
+    output.push_str(trimmed_script);
+    if !output.ends_with('\n') {
+        output.push('\n');
+    }
+    output
+}
+
+fn write_generated_script(slug: &str, script_content: &str) -> Result<PathBuf> {
+    write_generated_script_in_dir(&generated_scripts_dir(), slug, script_content)
+}
+
+fn write_generated_script_in_dir(output_dir: &Path, slug: &str, script_content: &str) -> Result<PathBuf> {
+    fs::create_dir_all(output_dir)
+        .with_context(|| format!("Failed to create output dir: {}", output_dir.display()))?;
+
+    for suffix in 0usize.. {
+        let candidate = if suffix == 0 {
+            slug.to_string()
+        } else {
+            format!("{slug}-{suffix}")
+        };
+        let path = output_dir.join(format!("{}.ts", candidate));
+        match OpenOptions::new().write(true).create_new(true).open(&path) {
+            Ok(mut file) => {
+                file.write_all(script_content.as_bytes())
+                    .with_context(|| format!("Failed writing generated script to {}", path.display()))?;
+                return Ok(path);
+            }
+            Err(error) if error.kind() == ErrorKind::AlreadyExists => continue,
+            Err(error) => {
+                return Err(error).with_context(|| {
+                    format!(
+                        "Failed creating generated script file {} (slug={})",
+                        path.display(),
+                        slug
+                    )
+                });
+            }
+        }
+    }
+
+    unreachable!("suffix loop should eventually create a unique script filename")
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+    use tempfile::tempdir;
+
+    #[test]
+    fn test_slugify_script_name_handles_spaces_and_symbols() {
+        assert_eq!(slugify_script_name("Build: API Client!"), "build-api-client");
+        assert_eq!(slugify_script_name("  ___  "), "ai-script");
+    }
+
+    #[test]
+    fn test_extract_script_code_prefers_typescript_fence_when_multiple_blocks_exist() {
+        let response = r#"
+Here's one idea:
+```markdown
+Not code
+```
+```typescript
+await div("hello");
+```
+"#;
+        assert_eq!(extract_script_code(response), "await div(\"hello\");");
+    }
+
+    #[test]
+    fn test_extract_script_code_falls_back_to_first_fenced_block() {
+        let response = r#"
+```python
+print("hello")
+```
+"#;
+        assert_eq!(extract_script_code(response), "print(\"hello\")");
+    }
+
+    #[test]
+    fn test_extract_script_code_returns_trimmed_response_when_no_fence_exists() {
+        let response = "const answer = 42;";
+        assert_eq!(extract_script_code(response), "const answer = 42;");
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_adds_missing_metadata_and_import() {
+        let script = "const name = await arg(\"Name?\");";
+        let output = enforce_script_kit_conventions(script, "Ask for user name", "ask-user-name");
+
+        assert!(output.contains("// Name: Ask User Name"));
+        assert!(output.contains("// Description: Ask for user name"));
+        assert!(output.contains("import \"@johnlindquist/kit\";"));
+        assert!(output.contains("await arg(\"Name?\");"));
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_keeps_existing_metadata_and_import() {
+        let script = r#"// Name: Existing
+// Description: Existing description
+import "@johnlindquist/kit";
+
+await div("ready");
+"#;
+        let output = enforce_script_kit_conventions(script, "ignored", "ignored");
+
+        assert_eq!(
+            output.matches("// Name:").count(),
+            1,
+            "should not duplicate existing Name metadata"
+        );
+        assert_eq!(
+            output.matches("// Description:").count(),
+            1,
+            "should not duplicate existing Description metadata"
+        );
+        assert_eq!(
+            output.matches("import \"@johnlindquist/kit\";").count(),
+            1,
+            "should not duplicate existing import"
+        );
+    }
+
+    #[test]
+    fn test_write_generated_script_in_dir_appends_numeric_suffix_for_collisions() {
+        let temp_dir = tempdir().unwrap();
+        let first = write_generated_script_in_dir(temp_dir.path(), "my-script", "a").unwrap();
+        let second = write_generated_script_in_dir(temp_dir.path(), "my-script", "b").unwrap();
+
+        assert_eq!(first.file_name().unwrap(), "my-script.ts");
+        assert_eq!(second.file_name().unwrap(), "my-script-1.ts");
+    }
+}
diff --git a/src/app_execute/builtin_execution.rs b/src/app_execute/builtin_execution.rs
index c2ec833eff5ada1847787967c7b1195720fa43db..beb3a48c404f463d5edf049315cbbb188d07d3a9
--- a/src/app_execute/builtin_execution.rs
+++ b/src/app_execute/builtin_execution.rs
@@ -544,6 +544,30 @@
 
                 use builtins::AiCommandType;
 
+                // Capture prompt text before reset for Shift+Tab/script-generation flows.
+                let script_generation_prompt = if matches!(cmd_type, AiCommandType::GenerateScript)
+                {
+                    Some(self.filter_text.trim().to_string())
+                } else {
+                    None
+                };
+
+                if matches!(cmd_type, AiCommandType::GenerateScript)
+                    && script_generation_prompt
+                        .as_ref()
+                        .is_some_and(|prompt| prompt.is_empty())
+                {
+                    self.toast_manager.push(
+                        components::toast::Toast::warning(
+                            "Type a prompt first, then run Generate Script with AI.",
+                            &self.theme,
+                        )
+                        .duration_ms(Some(3500)),
+                    );
+                    cx.notify();
+                    return;
+                }
+
                 // All AI commands: reset state, hide main window
                 script_kit_gpui::set_main_window_visible(false);
                 self.reset_to_script_list(cx);
@@ -614,6 +638,132 @@
                         }
                     }
 
+                    AiCommandType::GenerateScript => {
+                        let Some(prompt_description) = script_generation_prompt.clone() else {
+                            logging::log(
+                                "AI_SCRIPT_GEN",
+                                "state=failed attempted=capture_prompt failure=missing_prompt",
+                            );
+                            self.toast_manager.push(
+                                components::toast::Toast::error(
+                                    "No prompt available for AI script generation",
+                                    &self.theme,
+                                )
+                                .duration_ms(Some(5000)),
+                            );
+                            cx.notify();
+                            return;
+                        };
+
+                        let config = self.config.clone();
+                        let (tx, rx) = async_channel::bounded::<
+                            std::result::Result<ai::GeneratedScriptOutput, String>,
+                        >(1);
+
+                        logging::log(
+                            "AI_SCRIPT_GEN",
+                            &format!(
+                                "state=queued attempted=builtin_generate_script prompt_len={}",
+                                prompt_description.len()
+                            ),
+                        );
+
+                        std::thread::spawn(move || {
+                            let generation_result =
+                                ai::generate_script_from_prompt(&prompt_description, Some(&config))
+                                    .map_err(|error| error.to_string());
+
+                            if tx.send_blocking(generation_result).is_err() {
+                                logging::log(
+                                    "AI_SCRIPT_GEN",
+                                    "state=aborted attempted=send_result failure=result_channel_closed",
+                                );
+                            }
+                        });
+
+                        cx.spawn(async move |this, cx| {
+                            let Ok(result) = rx.recv().await else {
+                                logging::log(
+                                    "AI_SCRIPT_GEN",
+                                    "state=aborted attempted=recv_result failure=result_channel_closed",
+                                );
+                                return;
+                            };
+
+                            let _ = cx.update(|cx| {
+                                this.update(cx, |app, cx| match result {
+                                    Ok(generated) => {
+                                        let script_name = generated
+                                            .path
+                                            .file_name()
+                                            .and_then(|name| name.to_str())
+                                            .unwrap_or("generated script");
+
+                                        if let Err(error) =
+                                            script_creation::open_in_editor(&generated.path, &app.config)
+                                        {
+                                            logging::log(
+                                                "AI_SCRIPT_GEN",
+                                                &format!(
+                                                    "state=failed attempted=open_editor path={} error={}",
+                                                    generated.path.display(),
+                                                    error
+                                                ),
+                                            );
+                                            app.toast_manager.push(
+                                                components::toast::Toast::error(
+                                                    format!(
+                                                        "Generated {}, but failed to open editor: {}",
+                                                        script_name, error
+                                                    ),
+                                                    &app.theme,
+                                                )
+                                                .duration_ms(Some(7000)),
+                                            );
+                                            cx.notify();
+                                        } else {
+                                            logging::log(
+                                                "AI_SCRIPT_GEN",
+                                                &format!(
+                                                    "state=completed attempted=builtin_generate_script path={} model_id={} provider_id={}",
+                                                    generated.path.display(),
+                                                    generated.model_id,
+                                                    generated.provider_id
+                                                ),
+                                            );
+                                            app.toast_manager.push(
+                                                components::toast::Toast::success(
+                                                    format!("Generated and opened {}", script_name),
+                                                    &app.theme,
+                                                )
+                                                .duration_ms(Some(3500)),
+                                            );
+                                            app.close_and_reset_window(cx);
+                                        }
+                                    }
+                                    Err(error) => {
+                                        logging::log(
+                                            "AI_SCRIPT_GEN",
+                                            &format!(
+                                                "state=failed attempted=builtin_generate_script error={}",
+                                                error
+                                            ),
+                                        );
+                                        app.toast_manager.push(
+                                            components::toast::Toast::error(
+                                                format!("Failed to generate script: {}", error),
+                                                &app.theme,
+                                            )
+                                            .duration_ms(Some(7000)),
+                                        );
+                                        cx.notify();
+                                    }
+                                })
+                            });
+                        })
+                        .detach();
+                    }
+
                     AiCommandType::SendScreenToAi => {
                         // Capture entire screen and send to AI
                         match platform::capture_screen_screenshot() {
diff --git a/src/builtins/part_000.rs b/src/builtins/part_000.rs
index d6b9c2a9b35b40c5005dbb9f65147f528702cb9e..5f6d27d28d72e51126d10d8beccf931c689ef2bb
--- a/src/builtins/part_000.rs
+++ b/src/builtins/part_000.rs
@@ -96,6 +96,8 @@
     OpenAi,
     NewConversation,
     ClearConversation,
+    /// Generate a new Script Kit script from the main prompt text
+    GenerateScript,
     /// Send a screenshot of the entire screen to AI Chat
     SendScreenToAi,
     /// Send a screenshot of the focused window to AI Chat
diff --git a/src/builtins/part_001_entries/entries_002.rs b/src/builtins/part_001_entries/entries_002.rs
index 6d1c9334f0ccaf0aab48582aaf42dcb129e1cb6e..72b318c66aeaf124359f4ecd276dae0350287328
--- a/src/builtins/part_001_entries/entries_002.rs
+++ b/src/builtins/part_001_entries/entries_002.rs
@@ -61,6 +61,17 @@
     ));
 
     entries.push(BuiltInEntry::new_with_icon(
+        "builtin-generate-script-with-ai",
+        "Generate Script with AI",
+        "Generate a Script Kit script from your current prompt text",
+        vec![
+            "generate", "script", "ai", "create", "code", "typescript", "shift", "tab",
+        ],
+        BuiltInFeature::AiCommand(AiCommandType::GenerateScript),
+        "ðŸ§ ",
+    ));
+
+    entries.push(BuiltInEntry::new_with_icon(
         "builtin-send-screen-to-ai",
         "Send Screen to AI Chat",
         "Capture the full screen and send it to AI Chat",


thinking
**Planning tests for builtins**
codex
Iâ€™ve wired the new `GenerateScript` execution path in `builtin_execution`. Next Iâ€™m adding/adjusting built-ins tests to assert the new entry and command type are present and discoverable.
file update
M /Users/johnlindquist/dev/script-kit-gpui/src/builtins/tests/part_000.rs
@@ -304,2 +304,22 @@
         );
+
+        let generate_script = entries
+            .iter()
+            .find(|e| e.id == "builtin-generate-script-with-ai");
+        assert!(
+            generate_script.is_some(),
+            "builtin-generate-script-with-ai should exist"
+        );
+        let generate_script = generate_script.unwrap();
+        assert_eq!(
+            generate_script.feature,
+            BuiltInFeature::AiCommand(AiCommandType::GenerateScript)
+        );
+        assert!(
+            generate_script
+                .keywords
+                .iter()
+                .any(|keyword| keyword.eq_ignore_ascii_case("shift")),
+            "Generate Script command should be discoverable via Shift+Tab wording"
+        );
     }
apply_patch(auto_approved=true) exited 0 in 32ms:
Success. Updated the following files:
M src/builtins/tests/part_000.rs
file update:
diff --git a/src/ai/mod.rs b/src/ai/mod.rs
index a420b1a5faf59506acdb7caf60681c153a3f9bb6..9a73e9491862633b325b2c52b51a3e20395ff85c
--- a/src/ai/mod.rs
+++ b/src/ai/mod.rs
@@ -37,6 +37,7 @@
 pub(crate) mod providers;
 pub(crate) mod sdk_handlers;
 pub(crate) mod session;
+pub(crate) mod script_generation;
 pub(crate) mod storage;
 pub(crate) mod window;
 
@@ -44,6 +45,7 @@
 pub use self::config::{DetectedKeys, ModelInfo, ProviderConfig};
 pub use self::model::{Chat, ChatId, ChatSource, Message, MessageRole};
 pub use self::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+pub use self::script_generation::{generate_script_from_prompt, GeneratedScriptOutput};
 pub use self::sdk_handlers::try_handle_ai_message;
 pub use self::storage::{
     clear_all_chats, create_chat, delete_chat, get_all_chats, get_chat, get_chat_messages,
diff --git a/src/ai/script_generation.rs b/src/ai/script_generation.rs
new file mode 100644
index 0000000000000000000000000000000000000000..7f2ec8e7576ed50cd10f7aea31a6522875ef667a
--- /dev/null
+++ b/src/ai/script_generation.rs
@@ -0,0 +1,417 @@
+use anyhow::{Context, Result};
+use std::fs::{self, OpenOptions};
+use std::io::{ErrorKind, Write};
+use std::path::{Path, PathBuf};
+use std::sync::Arc;
+
+use super::config::ModelInfo;
+use super::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+
+const AI_SCRIPT_OUTPUT_DIR: &str = "~/.kenv/scripts";
+const AI_SCRIPT_DEFAULT_SLUG: &str = "ai-script";
+const AI_SCRIPT_MAX_SLUG_LEN: usize = 64;
+
+const AI_SCRIPT_GENERATION_SYSTEM_PROMPT: &str = r#"You write production-ready Script Kit scripts.
+
+Return ONLY TypeScript source code for one Script Kit script. Do not include explanations.
+
+Required output conventions:
+1) Include metadata comments at the top:
+   // Name: <clear title>
+   // Description: <one-line summary>
+2) Include: import "@johnlindquist/kit";
+3) Use await arg() for user input when useful.
+4) Use await div() for display output when useful.
+5) Keep the script runnable as-is with sensible defaults and light error handling."#;
+
+#[derive(Debug, Clone)]
+pub struct GeneratedScriptOutput {
+    pub path: PathBuf,
+    pub slug: String,
+    pub model_id: String,
+    pub provider_id: String,
+}
+
+pub fn generate_script_from_prompt(
+    prompt: &str,
+    config: Option<&crate::config::Config>,
+) -> Result<GeneratedScriptOutput> {
+    let normalized_prompt = prompt.trim();
+    if normalized_prompt.is_empty() {
+        anyhow::bail!("AI script generation requires a non-empty prompt");
+    }
+
+    let registry = ProviderRegistry::from_environment_with_config(config);
+    if !registry.has_any_provider() {
+        anyhow::bail!(
+            "No AI providers configured. Configure an API key first (Vercel, OpenAI, Anthropic, etc.)."
+        );
+    }
+
+    let (selected_model, provider) = select_generation_model(&registry)?;
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=provider_ready model_id={} provider_id={} prompt_len={}",
+            selected_model.id,
+            selected_model.provider,
+            normalized_prompt.len()
+        ),
+    );
+
+    let messages = vec![
+        ProviderMessage::system(AI_SCRIPT_GENERATION_SYSTEM_PROMPT),
+        ProviderMessage::user(format!(
+            "Generate a Script Kit script for this user request:\n\n{}",
+            normalized_prompt
+        )),
+    ];
+
+    let raw_response = provider
+        .send_message(&messages, &selected_model.id)
+        .with_context(|| {
+            format!(
+                "AI script generation failed (attempted=send_message, model_id={}, provider_id={})",
+                selected_model.id, selected_model.provider
+            )
+        })?;
+
+    let extracted = extract_script_code(&raw_response);
+    if extracted.trim().is_empty() {
+        anyhow::bail!(
+            "AI returned an empty response for script generation (state=empty_response)"
+        );
+    }
+
+    let slug = slugify_script_name(normalized_prompt);
+    let finalized = enforce_script_kit_conventions(&extracted, normalized_prompt, &slug);
+    let path = write_generated_script(&slug, &finalized).with_context(|| {
+        format!(
+            "Failed writing AI-generated script (state=write_failed, slug={})",
+            slug
+        )
+    })?;
+
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=script_written path={} slug={}",
+            path.display(),
+            slug
+        ),
+    );
+
+    Ok(GeneratedScriptOutput {
+        path,
+        slug,
+        model_id: selected_model.id,
+        provider_id: selected_model.provider,
+    })
+}
+
+fn select_generation_model(registry: &ProviderRegistry) -> Result<(ModelInfo, Arc<dyn AiProvider>)> {
+    let models = registry.get_all_models();
+    let selected_model = models
+        .iter()
+        .find(|model| model.provider.eq_ignore_ascii_case("vercel"))
+        .or_else(|| models.first())
+        .cloned()
+        .context("No AI models available in provider registry")?;
+
+    let provider = registry
+        .find_provider_for_model(&selected_model.id)
+        .cloned()
+        .with_context(|| {
+            format!(
+                "No provider found for selected model '{}' (state=provider_missing)",
+                selected_model.id
+            )
+        })?;
+
+    Ok((selected_model, provider))
+}
+
+fn generated_scripts_dir() -> PathBuf {
+    PathBuf::from(shellexpand::tilde(AI_SCRIPT_OUTPUT_DIR).as_ref())
+}
+
+fn split_fence_header_and_body(fence: &str) -> (&str, &str) {
+    match fence.find('\n') {
+        Some(newline_index) => (&fence[..newline_index], &fence[newline_index + 1..]),
+        None => ("", fence),
+    }
+}
+
+fn extract_fenced_code(response: &str, preferred_languages: Option<&[&str]>) -> Option<String> {
+    let mut remaining = response;
+
+    while let Some(start) = remaining.find("```") {
+        let after_start = &remaining[start + 3..];
+        let Some(end) = after_start.find("```") else {
+            break;
+        };
+
+        let fence_contents = &after_start[..end];
+        let (header, body) = split_fence_header_and_body(fence_contents);
+        let language = header
+            .trim()
+            .split(|c: char| c.is_whitespace() || c == '{')
+            .next()
+            .unwrap_or("")
+            .to_ascii_lowercase();
+        let code = body.trim();
+
+        if !code.is_empty() {
+            match preferred_languages {
+                Some(preferred) => {
+                    if preferred.iter().any(|candidate| *candidate == language) {
+                        return Some(code.to_string());
+                    }
+                }
+                None => return Some(code.to_string()),
+            }
+        }
+
+        remaining = &after_start[end + 3..];
+    }
+
+    None
+}
+
+fn extract_script_code(response: &str) -> String {
+    const PREFERRED_LANGUAGES: [&str; 6] = ["typescript", "ts", "javascript", "js", "tsx", "jsx"];
+
+    extract_fenced_code(response, Some(&PREFERRED_LANGUAGES))
+        .or_else(|| extract_fenced_code(response, None))
+        .unwrap_or_else(|| response.trim().to_string())
+}
+
+fn slugify_script_name(prompt: &str) -> String {
+    let mut slug = String::new();
+    let mut last_was_hyphen = false;
+
+    for character in prompt.to_ascii_lowercase().chars() {
+        if character.is_ascii_alphanumeric() {
+            slug.push(character);
+            last_was_hyphen = false;
+        } else if matches!(character, ' ' | '_' | '-') {
+            if !slug.is_empty() && !last_was_hyphen {
+                slug.push('-');
+                last_was_hyphen = true;
+            }
+        }
+    }
+
+    while slug.ends_with('-') {
+        slug.pop();
+    }
+
+    if slug.len() > AI_SCRIPT_MAX_SLUG_LEN {
+        slug.truncate(AI_SCRIPT_MAX_SLUG_LEN);
+        while slug.ends_with('-') {
+            slug.pop();
+        }
+    }
+
+    if slug.is_empty() {
+        AI_SCRIPT_DEFAULT_SLUG.to_string()
+    } else {
+        slug
+    }
+}
+
+fn slug_to_title(slug: &str) -> String {
+    slug.split('-')
+        .filter(|segment| !segment.is_empty())
+        .map(|segment| {
+            let mut chars = segment.chars();
+            match chars.next() {
+                Some(first) => first.to_uppercase().collect::<String>() + chars.as_str(),
+                None => String::new(),
+            }
+        })
+        .collect::<Vec<_>>()
+        .join(" ")
+}
+
+fn description_from_prompt(prompt: &str) -> String {
+    let normalized = prompt.split_whitespace().collect::<Vec<_>>().join(" ");
+    if normalized.is_empty() {
+        return "AI-generated Script Kit script".to_string();
+    }
+
+    let mut shortened = normalized;
+    if shortened.chars().count() > 110 {
+        shortened = format!("{}...", shortened.chars().take(107).collect::<String>());
+    }
+    shortened
+}
+
+fn has_kit_import(script: &str) -> bool {
+    script.contains("import \"@johnlindquist/kit\";")
+        || script.contains("import '@johnlindquist/kit';")
+        || script.contains("import \"@scriptkit/sdk\";")
+        || script.contains("import '@scriptkit/sdk';")
+}
+
+fn enforce_script_kit_conventions(script: &str, prompt: &str, slug: &str) -> String {
+    let mut prefix_lines: Vec<String> = Vec::new();
+    let trimmed_script = script.trim();
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Name:"))
+    {
+        prefix_lines.push(format!("// Name: {}", slug_to_title(slug)));
+    }
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Description:"))
+    {
+        prefix_lines.push(format!("// Description: {}", description_from_prompt(prompt)));
+    }
+
+    if !has_kit_import(trimmed_script) {
+        prefix_lines.push("import \"@johnlindquist/kit\";".to_string());
+    }
+
+    let mut output = String::new();
+    if !prefix_lines.is_empty() {
+        output.push_str(&prefix_lines.join("\n"));
+        output.push_str("\n\n");
+    }
+
+    output.push_str(trimmed_script);
+    if !output.ends_with('\n') {
+        output.push('\n');
+    }
+    output
+}
+
+fn write_generated_script(slug: &str, script_content: &str) -> Result<PathBuf> {
+    write_generated_script_in_dir(&generated_scripts_dir(), slug, script_content)
+}
+
+fn write_generated_script_in_dir(output_dir: &Path, slug: &str, script_content: &str) -> Result<PathBuf> {
+    fs::create_dir_all(output_dir)
+        .with_context(|| format!("Failed to create output dir: {}", output_dir.display()))?;
+
+    for suffix in 0usize.. {
+        let candidate = if suffix == 0 {
+            slug.to_string()
+        } else {
+            format!("{slug}-{suffix}")
+        };
+        let path = output_dir.join(format!("{}.ts", candidate));
+        match OpenOptions::new().write(true).create_new(true).open(&path) {
+            Ok(mut file) => {
+                file.write_all(script_content.as_bytes())
+                    .with_context(|| format!("Failed writing generated script to {}", path.display()))?;
+                return Ok(path);
+            }
+            Err(error) if error.kind() == ErrorKind::AlreadyExists => continue,
+            Err(error) => {
+                return Err(error).with_context(|| {
+                    format!(
+                        "Failed creating generated script file {} (slug={})",
+                        path.display(),
+                        slug
+                    )
+                });
+            }
+        }
+    }
+
+    unreachable!("suffix loop should eventually create a unique script filename")
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+    use tempfile::tempdir;
+
+    #[test]
+    fn test_slugify_script_name_handles_spaces_and_symbols() {
+        assert_eq!(slugify_script_name("Build: API Client!"), "build-api-client");
+        assert_eq!(slugify_script_name("  ___  "), "ai-script");
+    }
+
+    #[test]
+    fn test_extract_script_code_prefers_typescript_fence_when_multiple_blocks_exist() {
+        let response = r#"
+Here's one idea:
+```markdown
+Not code
+```
+```typescript
+await div("hello");
+```
+"#;
+        assert_eq!(extract_script_code(response), "await div(\"hello\");");
+    }
+
+    #[test]
+    fn test_extract_script_code_falls_back_to_first_fenced_block() {
+        let response = r#"
+```python
+print("hello")
+```
+"#;
+        assert_eq!(extract_script_code(response), "print(\"hello\")");
+    }
+
+    #[test]
+    fn test_extract_script_code_returns_trimmed_response_when_no_fence_exists() {
+        let response = "const answer = 42;";
+        assert_eq!(extract_script_code(response), "const answer = 42;");
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_adds_missing_metadata_and_import() {
+        let script = "const name = await arg(\"Name?\");";
+        let output = enforce_script_kit_conventions(script, "Ask for user name", "ask-user-name");
+
+        assert!(output.contains("// Name: Ask User Name"));
+        assert!(output.contains("// Description: Ask for user name"));
+        assert!(output.contains("import \"@johnlindquist/kit\";"));
+        assert!(output.contains("await arg(\"Name?\");"));
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_keeps_existing_metadata_and_import() {
+        let script = r#"// Name: Existing
+// Description: Existing description
+import "@johnlindquist/kit";
+
+await div("ready");
+"#;
+        let output = enforce_script_kit_conventions(script, "ignored", "ignored");
+
+        assert_eq!(
+            output.matches("// Name:").count(),
+            1,
+            "should not duplicate existing Name metadata"
+        );
+        assert_eq!(
+            output.matches("// Description:").count(),
+            1,
+            "should not duplicate existing Description metadata"
+        );
+        assert_eq!(
+            output.matches("import \"@johnlindquist/kit\";").count(),
+            1,
+            "should not duplicate existing import"
+        );
+    }
+
+    #[test]
+    fn test_write_generated_script_in_dir_appends_numeric_suffix_for_collisions() {
+        let temp_dir = tempdir().unwrap();
+        let first = write_generated_script_in_dir(temp_dir.path(), "my-script", "a").unwrap();
+        let second = write_generated_script_in_dir(temp_dir.path(), "my-script", "b").unwrap();
+
+        assert_eq!(first.file_name().unwrap(), "my-script.ts");
+        assert_eq!(second.file_name().unwrap(), "my-script-1.ts");
+    }
+}
diff --git a/src/app_execute/builtin_execution.rs b/src/app_execute/builtin_execution.rs
index c2ec833eff5ada1847787967c7b1195720fa43db..beb3a48c404f463d5edf049315cbbb188d07d3a9
--- a/src/app_execute/builtin_execution.rs
+++ b/src/app_execute/builtin_execution.rs
@@ -544,6 +544,30 @@
 
                 use builtins::AiCommandType;
 
+                // Capture prompt text before reset for Shift+Tab/script-generation flows.
+                let script_generation_prompt = if matches!(cmd_type, AiCommandType::GenerateScript)
+                {
+                    Some(self.filter_text.trim().to_string())
+                } else {
+                    None
+                };
+
+                if matches!(cmd_type, AiCommandType::GenerateScript)
+                    && script_generation_prompt
+                        .as_ref()
+                        .is_some_and(|prompt| prompt.is_empty())
+                {
+                    self.toast_manager.push(
+                        components::toast::Toast::warning(
+                            "Type a prompt first, then run Generate Script with AI.",
+                            &self.theme,
+                        )
+                        .duration_ms(Some(3500)),
+                    );
+                    cx.notify();
+                    return;
+                }
+
                 // All AI commands: reset state, hide main window
                 script_kit_gpui::set_main_window_visible(false);
                 self.reset_to_script_list(cx);
@@ -614,6 +638,132 @@
                         }
                     }
 
+                    AiCommandType::GenerateScript => {
+                        let Some(prompt_description) = script_generation_prompt.clone() else {
+                            logging::log(
+                                "AI_SCRIPT_GEN",
+                                "state=failed attempted=capture_prompt failure=missing_prompt",
+                            );
+                            self.toast_manager.push(
+                                components::toast::Toast::error(
+                                    "No prompt available for AI script generation",
+                                    &self.theme,
+                                )
+                                .duration_ms(Some(5000)),
+                            );
+                            cx.notify();
+                            return;
+                        };
+
+                        let config = self.config.clone();
+                        let (tx, rx) = async_channel::bounded::<
+                            std::result::Result<ai::GeneratedScriptOutput, String>,
+                        >(1);
+
+                        logging::log(
+                            "AI_SCRIPT_GEN",
+                            &format!(
+                                "state=queued attempted=builtin_generate_script prompt_len={}",
+                                prompt_description.len()
+                            ),
+                        );
+
+                        std::thread::spawn(move || {
+                            let generation_result =
+                                ai::generate_script_from_prompt(&prompt_description, Some(&config))
+                                    .map_err(|error| error.to_string());
+
+                            if tx.send_blocking(generation_result).is_err() {
+                                logging::log(
+                                    "AI_SCRIPT_GEN",
+                                    "state=aborted attempted=send_result failure=result_channel_closed",
+                                );
+                            }
+                        });
+
+                        cx.spawn(async move |this, cx| {
+                            let Ok(result) = rx.recv().await else {
+                                logging::log(
+                                    "AI_SCRIPT_GEN",
+                                    "state=aborted attempted=recv_result failure=result_channel_closed",
+                                );
+                                return;
+                            };
+
+                            let _ = cx.update(|cx| {
+                                this.update(cx, |app, cx| match result {
+                                    Ok(generated) => {
+                                        let script_name = generated
+                                            .path
+                                            .file_name()
+                                            .and_then(|name| name.to_str())
+                                            .unwrap_or("generated script");
+
+                                        if let Err(error) =
+                                            script_creation::open_in_editor(&generated.path, &app.config)
+                                        {
+                                            logging::log(
+                                                "AI_SCRIPT_GEN",
+                                                &format!(
+                                                    "state=failed attempted=open_editor path={} error={}",
+                                                    generated.path.display(),
+                                                    error
+                                                ),
+                                            );
+                                            app.toast_manager.push(
+                                                components::toast::Toast::error(
+                                                    format!(
+                                                        "Generated {}, but failed to open editor: {}",
+                                                        script_name, error
+                                                    ),
+                                                    &app.theme,
+                                                )
+                                                .duration_ms(Some(7000)),
+                                            );
+                                            cx.notify();
+                                        } else {
+                                            logging::log(
+                                                "AI_SCRIPT_GEN",
+                                                &format!(
+                                                    "state=completed attempted=builtin_generate_script path={} model_id={} provider_id={}",
+                                                    generated.path.display(),
+                                                    generated.model_id,
+                                                    generated.provider_id
+                                                ),
+                                            );
+                                            app.toast_manager.push(
+                                                components::toast::Toast::success(
+                                                    format!("Generated and opened {}", script_name),
+                                                    &app.theme,
+                                                )
+                                                .duration_ms(Some(3500)),
+                                            );
+                                            app.close_and_reset_window(cx);
+                                        }
+                                    }
+                                    Err(error) => {
+                                        logging::log(
+                                            "AI_SCRIPT_GEN",
+                                            &format!(
+                                                "state=failed attempted=builtin_generate_script error={}",
+                                                error
+                                            ),
+                                        );
+                                        app.toast_manager.push(
+                                            components::toast::Toast::error(
+                                                format!("Failed to generate script: {}", error),
+                                                &app.theme,
+                                            )
+                                            .duration_ms(Some(7000)),
+                                        );
+                                        cx.notify();
+                                    }
+                                })
+                            });
+                        })
+                        .detach();
+                    }
+
                     AiCommandType::SendScreenToAi => {
                         // Capture entire screen and send to AI
                         match platform::capture_screen_screenshot() {
diff --git a/src/builtins/part_000.rs b/src/builtins/part_000.rs
index d6b9c2a9b35b40c5005dbb9f65147f528702cb9e..5f6d27d28d72e51126d10d8beccf931c689ef2bb
--- a/src/builtins/part_000.rs
+++ b/src/builtins/part_000.rs
@@ -96,6 +96,8 @@
     OpenAi,
     NewConversation,
     ClearConversation,
+    /// Generate a new Script Kit script from the main prompt text
+    GenerateScript,
     /// Send a screenshot of the entire screen to AI Chat
     SendScreenToAi,
     /// Send a screenshot of the focused window to AI Chat
diff --git a/src/builtins/part_001_entries/entries_002.rs b/src/builtins/part_001_entries/entries_002.rs
index 6d1c9334f0ccaf0aab48582aaf42dcb129e1cb6e..72b318c66aeaf124359f4ecd276dae0350287328
--- a/src/builtins/part_001_entries/entries_002.rs
+++ b/src/builtins/part_001_entries/entries_002.rs
@@ -61,6 +61,17 @@
     ));
 
     entries.push(BuiltInEntry::new_with_icon(
+        "builtin-generate-script-with-ai",
+        "Generate Script with AI",
+        "Generate a Script Kit script from your current prompt text",
+        vec![
+            "generate", "script", "ai", "create", "code", "typescript", "shift", "tab",
+        ],
+        BuiltInFeature::AiCommand(AiCommandType::GenerateScript),
+        "ðŸ§ ",
+    ));
+
+    entries.push(BuiltInEntry::new_with_icon(
         "builtin-send-screen-to-ai",
         "Send Screen to AI Chat",
         "Capture the full screen and send it to AI Chat",
diff --git a/src/builtins/tests/part_000.rs b/src/builtins/tests/part_000.rs
index b3ab2d78ecc147bbdbcfb63b851efbc98de5959a..81a22289bae63689059113341ceb5ac1dd91f2b2
--- a/src/builtins/tests/part_000.rs
+++ b/src/builtins/tests/part_000.rs
@@ -302,6 +302,26 @@
             open_ai.unwrap().feature,
             BuiltInFeature::AiCommand(AiCommandType::OpenAi)
         );
+
+        let generate_script = entries
+            .iter()
+            .find(|e| e.id == "builtin-generate-script-with-ai");
+        assert!(
+            generate_script.is_some(),
+            "builtin-generate-script-with-ai should exist"
+        );
+        let generate_script = generate_script.unwrap();
+        assert_eq!(
+            generate_script.feature,
+            BuiltInFeature::AiCommand(AiCommandType::GenerateScript)
+        );
+        assert!(
+            generate_script
+                .keywords
+                .iter()
+                .any(|keyword| keyword.eq_ignore_ascii_case("shift")),
+            "Generate Script command should be discoverable via Shift+Tab wording"
+        );
     }
     #[test]
     fn test_get_builtin_entries_hides_preview_ai_commands() {

file update:
diff --git a/src/ai/mod.rs b/src/ai/mod.rs
index a420b1a5faf59506acdb7caf60681c153a3f9bb6..9a73e9491862633b325b2c52b51a3e20395ff85c
--- a/src/ai/mod.rs
+++ b/src/ai/mod.rs
@@ -37,6 +37,7 @@
 pub(crate) mod providers;
 pub(crate) mod sdk_handlers;
 pub(crate) mod session;
+pub(crate) mod script_generation;
 pub(crate) mod storage;
 pub(crate) mod window;
 
@@ -44,6 +45,7 @@
 pub use self::config::{DetectedKeys, ModelInfo, ProviderConfig};
 pub use self::model::{Chat, ChatId, ChatSource, Message, MessageRole};
 pub use self::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+pub use self::script_generation::{generate_script_from_prompt, GeneratedScriptOutput};
 pub use self::sdk_handlers::try_handle_ai_message;
 pub use self::storage::{
     clear_all_chats, create_chat, delete_chat, get_all_chats, get_chat, get_chat_messages,
diff --git a/src/ai/script_generation.rs b/src/ai/script_generation.rs
new file mode 100644
index 0000000000000000000000000000000000000000..7f2ec8e7576ed50cd10f7aea31a6522875ef667a
--- /dev/null
+++ b/src/ai/script_generation.rs
@@ -0,0 +1,417 @@
+use anyhow::{Context, Result};
+use std::fs::{self, OpenOptions};
+use std::io::{ErrorKind, Write};
+use std::path::{Path, PathBuf};
+use std::sync::Arc;
+
+use super::config::ModelInfo;
+use super::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+
+const AI_SCRIPT_OUTPUT_DIR: &str = "~/.kenv/scripts";
+const AI_SCRIPT_DEFAULT_SLUG: &str = "ai-script";
+const AI_SCRIPT_MAX_SLUG_LEN: usize = 64;
+
+const AI_SCRIPT_GENERATION_SYSTEM_PROMPT: &str = r#"You write production-ready Script Kit scripts.
+
+Return ONLY TypeScript source code for one Script Kit script. Do not include explanations.
+
+Required output conventions:
+1) Include metadata comments at the top:
+   // Name: <clear title>
+   // Description: <one-line summary>
+2) Include: import "@johnlindquist/kit";
+3) Use await arg() for user input when useful.
+4) Use await div() for display output when useful.
+5) Keep the script runnable as-is with sensible defaults and light error handling."#;
+
+#[derive(Debug, Clone)]
+pub struct GeneratedScriptOutput {
+    pub path: PathBuf,
+    pub slug: String,
+    pub model_id: String,
+    pub provider_id: String,
+}
+
+pub fn generate_script_from_prompt(
+    prompt: &str,
+    config: Option<&crate::config::Config>,
+) -> Result<GeneratedScriptOutput> {
+    let normalized_prompt = prompt.trim();
+    if normalized_prompt.is_empty() {
+        anyhow::bail!("AI script generation requires a non-empty prompt");
+    }
+
+    let registry = ProviderRegistry::from_environment_with_config(config);
+    if !registry.has_any_provider() {
+        anyhow::bail!(
+            "No AI providers configured. Configure an API key first (Vercel, OpenAI, Anthropic, etc.)."
+        );
+    }
+
+    let (selected_model, provider) = select_generation_model(&registry)?;
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=provider_ready model_id={} provider_id={} prompt_len={}",
+            selected_model.id,
+            selected_model.provider,
+            normalized_prompt.len()
+        ),
+    );
+
+    let messages = vec![
+        ProviderMessage::system(AI_SCRIPT_GENERATION_SYSTEM_PROMPT),
+        ProviderMessage::user(format!(
+            "Generate a Script Kit script for this user request:\n\n{}",
+            normalized_prompt
+        )),
+    ];
+
+    let raw_response = provider
+        .send_message(&messages, &selected_model.id)
+        .with_context(|| {
+            format!(
+                "AI script generation failed (attempted=send_message, model_id={}, provider_id={})",
+                selected_model.id, selected_model.provider
+            )
+        })?;
+
+    let extracted = extract_script_code(&raw_response);
+    if extracted.trim().is_empty() {
+        anyhow::bail!(
+            "AI returned an empty response for script generation (state=empty_response)"
+        );
+    }
+
+    let slug = slugify_script_name(normalized_prompt);
+    let finalized = enforce_script_kit_conventions(&extracted, normalized_prompt, &slug);
+    let path = write_generated_script(&slug, &finalized).with_context(|| {
+        format!(
+            "Failed writing AI-generated script (state=write_failed, slug={})",
+            slug
+        )
+    })?;
+
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=script_written path={} slug={}",
+            path.display(),
+            slug
+        ),
+    );
+
+    Ok(GeneratedScriptOutput {
+        path,
+        slug,
+        model_id: selected_model.id,
+        provider_id: selected_model.provider,
+    })
+}
+
+fn select_generation_model(registry: &ProviderRegistry) -> Result<(ModelInfo, Arc<dyn AiProvider>)> {
+    let models = registry.get_all_models();
+    let selected_model = models
+        .iter()
+        .find(|model| model.provider.eq_ignore_ascii_case("vercel"))
+        .or_else(|| models.first())
+        .cloned()
+        .context("No AI models available in provider registry")?;
+
+    let provider = registry
+        .find_provider_for_model(&selected_model.id)
+        .cloned()
+        .with_context(|| {
+            format!(
+                "No provider found for selected model '{}' (state=provider_missing)",
+                selected_model.id
+            )
+        })?;
+
+    Ok((selected_model, provider))
+}
+
+fn generated_scripts_dir() -> PathBuf {
+    PathBuf::from(shellexpand::tilde(AI_SCRIPT_OUTPUT_DIR).as_ref())
+}
+
+fn split_fence_header_and_body(fence: &str) -> (&str, &str) {
+    match fence.find('\n') {
+        Some(newline_index) => (&fence[..newline_index], &fence[newline_index + 1..]),
+        None => ("", fence),
+    }
+}
+
+fn extract_fenced_code(response: &str, preferred_languages: Option<&[&str]>) -> Option<String> {
+    let mut remaining = response;
+
+    while let Some(start) = remaining.find("```") {
+        let after_start = &remaining[start + 3..];
+        let Some(end) = after_start.find("```") else {
+            break;
+        };
+
+        let fence_contents = &after_start[..end];
+        let (header, body) = split_fence_header_and_body(fence_contents);
+        let language = header
+            .trim()
+            .split(|c: char| c.is_whitespace() || c == '{')
+            .next()
+            .unwrap_or("")
+            .to_ascii_lowercase();
+        let code = body.trim();
+
+        if !code.is_empty() {
+            match preferred_languages {
+                Some(preferred) => {
+                    if preferred.iter().any(|candidate| *candidate == language) {
+                        return Some(code.to_string());
+                    }
+                }
+                None => return Some(code.to_string()),
+            }
+        }
+
+        remaining = &after_start[end + 3..];
+    }
+
+    None
+}
+
+fn extract_script_code(response: &str) -> String {
+    const PREFERRED_LANGUAGES: [&str; 6] = ["typescript", "ts", "javascript", "js", "tsx", "jsx"];
+
+    extract_fenced_code(response, Some(&PREFERRED_LANGUAGES))
+        .or_else(|| extract_fenced_code(response, None))
+        .unwrap_or_else(|| response.trim().to_string())
+}
+
+fn slugify_script_name(prompt: &str) -> String {
+    let mut slug = String::new();
+    let mut last_was_hyphen = false;
+
+    for character in prompt.to_ascii_lowercase().chars() {
+        if character.is_ascii_alphanumeric() {
+            slug.push(character);
+            last_was_hyphen = false;
+        } else if matches!(character, ' ' | '_' | '-') {
+            if !slug.is_empty() && !last_was_hyphen {
+                slug.push('-');
+                last_was_hyphen = true;
+            }
+        }
+    }
+
+    while slug.ends_with('-') {
+        slug.pop();
+    }
+
+    if slug.len() > AI_SCRIPT_MAX_SLUG_LEN {
+        slug.truncate(AI_SCRIPT_MAX_SLUG_LEN);
+        while slug.ends_with('-') {
+            slug.pop();
+        }
+    }
+
+    if slug.is_empty() {
+        AI_SCRIPT_DEFAULT_SLUG.to_string()
+    } else {
+        slug
+    }
+}
+
+fn slug_to_title(slug: &str) -> String {
+    slug.split('-')
+        .filter(|segment| !segment.is_empty())
+        .map(|segment| {
+            let mut chars = segment.chars();
+            match chars.next() {
+                Some(first) => first.to_uppercase().collect::<String>() + chars.as_str(),
+                None => String::new(),
+            }
+        })
+        .collect::<Vec<_>>()
+        .join(" ")
+}
+
+fn description_from_prompt(prompt: &str) -> String {
+    let normalized = prompt.split_whitespace().collect::<Vec<_>>().join(" ");
+    if normalized.is_empty() {
+        return "AI-generated Script Kit script".to_string();
+    }
+
+    let mut shortened = normalized;
+    if shortened.chars().count() > 110 {
+        shortened = format!("{}...", shortened.chars().take(107).collect::<String>());
+    }
+    shortened
+}
+
+fn has_kit_import(script: &str) -> bool {
+    script.contains("import \"@johnlindquist/kit\";")
+        || script.contains("import '@johnlindquist/kit';")
+        || script.contains("import \"@scriptkit/sdk\";")
+        || script.contains("import '@scriptkit/sdk';")
+}
+
+fn enforce_script_kit_conventions(script: &str, prompt: &str, slug: &str) -> String {
+    let mut prefix_lines: Vec<String> = Vec::new();
+    let trimmed_script = script.trim();
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Name:"))
+    {
+        prefix_lines.push(format!("// Name: {}", slug_to_title(slug)));
+    }
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Description:"))
+    {
+        prefix_lines.push(format!("// Description: {}", description_from_prompt(prompt)));
+    }
+
+    if !has_kit_import(trimmed_script) {
+        prefix_lines.push("import \"@johnlindquist/kit\";".to_string());
+    }
+
+    let mut output = String::new();
+    if !prefix_lines.is_empty() {
+        output.push_str(&prefix_lines.join("\n"));
+        output.push_str("\n\n");
+    }
+
+    output.push_str(trimmed_script);
+    if !output.ends_with('\n') {
+        output.push('\n');
+    }
+    output
+}
+
+fn write_generated_script(slug: &str, script_content: &str) -> Result<PathBuf> {
+    write_generated_script_in_dir(&generated_scripts_dir(), slug, script_content)
+}
+
+fn write_generated_script_in_dir(output_dir: &Path, slug: &str, script_content: &str) -> Result<PathBuf> {
+    fs::create_dir_all(output_dir)
+        .with_context(|| format!("Failed to create output dir: {}", output_dir.display()))?;
+
+    for suffix in 0usize.. {
+        let candidate = if suffix == 0 {
+            slug.to_string()
+        } else {
+            format!("{slug}-{suffix}")
+        };
+        let path = output_dir.join(format!("{}.ts", candidate));
+        match OpenOptions::new().write(true).create_new(true).open(&path) {
+            Ok(mut file) => {
+                file.write_all(script_content.as_bytes())
+                    .with_context(|| format!("Failed writing generated script to {}", path.display()))?;
+                return Ok(path);
+            }
+            Err(error) if error.kind() == ErrorKind::AlreadyExists => continue,
+            Err(error) => {
+                return Err(error).with_context(|| {
+                    format!(
+                        "Failed creating generated script file {} (slug={})",
+                        path.display(),
+                        slug
+                    )
+                });
+            }
+        }
+    }
+
+    unreachable!("suffix loop should eventually create a unique script filename")
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+    use tempfile::tempdir;
+
+    #[test]
+    fn test_slugify_script_name_handles_spaces_and_symbols() {
+        assert_eq!(slugify_script_name("Build: API Client!"), "build-api-client");
+        assert_eq!(slugify_script_name("  ___  "), "ai-script");
+    }
+
+    #[test]
+    fn test_extract_script_code_prefers_typescript_fence_when_multiple_blocks_exist() {
+        let response = r#"
+Here's one idea:
+```markdown
+Not code
+```
+```typescript
+await div("hello");
+```
+"#;
+        assert_eq!(extract_script_code(response), "await div(\"hello\");");
+    }
+
+    #[test]
+    fn test_extract_script_code_falls_back_to_first_fenced_block() {
+        let response = r#"
+```python
+print("hello")
+```
+"#;
+        assert_eq!(extract_script_code(response), "print(\"hello\")");
+    }
+
+    #[test]
+    fn test_extract_script_code_returns_trimmed_response_when_no_fence_exists() {
+        let response = "const answer = 42;";
+        assert_eq!(extract_script_code(response), "const answer = 42;");
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_adds_missing_metadata_and_import() {
+        let script = "const name = await arg(\"Name?\");";
+        let output = enforce_script_kit_conventions(script, "Ask for user name", "ask-user-name");
+
+        assert!(output.contains("// Name: Ask User Name"));
+        assert!(output.contains("// Description: Ask for user name"));
+        assert!(output.contains("import \"@johnlindquist/kit\";"));
+        assert!(output.contains("await arg(\"Name?\");"));
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_keeps_existing_metadata_and_import() {
+        let script = r#"// Name: Existing
+// Description: Existing description
+import "@johnlindquist/kit";
+
+await div("ready");
+"#;
+        let output = enforce_script_kit_conventions(script, "ignored", "ignored");
+
+        assert_eq!(
+            output.matches("// Name:").count(),
+            1,
+            "should not duplicate existing Name metadata"
+        );
+        assert_eq!(
+            output.matches("// Description:").count(),
+            1,
+            "should not duplicate existing Description metadata"
+        );
+        assert_eq!(
+            output.matches("import \"@johnlindquist/kit\";").count(),
+            1,
+            "should not duplicate existing import"
+        );
+    }
+
+    #[test]
+    fn test_write_generated_script_in_dir_appends_numeric_suffix_for_collisions() {
+        let temp_dir = tempdir().unwrap();
+        let first = write_generated_script_in_dir(temp_dir.path(), "my-script", "a").unwrap();
+        let second = write_generated_script_in_dir(temp_dir.path(), "my-script", "b").unwrap();
+
+        assert_eq!(first.file_name().unwrap(), "my-script.ts");
+        assert_eq!(second.file_name().unwrap(), "my-script-1.ts");
+    }
+}
diff --git a/src/app_execute/builtin_execution.rs b/src/app_execute/builtin_execution.rs
index c2ec833eff5ada1847787967c7b1195720fa43db..beb3a48c404f463d5edf049315cbbb188d07d3a9
--- a/src/app_execute/builtin_execution.rs
+++ b/src/app_execute/builtin_execution.rs
@@ -544,6 +544,30 @@
 
                 use builtins::AiCommandType;
 
+                // Capture prompt text before reset for Shift+Tab/script-generation flows.
+                let script_generation_prompt = if matches!(cmd_type, AiCommandType::GenerateScript)
+                {
+                    Some(self.filter_text.trim().to_string())
+                } else {
+                    None
+                };
+
+                if matches!(cmd_type, AiCommandType::GenerateScript)
+                    && script_generation_prompt
+                        .as_ref()
+                        .is_some_and(|prompt| prompt.is_empty())
+                {
+                    self.toast_manager.push(
+                        components::toast::Toast::warning(
+                            "Type a prompt first, then run Generate Script with AI.",
+                            &self.theme,
+                        )
+                        .duration_ms(Some(3500)),
+                    );
+                    cx.notify();
+                    return;
+                }
+
                 // All AI commands: reset state, hide main window
                 script_kit_gpui::set_main_window_visible(false);
                 self.reset_to_script_list(cx);
@@ -614,6 +638,132 @@
                         }
                     }
 
+                    AiCommandType::GenerateScript => {
+                        let Some(prompt_description) = script_generation_prompt.clone() else {
+                            logging::log(
+                                "AI_SCRIPT_GEN",
+                                "state=failed attempted=capture_prompt failure=missing_prompt",
+                            );
+                            self.toast_manager.push(
+                                components::toast::Toast::error(
+                                    "No prompt available for AI script generation",
+                                    &self.theme,
+                                )
+                                .duration_ms(Some(5000)),
+                            );
+                            cx.notify();
+                            return;
+                        };
+
+                        let config = self.config.clone();
+                        let (tx, rx) = async_channel::bounded::<
+                            std::result::Result<ai::GeneratedScriptOutput, String>,
+                        >(1);
+
+                        logging::log(
+                            "AI_SCRIPT_GEN",
+                            &format!(
+                                "state=queued attempted=builtin_generate_script prompt_len={}",
+                                prompt_description.len()
+                            ),
+                        );
+
+                        std::thread::spawn(move || {
+                            let generation_result =
+                                ai::generate_script_from_prompt(&prompt_description, Some(&config))
+                                    .map_err(|error| error.to_string());
+
+                            if tx.send_blocking(generation_result).is_err() {
+                                logging::log(
+                                    "AI_SCRIPT_GEN",
+                                    "state=aborted attempted=send_result failure=result_channel_closed",
+                                );
+                            }
+                        });
+
+                        cx.spawn(async move |this, cx| {
+                            let Ok(result) = rx.recv().await else {
+                                logging::log(
+                                    "AI_SCRIPT_GEN",
+                                    "state=aborted attempted=recv_result failure=result_channel_closed",
+                                );
+                                return;
+                            };
+
+                            let _ = cx.update(|cx| {
+                                this.update(cx, |app, cx| match result {
+                                    Ok(generated) => {
+                                        let script_name = generated
+                                            .path
+                                            .file_name()
+                                            .and_then(|name| name.to_str())
+                                            .unwrap_or("generated script");
+
+                                        if let Err(error) =
+                                            script_creation::open_in_editor(&generated.path, &app.config)
+                                        {
+                                            logging::log(
+                                                "AI_SCRIPT_GEN",
+                                                &format!(
+                                                    "state=failed attempted=open_editor path={} error={}",
+                                                    generated.path.display(),
+                                                    error
+                                                ),
+                                            );
+                                            app.toast_manager.push(
+                                                components::toast::Toast::error(
+                                                    format!(
+                                                        "Generated {}, but failed to open editor: {}",
+                                                        script_name, error
+                                                    ),
+                                                    &app.theme,
+                                                )
+                                                .duration_ms(Some(7000)),
+                                            );
+                                            cx.notify();
+                                        } else {
+                                            logging::log(
+                                                "AI_SCRIPT_GEN",
+                                                &format!(
+                                                    "state=completed attempted=builtin_generate_script path={} model_id={} provider_id={}",
+                                                    generated.path.display(),
+                                                    generated.model_id,
+                                                    generated.provider_id
+                                                ),
+                                            );
+                                            app.toast_manager.push(
+                                                components::toast::Toast::success(
+                                                    format!("Generated and opened {}", script_name),
+                                                    &app.theme,
+                                                )
+                                                .duration_ms(Some(3500)),
+                                            );
+                                            app.close_and_reset_window(cx);
+                                        }
+                                    }
+                                    Err(error) => {
+                                        logging::log(
+                                            "AI_SCRIPT_GEN",
+                                            &format!(
+                                                "state=failed attempted=builtin_generate_script error={}",
+                                                error
+                                            ),
+                                        );
+                                        app.toast_manager.push(
+                                            components::toast::Toast::error(
+                                                format!("Failed to generate script: {}", error),
+                                                &app.theme,
+                                            )
+                                            .duration_ms(Some(7000)),
+                                        );
+                                        cx.notify();
+                                    }
+                                })
+                            });
+                        })
+                        .detach();
+                    }
+
                     AiCommandType::SendScreenToAi => {
                         // Capture entire screen and send to AI
                         match platform::capture_screen_screenshot() {
diff --git a/src/builtins/part_000.rs b/src/builtins/part_000.rs
index d6b9c2a9b35b40c5005dbb9f65147f528702cb9e..5f6d27d28d72e51126d10d8beccf931c689ef2bb
--- a/src/builtins/part_000.rs
+++ b/src/builtins/part_000.rs
@@ -96,6 +96,8 @@
     OpenAi,
     NewConversation,
     ClearConversation,
+    /// Generate a new Script Kit script from the main prompt text
+    GenerateScript,
     /// Send a screenshot of the entire screen to AI Chat
     SendScreenToAi,
     /// Send a screenshot of the focused window to AI Chat
diff --git a/src/builtins/part_001_entries/entries_002.rs b/src/builtins/part_001_entries/entries_002.rs
index 6d1c9334f0ccaf0aab48582aaf42dcb129e1cb6e..72b318c66aeaf124359f4ecd276dae0350287328
--- a/src/builtins/part_001_entries/entries_002.rs
+++ b/src/builtins/part_001_entries/entries_002.rs
@@ -61,6 +61,17 @@
     ));
 
     entries.push(BuiltInEntry::new_with_icon(
+        "builtin-generate-script-with-ai",
+        "Generate Script with AI",
+        "Generate a Script Kit script from your current prompt text",
+        vec![
+            "generate", "script", "ai", "create", "code", "typescript", "shift", "tab",
+        ],
+        BuiltInFeature::AiCommand(AiCommandType::GenerateScript),
+        "ðŸ§ ",
+    ));
+
+    entries.push(BuiltInEntry::new_with_icon(
         "builtin-send-screen-to-ai",
         "Send Screen to AI Chat",
         "Capture the full screen and send it to AI Chat",
diff --git a/src/builtins/tests/part_000.rs b/src/builtins/tests/part_000.rs
index b3ab2d78ecc147bbdbcfb63b851efbc98de5959a..81a22289bae63689059113341ceb5ac1dd91f2b2
--- a/src/builtins/tests/part_000.rs
+++ b/src/builtins/tests/part_000.rs
@@ -302,6 +302,26 @@
             open_ai.unwrap().feature,
             BuiltInFeature::AiCommand(AiCommandType::OpenAi)
         );
+
+        let generate_script = entries
+            .iter()
+            .find(|e| e.id == "builtin-generate-script-with-ai");
+        assert!(
+            generate_script.is_some(),
+            "builtin-generate-script-with-ai should exist"
+        );
+        let generate_script = generate_script.unwrap();
+        assert_eq!(
+            generate_script.feature,
+            BuiltInFeature::AiCommand(AiCommandType::GenerateScript)
+        );
+        assert!(
+            generate_script
+                .keywords
+                .iter()
+                .any(|keyword| keyword.eq_ignore_ascii_case("shift")),
+            "Generate Script command should be discoverable via Shift+Tab wording"
+        );
     }
     #[test]
     fn test_get_builtin_entries_hides_preview_ai_commands() {


thinking
**Planning scoped Rust checks**
exec
/bin/zsh -lc "sed -n '1,220p' src/builtins/mod.rs" in /Users/johnlindquist/dev/script-kit-gpui succeeded in 51ms:
//! Built-in Features Registry
//!
//! Provides a registry of built-in features that appear in the main search
//! alongside scripts. Features like Clipboard History and App Launcher are
//! configurable and can be enabled/disabled via config.
//!
//! ## Command Types
//!
//! The registry supports various command types organized by category:
//! - **System Actions**: Power management, UI controls, volume/brightness
//! - **Window Actions**: Window tiling and management for the frontmost window
//! - **Notes Commands**: Notes window operations
//! - **AI Commands**: AI chat window operations  
//! - **Script Commands**: Create new scripts and scriptlets
//! - **Permission Commands**: Accessibility permission management
//!

include!("part_000.rs");
include!("part_001.rs");
include!("part_002.rs");
file update:
diff --git a/src/ai/mod.rs b/src/ai/mod.rs
index a420b1a5faf59506acdb7caf60681c153a3f9bb6..9a73e9491862633b325b2c52b51a3e20395ff85c
--- a/src/ai/mod.rs
+++ b/src/ai/mod.rs
@@ -37,6 +37,7 @@
 pub(crate) mod providers;
 pub(crate) mod sdk_handlers;
 pub(crate) mod session;
+pub(crate) mod script_generation;
 pub(crate) mod storage;
 pub(crate) mod window;
 
@@ -44,6 +45,7 @@
 pub use self::config::{DetectedKeys, ModelInfo, ProviderConfig};
 pub use self::model::{Chat, ChatId, ChatSource, Message, MessageRole};
 pub use self::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+pub use self::script_generation::{generate_script_from_prompt, GeneratedScriptOutput};
 pub use self::sdk_handlers::try_handle_ai_message;
 pub use self::storage::{
     clear_all_chats, create_chat, delete_chat, get_all_chats, get_chat, get_chat_messages,
diff --git a/src/ai/script_generation.rs b/src/ai/script_generation.rs
new file mode 100644
index 0000000000000000000000000000000000000000..7f2ec8e7576ed50cd10f7aea31a6522875ef667a
--- /dev/null
+++ b/src/ai/script_generation.rs
@@ -0,0 +1,417 @@
+use anyhow::{Context, Result};
+use std::fs::{self, OpenOptions};
+use std::io::{ErrorKind, Write};
+use std::path::{Path, PathBuf};
+use std::sync::Arc;
+
+use super::config::ModelInfo;
+use super::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+
+const AI_SCRIPT_OUTPUT_DIR: &str = "~/.kenv/scripts";
+const AI_SCRIPT_DEFAULT_SLUG: &str = "ai-script";
+const AI_SCRIPT_MAX_SLUG_LEN: usize = 64;
+
+const AI_SCRIPT_GENERATION_SYSTEM_PROMPT: &str = r#"You write production-ready Script Kit scripts.
+
+Return ONLY TypeScript source code for one Script Kit script. Do not include explanations.
+
+Required output conventions:
+1) Include metadata comments at the top:
+   // Name: <clear title>
+   // Description: <one-line summary>
+2) Include: import "@johnlindquist/kit";
+3) Use await arg() for user input when useful.
+4) Use await div() for display output when useful.
+5) Keep the script runnable as-is with sensible defaults and light error handling."#;
+
+#[derive(Debug, Clone)]
+pub struct GeneratedScriptOutput {
+    pub path: PathBuf,
+    pub slug: String,
+    pub model_id: String,
+    pub provider_id: String,
+}
+
+pub fn generate_script_from_prompt(
+    prompt: &str,
+    config: Option<&crate::config::Config>,
+) -> Result<GeneratedScriptOutput> {
+    let normalized_prompt = prompt.trim();
+    if normalized_prompt.is_empty() {
+        anyhow::bail!("AI script generation requires a non-empty prompt");
+    }
+
+    let registry = ProviderRegistry::from_environment_with_config(config);
+    if !registry.has_any_provider() {
+        anyhow::bail!(
+            "No AI providers configured. Configure an API key first (Vercel, OpenAI, Anthropic, etc.)."
+        );
+    }
+
+    let (selected_model, provider) = select_generation_model(&registry)?;
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=provider_ready model_id={} provider_id={} prompt_len={}",
+            selected_model.id,
+            selected_model.provider,
+            normalized_prompt.len()
+        ),
+    );
+
+    let messages = vec![
+        ProviderMessage::system(AI_SCRIPT_GENERATION_SYSTEM_PROMPT),
+        ProviderMessage::user(format!(
+            "Generate a Script Kit script for this user request:\n\n{}",
+            normalized_prompt
+        )),
+    ];
+
+    let raw_response = provider
+        .send_message(&messages, &selected_model.id)
+        .with_context(|| {
+            format!(
+                "AI script generation failed (attempted=send_message, model_id={}, provider_id={})",
+                selected_model.id, selected_model.provider
+            )
+        })?;
+
+    let extracted = extract_script_code(&raw_response);
+    if extracted.trim().is_empty() {
+        anyhow::bail!(
+            "AI returned an empty response for script generation (state=empty_response)"
+        );
+    }
+
+    let slug = slugify_script_name(normalized_prompt);
+    let finalized = enforce_script_kit_conventions(&extracted, normalized_prompt, &slug);
+    let path = write_generated_script(&slug, &finalized).with_context(|| {
+        format!(
+            "Failed writing AI-generated script (state=write_failed, slug={})",
+            slug
+        )
+    })?;
+
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=script_written path={} slug={}",
+            path.display(),
+            slug
+        ),
+    );
+
+    Ok(GeneratedScriptOutput {
+        path,
+        slug,
+        model_id: selected_model.id,
+        provider_id: selected_model.provider,
+    })
+}
+
+fn select_generation_model(registry: &ProviderRegistry) -> Result<(ModelInfo, Arc<dyn AiProvider>)> {
+    let models = registry.get_all_models();
+    let selected_model = models
+        .iter()
+        .find(|model| model.provider.eq_ignore_ascii_case("vercel"))
+        .or_else(|| models.first())
+        .cloned()
+        .context("No AI models available in provider registry")?;
+
+    let provider = registry
+        .find_provider_for_model(&selected_model.id)
+        .cloned()
+        .with_context(|| {
+            format!(
+                "No provider found for selected model '{}' (state=provider_missing)",
+                selected_model.id
+            )
+        })?;
+
+    Ok((selected_model, provider))
+}
+
+fn generated_scripts_dir() -> PathBuf {
+    PathBuf::from(shellexpand::tilde(AI_SCRIPT_OUTPUT_DIR).as_ref())
+}
+
+fn split_fence_header_and_body(fence: &str) -> (&str, &str) {
+    match fence.find('\n') {
+        Some(newline_index) => (&fence[..newline_index], &fence[newline_index + 1..]),
+        None => ("", fence),
+    }
+}
+
+fn extract_fenced_code(response: &str, preferred_languages: Option<&[&str]>) -> Option<String> {
+    let mut remaining = response;
+
+    while let Some(start) = remaining.find("```") {
+        let after_start = &remaining[start + 3..];
+        let Some(end) = after_start.find("```") else {
+            break;
+        };
+
+        let fence_contents = &after_start[..end];
+        let (header, body) = split_fence_header_and_body(fence_contents);
+        let language = header
+            .trim()
+            .split(|c: char| c.is_whitespace() || c == '{')
+            .next()
+            .unwrap_or("")
+            .to_ascii_lowercase();
+        let code = body.trim();
+
+        if !code.is_empty() {
+            match preferred_languages {
+                Some(preferred) => {
+                    if preferred.iter().any(|candidate| *candidate == language) {
+                        return Some(code.to_string());
+                    }
+                }
+                None => return Some(code.to_string()),
+            }
+        }
+
+        remaining = &after_start[end + 3..];
+    }
+
+    None
+}
+
+fn extract_script_code(response: &str) -> String {
+    const PREFERRED_LANGUAGES: [&str; 6] = ["typescript", "ts", "javascript", "js", "tsx", "jsx"];
+
+    extract_fenced_code(response, Some(&PREFERRED_LANGUAGES))
+        .or_else(|| extract_fenced_code(response, None))
+        .unwrap_or_else(|| response.trim().to_string())
+}
+
+fn slugify_script_name(prompt: &str) -> String {
+    let mut slug = String::new();
+    let mut last_was_hyphen = false;
+
+    for character in prompt.to_ascii_lowercase().chars() {
+        if character.is_ascii_alphanumeric() {
+            slug.push(character);
+            last_was_hyphen = false;
+        } else if matches!(character, ' ' | '_' | '-') {
+            if !slug.is_empty() && !last_was_hyphen {
+                slug.push('-');
+                last_was_hyphen = true;
+            }
+        }
+    }
+
+    while slug.ends_with('-') {
+        slug.pop();
+    }
+
+    if slug.len() > AI_SCRIPT_MAX_SLUG_LEN {
+        slug.truncate(AI_SCRIPT_MAX_SLUG_LEN);
+        while slug.ends_with('-') {
+            slug.pop();
+        }
+    }
+
+    if slug.is_empty() {
+        AI_SCRIPT_DEFAULT_SLUG.to_string()
+    } else {
+        slug
+    }
+}
+
+fn slug_to_title(slug: &str) -> String {
+    slug.split('-')
+        .filter(|segment| !segment.is_empty())
+        .map(|segment| {
+            let mut chars = segment.chars();
+            match chars.next() {
+                Some(first) => first.to_uppercase().collect::<String>() + chars.as_str(),
+                None => String::new(),
+            }
+        })
+        .collect::<Vec<_>>()
+        .join(" ")
+}
+
+fn description_from_prompt(prompt: &str) -> String {
+    let normalized = prompt.split_whitespace().collect::<Vec<_>>().join(" ");
+    if normalized.is_empty() {
+        return "AI-generated Script Kit script".to_string();
+    }
+
+    let mut shortened = normalized;
+    if shortened.chars().count() > 110 {
+        shortened = format!("{}...", shortened.chars().take(107).collect::<String>());
+    }
+    shortened
+}
+
+fn has_kit_import(script: &str) -> bool {
+    script.contains("import \"@johnlindquist/kit\";")
+        || script.contains("import '@johnlindquist/kit';")
+        || script.contains("import \"@scriptkit/sdk\";")
+        || script.contains("import '@scriptkit/sdk';")
+}
+
+fn enforce_script_kit_conventions(script: &str, prompt: &str, slug: &str) -> String {
+    let mut prefix_lines: Vec<String> = Vec::new();
+    let trimmed_script = script.trim();
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Name:"))
+    {
+        prefix_lines.push(format!("// Name: {}", slug_to_title(slug)));
+    }
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Description:"))
+    {
+        prefix_lines.push(format!("// Description: {}", description_from_prompt(prompt)));
+    }
+
+    if !has_kit_import(trimmed_script) {
+        prefix_lines.push("import \"@johnlindquist/kit\";".to_string());
+    }
+
+    let mut output = String::new();
+    if !prefix_lines.is_empty() {
+        output.push_str(&prefix_lines.join("\n"));
+        output.push_str("\n\n");
+    }
+
+    output.push_str(trimmed_script);
+    if !output.ends_with('\n') {
+        output.push('\n');
+    }
+    output
+}
+
+fn write_generated_script(slug: &str, script_content: &str) -> Result<PathBuf> {
+    write_generated_script_in_dir(&generated_scripts_dir(), slug, script_content)
+}
+
+fn write_generated_script_in_dir(output_dir: &Path, slug: &str, script_content: &str) -> Result<PathBuf> {
+    fs::create_dir_all(output_dir)
+        .with_context(|| format!("Failed to create output dir: {}", output_dir.display()))?;
+
+    for suffix in 0usize.. {
+        let candidate = if suffix == 0 {
+            slug.to_string()
+        } else {
+            format!("{slug}-{suffix}")
+        };
+        let path = output_dir.join(format!("{}.ts", candidate));
+        match OpenOptions::new().write(true).create_new(true).open(&path) {
+            Ok(mut file) => {
+                file.write_all(script_content.as_bytes())
+                    .with_context(|| format!("Failed writing generated script to {}", path.display()))?;
+                return Ok(path);
+            }
+            Err(error) if error.kind() == ErrorKind::AlreadyExists => continue,
+            Err(error) => {
+                return Err(error).with_context(|| {
+                    format!(
+                        "Failed creating generated script file {} (slug={})",
+                        path.display(),
+                        slug
+                    )
+                });
+            }
+        }
+    }
+
+    unreachable!("suffix loop should eventually create a unique script filename")
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+    use tempfile::tempdir;
+
+    #[test]
+    fn test_slugify_script_name_handles_spaces_and_symbols() {
+        assert_eq!(slugify_script_name("Build: API Client!"), "build-api-client");
+        assert_eq!(slugify_script_name("  ___  "), "ai-script");
+    }
+
+    #[test]
+    fn test_extract_script_code_prefers_typescript_fence_when_multiple_blocks_exist() {
+        let response = r#"
+Here's one idea:
+```markdown
+Not code
+```
+```typescript
+await div("hello");
+```
+"#;
+        assert_eq!(extract_script_code(response), "await div(\"hello\");");
+    }
+
+    #[test]
+    fn test_extract_script_code_falls_back_to_first_fenced_block() {
+        let response = r#"
+```python
+print("hello")
+```
+"#;
+        assert_eq!(extract_script_code(response), "print(\"hello\")");
+    }
+
+    #[test]
+    fn test_extract_script_code_returns_trimmed_response_when_no_fence_exists() {
+        let response = "const answer = 42;";
+        assert_eq!(extract_script_code(response), "const answer = 42;");
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_adds_missing_metadata_and_import() {
+        let script = "const name = await arg(\"Name?\");";
+        let output = enforce_script_kit_conventions(script, "Ask for user name", "ask-user-name");
+
+        assert!(output.contains("// Name: Ask User Name"));
+        assert!(output.contains("// Description: Ask for user name"));
+        assert!(output.contains("import \"@johnlindquist/kit\";"));
+        assert!(output.contains("await arg(\"Name?\");"));
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_keeps_existing_metadata_and_import() {
+        let script = r#"// Name: Existing
+// Description: Existing description
+import "@johnlindquist/kit";
+
+await div("ready");
+"#;
+        let output = enforce_script_kit_conventions(script, "ignored", "ignored");
+
+        assert_eq!(
+            output.matches("// Name:").count(),
+            1,
+            "should not duplicate existing Name metadata"
+        );
+        assert_eq!(
+            output.matches("// Description:").count(),
+            1,
+            "should not duplicate existing Description metadata"
+        );
+        assert_eq!(
+            output.matches("import \"@johnlindquist/kit\";").count(),
+            1,
+            "should not duplicate existing import"
+        );
+    }
+
+    #[test]
+    fn test_write_generated_script_in_dir_appends_numeric_suffix_for_collisions() {
+        let temp_dir = tempdir().unwrap();
+        let first = write_generated_script_in_dir(temp_dir.path(), "my-script", "a").unwrap();
+        let second = write_generated_script_in_dir(temp_dir.path(), "my-script", "b").unwrap();
+
+        assert_eq!(first.file_name().unwrap(), "my-script.ts");
+        assert_eq!(second.file_name().unwrap(), "my-script-1.ts");
+    }
+}
diff --git a/src/app_execute/builtin_execution.rs b/src/app_execute/builtin_execution.rs
index c2ec833eff5ada1847787967c7b1195720fa43db..beb3a48c404f463d5edf049315cbbb188d07d3a9
--- a/src/app_execute/builtin_execution.rs
+++ b/src/app_execute/builtin_execution.rs
@@ -544,6 +544,30 @@
 
                 use builtins::AiCommandType;
 
+                // Capture prompt text before reset for Shift+Tab/script-generation flows.
+                let script_generation_prompt = if matches!(cmd_type, AiCommandType::GenerateScript)
+                {
+                    Some(self.filter_text.trim().to_string())
+                } else {
+                    None
+                };
+
+                if matches!(cmd_type, AiCommandType::GenerateScript)
+                    && script_generation_prompt
+                        .as_ref()
+                        .is_some_and(|prompt| prompt.is_empty())
+                {
+                    self.toast_manager.push(
+                        components::toast::Toast::warning(
+                            "Type a prompt first, then run Generate Script with AI.",
+                            &self.theme,
+                        )
+                        .duration_ms(Some(3500)),
+                    );
+                    cx.notify();
+                    return;
+                }
+
                 // All AI commands: reset state, hide main window
                 script_kit_gpui::set_main_window_visible(false);
                 self.reset_to_script_list(cx);
@@ -614,6 +638,132 @@
                         }
                     }
 
+                    AiCommandType::GenerateScript => {
+                        let Some(prompt_description) = script_generation_prompt.clone() else {
+                            logging::log(
+                                "AI_SCRIPT_GEN",
+                                "state=failed attempted=capture_prompt failure=missing_prompt",
+                            );
+                            self.toast_manager.push(
+                                components::toast::Toast::error(
+                                    "No prompt available for AI script generation",
+                                    &self.theme,
+                                )
+                                .duration_ms(Some(5000)),
+                            );
+                            cx.notify();
+                            return;
+                        };
+
+                        let config = self.config.clone();
+                        let (tx, rx) = async_channel::bounded::<
+                            std::result::Result<ai::GeneratedScriptOutput, String>,
+                        >(1);
+
+                        logging::log(
+                            "AI_SCRIPT_GEN",
+                            &format!(
+                                "state=queued attempted=builtin_generate_script prompt_len={}",
+                                prompt_description.len()
+                            ),
+                        );
+
+                        std::thread::spawn(move || {
+                            let generation_result =
+                                ai::generate_script_from_prompt(&prompt_description, Some(&config))
+                                    .map_err(|error| error.to_string());
+
+                            if tx.send_blocking(generation_result).is_err() {
+                                logging::log(
+                                    "AI_SCRIPT_GEN",
+                                    "state=aborted attempted=send_result failure=result_channel_closed",
+                                );
+                            }
+                        });
+
+                        cx.spawn(async move |this, cx| {
+                            let Ok(result) = rx.recv().await else {
+                                logging::log(
+                                    "AI_SCRIPT_GEN",
+                                    "state=aborted attempted=recv_result failure=result_channel_closed",
+                                );
+                                return;
+                            };
+
+                            let _ = cx.update(|cx| {
+                                this.update(cx, |app, cx| match result {
+                                    Ok(generated) => {
+                                        let script_name = generated
+                                            .path
+                                            .file_name()
+                                            .and_then(|name| name.to_str())
+                                            .unwrap_or("generated script");
+
+                                        if let Err(error) =
+                                            script_creation::open_in_editor(&generated.path, &app.config)
+                                        {
+                                            logging::log(
+                                                "AI_SCRIPT_GEN",
+                                                &format!(
+                                                    "state=failed attempted=open_editor path={} error={}",
+                                                    generated.path.display(),
+                                                    error
+                                                ),
+                                            );
+                                            app.toast_manager.push(
+                                                components::toast::Toast::error(
+                                                    format!(
+                                                        "Generated {}, but failed to open editor: {}",
+                                                        script_name, error
+                                                    ),
+                                                    &app.theme,
+                                                )
+                                                .duration_ms(Some(7000)),
+                                            );
+                                            cx.notify();
+                                        } else {
+                                            logging::log(
+                                                "AI_SCRIPT_GEN",
+                                                &format!(
+                                                    "state=completed attempted=builtin_generate_script path={} model_id={} provider_id={}",
+                                                    generated.path.display(),
+                                                    generated.model_id,
+                                                    generated.provider_id
+                                                ),
+                                            );
+                                            app.toast_manager.push(
+                                                components::toast::Toast::success(
+                                                    format!("Generated and opened {}", script_name),
+                                                    &app.theme,
+                                                )
+                                                .duration_ms(Some(3500)),
+                                            );
+                                            app.close_and_reset_window(cx);
+                                        }
+                                    }
+                                    Err(error) => {
+                                        logging::log(
+                                            "AI_SCRIPT_GEN",
+                                            &format!(
+                                                "state=failed attempted=builtin_generate_script error={}",
+                                                error
+                                            ),
+                                        );
+                                        app.toast_manager.push(
+                                            components::toast::Toast::error(
+                                                format!("Failed to generate script: {}", error),
+                                                &app.theme,
+                                            )
+                                            .duration_ms(Some(7000)),
+                                        );
+                                        cx.notify();
+                                    }
+                                })
+                            });
+                        })
+                        .detach();
+                    }
+
                     AiCommandType::SendScreenToAi => {
                         // Capture entire screen and send to AI
                         match platform::capture_screen_screenshot() {
diff --git a/src/builtins/part_000.rs b/src/builtins/part_000.rs
index d6b9c2a9b35b40c5005dbb9f65147f528702cb9e..5f6d27d28d72e51126d10d8beccf931c689ef2bb
--- a/src/builtins/part_000.rs
+++ b/src/builtins/part_000.rs
@@ -96,6 +96,8 @@
     OpenAi,
     NewConversation,
     ClearConversation,
+    /// Generate a new Script Kit script from the main prompt text
+    GenerateScript,
     /// Send a screenshot of the entire screen to AI Chat
     SendScreenToAi,
     /// Send a screenshot of the focused window to AI Chat
diff --git a/src/builtins/part_001_entries/entries_002.rs b/src/builtins/part_001_entries/entries_002.rs
index 6d1c9334f0ccaf0aab48582aaf42dcb129e1cb6e..72b318c66aeaf124359f4ecd276dae0350287328
--- a/src/builtins/part_001_entries/entries_002.rs
+++ b/src/builtins/part_001_entries/entries_002.rs
@@ -61,6 +61,17 @@
     ));
 
     entries.push(BuiltInEntry::new_with_icon(
+        "builtin-generate-script-with-ai",
+        "Generate Script with AI",
+        "Generate a Script Kit script from your current prompt text",
+        vec![
+            "generate", "script", "ai", "create", "code", "typescript", "shift", "tab",
+        ],
+        BuiltInFeature::AiCommand(AiCommandType::GenerateScript),
+        "ðŸ§ ",
+    ));
+
+    entries.push(BuiltInEntry::new_with_icon(
         "builtin-send-screen-to-ai",
         "Send Screen to AI Chat",
         "Capture the full screen and send it to AI Chat",
diff --git a/src/builtins/tests/part_000.rs b/src/builtins/tests/part_000.rs
index b3ab2d78ecc147bbdbcfb63b851efbc98de5959a..81a22289bae63689059113341ceb5ac1dd91f2b2
--- a/src/builtins/tests/part_000.rs
+++ b/src/builtins/tests/part_000.rs
@@ -302,6 +302,26 @@
             open_ai.unwrap().feature,
             BuiltInFeature::AiCommand(AiCommandType::OpenAi)
         );
+
+        let generate_script = entries
+            .iter()
+            .find(|e| e.id == "builtin-generate-script-with-ai");
+        assert!(
+            generate_script.is_some(),
+            "builtin-generate-script-with-ai should exist"
+        );
+        let generate_script = generate_script.unwrap();
+        assert_eq!(
+            generate_script.feature,
+            BuiltInFeature::AiCommand(AiCommandType::GenerateScript)
+        );
+        assert!(
+            generate_script
+                .keywords
+                .iter()
+                .any(|keyword| keyword.eq_ignore_ascii_case("shift")),
+            "Generate Script command should be discoverable via Shift+Tab wording"
+        );
     }
     #[test]
     fn test_get_builtin_entries_hides_preview_ai_commands() {


thinking
**Inspecting test inclusions**
exec
/bin/zsh -lc "sed -n '1,220p' src/builtins/part_001.rs" in /Users/johnlindquist/dev/script-kit-gpui succeeded in 51ms:
/// Get the list of enabled built-in entries based on configuration
///
/// # Arguments
/// * `config` - The built-in features configuration
///
/// # Returns
/// A vector of enabled built-in entries that should appear in the main search
///
/// Note: AppLauncher built-in is no longer used since apps now appear directly
/// in the main search results. The config option is retained for future use
/// (e.g., to control whether apps are included in search at all).
pub fn get_builtin_entries(config: &BuiltInConfig) -> Vec<BuiltInEntry> {
    let mut entries = Vec::new();

    include!("part_001_entries/entries_000.rs");
    include!("part_001_entries/entries_001.rs");
    include!("part_001_entries/entries_002.rs");
    include!("part_001_entries/entries_003.rs");

    debug!(count = entries.len(), "Built-in entries loaded");
file update:
diff --git a/src/ai/mod.rs b/src/ai/mod.rs
index a420b1a5faf59506acdb7caf60681c153a3f9bb6..9a73e9491862633b325b2c52b51a3e20395ff85c
--- a/src/ai/mod.rs
+++ b/src/ai/mod.rs
@@ -37,6 +37,7 @@
 pub(crate) mod providers;
 pub(crate) mod sdk_handlers;
 pub(crate) mod session;
+pub(crate) mod script_generation;
 pub(crate) mod storage;
 pub(crate) mod window;
 
@@ -44,6 +45,7 @@
 pub use self::config::{DetectedKeys, ModelInfo, ProviderConfig};
 pub use self::model::{Chat, ChatId, ChatSource, Message, MessageRole};
 pub use self::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+pub use self::script_generation::{generate_script_from_prompt, GeneratedScriptOutput};
 pub use self::sdk_handlers::try_handle_ai_message;
 pub use self::storage::{
     clear_all_chats, create_chat, delete_chat, get_all_chats, get_chat, get_chat_messages,
diff --git a/src/ai/script_generation.rs b/src/ai/script_generation.rs
new file mode 100644
index 0000000000000000000000000000000000000000..7f2ec8e7576ed50cd10f7aea31a6522875ef667a
--- /dev/null
+++ b/src/ai/script_generation.rs
@@ -0,0 +1,417 @@
+use anyhow::{Context, Result};
+use std::fs::{self, OpenOptions};
+use std::io::{ErrorKind, Write};
+use std::path::{Path, PathBuf};
+use std::sync::Arc;
+
+use super::config::ModelInfo;
+use super::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+
+const AI_SCRIPT_OUTPUT_DIR: &str = "~/.kenv/scripts";
+const AI_SCRIPT_DEFAULT_SLUG: &str = "ai-script";
+const AI_SCRIPT_MAX_SLUG_LEN: usize = 64;
+
+const AI_SCRIPT_GENERATION_SYSTEM_PROMPT: &str = r#"You write production-ready Script Kit scripts.
+
+Return ONLY TypeScript source code for one Script Kit script. Do not include explanations.
+
+Required output conventions:
+1) Include metadata comments at the top:
+   // Name: <clear title>
+   // Description: <one-line summary>
+2) Include: import "@johnlindquist/kit";
+3) Use await arg() for user input when useful.
+4) Use await div() for display output when useful.
+5) Keep the script runnable as-is with sensible defaults and light error handling."#;
+
+#[derive(Debug, Clone)]
+pub struct GeneratedScriptOutput {
+    pub path: PathBuf,
+    pub slug: String,
+    pub model_id: String,
+    pub provider_id: String,
+}
+
+pub fn generate_script_from_prompt(
+    prompt: &str,
+    config: Option<&crate::config::Config>,
+) -> Result<GeneratedScriptOutput> {
+    let normalized_prompt = prompt.trim();
+    if normalized_prompt.is_empty() {
+        anyhow::bail!("AI script generation requires a non-empty prompt");
+    }
+
+    let registry = ProviderRegistry::from_environment_with_config(config);
+    if !registry.has_any_provider() {
+        anyhow::bail!(
+            "No AI providers configured. Configure an API key first (Vercel, OpenAI, Anthropic, etc.)."
+        );
+    }
+
+    let (selected_model, provider) = select_generation_model(&registry)?;
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=provider_ready model_id={} provider_id={} prompt_len={}",
+            selected_model.id,
+            selected_model.provider,
+            normalized_prompt.len()
+        ),
+    );
+
+    let messages = vec![
+        ProviderMessage::system(AI_SCRIPT_GENERATION_SYSTEM_PROMPT),
+        ProviderMessage::user(format!(
+            "Generate a Script Kit script for this user request:\n\n{}",
+            normalized_prompt
+        )),
+    ];
+
+    let raw_response = provider
+        .send_message(&messages, &selected_model.id)
+        .with_context(|| {
+            format!(
+                "AI script generation failed (attempted=send_message, model_id={}, provider_id={})",
+                selected_model.id, selected_model.provider
+            )
+        })?;
+
+    let extracted = extract_script_code(&raw_response);
+    if extracted.trim().is_empty() {
+        anyhow::bail!(
+            "AI returned an empty response for script generation (state=empty_response)"
+        );
+    }
+
+    let slug = slugify_script_name(normalized_prompt);
+    let finalized = enforce_script_kit_conventions(&extracted, normalized_prompt, &slug);
+    let path = write_generated_script(&slug, &finalized).with_context(|| {
+        format!(
+            "Failed writing AI-generated script (state=write_failed, slug={})",
+            slug
+        )
+    })?;
+
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=script_written path={} slug={}",
+            path.display(),
+            slug
+        ),
+    );
+
+    Ok(GeneratedScriptOutput {
+        path,
+        slug,
+        model_id: selected_model.id,
+        provider_id: selected_model.provider,
+    })
+}
+
+fn select_generation_model(registry: &ProviderRegistry) -> Result<(ModelInfo, Arc<dyn AiProvider>)> {
+    let models = registry.get_all_models();
+    let selected_model = models
+        .iter()
+        .find(|model| model.provider.eq_ignore_ascii_case("vercel"))
+        .or_else(|| models.first())
+        .cloned()
+        .context("No AI models available in provider registry")?;
+
+    let provider = registry
+        .find_provider_for_model(&selected_model.id)
+        .cloned()
+        .with_context(|| {
+            format!(
+                "No provider found for selected model '{}' (state=provider_missing)",
+                selected_model.id
+            )
+        })?;
+
+    Ok((selected_model, provider))
+}
+
+fn generated_scripts_dir() -> PathBuf {
+    PathBuf::from(shellexpand::tilde(AI_SCRIPT_OUTPUT_DIR).as_ref())
+}
+
+fn split_fence_header_and_body(fence: &str) -> (&str, &str) {
+    match fence.find('\n') {
+        Some(newline_index) => (&fence[..newline_index], &fence[newline_index + 1..]),
+        None => ("", fence),
+    }
+}
+
+fn extract_fenced_code(response: &str, preferred_languages: Option<&[&str]>) -> Option<String> {
+    let mut remaining = response;
+
+    while let Some(start) = remaining.find("```") {
+        let after_start = &remaining[start + 3..];
+        let Some(end) = after_start.find("```") else {
+            break;
+        };
+
+        let fence_contents = &after_start[..end];
+        let (header, body) = split_fence_header_and_body(fence_contents);
+        let language = header
+            .trim()
+            .split(|c: char| c.is_whitespace() || c == '{')
+            .next()
+            .unwrap_or("")
+            .to_ascii_lowercase();
+        let code = body.trim();
+
+        if !code.is_empty() {
+            match preferred_languages {
+                Some(preferred) => {
+                    if preferred.iter().any(|candidate| *candidate == language) {
+                        return Some(code.to_string());
+                    }
+                }
+                None => return Some(code.to_string()),
+            }
+        }
+
+        remaining = &after_start[end + 3..];
+    }
+
+    None
+}
+
+fn extract_script_code(response: &str) -> String {
+    const PREFERRED_LANGUAGES: [&str; 6] = ["typescript", "ts", "javascript", "js", "tsx", "jsx"];
+
+    extract_fenced_code(response, Some(&PREFERRED_LANGUAGES))
+        .or_else(|| extract_fenced_code(response, None))
+        .unwrap_or_else(|| response.trim().to_string())
+}
+
+fn slugify_script_name(prompt: &str) -> String {
+    let mut slug = String::new();
+    let mut last_was_hyphen = false;
+
+    for character in prompt.to_ascii_lowercase().chars() {
+        if character.is_ascii_alphanumeric() {
+            slug.push(character);
+            last_was_hyphen = false;
+        } else if matches!(character, ' ' | '_' | '-') {
+            if !slug.is_empty() && !last_was_hyphen {
+                slug.push('-');
+                last_was_hyphen = true;
+            }
+        }
+    }
+
+    while slug.ends_with('-') {
+        slug.pop();
+    }
+
+    if slug.len() > AI_SCRIPT_MAX_SLUG_LEN {
+        slug.truncate(AI_SCRIPT_MAX_SLUG_LEN);
+        while slug.ends_with('-') {
+            slug.pop();
+        }
+    }
+
+    if slug.is_empty() {
+        AI_SCRIPT_DEFAULT_SLUG.to_string()
+    } else {
+        slug
+    }
+}
+
+fn slug_to_title(slug: &str) -> String {
+    slug.split('-')
+        .filter(|segment| !segment.is_empty())
+        .map(|segment| {
+            let mut chars = segment.chars();
+            match chars.next() {
+                Some(first) => first.to_uppercase().collect::<String>() + chars.as_str(),
+                None => String::new(),
+            }
+        })
+        .collect::<Vec<_>>()
+        .join(" ")
+}
+
+fn description_from_prompt(prompt: &str) -> String {
+    let normalized = prompt.split_whitespace().collect::<Vec<_>>().join(" ");
+    if normalized.is_empty() {
+        return "AI-generated Script Kit script".to_string();
+    }
+
+    let mut shortened = normalized;
+    if shortened.chars().count() > 110 {
+        shortened = format!("{}...", shortened.chars().take(107).collect::<String>());
+    }
+    shortened
+}
+
+fn has_kit_import(script: &str) -> bool {
+    script.contains("import \"@johnlindquist/kit\";")
+        || script.contains("import '@johnlindquist/kit';")
+        || script.contains("import \"@scriptkit/sdk\";")
+        || script.contains("import '@scriptkit/sdk';")
+}
+
+fn enforce_script_kit_conventions(script: &str, prompt: &str, slug: &str) -> String {
+    let mut prefix_lines: Vec<String> = Vec::new();
+    let trimmed_script = script.trim();
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Name:"))
+    {
+        prefix_lines.push(format!("// Name: {}", slug_to_title(slug)));
+    }
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Description:"))
+    {
+        prefix_lines.push(format!("// Description: {}", description_from_prompt(prompt)));
+    }
+
+    if !has_kit_import(trimmed_script) {
+        prefix_lines.push("import \"@johnlindquist/kit\";".to_string());
+    }
+
+    let mut output = String::new();
+    if !prefix_lines.is_empty() {
+        output.push_str(&prefix_lines.join("\n"));
+        output.push_str("\n\n");
+    }
+
+    output.push_str(trimmed_script);
+    if !output.ends_with('\n') {
+        output.push('\n');
+    }
+    output
+}
+
+fn write_generated_script(slug: &str, script_content: &str) -> Result<PathBuf> {
+    write_generated_script_in_dir(&generated_scripts_dir(), slug, script_content)
+}
+
+fn write_generated_script_in_dir(output_dir: &Path, slug: &str, script_content: &str) -> Result<PathBuf> {
+    fs::create_dir_all(output_dir)
+        .with_context(|| format!("Failed to create output dir: {}", output_dir.display()))?;
+
+    for suffix in 0usize.. {
+        let candidate = if suffix == 0 {
+            slug.to_string()
+        } else {
+            format!("{slug}-{suffix}")
+        };
+        let path = output_dir.join(format!("{}.ts", candidate));
+        match OpenOptions::new().write(true).create_new(true).open(&path) {
+            Ok(mut file) => {
+                file.write_all(script_content.as_bytes())
+                    .with_context(|| format!("Failed writing generated script to {}", path.display()))?;
+                return Ok(path);
+            }
+            Err(error) if error.kind() == ErrorKind::AlreadyExists => continue,
+            Err(error) => {
+                return Err(error).with_context(|| {
+                    format!(
+                        "Failed creating generated script file {} (slug={})",
+                        path.display(),
+                        slug
+                    )
+                });
+            }
+        }
+    }
+
+    unreachable!("suffix loop should eventually create a unique script filename")
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+    use tempfile::tempdir;
+
+    #[test]
+    fn test_slugify_script_name_handles_spaces_and_symbols() {
+        assert_eq!(slugify_script_name("Build: API Client!"), "build-api-client");
+        assert_eq!(slugify_script_name("  ___  "), "ai-script");
+    }
+
+    #[test]
+    fn test_extract_script_code_prefers_typescript_fence_when_multiple_blocks_exist() {
+        let response = r#"
+Here's one idea:
+```markdown
+Not code
+```
+```typescript
+await div("hello");
+```
+"#;
+        assert_eq!(extract_script_code(response), "await div(\"hello\");");
+    }
+
+    #[test]
+    fn test_extract_script_code_falls_back_to_first_fenced_block() {
+        let response = r#"
+```python
+print("hello")
+```
+"#;
+        assert_eq!(extract_script_code(response), "print(\"hello\")");
+    }
+
+    #[test]
+    fn test_extract_script_code_returns_trimmed_response_when_no_fence_exists() {
+        let response = "const answer = 42;";
+        assert_eq!(extract_script_code(response), "const answer = 42;");
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_adds_missing_metadata_and_import() {
+        let script = "const name = await arg(\"Name?\");";
+        let output = enforce_script_kit_conventions(script, "Ask for user name", "ask-user-name");
+
+        assert!(output.contains("// Name: Ask User Name"));
+        assert!(output.contains("// Description: Ask for user name"));
+        assert!(output.contains("import \"@johnlindquist/kit\";"));
+        assert!(output.contains("await arg(\"Name?\");"));
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_keeps_existing_metadata_and_import() {
+        let script = r#"// Name: Existing
+// Description: Existing description
+import "@johnlindquist/kit";
+
+await div("ready");
+"#;
+        let output = enforce_script_kit_conventions(script, "ignored", "ignored");
+
+        assert_eq!(
+            output.matches("// Name:").count(),
+            1,
+            "should not duplicate existing Name metadata"
+        );
+        assert_eq!(
+            output.matches("// Description:").count(),
+            1,
+            "should not duplicate existing Description metadata"
+        );
+        assert_eq!(
+            output.matches("import \"@johnlindquist/kit\";").count(),
+            1,
+            "should not duplicate existing import"
+        );
+    }
+
+    #[test]
+    fn test_write_generated_script_in_dir_appends_numeric_suffix_for_collisions() {
+        let temp_dir = tempdir().unwrap();
+        let first = write_generated_script_in_dir(temp_dir.path(), "my-script", "a").unwrap();
+        let second = write_generated_script_in_dir(temp_dir.path(), "my-script", "b").unwrap();
+
+        assert_eq!(first.file_name().unwrap(), "my-script.ts");
+        assert_eq!(second.file_name().unwrap(), "my-script-1.ts");
+    }
+}
diff --git a/src/app_execute/builtin_execution.rs b/src/app_execute/builtin_execution.rs
index c2ec833eff5ada1847787967c7b1195720fa43db..beb3a48c404f463d5edf049315cbbb188d07d3a9
--- a/src/app_execute/builtin_execution.rs
+++ b/src/app_execute/builtin_execution.rs
@@ -544,6 +544,30 @@
 
                 use builtins::AiCommandType;
 
+                // Capture prompt text before reset for Shift+Tab/script-generation flows.
+                let script_generation_prompt = if matches!(cmd_type, AiCommandType::GenerateScript)
+                {
+                    Some(self.filter_text.trim().to_string())
+                } else {
+                    None
+                };
+
+                if matches!(cmd_type, AiCommandType::GenerateScript)
+                    && script_generation_prompt
+                        .as_ref()
+                        .is_some_and(|prompt| prompt.is_empty())
+                {
+                    self.toast_manager.push(
+                        components::toast::Toast::warning(
+                            "Type a prompt first, then run Generate Script with AI.",
+                            &self.theme,
+                        )
+                        .duration_ms(Some(3500)),
+                    );
+                    cx.notify();
+                    return;
+                }
+
                 // All AI commands: reset state, hide main window
                 script_kit_gpui::set_main_window_visible(false);
                 self.reset_to_script_list(cx);
@@ -614,6 +638,132 @@
                         }
                     }
 
+                    AiCommandType::GenerateScript => {
+                        let Some(prompt_description) = script_generation_prompt.clone() else {
+                            logging::log(
+                                "AI_SCRIPT_GEN",
+                                "state=failed attempted=capture_prompt failure=missing_prompt",
+                            );
+                            self.toast_manager.push(
+                                components::toast::Toast::error(
+                                    "No prompt available for AI script generation",
+                                    &self.theme,
+                                )
+                                .duration_ms(Some(5000)),
+                            );
+                            cx.notify();
+                            return;
+                        };
+
+                        let config = self.config.clone();
+                        let (tx, rx) = async_channel::bounded::<
+                            std::result::Result<ai::GeneratedScriptOutput, String>,
+                        >(1);
+
+                        logging::log(
+                            "AI_SCRIPT_GEN",
+                            &format!(
+                                "state=queued attempted=builtin_generate_script prompt_len={}",
+                                prompt_description.len()
+                            ),
+                        );
+
+                        std::thread::spawn(move || {
+                            let generation_result =
+                                ai::generate_script_from_prompt(&prompt_description, Some(&config))
+                                    .map_err(|error| error.to_string());
+
+                            if tx.send_blocking(generation_result).is_err() {
+                                logging::log(
+                                    "AI_SCRIPT_GEN",
+                                    "state=aborted attempted=send_result failure=result_channel_closed",
+                                );
+                            }
+                        });
+
+                        cx.spawn(async move |this, cx| {
+                            let Ok(result) = rx.recv().await else {
+                                logging::log(
+                                    "AI_SCRIPT_GEN",
+                                    "state=aborted attempted=recv_result failure=result_channel_closed",
+                                );
+                                return;
+                            };
+
+                            let _ = cx.update(|cx| {
+                                this.update(cx, |app, cx| match result {
+                                    Ok(generated) => {
+                                        let script_name = generated
+                                            .path
+                                            .file_name()
+                                            .and_then(|name| name.to_str())
+                                            .unwrap_or("generated script");
+
+                                        if let Err(error) =
+                                            script_creation::open_in_editor(&generated.path, &app.config)
+                                        {
+                                            logging::log(
+                                                "AI_SCRIPT_GEN",
+                                                &format!(
+                                                    "state=failed attempted=open_editor path={} error={}",
+                                                    generated.path.display(),
+                                                    error
+                                                ),
+                                            );
+                                            app.toast_manager.push(
+                                                components::toast::Toast::error(
+                                                    format!(
+                                                        "Generated {}, but failed to open editor: {}",
+                                                        script_name, error
+                                                    ),
+                                                    &app.theme,
+                                                )
+                                                .duration_ms(Some(7000)),
+                                            );
+                                            cx.notify();
+                                        } else {
+                                            logging::log(
+                                                "AI_SCRIPT_GEN",
+                                                &format!(
+                                                    "state=completed attempted=builtin_generate_script path={} model_id={} provider_id={}",
+                                                    generated.path.display(),
+                                                    generated.model_id,
+                                                    generated.provider_id
+                                                ),
+                                            );
+                                            app.toast_manager.push(
+                                                components::toast::Toast::success(
+                                                    format!("Generated and opened {}", script_name),
+                                                    &app.theme,
+                                                )
+                                                .duration_ms(Some(3500)),
+                                            );
+                                            app.close_and_reset_window(cx);
+                                        }
+                                    }
+                                    Err(error) => {
+                                        logging::log(
+                                            "AI_SCRIPT_GEN",
+                                            &format!(
+                                                "state=failed attempted=builtin_generate_script error={}",
+                                                error
+                                            ),
+                                        );
+                                        app.toast_manager.push(
+                                            components::toast::Toast::error(
+                                                format!("Failed to generate script: {}", error),
+                                                &app.theme,
+                                            )
+                                            .duration_ms(Some(7000)),
+                                        );
+                                        cx.notify();
+                                    }
+                                })
+                            });
+                        })
+                        .detach();
+                    }
+
                     AiCommandType::SendScreenToAi => {
                         // Capture entire screen and send to AI
                         match platform::capture_screen_screenshot() {
diff --git a/src/builtins/part_000.rs b/src/builtins/part_000.rs
index d6b9c2a9b35b40c5005dbb9f65147f528702cb9e..5f6d27d28d72e51126d10d8beccf931c689ef2bb
--- a/src/builtins/part_000.rs
+++ b/src/builtins/part_000.rs
@@ -96,6 +96,8 @@
     OpenAi,
     NewConversation,
     ClearConversation,
+    /// Generate a new Script Kit script from the main prompt text
+    GenerateScript,
     /// Send a screenshot of the entire screen to AI Chat
     SendScreenToAi,
     /// Send a screenshot of the focused window to AI Chat
diff --git a/src/builtins/part_001_entries/entries_002.rs b/src/builtins/part_001_entries/entries_002.rs
index 6d1c9334f0ccaf0aab48582aaf42dcb129e1cb6e..72b318c66aeaf124359f4ecd276dae0350287328
--- a/src/builtins/part_001_entries/entries_002.rs
+++ b/src/builtins/part_001_entries/entries_002.rs
@@ -61,6 +61,17 @@
     ));
 
     entries.push(BuiltInEntry::new_with_icon(
+        "builtin-generate-script-with-ai",
+        "Generate Script with AI",
+        "Generate a Script Kit script from your current prompt text",
+        vec![
+            "generate", "script", "ai", "create", "code", "typescript", "shift", "tab",
+        ],
+        BuiltInFeature::AiCommand(AiCommandType::GenerateScript),
+        "ðŸ§ ",
+    ));
+
+    entries.push(BuiltInEntry::new_with_icon(
         "builtin-send-screen-to-ai",
         "Send Screen to AI Chat",
         "Capture the full screen and send it to AI Chat",
diff --git a/src/builtins/tests/part_000.rs b/src/builtins/tests/part_000.rs
index b3ab2d78ecc147bbdbcfb63b851efbc98de5959a..81a22289bae63689059113341ceb5ac1dd91f2b2
--- a/src/builtins/tests/part_000.rs
+++ b/src/builtins/tests/part_000.rs
@@ -302,6 +302,26 @@
             open_ai.unwrap().feature,
             BuiltInFeature::AiCommand(AiCommandType::OpenAi)
         );
+
+        let generate_script = entries
+            .iter()
+            .find(|e| e.id == "builtin-generate-script-with-ai");
+        assert!(
+            generate_script.is_some(),
+            "builtin-generate-script-with-ai should exist"
+        );
+        let generate_script = generate_script.unwrap();
+        assert_eq!(
+            generate_script.feature,
+            BuiltInFeature::AiCommand(AiCommandType::GenerateScript)
+        );
+        assert!(
+            generate_script
+                .keywords
+                .iter()
+                .any(|keyword| keyword.eq_ignore_ascii_case("shift")),
+            "Generate Script command should be discoverable via Shift+Tab wording"
+        );
     }
     #[test]
     fn test_get_builtin_entries_hides_preview_ai_commands() {


thinking
**Locating builtins tests**
exec
/bin/zsh -lc "sed -n '1,220p' src/builtins/part_003.rs" in /Users/johnlindquist/dev/script-kit-gpui succeeded in 51ms:
#[cfg(test)]
mod tests {
    include!("tests/part_000.rs");
    include!("tests/part_001.rs");
}
file update:
diff --git a/src/ai/mod.rs b/src/ai/mod.rs
index a420b1a5faf59506acdb7caf60681c153a3f9bb6..9a73e9491862633b325b2c52b51a3e20395ff85c
--- a/src/ai/mod.rs
+++ b/src/ai/mod.rs
@@ -37,6 +37,7 @@
 pub(crate) mod providers;
 pub(crate) mod sdk_handlers;
 pub(crate) mod session;
+pub(crate) mod script_generation;
 pub(crate) mod storage;
 pub(crate) mod window;
 
@@ -44,6 +45,7 @@
 pub use self::config::{DetectedKeys, ModelInfo, ProviderConfig};
 pub use self::model::{Chat, ChatId, ChatSource, Message, MessageRole};
 pub use self::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+pub use self::script_generation::{generate_script_from_prompt, GeneratedScriptOutput};
 pub use self::sdk_handlers::try_handle_ai_message;
 pub use self::storage::{
     clear_all_chats, create_chat, delete_chat, get_all_chats, get_chat, get_chat_messages,
diff --git a/src/ai/script_generation.rs b/src/ai/script_generation.rs
new file mode 100644
index 0000000000000000000000000000000000000000..7f2ec8e7576ed50cd10f7aea31a6522875ef667a
--- /dev/null
+++ b/src/ai/script_generation.rs
@@ -0,0 +1,417 @@
+use anyhow::{Context, Result};
+use std::fs::{self, OpenOptions};
+use std::io::{ErrorKind, Write};
+use std::path::{Path, PathBuf};
+use std::sync::Arc;
+
+use super::config::ModelInfo;
+use super::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+
+const AI_SCRIPT_OUTPUT_DIR: &str = "~/.kenv/scripts";
+const AI_SCRIPT_DEFAULT_SLUG: &str = "ai-script";
+const AI_SCRIPT_MAX_SLUG_LEN: usize = 64;
+
+const AI_SCRIPT_GENERATION_SYSTEM_PROMPT: &str = r#"You write production-ready Script Kit scripts.
+
+Return ONLY TypeScript source code for one Script Kit script. Do not include explanations.
+
+Required output conventions:
+1) Include metadata comments at the top:
+   // Name: <clear title>
+   // Description: <one-line summary>
+2) Include: import "@johnlindquist/kit";
+3) Use await arg() for user input when useful.
+4) Use await div() for display output when useful.
+5) Keep the script runnable as-is with sensible defaults and light error handling."#;
+
+#[derive(Debug, Clone)]
+pub struct GeneratedScriptOutput {
+    pub path: PathBuf,
+    pub slug: String,
+    pub model_id: String,
+    pub provider_id: String,
+}
+
+pub fn generate_script_from_prompt(
+    prompt: &str,
+    config: Option<&crate::config::Config>,
+) -> Result<GeneratedScriptOutput> {
+    let normalized_prompt = prompt.trim();
+    if normalized_prompt.is_empty() {
+        anyhow::bail!("AI script generation requires a non-empty prompt");
+    }
+
+    let registry = ProviderRegistry::from_environment_with_config(config);
+    if !registry.has_any_provider() {
+        anyhow::bail!(
+            "No AI providers configured. Configure an API key first (Vercel, OpenAI, Anthropic, etc.)."
+        );
+    }
+
+    let (selected_model, provider) = select_generation_model(&registry)?;
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=provider_ready model_id={} provider_id={} prompt_len={}",
+            selected_model.id,
+            selected_model.provider,
+            normalized_prompt.len()
+        ),
+    );
+
+    let messages = vec![
+        ProviderMessage::system(AI_SCRIPT_GENERATION_SYSTEM_PROMPT),
+        ProviderMessage::user(format!(
+            "Generate a Script Kit script for this user request:\n\n{}",
+            normalized_prompt
+        )),
+    ];
+
+    let raw_response = provider
+        .send_message(&messages, &selected_model.id)
+        .with_context(|| {
+            format!(
+                "AI script generation failed (attempted=send_message, model_id={}, provider_id={})",
+                selected_model.id, selected_model.provider
+            )
+        })?;
+
+    let extracted = extract_script_code(&raw_response);
+    if extracted.trim().is_empty() {
+        anyhow::bail!(
+            "AI returned an empty response for script generation (state=empty_response)"
+        );
+    }
+
+    let slug = slugify_script_name(normalized_prompt);
+    let finalized = enforce_script_kit_conventions(&extracted, normalized_prompt, &slug);
+    let path = write_generated_script(&slug, &finalized).with_context(|| {
+        format!(
+            "Failed writing AI-generated script (state=write_failed, slug={})",
+            slug
+        )
+    })?;
+
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=script_written path={} slug={}",
+            path.display(),
+            slug
+        ),
+    );
+
+    Ok(GeneratedScriptOutput {
+        path,
+        slug,
+        model_id: selected_model.id,
+        provider_id: selected_model.provider,
+    })
+}
+
+fn select_generation_model(registry: &ProviderRegistry) -> Result<(ModelInfo, Arc<dyn AiProvider>)> {
+    let models = registry.get_all_models();
+    let selected_model = models
+        .iter()
+        .find(|model| model.provider.eq_ignore_ascii_case("vercel"))
+        .or_else(|| models.first())
+        .cloned()
+        .context("No AI models available in provider registry")?;
+
+    let provider = registry
+        .find_provider_for_model(&selected_model.id)
+        .cloned()
+        .with_context(|| {
+            format!(
+                "No provider found for selected model '{}' (state=provider_missing)",
+                selected_model.id
+            )
+        })?;
+
+    Ok((selected_model, provider))
+}
+
+fn generated_scripts_dir() -> PathBuf {
+    PathBuf::from(shellexpand::tilde(AI_SCRIPT_OUTPUT_DIR).as_ref())
+}
+
+fn split_fence_header_and_body(fence: &str) -> (&str, &str) {
+    match fence.find('\n') {
+        Some(newline_index) => (&fence[..newline_index], &fence[newline_index + 1..]),
+        None => ("", fence),
+    }
+}
+
+fn extract_fenced_code(response: &str, preferred_languages: Option<&[&str]>) -> Option<String> {
+    let mut remaining = response;
+
+    while let Some(start) = remaining.find("```") {
+        let after_start = &remaining[start + 3..];
+        let Some(end) = after_start.find("```") else {
+            break;
+        };
+
+        let fence_contents = &after_start[..end];
+        let (header, body) = split_fence_header_and_body(fence_contents);
+        let language = header
+            .trim()
+            .split(|c: char| c.is_whitespace() || c == '{')
+            .next()
+            .unwrap_or("")
+            .to_ascii_lowercase();
+        let code = body.trim();
+
+        if !code.is_empty() {
+            match preferred_languages {
+                Some(preferred) => {
+                    if preferred.iter().any(|candidate| *candidate == language) {
+                        return Some(code.to_string());
+                    }
+                }
+                None => return Some(code.to_string()),
+            }
+        }
+
+        remaining = &after_start[end + 3..];
+    }
+
+    None
+}
+
+fn extract_script_code(response: &str) -> String {
+    const PREFERRED_LANGUAGES: [&str; 6] = ["typescript", "ts", "javascript", "js", "tsx", "jsx"];
+
+    extract_fenced_code(response, Some(&PREFERRED_LANGUAGES))
+        .or_else(|| extract_fenced_code(response, None))
+        .unwrap_or_else(|| response.trim().to_string())
+}
+
+fn slugify_script_name(prompt: &str) -> String {
+    let mut slug = String::new();
+    let mut last_was_hyphen = false;
+
+    for character in prompt.to_ascii_lowercase().chars() {
+        if character.is_ascii_alphanumeric() {
+            slug.push(character);
+            last_was_hyphen = false;
+        } else if matches!(character, ' ' | '_' | '-') {
+            if !slug.is_empty() && !last_was_hyphen {
+                slug.push('-');
+                last_was_hyphen = true;
+            }
+        }
+    }
+
+    while slug.ends_with('-') {
+        slug.pop();
+    }
+
+    if slug.len() > AI_SCRIPT_MAX_SLUG_LEN {
+        slug.truncate(AI_SCRIPT_MAX_SLUG_LEN);
+        while slug.ends_with('-') {
+            slug.pop();
+        }
+    }
+
+    if slug.is_empty() {
+        AI_SCRIPT_DEFAULT_SLUG.to_string()
+    } else {
+        slug
+    }
+}
+
+fn slug_to_title(slug: &str) -> String {
+    slug.split('-')
+        .filter(|segment| !segment.is_empty())
+        .map(|segment| {
+            let mut chars = segment.chars();
+            match chars.next() {
+                Some(first) => first.to_uppercase().collect::<String>() + chars.as_str(),
+                None => String::new(),
+            }
+        })
+        .collect::<Vec<_>>()
+        .join(" ")
+}
+
+fn description_from_prompt(prompt: &str) -> String {
+    let normalized = prompt.split_whitespace().collect::<Vec<_>>().join(" ");
+    if normalized.is_empty() {
+        return "AI-generated Script Kit script".to_string();
+    }
+
+    let mut shortened = normalized;
+    if shortened.chars().count() > 110 {
+        shortened = format!("{}...", shortened.chars().take(107).collect::<String>());
+    }
+    shortened
+}
+
+fn has_kit_import(script: &str) -> bool {
+    script.contains("import \"@johnlindquist/kit\";")
+        || script.contains("import '@johnlindquist/kit';")
+        || script.contains("import \"@scriptkit/sdk\";")
+        || script.contains("import '@scriptkit/sdk';")
+}
+
+fn enforce_script_kit_conventions(script: &str, prompt: &str, slug: &str) -> String {
+    let mut prefix_lines: Vec<String> = Vec::new();
+    let trimmed_script = script.trim();
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Name:"))
+    {
+        prefix_lines.push(format!("// Name: {}", slug_to_title(slug)));
+    }
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Description:"))
+    {
+        prefix_lines.push(format!("// Description: {}", description_from_prompt(prompt)));
+    }
+
+    if !has_kit_import(trimmed_script) {
+        prefix_lines.push("import \"@johnlindquist/kit\";".to_string());
+    }
+
+    let mut output = String::new();
+    if !prefix_lines.is_empty() {
+        output.push_str(&prefix_lines.join("\n"));
+        output.push_str("\n\n");
+    }
+
+    output.push_str(trimmed_script);
+    if !output.ends_with('\n') {
+        output.push('\n');
+    }
+    output
+}
+
+fn write_generated_script(slug: &str, script_content: &str) -> Result<PathBuf> {
+    write_generated_script_in_dir(&generated_scripts_dir(), slug, script_content)
+}
+
+fn write_generated_script_in_dir(output_dir: &Path, slug: &str, script_content: &str) -> Result<PathBuf> {
+    fs::create_dir_all(output_dir)
+        .with_context(|| format!("Failed to create output dir: {}", output_dir.display()))?;
+
+    for suffix in 0usize.. {
+        let candidate = if suffix == 0 {
+            slug.to_string()
+        } else {
+            format!("{slug}-{suffix}")
+        };
+        let path = output_dir.join(format!("{}.ts", candidate));
+        match OpenOptions::new().write(true).create_new(true).open(&path) {
+            Ok(mut file) => {
+                file.write_all(script_content.as_bytes())
+                    .with_context(|| format!("Failed writing generated script to {}", path.display()))?;
+                return Ok(path);
+            }
+            Err(error) if error.kind() == ErrorKind::AlreadyExists => continue,
+            Err(error) => {
+                return Err(error).with_context(|| {
+                    format!(
+                        "Failed creating generated script file {} (slug={})",
+                        path.display(),
+                        slug
+                    )
+                });
+            }
+        }
+    }
+
+    unreachable!("suffix loop should eventually create a unique script filename")
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+    use tempfile::tempdir;
+
+    #[test]
+    fn test_slugify_script_name_handles_spaces_and_symbols() {
+        assert_eq!(slugify_script_name("Build: API Client!"), "build-api-client");
+        assert_eq!(slugify_script_name("  ___  "), "ai-script");
+    }
+
+    #[test]
+    fn test_extract_script_code_prefers_typescript_fence_when_multiple_blocks_exist() {
+        let response = r#"
+Here's one idea:
+```markdown
+Not code
+```
+```typescript
+await div("hello");
+```
+"#;
+        assert_eq!(extract_script_code(response), "await div(\"hello\");");
+    }
+
+    #[test]
+    fn test_extract_script_code_falls_back_to_first_fenced_block() {
+        let response = r#"
+```python
+print("hello")
+```
+"#;
+        assert_eq!(extract_script_code(response), "print(\"hello\")");
+    }
+
+    #[test]
+    fn test_extract_script_code_returns_trimmed_response_when_no_fence_exists() {
+        let response = "const answer = 42;";
+        assert_eq!(extract_script_code(response), "const answer = 42;");
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_adds_missing_metadata_and_import() {
+        let script = "const name = await arg(\"Name?\");";
+        let output = enforce_script_kit_conventions(script, "Ask for user name", "ask-user-name");
+
+        assert!(output.contains("// Name: Ask User Name"));
+        assert!(output.contains("// Description: Ask for user name"));
+        assert!(output.contains("import \"@johnlindquist/kit\";"));
+        assert!(output.contains("await arg(\"Name?\");"));
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_keeps_existing_metadata_and_import() {
+        let script = r#"// Name: Existing
+// Description: Existing description
+import "@johnlindquist/kit";
+
+await div("ready");
+"#;
+        let output = enforce_script_kit_conventions(script, "ignored", "ignored");
+
+        assert_eq!(
+            output.matches("// Name:").count(),
+            1,
+            "should not duplicate existing Name metadata"
+        );
+        assert_eq!(
+            output.matches("// Description:").count(),
+            1,
+            "should not duplicate existing Description metadata"
+        );
+        assert_eq!(
+            output.matches("import \"@johnlindquist/kit\";").count(),
+            1,
+            "should not duplicate existing import"
+        );
+    }
+
+    #[test]
+    fn test_write_generated_script_in_dir_appends_numeric_suffix_for_collisions() {
+        let temp_dir = tempdir().unwrap();
+        let first = write_generated_script_in_dir(temp_dir.path(), "my-script", "a").unwrap();
+        let second = write_generated_script_in_dir(temp_dir.path(), "my-script", "b").unwrap();
+
+        assert_eq!(first.file_name().unwrap(), "my-script.ts");
+        assert_eq!(second.file_name().unwrap(), "my-script-1.ts");
+    }
+}
diff --git a/src/app_execute/builtin_execution.rs b/src/app_execute/builtin_execution.rs
index c2ec833eff5ada1847787967c7b1195720fa43db..beb3a48c404f463d5edf049315cbbb188d07d3a9
--- a/src/app_execute/builtin_execution.rs
+++ b/src/app_execute/builtin_execution.rs
@@ -544,6 +544,30 @@
 
                 use builtins::AiCommandType;
 
+                // Capture prompt text before reset for Shift+Tab/script-generation flows.
+                let script_generation_prompt = if matches!(cmd_type, AiCommandType::GenerateScript)
+                {
+                    Some(self.filter_text.trim().to_string())
+                } else {
+                    None
+                };
+
+                if matches!(cmd_type, AiCommandType::GenerateScript)
+                    && script_generation_prompt
+                        .as_ref()
+                        .is_some_and(|prompt| prompt.is_empty())
+                {
+                    self.toast_manager.push(
+                        components::toast::Toast::warning(
+                            "Type a prompt first, then run Generate Script with AI.",
+                            &self.theme,
+                        )
+                        .duration_ms(Some(3500)),
+                    );
+                    cx.notify();
+                    return;
+                }
+
                 // All AI commands: reset state, hide main window
                 script_kit_gpui::set_main_window_visible(false);
                 self.reset_to_script_list(cx);
@@ -614,6 +638,132 @@
                         }
                     }
 
+                    AiCommandType::GenerateScript => {
+                        let Some(prompt_description) = script_generation_prompt.clone() else {
+                            logging::log(
+                                "AI_SCRIPT_GEN",
+                                "state=failed attempted=capture_prompt failure=missing_prompt",
+                            );
+                            self.toast_manager.push(
+                                components::toast::Toast::error(
+                                    "No prompt available for AI script generation",
+                                    &self.theme,
+                                )
+                                .duration_ms(Some(5000)),
+                            );
+                            cx.notify();
+                            return;
+                        };
+
+                        let config = self.config.clone();
+                        let (tx, rx) = async_channel::bounded::<
+                            std::result::Result<ai::GeneratedScriptOutput, String>,
+                        >(1);
+
+                        logging::log(
+                            "AI_SCRIPT_GEN",
+                            &format!(
+                                "state=queued attempted=builtin_generate_script prompt_len={}",
+                                prompt_description.len()
+                            ),
+                        );
+
+                        std::thread::spawn(move || {
+                            let generation_result =
+                                ai::generate_script_from_prompt(&prompt_description, Some(&config))
+                                    .map_err(|error| error.to_string());
+
+                            if tx.send_blocking(generation_result).is_err() {
+                                logging::log(
+                                    "AI_SCRIPT_GEN",
+                                    "state=aborted attempted=send_result failure=result_channel_closed",
+                                );
+                            }
+                        });
+
+                        cx.spawn(async move |this, cx| {
+                            let Ok(result) = rx.recv().await else {
+                                logging::log(
+                                    "AI_SCRIPT_GEN",
+                                    "state=aborted attempted=recv_result failure=result_channel_closed",
+                                );
+                                return;
+                            };
+
+                            let _ = cx.update(|cx| {
+                                this.update(cx, |app, cx| match result {
+                                    Ok(generated) => {
+                                        let script_name = generated
+                                            .path
+                                            .file_name()
+                                            .and_then(|name| name.to_str())
+                                            .unwrap_or("generated script");
+
+                                        if let Err(error) =
+                                            script_creation::open_in_editor(&generated.path, &app.config)
+                                        {
+                                            logging::log(
+                                                "AI_SCRIPT_GEN",
+                                                &format!(
+                                                    "state=failed attempted=open_editor path={} error={}",
+                                                    generated.path.display(),
+                                                    error
+                                                ),
+                                            );
+                                            app.toast_manager.push(
+                                                components::toast::Toast::error(
+                                                    format!(
+                                                        "Generated {}, but failed to open editor: {}",
+                                                        script_name, error
+                                                    ),
+                                                    &app.theme,
+                                                )
+                                                .duration_ms(Some(7000)),
+                                            );
+                                            cx.notify();
+                                        } else {
+                                            logging::log(
+                                                "AI_SCRIPT_GEN",
+                                                &format!(
+                                                    "state=completed attempted=builtin_generate_script path={} model_id={} provider_id={}",
+                                                    generated.path.display(),
+                                                    generated.model_id,
+                                                    generated.provider_id
+                                                ),
+                                            );
+                                            app.toast_manager.push(
+                                                components::toast::Toast::success(
+                                                    format!("Generated and opened {}", script_name),
+                                                    &app.theme,
+                                                )
+                                                .duration_ms(Some(3500)),
+                                            );
+                                            app.close_and_reset_window(cx);
+                                        }
+                                    }
+                                    Err(error) => {
+                                        logging::log(
+                                            "AI_SCRIPT_GEN",
+                                            &format!(
+                                                "state=failed attempted=builtin_generate_script error={}",
+                                                error
+                                            ),
+                                        );
+                                        app.toast_manager.push(
+                                            components::toast::Toast::error(
+                                                format!("Failed to generate script: {}", error),
+                                                &app.theme,
+                                            )
+                                            .duration_ms(Some(7000)),
+                                        );
+                                        cx.notify();
+                                    }
+                                })
+                            });
+                        })
+                        .detach();
+                    }
+
                     AiCommandType::SendScreenToAi => {
                         // Capture entire screen and send to AI
                         match platform::capture_screen_screenshot() {
diff --git a/src/builtins/part_000.rs b/src/builtins/part_000.rs
index d6b9c2a9b35b40c5005dbb9f65147f528702cb9e..5f6d27d28d72e51126d10d8beccf931c689ef2bb
--- a/src/builtins/part_000.rs
+++ b/src/builtins/part_000.rs
@@ -96,6 +96,8 @@
     OpenAi,
     NewConversation,
     ClearConversation,
+    /// Generate a new Script Kit script from the main prompt text
+    GenerateScript,
     /// Send a screenshot of the entire screen to AI Chat
     SendScreenToAi,
     /// Send a screenshot of the focused window to AI Chat
diff --git a/src/builtins/part_001_entries/entries_002.rs b/src/builtins/part_001_entries/entries_002.rs
index 6d1c9334f0ccaf0aab48582aaf42dcb129e1cb6e..72b318c66aeaf124359f4ecd276dae0350287328
--- a/src/builtins/part_001_entries/entries_002.rs
+++ b/src/builtins/part_001_entries/entries_002.rs
@@ -61,6 +61,17 @@
     ));
 
     entries.push(BuiltInEntry::new_with_icon(
+        "builtin-generate-script-with-ai",
+        "Generate Script with AI",
+        "Generate a Script Kit script from your current prompt text",
+        vec![
+            "generate", "script", "ai", "create", "code", "typescript", "shift", "tab",
+        ],
+        BuiltInFeature::AiCommand(AiCommandType::GenerateScript),
+        "ðŸ§ ",
+    ));
+
+    entries.push(BuiltInEntry::new_with_icon(
         "builtin-send-screen-to-ai",
         "Send Screen to AI Chat",
         "Capture the full screen and send it to AI Chat",
diff --git a/src/builtins/tests/part_000.rs b/src/builtins/tests/part_000.rs
index b3ab2d78ecc147bbdbcfb63b851efbc98de5959a..81a22289bae63689059113341ceb5ac1dd91f2b2
--- a/src/builtins/tests/part_000.rs
+++ b/src/builtins/tests/part_000.rs
@@ -302,6 +302,26 @@
             open_ai.unwrap().feature,
             BuiltInFeature::AiCommand(AiCommandType::OpenAi)
         );
+
+        let generate_script = entries
+            .iter()
+            .find(|e| e.id == "builtin-generate-script-with-ai");
+        assert!(
+            generate_script.is_some(),
+            "builtin-generate-script-with-ai should exist"
+        );
+        let generate_script = generate_script.unwrap();
+        assert_eq!(
+            generate_script.feature,
+            BuiltInFeature::AiCommand(AiCommandType::GenerateScript)
+        );
+        assert!(
+            generate_script
+                .keywords
+                .iter()
+                .any(|keyword| keyword.eq_ignore_ascii_case("shift")),
+            "Generate Script command should be discoverable via Shift+Tab wording"
+        );
     }
     #[test]
     fn test_get_builtin_entries_hides_preview_ai_commands() {


thinking
**Planning scoped test and compile runs**
codex
The core code paths are now in place. Iâ€™m running scoped verification next: targeted AI/builtins tests plus a binary check to ensure `builtin_execution` compiles with the new command branch.

thinking
**Planning targeted test runs**
exec
/bin/zsh -lc 'cargo test --lib ai::script_generation::tests:: -- --nocapture' in /Users/johnlindquist/dev/script-kit-gpui exited 101 in 18.79s:
   Compiling script-kit-gpui v0.1.0 (/Users/johnlindquist/dev/script-kit-gpui)
error[E0761]: file for module `tests` found at both "src/protocol/message/tests.rs" and "src/protocol/message/tests/mod.rs"
  --> src/protocol/message/mod.rs:87:1
   |
87 | mod tests;
   | ^^^^^^^^^^
   |
   = help: delete or rename one of them to remove the ambiguity

error[E0761]: file for module `tests` found at both "src/designs/core/tests.rs" and "src/designs/core/tests/mod.rs"
 --> src/designs/core/part_04.rs:2:1
  |
2 | mod tests;
  | ^^^^^^^^^^
  |
  = help: delete or rename one of them to remove the ambiguity

error[E0412]: cannot find type `Action` in this scope
   --> src/actions/builders_tests/part_01.rs:18:26
    |
file update:
diff --git a/src/ai/mod.rs b/src/ai/mod.rs
index a420b1a5faf59506acdb7caf60681c153a3f9bb6..9a73e9491862633b325b2c52b51a3e20395ff85c
--- a/src/ai/mod.rs
+++ b/src/ai/mod.rs
@@ -37,6 +37,7 @@
 pub(crate) mod providers;
 pub(crate) mod sdk_handlers;
 pub(crate) mod session;
+pub(crate) mod script_generation;
 pub(crate) mod storage;
 pub(crate) mod window;
 
@@ -44,6 +45,7 @@
 pub use self::config::{DetectedKeys, ModelInfo, ProviderConfig};
 pub use self::model::{Chat, ChatId, ChatSource, Message, MessageRole};
 pub use self::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+pub use self::script_generation::{generate_script_from_prompt, GeneratedScriptOutput};
 pub use self::sdk_handlers::try_handle_ai_message;
 pub use self::storage::{
     clear_all_chats, create_chat, delete_chat, get_all_chats, get_chat, get_chat_messages,
diff --git a/src/ai/script_generation.rs b/src/ai/script_generation.rs
new file mode 100644
index 0000000000000000000000000000000000000000..7f2ec8e7576ed50cd10f7aea31a6522875ef667a
--- /dev/null
+++ b/src/ai/script_generation.rs
@@ -0,0 +1,417 @@
+use anyhow::{Context, Result};
+use std::fs::{self, OpenOptions};
+use std::io::{ErrorKind, Write};
+use std::path::{Path, PathBuf};
+use std::sync::Arc;
+
+use super::config::ModelInfo;
+use super::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+
+const AI_SCRIPT_OUTPUT_DIR: &str = "~/.kenv/scripts";
+const AI_SCRIPT_DEFAULT_SLUG: &str = "ai-script";
+const AI_SCRIPT_MAX_SLUG_LEN: usize = 64;
+
+const AI_SCRIPT_GENERATION_SYSTEM_PROMPT: &str = r#"You write production-ready Script Kit scripts.
+
+Return ONLY TypeScript source code for one Script Kit script. Do not include explanations.
+
+Required output conventions:
+1) Include metadata comments at the top:
+   // Name: <clear title>
+   // Description: <one-line summary>
+2) Include: import "@johnlindquist/kit";
+3) Use await arg() for user input when useful.
+4) Use await div() for display output when useful.
+5) Keep the script runnable as-is with sensible defaults and light error handling."#;
+
+#[derive(Debug, Clone)]
+pub struct GeneratedScriptOutput {
+    pub path: PathBuf,
+    pub slug: String,
+    pub model_id: String,
+    pub provider_id: String,
+}
+
+pub fn generate_script_from_prompt(
+    prompt: &str,
+    config: Option<&crate::config::Config>,
+) -> Result<GeneratedScriptOutput> {
+    let normalized_prompt = prompt.trim();
+    if normalized_prompt.is_empty() {
+        anyhow::bail!("AI script generation requires a non-empty prompt");
+    }
+
+    let registry = ProviderRegistry::from_environment_with_config(config);
+    if !registry.has_any_provider() {
+        anyhow::bail!(
+            "No AI providers configured. Configure an API key first (Vercel, OpenAI, Anthropic, etc.)."
+        );
+    }
+
+    let (selected_model, provider) = select_generation_model(&registry)?;
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=provider_ready model_id={} provider_id={} prompt_len={}",
+            selected_model.id,
+            selected_model.provider,
+            normalized_prompt.len()
+        ),
+    );
+
+    let messages = vec![
+        ProviderMessage::system(AI_SCRIPT_GENERATION_SYSTEM_PROMPT),
+        ProviderMessage::user(format!(
+            "Generate a Script Kit script for this user request:\n\n{}",
+            normalized_prompt
+        )),
+    ];
+
+    let raw_response = provider
+        .send_message(&messages, &selected_model.id)
+        .with_context(|| {
+            format!(
+                "AI script generation failed (attempted=send_message, model_id={}, provider_id={})",
+                selected_model.id, selected_model.provider
+            )
+        })?;
+
+    let extracted = extract_script_code(&raw_response);
+    if extracted.trim().is_empty() {
+        anyhow::bail!(
+            "AI returned an empty response for script generation (state=empty_response)"
+        );
+    }
+
+    let slug = slugify_script_name(normalized_prompt);
+    let finalized = enforce_script_kit_conventions(&extracted, normalized_prompt, &slug);
+    let path = write_generated_script(&slug, &finalized).with_context(|| {
+        format!(
+            "Failed writing AI-generated script (state=write_failed, slug={})",
+            slug
+        )
+    })?;
+
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=script_written path={} slug={}",
+            path.display(),
+            slug
+        ),
+    );
+
+    Ok(GeneratedScriptOutput {
+        path,
+        slug,
+        model_id: selected_model.id,
+        provider_id: selected_model.provider,
+    })
+}
+
+fn select_generation_model(registry: &ProviderRegistry) -> Result<(ModelInfo, Arc<dyn AiProvider>)> {
+    let models = registry.get_all_models();
+    let selected_model = models
+        .iter()
+        .find(|model| model.provider.eq_ignore_ascii_case("vercel"))
+        .or_else(|| models.first())
+        .cloned()
+        .context("No AI models available in provider registry")?;
+
+    let provider = registry
+        .find_provider_for_model(&selected_model.id)
+        .cloned()
+        .with_context(|| {
+            format!(
+                "No provider found for selected model '{}' (state=provider_missing)",
+                selected_model.id
+            )
+        })?;
+
+    Ok((selected_model, provider))
+}
+
+fn generated_scripts_dir() -> PathBuf {
+    PathBuf::from(shellexpand::tilde(AI_SCRIPT_OUTPUT_DIR).as_ref())
+}
+
+fn split_fence_header_and_body(fence: &str) -> (&str, &str) {
+    match fence.find('\n') {
+        Some(newline_index) => (&fence[..newline_index], &fence[newline_index + 1..]),
+        None => ("", fence),
+    }
+}
+
+fn extract_fenced_code(response: &str, preferred_languages: Option<&[&str]>) -> Option<String> {
+    let mut remaining = response;
+
+    while let Some(start) = remaining.find("```") {
+        let after_start = &remaining[start + 3..];
+        let Some(end) = after_start.find("```") else {
+            break;
+        };
+
+        let fence_contents = &after_start[..end];
+        let (header, body) = split_fence_header_and_body(fence_contents);
+        let language = header
+            .trim()
+            .split(|c: char| c.is_whitespace() || c == '{')
+            .next()
+            .unwrap_or("")
+            .to_ascii_lowercase();
+        let code = body.trim();
+
+        if !code.is_empty() {
+            match preferred_languages {
+                Some(preferred) => {
+                    if preferred.iter().any(|candidate| *candidate == language) {
+                        return Some(code.to_string());
+                    }
+                }
+                None => return Some(code.to_string()),
+            }
+        }
+
+        remaining = &after_start[end + 3..];
+    }
+
+    None
+}
+
+fn extract_script_code(response: &str) -> String {
+    const PREFERRED_LANGUAGES: [&str; 6] = ["typescript", "ts", "javascript", "js", "tsx", "jsx"];
+
+    extract_fenced_code(response, Some(&PREFERRED_LANGUAGES))
+        .or_else(|| extract_fenced_code(response, None))
+        .unwrap_or_else(|| response.trim().to_string())
+}
+
+fn slugify_script_name(prompt: &str) -> String {
+    let mut slug = String::new();
+    let mut last_was_hyphen = false;
+
+    for character in prompt.to_ascii_lowercase().chars() {
+        if character.is_ascii_alphanumeric() {
+            slug.push(character);
+            last_was_hyphen = false;
+        } else if matches!(character, ' ' | '_' | '-') {
+            if !slug.is_empty() && !last_was_hyphen {
+                slug.push('-');
+                last_was_hyphen = true;
+            }
+        }
+    }
+
+    while slug.ends_with('-') {
+        slug.pop();
+    }
+
+    if slug.len() > AI_SCRIPT_MAX_SLUG_LEN {
+        slug.truncate(AI_SCRIPT_MAX_SLUG_LEN);
+        while slug.ends_with('-') {
+            slug.pop();
+        }
+    }
+
+    if slug.is_empty() {
+        AI_SCRIPT_DEFAULT_SLUG.to_string()
+    } else {
+        slug
+    }
+}
+
+fn slug_to_title(slug: &str) -> String {
+    slug.split('-')
+        .filter(|segment| !segment.is_empty())
+        .map(|segment| {
+            let mut chars = segment.chars();
+            match chars.next() {
+                Some(first) => first.to_uppercase().collect::<String>() + chars.as_str(),
+                None => String::new(),
+            }
+        })
+        .collect::<Vec<_>>()
+        .join(" ")
+}
+
+fn description_from_prompt(prompt: &str) -> String {
+    let normalized = prompt.split_whitespace().collect::<Vec<_>>().join(" ");
+    if normalized.is_empty() {
+        return "AI-generated Script Kit script".to_string();
+    }
+
+    let mut shortened = normalized;
+    if shortened.chars().count() > 110 {
+        shortened = format!("{}...", shortened.chars().take(107).collect::<String>());
+    }
+    shortened
+}
+
+fn has_kit_import(script: &str) -> bool {
+    script.contains("import \"@johnlindquist/kit\";")
+        || script.contains("import '@johnlindquist/kit';")
+        || script.contains("import \"@scriptkit/sdk\";")
+        || script.contains("import '@scriptkit/sdk';")
+}
+
+fn enforce_script_kit_conventions(script: &str, prompt: &str, slug: &str) -> String {
+    let mut prefix_lines: Vec<String> = Vec::new();
+    let trimmed_script = script.trim();
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Name:"))
+    {
+        prefix_lines.push(format!("// Name: {}", slug_to_title(slug)));
+    }
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Description:"))
+    {
+        prefix_lines.push(format!("// Description: {}", description_from_prompt(prompt)));
+    }
+
+    if !has_kit_import(trimmed_script) {
+        prefix_lines.push("import \"@johnlindquist/kit\";".to_string());
+    }
+
+    let mut output = String::new();
+    if !prefix_lines.is_empty() {
+        output.push_str(&prefix_lines.join("\n"));
+        output.push_str("\n\n");
+    }
+
+    output.push_str(trimmed_script);
+    if !output.ends_with('\n') {
+        output.push('\n');
+    }
+    output
+}
+
+fn write_generated_script(slug: &str, script_content: &str) -> Result<PathBuf> {
+    write_generated_script_in_dir(&generated_scripts_dir(), slug, script_content)
+}
+
+fn write_generated_script_in_dir(output_dir: &Path, slug: &str, script_content: &str) -> Result<PathBuf> {
+    fs::create_dir_all(output_dir)
+        .with_context(|| format!("Failed to create output dir: {}", output_dir.display()))?;
+
+    for suffix in 0usize.. {
+        let candidate = if suffix == 0 {
+            slug.to_string()
+        } else {
+            format!("{slug}-{suffix}")
+        };
+        let path = output_dir.join(format!("{}.ts", candidate));
+        match OpenOptions::new().write(true).create_new(true).open(&path) {
+            Ok(mut file) => {
+                file.write_all(script_content.as_bytes())
+                    .with_context(|| format!("Failed writing generated script to {}", path.display()))?;
+                return Ok(path);
+            }
+            Err(error) if error.kind() == ErrorKind::AlreadyExists => continue,
+            Err(error) => {
+                return Err(error).with_context(|| {
+                    format!(
+                        "Failed creating generated script file {} (slug={})",
+                        path.display(),
+                        slug
+                    )
+                });
+            }
+        }
+    }
+
+    unreachable!("suffix loop should eventually create a unique script filename")
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+    use tempfile::tempdir;
+
+    #[test]
+    fn test_slugify_script_name_handles_spaces_and_symbols() {
+        assert_eq!(slugify_script_name("Build: API Client!"), "build-api-client");
+        assert_eq!(slugify_script_name("  ___  "), "ai-script");
+    }
+
+    #[test]
+    fn test_extract_script_code_prefers_typescript_fence_when_multiple_blocks_exist() {
+        let response = r#"
+Here's one idea:
+```markdown
+Not code
+```
+```typescript
+await div("hello");
+```
+"#;
+        assert_eq!(extract_script_code(response), "await div(\"hello\");");
+    }
+
+    #[test]
+    fn test_extract_script_code_falls_back_to_first_fenced_block() {
+        let response = r#"
+```python
+print("hello")
+```
+"#;
+        assert_eq!(extract_script_code(response), "print(\"hello\")");
+    }
+
+    #[test]
+    fn test_extract_script_code_returns_trimmed_response_when_no_fence_exists() {
+        let response = "const answer = 42;";
+        assert_eq!(extract_script_code(response), "const answer = 42;");
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_adds_missing_metadata_and_import() {
+        let script = "const name = await arg(\"Name?\");";
+        let output = enforce_script_kit_conventions(script, "Ask for user name", "ask-user-name");
+
+        assert!(output.contains("// Name: Ask User Name"));
+        assert!(output.contains("// Description: Ask for user name"));
+        assert!(output.contains("import \"@johnlindquist/kit\";"));
+        assert!(output.contains("await arg(\"Name?\");"));
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_keeps_existing_metadata_and_import() {
+        let script = r#"// Name: Existing
+// Description: Existing description
+import "@johnlindquist/kit";
+
+await div("ready");
+"#;
+        let output = enforce_script_kit_conventions(script, "ignored", "ignored");
+
+        assert_eq!(
+            output.matches("// Name:").count(),
+            1,
+            "should not duplicate existing Name metadata"
+        );
+        assert_eq!(
+            output.matches("// Description:").count(),
+            1,
+            "should not duplicate existing Description metadata"
+        );
+        assert_eq!(
+            output.matches("import \"@johnlindquist/kit\";").count(),
+            1,
+            "should not duplicate existing import"
+        );
+    }
+
+    #[test]
+    fn test_write_generated_script_in_dir_appends_numeric_suffix_for_collisions() {
+        let temp_dir = tempdir().unwrap();
+        let first = write_generated_script_in_dir(temp_dir.path(), "my-script", "a").unwrap();
+        let second = write_generated_script_in_dir(temp_dir.path(), "my-script", "b").unwrap();
+
+        assert_eq!(first.file_name().unwrap(), "my-script.ts");
+        assert_eq!(second.file_name().unwrap(), "my-script-1.ts");
+    }
+}
diff --git a/src/app_execute/builtin_execution.rs b/src/app_execute/builtin_execution.rs
index c2ec833eff5ada1847787967c7b1195720fa43db..beb3a48c404f463d5edf049315cbbb188d07d3a9
--- a/src/app_execute/builtin_execution.rs
+++ b/src/app_execute/builtin_execution.rs
@@ -544,6 +544,30 @@
 
                 use builtins::AiCommandType;
 
+                // Capture prompt text before reset for Shift+Tab/script-generation flows.
+                let script_generation_prompt = if matches!(cmd_type, AiCommandType::GenerateScript)
+                {
+                    Some(self.filter_text.trim().to_string())
+                } else {
+                    None
+                };
+
+                if matches!(cmd_type, AiCommandType::GenerateScript)
+                    && script_generation_prompt
+                        .as_ref()
+                        .is_some_and(|prompt| prompt.is_empty())
+                {
+                    self.toast_manager.push(
+                        components::toast::Toast::warning(
+                            "Type a prompt first, then run Generate Script with AI.",
+                            &self.theme,
+                        )
+                        .duration_ms(Some(3500)),
+                    );
+                    cx.notify();
+                    return;
+                }
+
                 // All AI commands: reset state, hide main window
                 script_kit_gpui::set_main_window_visible(false);
                 self.reset_to_script_list(cx);
@@ -614,6 +638,132 @@
                         }
                     }
 
+                    AiCommandType::GenerateScript => {
+                        let Some(prompt_description) = script_generation_prompt.clone() else {
+                            logging::log(
+                                "AI_SCRIPT_GEN",
+                                "state=failed attempted=capture_prompt failure=missing_prompt",
+                            );
+                            self.toast_manager.push(
+                                components::toast::Toast::error(
+                                    "No prompt available for AI script generation",
+                                    &self.theme,
+                                )
+                                .duration_ms(Some(5000)),
+                            );
+                            cx.notify();
+                            return;
+                        };
+
+                        let config = self.config.clone();
+                        let (tx, rx) = async_channel::bounded::<
+                            std::result::Result<ai::GeneratedScriptOutput, String>,
+                        >(1);
+
+                        logging::log(
+                            "AI_SCRIPT_GEN",
+                            &format!(
+                                "state=queued attempted=builtin_generate_script prompt_len={}",
+                                prompt_description.len()
+                            ),
+                        );
+
+                        std::thread::spawn(move || {
+                            let generation_result =
+                                ai::generate_script_from_prompt(&prompt_description, Some(&config))
+                                    .map_err(|error| error.to_string());
+
+                            if tx.send_blocking(generation_result).is_err() {
+                                logging::log(
+                                    "AI_SCRIPT_GEN",
+                                    "state=aborted attempted=send_result failure=result_channel_closed",
+                                );
+                            }
+                        });
+
+                        cx.spawn(async move |this, cx| {
+                            let Ok(result) = rx.recv().await else {
+                                logging::log(
+                                    "AI_SCRIPT_GEN",
+                                    "state=aborted attempted=recv_result failure=result_channel_closed",
+                                );
+                                return;
+                            };
+
+                            let _ = cx.update(|cx| {
+                                this.update(cx, |app, cx| match result {
+                                    Ok(generated) => {
+                                        let script_name = generated
+                                            .path
+                                            .file_name()
+                                            .and_then(|name| name.to_str())
+                                            .unwrap_or("generated script");
+
+                                        if let Err(error) =
+                                            script_creation::open_in_editor(&generated.path, &app.config)
+                                        {
+                                            logging::log(
+                                                "AI_SCRIPT_GEN",
+                                                &format!(
+                                                    "state=failed attempted=open_editor path={} error={}",
+                                                    generated.path.display(),
+                                                    error
+                                                ),
+                                            );
+                                            app.toast_manager.push(
+                                                components::toast::Toast::error(
+                                                    format!(
+                                                        "Generated {}, but failed to open editor: {}",
+                                                        script_name, error
+                                                    ),
+                                                    &app.theme,
+                                                )
+                                                .duration_ms(Some(7000)),
+                                            );
+                                            cx.notify();
+                                        } else {
+                                            logging::log(
+                                                "AI_SCRIPT_GEN",
+                                                &format!(
+                                                    "state=completed attempted=builtin_generate_script path={} model_id={} provider_id={}",
+                                                    generated.path.display(),
+                                                    generated.model_id,
+                                                    generated.provider_id
+                                                ),
+                                            );
+                                            app.toast_manager.push(
+                                                components::toast::Toast::success(
+                                                    format!("Generated and opened {}", script_name),
+                                                    &app.theme,
+                                                )
+                                                .duration_ms(Some(3500)),
+                                            );
+                                            app.close_and_reset_window(cx);
+                                        }
+                                    }
+                                    Err(error) => {
+                                        logging::log(
+                                            "AI_SCRIPT_GEN",
+                                            &format!(
+                                                "state=failed attempted=builtin_generate_script error={}",
+                                                error
+                                            ),
+                                        );
+                                        app.toast_manager.push(
+                                            components::toast::Toast::error(
+                                                format!("Failed to generate script: {}", error),
+                                                &app.theme,
+                                            )
+                                            .duration_ms(Some(7000)),
+                                        );
+                                        cx.notify();
+                                    }
+                                })
+                            });
+                        })
+                        .detach();
+                    }
+
                     AiCommandType::SendScreenToAi => {
                         // Capture entire screen and send to AI
                         match platform::capture_screen_screenshot() {
diff --git a/src/builtins/part_000.rs b/src/builtins/part_000.rs
index d6b9c2a9b35b40c5005dbb9f65147f528702cb9e..5f6d27d28d72e51126d10d8beccf931c689ef2bb
--- a/src/builtins/part_000.rs
+++ b/src/builtins/part_000.rs
@@ -96,6 +96,8 @@
     OpenAi,
     NewConversation,
     ClearConversation,
+    /// Generate a new Script Kit script from the main prompt text
+    GenerateScript,
     /// Send a screenshot of the entire screen to AI Chat
     SendScreenToAi,
     /// Send a screenshot of the focused window to AI Chat
diff --git a/src/builtins/part_001_entries/entries_002.rs b/src/builtins/part_001_entries/entries_002.rs
index 6d1c9334f0ccaf0aab48582aaf42dcb129e1cb6e..72b318c66aeaf124359f4ecd276dae0350287328
--- a/src/builtins/part_001_entries/entries_002.rs
+++ b/src/builtins/part_001_entries/entries_002.rs
@@ -61,6 +61,17 @@
     ));
 
     entries.push(BuiltInEntry::new_with_icon(
+        "builtin-generate-script-with-ai",
+        "Generate Script with AI",
+        "Generate a Script Kit script from your current prompt text",
+        vec![
+            "generate", "script", "ai", "create", "code", "typescript", "shift", "tab",
+        ],
+        BuiltInFeature::AiCommand(AiCommandType::GenerateScript),
+        "ðŸ§ ",
+    ));
+
+    entries.push(BuiltInEntry::new_with_icon(
         "builtin-send-screen-to-ai",
         "Send Screen to AI Chat",
         "Capture the full screen and send it to AI Chat",
diff --git a/src/builtins/tests/part_000.rs b/src/builtins/tests/part_000.rs
index b3ab2d78ecc147bbdbcfb63b851efbc98de5959a..81a22289bae63689059113341ceb5ac1dd91f2b2
--- a/src/builtins/tests/part_000.rs
+++ b/src/builtins/tests/part_000.rs
@@ -302,6 +302,26 @@
             open_ai.unwrap().feature,
             BuiltInFeature::AiCommand(AiCommandType::OpenAi)
         );
+
+        let generate_script = entries
+            .iter()
+            .find(|e| e.id == "builtin-generate-script-with-ai");
+        assert!(
+            generate_script.is_some(),
+            "builtin-generate-script-with-ai should exist"
+        );
+        let generate_script = generate_script.unwrap();
+        assert_eq!(
+            generate_script.feature,
+            BuiltInFeature::AiCommand(AiCommandType::GenerateScript)
+        );
+        assert!(
+            generate_script
+                .keywords
+                .iter()
+                .any(|keyword| keyword.eq_ignore_ascii_case("shift")),
+            "Generate Script command should be discoverable via Shift+Tab wording"
+        );
     }
     #[test]
     fn test_get_builtin_entries_hides_preview_ai_commands() {


thinking
**Exploring scoped compile strategies**
codex
The first scoped test command is blocked by unrelated in-progress test-module breakages from other agents (duplicate `tests` modules and many unrelated action test errors). Iâ€™m switching to scoped non-test builds plus targeted checks that avoid the shared `cfg(test)` failure surface.

thinking
**Checking binary compilation**
exec
/bin/zsh -lc 'cargo check --bin script-kit-gpui' in /Users/johnlindquist/dev/script-kit-gpui succeeded in 11.15s:
    Checking script-kit-gpui v0.1.0 (/Users/johnlindquist/dev/script-kit-gpui)
warning: glob import doesn't reexport anything with visibility `pub(in crate::prompts)` because no imported item is public enough
  --> src/prompts/div/mod.rs:32:16
   |
32 | pub(super) use inline::*;
   |                ^^^^^^^^^
   |
note: the most public imported item is `pub(self)`
  --> src/prompts/div/mod.rs:32:16
   |
32 | pub(super) use inline::*;
   |                ^^^^^^^^^
   = help: reduce the glob import's visibility or increase visibility of imported items
   = note: `#[warn(unused_imports)]` (part of `#[warn(unused)]`) on by default

warning: glob import doesn't reexport anything with visibility `pub(in crate::prompts)` because no imported item is public enough
  --> src/prompts/div/mod.rs:34:16
   |
34 | pub(super) use render_html::*;
   |                ^^^^^^^^^^^^^^
file update:
diff --git a/src/ai/mod.rs b/src/ai/mod.rs
index a420b1a5faf59506acdb7caf60681c153a3f9bb6..9a73e9491862633b325b2c52b51a3e20395ff85c
--- a/src/ai/mod.rs
+++ b/src/ai/mod.rs
@@ -37,6 +37,7 @@
 pub(crate) mod providers;
 pub(crate) mod sdk_handlers;
 pub(crate) mod session;
+pub(crate) mod script_generation;
 pub(crate) mod storage;
 pub(crate) mod window;
 
@@ -44,6 +45,7 @@
 pub use self::config::{DetectedKeys, ModelInfo, ProviderConfig};
 pub use self::model::{Chat, ChatId, ChatSource, Message, MessageRole};
 pub use self::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+pub use self::script_generation::{generate_script_from_prompt, GeneratedScriptOutput};
 pub use self::sdk_handlers::try_handle_ai_message;
 pub use self::storage::{
     clear_all_chats, create_chat, delete_chat, get_all_chats, get_chat, get_chat_messages,
diff --git a/src/ai/script_generation.rs b/src/ai/script_generation.rs
new file mode 100644
index 0000000000000000000000000000000000000000..7f2ec8e7576ed50cd10f7aea31a6522875ef667a
--- /dev/null
+++ b/src/ai/script_generation.rs
@@ -0,0 +1,417 @@
+use anyhow::{Context, Result};
+use std::fs::{self, OpenOptions};
+use std::io::{ErrorKind, Write};
+use std::path::{Path, PathBuf};
+use std::sync::Arc;
+
+use super::config::ModelInfo;
+use super::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+
+const AI_SCRIPT_OUTPUT_DIR: &str = "~/.kenv/scripts";
+const AI_SCRIPT_DEFAULT_SLUG: &str = "ai-script";
+const AI_SCRIPT_MAX_SLUG_LEN: usize = 64;
+
+const AI_SCRIPT_GENERATION_SYSTEM_PROMPT: &str = r#"You write production-ready Script Kit scripts.
+
+Return ONLY TypeScript source code for one Script Kit script. Do not include explanations.
+
+Required output conventions:
+1) Include metadata comments at the top:
+   // Name: <clear title>
+   // Description: <one-line summary>
+2) Include: import "@johnlindquist/kit";
+3) Use await arg() for user input when useful.
+4) Use await div() for display output when useful.
+5) Keep the script runnable as-is with sensible defaults and light error handling."#;
+
+#[derive(Debug, Clone)]
+pub struct GeneratedScriptOutput {
+    pub path: PathBuf,
+    pub slug: String,
+    pub model_id: String,
+    pub provider_id: String,
+}
+
+pub fn generate_script_from_prompt(
+    prompt: &str,
+    config: Option<&crate::config::Config>,
+) -> Result<GeneratedScriptOutput> {
+    let normalized_prompt = prompt.trim();
+    if normalized_prompt.is_empty() {
+        anyhow::bail!("AI script generation requires a non-empty prompt");
+    }
+
+    let registry = ProviderRegistry::from_environment_with_config(config);
+    if !registry.has_any_provider() {
+        anyhow::bail!(
+            "No AI providers configured. Configure an API key first (Vercel, OpenAI, Anthropic, etc.)."
+        );
+    }
+
+    let (selected_model, provider) = select_generation_model(&registry)?;
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=provider_ready model_id={} provider_id={} prompt_len={}",
+            selected_model.id,
+            selected_model.provider,
+            normalized_prompt.len()
+        ),
+    );
+
+    let messages = vec![
+        ProviderMessage::system(AI_SCRIPT_GENERATION_SYSTEM_PROMPT),
+        ProviderMessage::user(format!(
+            "Generate a Script Kit script for this user request:\n\n{}",
+            normalized_prompt
+        )),
+    ];
+
+    let raw_response = provider
+        .send_message(&messages, &selected_model.id)
+        .with_context(|| {
+            format!(
+                "AI script generation failed (attempted=send_message, model_id={}, provider_id={})",
+                selected_model.id, selected_model.provider
+            )
+        })?;
+
+    let extracted = extract_script_code(&raw_response);
+    if extracted.trim().is_empty() {
+        anyhow::bail!(
+            "AI returned an empty response for script generation (state=empty_response)"
+        );
+    }
+
+    let slug = slugify_script_name(normalized_prompt);
+    let finalized = enforce_script_kit_conventions(&extracted, normalized_prompt, &slug);
+    let path = write_generated_script(&slug, &finalized).with_context(|| {
+        format!(
+            "Failed writing AI-generated script (state=write_failed, slug={})",
+            slug
+        )
+    })?;
+
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=script_written path={} slug={}",
+            path.display(),
+            slug
+        ),
+    );
+
+    Ok(GeneratedScriptOutput {
+        path,
+        slug,
+        model_id: selected_model.id,
+        provider_id: selected_model.provider,
+    })
+}
+
+fn select_generation_model(registry: &ProviderRegistry) -> Result<(ModelInfo, Arc<dyn AiProvider>)> {
+    let models = registry.get_all_models();
+    let selected_model = models
+        .iter()
+        .find(|model| model.provider.eq_ignore_ascii_case("vercel"))
+        .or_else(|| models.first())
+        .cloned()
+        .context("No AI models available in provider registry")?;
+
+    let provider = registry
+        .find_provider_for_model(&selected_model.id)
+        .cloned()
+        .with_context(|| {
+            format!(
+                "No provider found for selected model '{}' (state=provider_missing)",
+                selected_model.id
+            )
+        })?;
+
+    Ok((selected_model, provider))
+}
+
+fn generated_scripts_dir() -> PathBuf {
+    PathBuf::from(shellexpand::tilde(AI_SCRIPT_OUTPUT_DIR).as_ref())
+}
+
+fn split_fence_header_and_body(fence: &str) -> (&str, &str) {
+    match fence.find('\n') {
+        Some(newline_index) => (&fence[..newline_index], &fence[newline_index + 1..]),
+        None => ("", fence),
+    }
+}
+
+fn extract_fenced_code(response: &str, preferred_languages: Option<&[&str]>) -> Option<String> {
+    let mut remaining = response;
+
+    while let Some(start) = remaining.find("```") {
+        let after_start = &remaining[start + 3..];
+        let Some(end) = after_start.find("```") else {
+            break;
+        };
+
+        let fence_contents = &after_start[..end];
+        let (header, body) = split_fence_header_and_body(fence_contents);
+        let language = header
+            .trim()
+            .split(|c: char| c.is_whitespace() || c == '{')
+            .next()
+            .unwrap_or("")
+            .to_ascii_lowercase();
+        let code = body.trim();
+
+        if !code.is_empty() {
+            match preferred_languages {
+                Some(preferred) => {
+                    if preferred.iter().any(|candidate| *candidate == language) {
+                        return Some(code.to_string());
+                    }
+                }
+                None => return Some(code.to_string()),
+            }
+        }
+
+        remaining = &after_start[end + 3..];
+    }
+
+    None
+}
+
+fn extract_script_code(response: &str) -> String {
+    const PREFERRED_LANGUAGES: [&str; 6] = ["typescript", "ts", "javascript", "js", "tsx", "jsx"];
+
+    extract_fenced_code(response, Some(&PREFERRED_LANGUAGES))
+        .or_else(|| extract_fenced_code(response, None))
+        .unwrap_or_else(|| response.trim().to_string())
+}
+
+fn slugify_script_name(prompt: &str) -> String {
+    let mut slug = String::new();
+    let mut last_was_hyphen = false;
+
+    for character in prompt.to_ascii_lowercase().chars() {
+        if character.is_ascii_alphanumeric() {
+            slug.push(character);
+            last_was_hyphen = false;
+        } else if matches!(character, ' ' | '_' | '-') {
+            if !slug.is_empty() && !last_was_hyphen {
+                slug.push('-');
+                last_was_hyphen = true;
+            }
+        }
+    }
+
+    while slug.ends_with('-') {
+        slug.pop();
+    }
+
+    if slug.len() > AI_SCRIPT_MAX_SLUG_LEN {
+        slug.truncate(AI_SCRIPT_MAX_SLUG_LEN);
+        while slug.ends_with('-') {
+            slug.pop();
+        }
+    }
+
+    if slug.is_empty() {
+        AI_SCRIPT_DEFAULT_SLUG.to_string()
+    } else {
+        slug
+    }
+}
+
+fn slug_to_title(slug: &str) -> String {
+    slug.split('-')
+        .filter(|segment| !segment.is_empty())
+        .map(|segment| {
+            let mut chars = segment.chars();
+            match chars.next() {
+                Some(first) => first.to_uppercase().collect::<String>() + chars.as_str(),
+                None => String::new(),
+            }
+        })
+        .collect::<Vec<_>>()
+        .join(" ")
+}
+
+fn description_from_prompt(prompt: &str) -> String {
+    let normalized = prompt.split_whitespace().collect::<Vec<_>>().join(" ");
+    if normalized.is_empty() {
+        return "AI-generated Script Kit script".to_string();
+    }
+
+    let mut shortened = normalized;
+    if shortened.chars().count() > 110 {
+        shortened = format!("{}...", shortened.chars().take(107).collect::<String>());
+    }
+    shortened
+}
+
+fn has_kit_import(script: &str) -> bool {
+    script.contains("import \"@johnlindquist/kit\";")
+        || script.contains("import '@johnlindquist/kit';")
+        || script.contains("import \"@scriptkit/sdk\";")
+        || script.contains("import '@scriptkit/sdk';")
+}
+
+fn enforce_script_kit_conventions(script: &str, prompt: &str, slug: &str) -> String {
+    let mut prefix_lines: Vec<String> = Vec::new();
+    let trimmed_script = script.trim();
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Name:"))
+    {
+        prefix_lines.push(format!("// Name: {}", slug_to_title(slug)));
+    }
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Description:"))
+    {
+        prefix_lines.push(format!("// Description: {}", description_from_prompt(prompt)));
+    }
+
+    if !has_kit_import(trimmed_script) {
+        prefix_lines.push("import \"@johnlindquist/kit\";".to_string());
+    }
+
+    let mut output = String::new();
+    if !prefix_lines.is_empty() {
+        output.push_str(&prefix_lines.join("\n"));
+        output.push_str("\n\n");
+    }
+
+    output.push_str(trimmed_script);
+    if !output.ends_with('\n') {
+        output.push('\n');
+    }
+    output
+}
+
+fn write_generated_script(slug: &str, script_content: &str) -> Result<PathBuf> {
+    write_generated_script_in_dir(&generated_scripts_dir(), slug, script_content)
+}
+
+fn write_generated_script_in_dir(output_dir: &Path, slug: &str, script_content: &str) -> Result<PathBuf> {
+    fs::create_dir_all(output_dir)
+        .with_context(|| format!("Failed to create output dir: {}", output_dir.display()))?;
+
+    for suffix in 0usize.. {
+        let candidate = if suffix == 0 {
+            slug.to_string()
+        } else {
+            format!("{slug}-{suffix}")
+        };
+        let path = output_dir.join(format!("{}.ts", candidate));
+        match OpenOptions::new().write(true).create_new(true).open(&path) {
+            Ok(mut file) => {
+                file.write_all(script_content.as_bytes())
+                    .with_context(|| format!("Failed writing generated script to {}", path.display()))?;
+                return Ok(path);
+            }
+            Err(error) if error.kind() == ErrorKind::AlreadyExists => continue,
+            Err(error) => {
+                return Err(error).with_context(|| {
+                    format!(
+                        "Failed creating generated script file {} (slug={})",
+                        path.display(),
+                        slug
+                    )
+                });
+            }
+        }
+    }
+
+    unreachable!("suffix loop should eventually create a unique script filename")
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+    use tempfile::tempdir;
+
+    #[test]
+    fn test_slugify_script_name_handles_spaces_and_symbols() {
+        assert_eq!(slugify_script_name("Build: API Client!"), "build-api-client");
+        assert_eq!(slugify_script_name("  ___  "), "ai-script");
+    }
+
+    #[test]
+    fn test_extract_script_code_prefers_typescript_fence_when_multiple_blocks_exist() {
+        let response = r#"
+Here's one idea:
+```markdown
+Not code
+```
+```typescript
+await div("hello");
+```
+"#;
+        assert_eq!(extract_script_code(response), "await div(\"hello\");");
+    }
+
+    #[test]
+    fn test_extract_script_code_falls_back_to_first_fenced_block() {
+        let response = r#"
+```python
+print("hello")
+```
+"#;
+        assert_eq!(extract_script_code(response), "print(\"hello\")");
+    }
+
+    #[test]
+    fn test_extract_script_code_returns_trimmed_response_when_no_fence_exists() {
+        let response = "const answer = 42;";
+        assert_eq!(extract_script_code(response), "const answer = 42;");
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_adds_missing_metadata_and_import() {
+        let script = "const name = await arg(\"Name?\");";
+        let output = enforce_script_kit_conventions(script, "Ask for user name", "ask-user-name");
+
+        assert!(output.contains("// Name: Ask User Name"));
+        assert!(output.contains("// Description: Ask for user name"));
+        assert!(output.contains("import \"@johnlindquist/kit\";"));
+        assert!(output.contains("await arg(\"Name?\");"));
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_keeps_existing_metadata_and_import() {
+        let script = r#"// Name: Existing
+// Description: Existing description
+import "@johnlindquist/kit";
+
+await div("ready");
+"#;
+        let output = enforce_script_kit_conventions(script, "ignored", "ignored");
+
+        assert_eq!(
+            output.matches("// Name:").count(),
+            1,
+            "should not duplicate existing Name metadata"
+        );
+        assert_eq!(
+            output.matches("// Description:").count(),
+            1,
+            "should not duplicate existing Description metadata"
+        );
+        assert_eq!(
+            output.matches("import \"@johnlindquist/kit\";").count(),
+            1,
+            "should not duplicate existing import"
+        );
+    }
+
+    #[test]
+    fn test_write_generated_script_in_dir_appends_numeric_suffix_for_collisions() {
+        let temp_dir = tempdir().unwrap();
+        let first = write_generated_script_in_dir(temp_dir.path(), "my-script", "a").unwrap();
+        let second = write_generated_script_in_dir(temp_dir.path(), "my-script", "b").unwrap();
+
+        assert_eq!(first.file_name().unwrap(), "my-script.ts");
+        assert_eq!(second.file_name().unwrap(), "my-script-1.ts");
+    }
+}
diff --git a/src/app_execute/builtin_execution.rs b/src/app_execute/builtin_execution.rs
index c2ec833eff5ada1847787967c7b1195720fa43db..beb3a48c404f463d5edf049315cbbb188d07d3a9
--- a/src/app_execute/builtin_execution.rs
+++ b/src/app_execute/builtin_execution.rs
@@ -544,6 +544,30 @@
 
                 use builtins::AiCommandType;
 
+                // Capture prompt text before reset for Shift+Tab/script-generation flows.
+                let script_generation_prompt = if matches!(cmd_type, AiCommandType::GenerateScript)
+                {
+                    Some(self.filter_text.trim().to_string())
+                } else {
+                    None
+                };
+
+                if matches!(cmd_type, AiCommandType::GenerateScript)
+                    && script_generation_prompt
+                        .as_ref()
+                        .is_some_and(|prompt| prompt.is_empty())
+                {
+                    self.toast_manager.push(
+                        components::toast::Toast::warning(
+                            "Type a prompt first, then run Generate Script with AI.",
+                            &self.theme,
+                        )
+                        .duration_ms(Some(3500)),
+                    );
+                    cx.notify();
+                    return;
+                }
+
                 // All AI commands: reset state, hide main window
                 script_kit_gpui::set_main_window_visible(false);
                 self.reset_to_script_list(cx);
@@ -614,6 +638,132 @@
                         }
                     }
 
+                    AiCommandType::GenerateScript => {
+                        let Some(prompt_description) = script_generation_prompt.clone() else {
+                            logging::log(
+                                "AI_SCRIPT_GEN",
+                                "state=failed attempted=capture_prompt failure=missing_prompt",
+                            );
+                            self.toast_manager.push(
+                                components::toast::Toast::error(
+                                    "No prompt available for AI script generation",
+                                    &self.theme,
+                                )
+                                .duration_ms(Some(5000)),
+                            );
+                            cx.notify();
+                            return;
+                        };
+
+                        let config = self.config.clone();
+                        let (tx, rx) = async_channel::bounded::<
+                            std::result::Result<ai::GeneratedScriptOutput, String>,
+                        >(1);
+
+                        logging::log(
+                            "AI_SCRIPT_GEN",
+                            &format!(
+                                "state=queued attempted=builtin_generate_script prompt_len={}",
+                                prompt_description.len()
+                            ),
+                        );
+
+                        std::thread::spawn(move || {
+                            let generation_result =
+                                ai::generate_script_from_prompt(&prompt_description, Some(&config))
+                                    .map_err(|error| error.to_string());
+
+                            if tx.send_blocking(generation_result).is_err() {
+                                logging::log(
+                                    "AI_SCRIPT_GEN",
+                                    "state=aborted attempted=send_result failure=result_channel_closed",
+                                );
+                            }
+                        });
+
+                        cx.spawn(async move |this, cx| {
+                            let Ok(result) = rx.recv().await else {
+                                logging::log(
+                                    "AI_SCRIPT_GEN",
+                                    "state=aborted attempted=recv_result failure=result_channel_closed",
+                                );
+                                return;
+                            };
+
+                            let _ = cx.update(|cx| {
+                                this.update(cx, |app, cx| match result {
+                                    Ok(generated) => {
+                                        let script_name = generated
+                                            .path
+                                            .file_name()
+                                            .and_then(|name| name.to_str())
+                                            .unwrap_or("generated script");
+
+                                        if let Err(error) =
+                                            script_creation::open_in_editor(&generated.path, &app.config)
+                                        {
+                                            logging::log(
+                                                "AI_SCRIPT_GEN",
+                                                &format!(
+                                                    "state=failed attempted=open_editor path={} error={}",
+                                                    generated.path.display(),
+                                                    error
+                                                ),
+                                            );
+                                            app.toast_manager.push(
+                                                components::toast::Toast::error(
+                                                    format!(
+                                                        "Generated {}, but failed to open editor: {}",
+                                                        script_name, error
+                                                    ),
+                                                    &app.theme,
+                                                )
+                                                .duration_ms(Some(7000)),
+                                            );
+                                            cx.notify();
+                                        } else {
+                                            logging::log(
+                                                "AI_SCRIPT_GEN",
+                                                &format!(
+                                                    "state=completed attempted=builtin_generate_script path={} model_id={} provider_id={}",
+                                                    generated.path.display(),
+                                                    generated.model_id,
+                                                    generated.provider_id
+                                                ),
+                                            );
+                                            app.toast_manager.push(
+                                                components::toast::Toast::success(
+                                                    format!("Generated and opened {}", script_name),
+                                                    &app.theme,
+                                                )
+                                                .duration_ms(Some(3500)),
+                                            );
+                                            app.close_and_reset_window(cx);
+                                        }
+                                    }
+                                    Err(error) => {
+                                        logging::log(
+                                            "AI_SCRIPT_GEN",
+                                            &format!(
+                                                "state=failed attempted=builtin_generate_script error={}",
+                                                error
+                                            ),
+                                        );
+                                        app.toast_manager.push(
+                                            components::toast::Toast::error(
+                                                format!("Failed to generate script: {}", error),
+                                                &app.theme,
+                                            )
+                                            .duration_ms(Some(7000)),
+                                        );
+                                        cx.notify();
+                                    }
+                                })
+                            });
+                        })
+                        .detach();
+                    }
+
                     AiCommandType::SendScreenToAi => {
                         // Capture entire screen and send to AI
                         match platform::capture_screen_screenshot() {
diff --git a/src/builtins/part_000.rs b/src/builtins/part_000.rs
index d6b9c2a9b35b40c5005dbb9f65147f528702cb9e..5f6d27d28d72e51126d10d8beccf931c689ef2bb
--- a/src/builtins/part_000.rs
+++ b/src/builtins/part_000.rs
@@ -96,6 +96,8 @@
     OpenAi,
     NewConversation,
     ClearConversation,
+    /// Generate a new Script Kit script from the main prompt text
+    GenerateScript,
     /// Send a screenshot of the entire screen to AI Chat
     SendScreenToAi,
     /// Send a screenshot of the focused window to AI Chat
diff --git a/src/builtins/part_001_entries/entries_002.rs b/src/builtins/part_001_entries/entries_002.rs
index 6d1c9334f0ccaf0aab48582aaf42dcb129e1cb6e..72b318c66aeaf124359f4ecd276dae0350287328
--- a/src/builtins/part_001_entries/entries_002.rs
+++ b/src/builtins/part_001_entries/entries_002.rs
@@ -61,6 +61,17 @@
     ));
 
     entries.push(BuiltInEntry::new_with_icon(
+        "builtin-generate-script-with-ai",
+        "Generate Script with AI",
+        "Generate a Script Kit script from your current prompt text",
+        vec![
+            "generate", "script", "ai", "create", "code", "typescript", "shift", "tab",
+        ],
+        BuiltInFeature::AiCommand(AiCommandType::GenerateScript),
+        "ðŸ§ ",
+    ));
+
+    entries.push(BuiltInEntry::new_with_icon(
         "builtin-send-screen-to-ai",
         "Send Screen to AI Chat",
         "Capture the full screen and send it to AI Chat",
diff --git a/src/builtins/tests/part_000.rs b/src/builtins/tests/part_000.rs
index b3ab2d78ecc147bbdbcfb63b851efbc98de5959a..81a22289bae63689059113341ceb5ac1dd91f2b2
--- a/src/builtins/tests/part_000.rs
+++ b/src/builtins/tests/part_000.rs
@@ -302,6 +302,26 @@
             open_ai.unwrap().feature,
             BuiltInFeature::AiCommand(AiCommandType::OpenAi)
         );
+
+        let generate_script = entries
+            .iter()
+            .find(|e| e.id == "builtin-generate-script-with-ai");
+        assert!(
+            generate_script.is_some(),
+            "builtin-generate-script-with-ai should exist"
+        );
+        let generate_script = generate_script.unwrap();
+        assert_eq!(
+            generate_script.feature,
+            BuiltInFeature::AiCommand(AiCommandType::GenerateScript)
+        );
+        assert!(
+            generate_script
+                .keywords
+                .iter()
+                .any(|keyword| keyword.eq_ignore_ascii_case("shift")),
+            "Generate Script command should be discoverable via Shift+Tab wording"
+        );
     }
     #[test]
     fn test_get_builtin_entries_hides_preview_ai_commands() {


thinking
**Testing binary with targeted test**
exec
/bin/zsh -lc 'cargo test --bin script-kit-gpui main_window_visibility_is_shared_with_library -- --nocapture' in /Users/johnlindquist/dev/script-kit-gpui exited 101 in 27.82s:
   Compiling script-kit-gpui v0.1.0 (/Users/johnlindquist/dev/script-kit-gpui)
warning: glob import doesn't reexport anything with visibility `pub(in crate::prompts)` because no imported item is public enough
  --> src/prompts/div/mod.rs:32:16
   |
32 | pub(super) use inline::*;
   |                ^^^^^^^^^
   |
note: the most public imported item is `pub(self)`
  --> src/prompts/div/mod.rs:32:16
   |
32 | pub(super) use inline::*;
   |                ^^^^^^^^^
   = help: reduce the glob import's visibility or increase visibility of imported items
   = note: `#[warn(unused_imports)]` (part of `#[warn(unused)]`) on by default

warning: glob import doesn't reexport anything with visibility `pub(in crate::prompts)` because no imported item is public enough
  --> src/prompts/div/mod.rs:34:16
   |
34 | pub(super) use render_html::*;
   |                ^^^^^^^^^^^^^^
file update:
diff --git a/src/ai/mod.rs b/src/ai/mod.rs
index a420b1a5faf59506acdb7caf60681c153a3f9bb6..9a73e9491862633b325b2c52b51a3e20395ff85c
--- a/src/ai/mod.rs
+++ b/src/ai/mod.rs
@@ -37,6 +37,7 @@
 pub(crate) mod providers;
 pub(crate) mod sdk_handlers;
 pub(crate) mod session;
+pub(crate) mod script_generation;
 pub(crate) mod storage;
 pub(crate) mod window;
 
@@ -44,6 +45,7 @@
 pub use self::config::{DetectedKeys, ModelInfo, ProviderConfig};
 pub use self::model::{Chat, ChatId, ChatSource, Message, MessageRole};
 pub use self::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+pub use self::script_generation::{generate_script_from_prompt, GeneratedScriptOutput};
 pub use self::sdk_handlers::try_handle_ai_message;
 pub use self::storage::{
     clear_all_chats, create_chat, delete_chat, get_all_chats, get_chat, get_chat_messages,
diff --git a/src/ai/script_generation.rs b/src/ai/script_generation.rs
new file mode 100644
index 0000000000000000000000000000000000000000..7f2ec8e7576ed50cd10f7aea31a6522875ef667a
--- /dev/null
+++ b/src/ai/script_generation.rs
@@ -0,0 +1,417 @@
+use anyhow::{Context, Result};
+use std::fs::{self, OpenOptions};
+use std::io::{ErrorKind, Write};
+use std::path::{Path, PathBuf};
+use std::sync::Arc;
+
+use super::config::ModelInfo;
+use super::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+
+const AI_SCRIPT_OUTPUT_DIR: &str = "~/.kenv/scripts";
+const AI_SCRIPT_DEFAULT_SLUG: &str = "ai-script";
+const AI_SCRIPT_MAX_SLUG_LEN: usize = 64;
+
+const AI_SCRIPT_GENERATION_SYSTEM_PROMPT: &str = r#"You write production-ready Script Kit scripts.
+
+Return ONLY TypeScript source code for one Script Kit script. Do not include explanations.
+
+Required output conventions:
+1) Include metadata comments at the top:
+   // Name: <clear title>
+   // Description: <one-line summary>
+2) Include: import "@johnlindquist/kit";
+3) Use await arg() for user input when useful.
+4) Use await div() for display output when useful.
+5) Keep the script runnable as-is with sensible defaults and light error handling."#;
+
+#[derive(Debug, Clone)]
+pub struct GeneratedScriptOutput {
+    pub path: PathBuf,
+    pub slug: String,
+    pub model_id: String,
+    pub provider_id: String,
+}
+
+pub fn generate_script_from_prompt(
+    prompt: &str,
+    config: Option<&crate::config::Config>,
+) -> Result<GeneratedScriptOutput> {
+    let normalized_prompt = prompt.trim();
+    if normalized_prompt.is_empty() {
+        anyhow::bail!("AI script generation requires a non-empty prompt");
+    }
+
+    let registry = ProviderRegistry::from_environment_with_config(config);
+    if !registry.has_any_provider() {
+        anyhow::bail!(
+            "No AI providers configured. Configure an API key first (Vercel, OpenAI, Anthropic, etc.)."
+        );
+    }
+
+    let (selected_model, provider) = select_generation_model(&registry)?;
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=provider_ready model_id={} provider_id={} prompt_len={}",
+            selected_model.id,
+            selected_model.provider,
+            normalized_prompt.len()
+        ),
+    );
+
+    let messages = vec![
+        ProviderMessage::system(AI_SCRIPT_GENERATION_SYSTEM_PROMPT),
+        ProviderMessage::user(format!(
+            "Generate a Script Kit script for this user request:\n\n{}",
+            normalized_prompt
+        )),
+    ];
+
+    let raw_response = provider
+        .send_message(&messages, &selected_model.id)
+        .with_context(|| {
+            format!(
+                "AI script generation failed (attempted=send_message, model_id={}, provider_id={})",
+                selected_model.id, selected_model.provider
+            )
+        })?;
+
+    let extracted = extract_script_code(&raw_response);
+    if extracted.trim().is_empty() {
+        anyhow::bail!(
+            "AI returned an empty response for script generation (state=empty_response)"
+        );
+    }
+
+    let slug = slugify_script_name(normalized_prompt);
+    let finalized = enforce_script_kit_conventions(&extracted, normalized_prompt, &slug);
+    let path = write_generated_script(&slug, &finalized).with_context(|| {
+        format!(
+            "Failed writing AI-generated script (state=write_failed, slug={})",
+            slug
+        )
+    })?;
+
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=script_written path={} slug={}",
+            path.display(),
+            slug
+        ),
+    );
+
+    Ok(GeneratedScriptOutput {
+        path,
+        slug,
+        model_id: selected_model.id,
+        provider_id: selected_model.provider,
+    })
+}
+
+fn select_generation_model(registry: &ProviderRegistry) -> Result<(ModelInfo, Arc<dyn AiProvider>)> {
+    let models = registry.get_all_models();
+    let selected_model = models
+        .iter()
+        .find(|model| model.provider.eq_ignore_ascii_case("vercel"))
+        .or_else(|| models.first())
+        .cloned()
+        .context("No AI models available in provider registry")?;
+
+    let provider = registry
+        .find_provider_for_model(&selected_model.id)
+        .cloned()
+        .with_context(|| {
+            format!(
+                "No provider found for selected model '{}' (state=provider_missing)",
+                selected_model.id
+            )
+        })?;
+
+    Ok((selected_model, provider))
+}
+
+fn generated_scripts_dir() -> PathBuf {
+    PathBuf::from(shellexpand::tilde(AI_SCRIPT_OUTPUT_DIR).as_ref())
+}
+
+fn split_fence_header_and_body(fence: &str) -> (&str, &str) {
+    match fence.find('\n') {
+        Some(newline_index) => (&fence[..newline_index], &fence[newline_index + 1..]),
+        None => ("", fence),
+    }
+}
+
+fn extract_fenced_code(response: &str, preferred_languages: Option<&[&str]>) -> Option<String> {
+    let mut remaining = response;
+
+    while let Some(start) = remaining.find("```") {
+        let after_start = &remaining[start + 3..];
+        let Some(end) = after_start.find("```") else {
+            break;
+        };
+
+        let fence_contents = &after_start[..end];
+        let (header, body) = split_fence_header_and_body(fence_contents);
+        let language = header
+            .trim()
+            .split(|c: char| c.is_whitespace() || c == '{')
+            .next()
+            .unwrap_or("")
+            .to_ascii_lowercase();
+        let code = body.trim();
+
+        if !code.is_empty() {
+            match preferred_languages {
+                Some(preferred) => {
+                    if preferred.iter().any(|candidate| *candidate == language) {
+                        return Some(code.to_string());
+                    }
+                }
+                None => return Some(code.to_string()),
+            }
+        }
+
+        remaining = &after_start[end + 3..];
+    }
+
+    None
+}
+
+fn extract_script_code(response: &str) -> String {
+    const PREFERRED_LANGUAGES: [&str; 6] = ["typescript", "ts", "javascript", "js", "tsx", "jsx"];
+
+    extract_fenced_code(response, Some(&PREFERRED_LANGUAGES))
+        .or_else(|| extract_fenced_code(response, None))
+        .unwrap_or_else(|| response.trim().to_string())
+}
+
+fn slugify_script_name(prompt: &str) -> String {
+    let mut slug = String::new();
+    let mut last_was_hyphen = false;
+
+    for character in prompt.to_ascii_lowercase().chars() {
+        if character.is_ascii_alphanumeric() {
+            slug.push(character);
+            last_was_hyphen = false;
+        } else if matches!(character, ' ' | '_' | '-') {
+            if !slug.is_empty() && !last_was_hyphen {
+                slug.push('-');
+                last_was_hyphen = true;
+            }
+        }
+    }
+
+    while slug.ends_with('-') {
+        slug.pop();
+    }
+
+    if slug.len() > AI_SCRIPT_MAX_SLUG_LEN {
+        slug.truncate(AI_SCRIPT_MAX_SLUG_LEN);
+        while slug.ends_with('-') {
+            slug.pop();
+        }
+    }
+
+    if slug.is_empty() {
+        AI_SCRIPT_DEFAULT_SLUG.to_string()
+    } else {
+        slug
+    }
+}
+
+fn slug_to_title(slug: &str) -> String {
+    slug.split('-')
+        .filter(|segment| !segment.is_empty())
+        .map(|segment| {
+            let mut chars = segment.chars();
+            match chars.next() {
+                Some(first) => first.to_uppercase().collect::<String>() + chars.as_str(),
+                None => String::new(),
+            }
+        })
+        .collect::<Vec<_>>()
+        .join(" ")
+}
+
+fn description_from_prompt(prompt: &str) -> String {
+    let normalized = prompt.split_whitespace().collect::<Vec<_>>().join(" ");
+    if normalized.is_empty() {
+        return "AI-generated Script Kit script".to_string();
+    }
+
+    let mut shortened = normalized;
+    if shortened.chars().count() > 110 {
+        shortened = format!("{}...", shortened.chars().take(107).collect::<String>());
+    }
+    shortened
+}
+
+fn has_kit_import(script: &str) -> bool {
+    script.contains("import \"@johnlindquist/kit\";")
+        || script.contains("import '@johnlindquist/kit';")
+        || script.contains("import \"@scriptkit/sdk\";")
+        || script.contains("import '@scriptkit/sdk';")
+}
+
+fn enforce_script_kit_conventions(script: &str, prompt: &str, slug: &str) -> String {
+    let mut prefix_lines: Vec<String> = Vec::new();
+    let trimmed_script = script.trim();
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Name:"))
+    {
+        prefix_lines.push(format!("// Name: {}", slug_to_title(slug)));
+    }
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Description:"))
+    {
+        prefix_lines.push(format!("// Description: {}", description_from_prompt(prompt)));
+    }
+
+    if !has_kit_import(trimmed_script) {
+        prefix_lines.push("import \"@johnlindquist/kit\";".to_string());
+    }
+
+    let mut output = String::new();
+    if !prefix_lines.is_empty() {
+        output.push_str(&prefix_lines.join("\n"));
+        output.push_str("\n\n");
+    }
+
+    output.push_str(trimmed_script);
+    if !output.ends_with('\n') {
+        output.push('\n');
+    }
+    output
+}
+
+fn write_generated_script(slug: &str, script_content: &str) -> Result<PathBuf> {
+    write_generated_script_in_dir(&generated_scripts_dir(), slug, script_content)
+}
+
+fn write_generated_script_in_dir(output_dir: &Path, slug: &str, script_content: &str) -> Result<PathBuf> {
+    fs::create_dir_all(output_dir)
+        .with_context(|| format!("Failed to create output dir: {}", output_dir.display()))?;
+
+    for suffix in 0usize.. {
+        let candidate = if suffix == 0 {
+            slug.to_string()
+        } else {
+            format!("{slug}-{suffix}")
+        };
+        let path = output_dir.join(format!("{}.ts", candidate));
+        match OpenOptions::new().write(true).create_new(true).open(&path) {
+            Ok(mut file) => {
+                file.write_all(script_content.as_bytes())
+                    .with_context(|| format!("Failed writing generated script to {}", path.display()))?;
+                return Ok(path);
+            }
+            Err(error) if error.kind() == ErrorKind::AlreadyExists => continue,
+            Err(error) => {
+                return Err(error).with_context(|| {
+                    format!(
+                        "Failed creating generated script file {} (slug={})",
+                        path.display(),
+                        slug
+                    )
+                });
+            }
+        }
+    }
+
+    unreachable!("suffix loop should eventually create a unique script filename")
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+    use tempfile::tempdir;
+
+    #[test]
+    fn test_slugify_script_name_handles_spaces_and_symbols() {
+        assert_eq!(slugify_script_name("Build: API Client!"), "build-api-client");
+        assert_eq!(slugify_script_name("  ___  "), "ai-script");
+    }
+
+    #[test]
+    fn test_extract_script_code_prefers_typescript_fence_when_multiple_blocks_exist() {
+        let response = r#"
+Here's one idea:
+```markdown
+Not code
+```
+```typescript
+await div("hello");
+```
+"#;
+        assert_eq!(extract_script_code(response), "await div(\"hello\");");
+    }
+
+    #[test]
+    fn test_extract_script_code_falls_back_to_first_fenced_block() {
+        let response = r#"
+```python
+print("hello")
+```
+"#;
+        assert_eq!(extract_script_code(response), "print(\"hello\")");
+    }
+
+    #[test]
+    fn test_extract_script_code_returns_trimmed_response_when_no_fence_exists() {
+        let response = "const answer = 42;";
+        assert_eq!(extract_script_code(response), "const answer = 42;");
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_adds_missing_metadata_and_import() {
+        let script = "const name = await arg(\"Name?\");";
+        let output = enforce_script_kit_conventions(script, "Ask for user name", "ask-user-name");
+
+        assert!(output.contains("// Name: Ask User Name"));
+        assert!(output.contains("// Description: Ask for user name"));
+        assert!(output.contains("import \"@johnlindquist/kit\";"));
+        assert!(output.contains("await arg(\"Name?\");"));
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_keeps_existing_metadata_and_import() {
+        let script = r#"// Name: Existing
+// Description: Existing description
+import "@johnlindquist/kit";
+
+await div("ready");
+"#;
+        let output = enforce_script_kit_conventions(script, "ignored", "ignored");
+
+        assert_eq!(
+            output.matches("// Name:").count(),
+            1,
+            "should not duplicate existing Name metadata"
+        );
+        assert_eq!(
+            output.matches("// Description:").count(),
+            1,
+            "should not duplicate existing Description metadata"
+        );
+        assert_eq!(
+            output.matches("import \"@johnlindquist/kit\";").count(),
+            1,
+            "should not duplicate existing import"
+        );
+    }
+
+    #[test]
+    fn test_write_generated_script_in_dir_appends_numeric_suffix_for_collisions() {
+        let temp_dir = tempdir().unwrap();
+        let first = write_generated_script_in_dir(temp_dir.path(), "my-script", "a").unwrap();
+        let second = write_generated_script_in_dir(temp_dir.path(), "my-script", "b").unwrap();
+
+        assert_eq!(first.file_name().unwrap(), "my-script.ts");
+        assert_eq!(second.file_name().unwrap(), "my-script-1.ts");
+    }
+}
diff --git a/src/app_execute/builtin_execution.rs b/src/app_execute/builtin_execution.rs
index c2ec833eff5ada1847787967c7b1195720fa43db..beb3a48c404f463d5edf049315cbbb188d07d3a9
--- a/src/app_execute/builtin_execution.rs
+++ b/src/app_execute/builtin_execution.rs
@@ -544,6 +544,30 @@
 
                 use builtins::AiCommandType;
 
+                // Capture prompt text before reset for Shift+Tab/script-generation flows.
+                let script_generation_prompt = if matches!(cmd_type, AiCommandType::GenerateScript)
+                {
+                    Some(self.filter_text.trim().to_string())
+                } else {
+                    None
+                };
+
+                if matches!(cmd_type, AiCommandType::GenerateScript)
+                    && script_generation_prompt
+                        .as_ref()
+                        .is_some_and(|prompt| prompt.is_empty())
+                {
+                    self.toast_manager.push(
+                        components::toast::Toast::warning(
+                            "Type a prompt first, then run Generate Script with AI.",
+                            &self.theme,
+                        )
+                        .duration_ms(Some(3500)),
+                    );
+                    cx.notify();
+                    return;
+                }
+
                 // All AI commands: reset state, hide main window
                 script_kit_gpui::set_main_window_visible(false);
                 self.reset_to_script_list(cx);
@@ -614,6 +638,132 @@
                         }
                     }
 
+                    AiCommandType::GenerateScript => {
+                        let Some(prompt_description) = script_generation_prompt.clone() else {
+                            logging::log(
+                                "AI_SCRIPT_GEN",
+                                "state=failed attempted=capture_prompt failure=missing_prompt",
+                            );
+                            self.toast_manager.push(
+                                components::toast::Toast::error(
+                                    "No prompt available for AI script generation",
+                                    &self.theme,
+                                )
+                                .duration_ms(Some(5000)),
+                            );
+                            cx.notify();
+                            return;
+                        };
+
+                        let config = self.config.clone();
+                        let (tx, rx) = async_channel::bounded::<
+                            std::result::Result<ai::GeneratedScriptOutput, String>,
+                        >(1);
+
+                        logging::log(
+                            "AI_SCRIPT_GEN",
+                            &format!(
+                                "state=queued attempted=builtin_generate_script prompt_len={}",
+                                prompt_description.len()
+                            ),
+                        );
+
+                        std::thread::spawn(move || {
+                            let generation_result =
+                                ai::generate_script_from_prompt(&prompt_description, Some(&config))
+                                    .map_err(|error| error.to_string());
+
+                            if tx.send_blocking(generation_result).is_err() {
+                                logging::log(
+                                    "AI_SCRIPT_GEN",
+                                    "state=aborted attempted=send_result failure=result_channel_closed",
+                                );
+                            }
+                        });
+
+                        cx.spawn(async move |this, cx| {
+                            let Ok(result) = rx.recv().await else {
+                                logging::log(
+                                    "AI_SCRIPT_GEN",
+                                    "state=aborted attempted=recv_result failure=result_channel_closed",
+                                );
+                                return;
+                            };
+
+                            let _ = cx.update(|cx| {
+                                this.update(cx, |app, cx| match result {
+                                    Ok(generated) => {
+                                        let script_name = generated
+                                            .path
+                                            .file_name()
+                                            .and_then(|name| name.to_str())
+                                            .unwrap_or("generated script");
+
+                                        if let Err(error) =
+                                            script_creation::open_in_editor(&generated.path, &app.config)
+                                        {
+                                            logging::log(
+                                                "AI_SCRIPT_GEN",
+                                                &format!(
+                                                    "state=failed attempted=open_editor path={} error={}",
+                                                    generated.path.display(),
+                                                    error
+                                                ),
+                                            );
+                                            app.toast_manager.push(
+                                                components::toast::Toast::error(
+                                                    format!(
+                                                        "Generated {}, but failed to open editor: {}",
+                                                        script_name, error
+                                                    ),
+                                                    &app.theme,
+                                                )
+                                                .duration_ms(Some(7000)),
+                                            );
+                                            cx.notify();
+                                        } else {
+                                            logging::log(
+                                                "AI_SCRIPT_GEN",
+                                                &format!(
+                                                    "state=completed attempted=builtin_generate_script path={} model_id={} provider_id={}",
+                                                    generated.path.display(),
+                                                    generated.model_id,
+                                                    generated.provider_id
+                                                ),
+                                            );
+                                            app.toast_manager.push(
+                                                components::toast::Toast::success(
+                                                    format!("Generated and opened {}", script_name),
+                                                    &app.theme,
+                                                )
+                                                .duration_ms(Some(3500)),
+                                            );
+                                            app.close_and_reset_window(cx);
+                                        }
+                                    }
+                                    Err(error) => {
+                                        logging::log(
+                                            "AI_SCRIPT_GEN",
+                                            &format!(
+                                                "state=failed attempted=builtin_generate_script error={}",
+                                                error
+                                            ),
+                                        );
+                                        app.toast_manager.push(
+                                            components::toast::Toast::error(
+                                                format!("Failed to generate script: {}", error),
+                                                &app.theme,
+                                            )
+                                            .duration_ms(Some(7000)),
+                                        );
+                                        cx.notify();
+                                    }
+                                })
+                            });
+                        })
+                        .detach();
+                    }
+
                     AiCommandType::SendScreenToAi => {
                         // Capture entire screen and send to AI
                         match platform::capture_screen_screenshot() {
diff --git a/src/builtins/part_000.rs b/src/builtins/part_000.rs
index d6b9c2a9b35b40c5005dbb9f65147f528702cb9e..5f6d27d28d72e51126d10d8beccf931c689ef2bb
--- a/src/builtins/part_000.rs
+++ b/src/builtins/part_000.rs
@@ -96,6 +96,8 @@
     OpenAi,
     NewConversation,
     ClearConversation,
+    /// Generate a new Script Kit script from the main prompt text
+    GenerateScript,
     /// Send a screenshot of the entire screen to AI Chat
     SendScreenToAi,
     /// Send a screenshot of the focused window to AI Chat
diff --git a/src/builtins/part_001_entries/entries_002.rs b/src/builtins/part_001_entries/entries_002.rs
index 6d1c9334f0ccaf0aab48582aaf42dcb129e1cb6e..72b318c66aeaf124359f4ecd276dae0350287328
--- a/src/builtins/part_001_entries/entries_002.rs
+++ b/src/builtins/part_001_entries/entries_002.rs
@@ -61,6 +61,17 @@
     ));
 
     entries.push(BuiltInEntry::new_with_icon(
+        "builtin-generate-script-with-ai",
+        "Generate Script with AI",
+        "Generate a Script Kit script from your current prompt text",
+        vec![
+            "generate", "script", "ai", "create", "code", "typescript", "shift", "tab",
+        ],
+        BuiltInFeature::AiCommand(AiCommandType::GenerateScript),
+        "ðŸ§ ",
+    ));
+
+    entries.push(BuiltInEntry::new_with_icon(
         "builtin-send-screen-to-ai",
         "Send Screen to AI Chat",
         "Capture the full screen and send it to AI Chat",
diff --git a/src/builtins/tests/part_000.rs b/src/builtins/tests/part_000.rs
index b3ab2d78ecc147bbdbcfb63b851efbc98de5959a..81a22289bae63689059113341ceb5ac1dd91f2b2
--- a/src/builtins/tests/part_000.rs
+++ b/src/builtins/tests/part_000.rs
@@ -302,6 +302,26 @@
             open_ai.unwrap().feature,
             BuiltInFeature::AiCommand(AiCommandType::OpenAi)
         );
+
+        let generate_script = entries
+            .iter()
+            .find(|e| e.id == "builtin-generate-script-with-ai");
+        assert!(
+            generate_script.is_some(),
+            "builtin-generate-script-with-ai should exist"
+        );
+        let generate_script = generate_script.unwrap();
+        assert_eq!(
+            generate_script.feature,
+            BuiltInFeature::AiCommand(AiCommandType::GenerateScript)
+        );
+        assert!(
+            generate_script
+                .keywords
+                .iter()
+                .any(|keyword| keyword.eq_ignore_ascii_case("shift")),
+            "Generate Script command should be discoverable via Shift+Tab wording"
+        );
     }
     #[test]
     fn test_get_builtin_entries_hides_preview_ai_commands() {


thinking
**Verifying library compilation**
exec
/bin/zsh -lc 'cargo check --lib' in /Users/johnlindquist/dev/script-kit-gpui succeeded in 253ms:
warning: glob import doesn't reexport anything with visibility `pub(in crate::prompts)` because no imported item is public enough
  --> src/prompts/div/mod.rs:32:16
   |
32 | pub(super) use inline::*;
   |                ^^^^^^^^^
   |
note: the most public imported item is `pub(self)`
  --> src/prompts/div/mod.rs:32:16
   |
32 | pub(super) use inline::*;
   |                ^^^^^^^^^
   = help: reduce the glob import's visibility or increase visibility of imported items
   = note: `#[warn(unused_imports)]` (part of `#[warn(unused)]`) on by default

warning: glob import doesn't reexport anything with visibility `pub(in crate::prompts)` because no imported item is public enough
  --> src/prompts/div/mod.rs:34:16
   |
34 | pub(super) use render_html::*;
   |                ^^^^^^^^^^^^^^
   |
file update:
diff --git a/src/ai/mod.rs b/src/ai/mod.rs
index a420b1a5faf59506acdb7caf60681c153a3f9bb6..9a73e9491862633b325b2c52b51a3e20395ff85c
--- a/src/ai/mod.rs
+++ b/src/ai/mod.rs
@@ -37,6 +37,7 @@
 pub(crate) mod providers;
 pub(crate) mod sdk_handlers;
 pub(crate) mod session;
+pub(crate) mod script_generation;
 pub(crate) mod storage;
 pub(crate) mod window;
 
@@ -44,6 +45,7 @@
 pub use self::config::{DetectedKeys, ModelInfo, ProviderConfig};
 pub use self::model::{Chat, ChatId, ChatSource, Message, MessageRole};
 pub use self::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+pub use self::script_generation::{generate_script_from_prompt, GeneratedScriptOutput};
 pub use self::sdk_handlers::try_handle_ai_message;
 pub use self::storage::{
     clear_all_chats, create_chat, delete_chat, get_all_chats, get_chat, get_chat_messages,
diff --git a/src/ai/script_generation.rs b/src/ai/script_generation.rs
new file mode 100644
index 0000000000000000000000000000000000000000..7f2ec8e7576ed50cd10f7aea31a6522875ef667a
--- /dev/null
+++ b/src/ai/script_generation.rs
@@ -0,0 +1,417 @@
+use anyhow::{Context, Result};
+use std::fs::{self, OpenOptions};
+use std::io::{ErrorKind, Write};
+use std::path::{Path, PathBuf};
+use std::sync::Arc;
+
+use super::config::ModelInfo;
+use super::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+
+const AI_SCRIPT_OUTPUT_DIR: &str = "~/.kenv/scripts";
+const AI_SCRIPT_DEFAULT_SLUG: &str = "ai-script";
+const AI_SCRIPT_MAX_SLUG_LEN: usize = 64;
+
+const AI_SCRIPT_GENERATION_SYSTEM_PROMPT: &str = r#"You write production-ready Script Kit scripts.
+
+Return ONLY TypeScript source code for one Script Kit script. Do not include explanations.
+
+Required output conventions:
+1) Include metadata comments at the top:
+   // Name: <clear title>
+   // Description: <one-line summary>
+2) Include: import "@johnlindquist/kit";
+3) Use await arg() for user input when useful.
+4) Use await div() for display output when useful.
+5) Keep the script runnable as-is with sensible defaults and light error handling."#;
+
+#[derive(Debug, Clone)]
+pub struct GeneratedScriptOutput {
+    pub path: PathBuf,
+    pub slug: String,
+    pub model_id: String,
+    pub provider_id: String,
+}
+
+pub fn generate_script_from_prompt(
+    prompt: &str,
+    config: Option<&crate::config::Config>,
+) -> Result<GeneratedScriptOutput> {
+    let normalized_prompt = prompt.trim();
+    if normalized_prompt.is_empty() {
+        anyhow::bail!("AI script generation requires a non-empty prompt");
+    }
+
+    let registry = ProviderRegistry::from_environment_with_config(config);
+    if !registry.has_any_provider() {
+        anyhow::bail!(
+            "No AI providers configured. Configure an API key first (Vercel, OpenAI, Anthropic, etc.)."
+        );
+    }
+
+    let (selected_model, provider) = select_generation_model(&registry)?;
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=provider_ready model_id={} provider_id={} prompt_len={}",
+            selected_model.id,
+            selected_model.provider,
+            normalized_prompt.len()
+        ),
+    );
+
+    let messages = vec![
+        ProviderMessage::system(AI_SCRIPT_GENERATION_SYSTEM_PROMPT),
+        ProviderMessage::user(format!(
+            "Generate a Script Kit script for this user request:\n\n{}",
+            normalized_prompt
+        )),
+    ];
+
+    let raw_response = provider
+        .send_message(&messages, &selected_model.id)
+        .with_context(|| {
+            format!(
+                "AI script generation failed (attempted=send_message, model_id={}, provider_id={})",
+                selected_model.id, selected_model.provider
+            )
+        })?;
+
+    let extracted = extract_script_code(&raw_response);
+    if extracted.trim().is_empty() {
+        anyhow::bail!(
+            "AI returned an empty response for script generation (state=empty_response)"
+        );
+    }
+
+    let slug = slugify_script_name(normalized_prompt);
+    let finalized = enforce_script_kit_conventions(&extracted, normalized_prompt, &slug);
+    let path = write_generated_script(&slug, &finalized).with_context(|| {
+        format!(
+            "Failed writing AI-generated script (state=write_failed, slug={})",
+            slug
+        )
+    })?;
+
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=script_written path={} slug={}",
+            path.display(),
+            slug
+        ),
+    );
+
+    Ok(GeneratedScriptOutput {
+        path,
+        slug,
+        model_id: selected_model.id,
+        provider_id: selected_model.provider,
+    })
+}
+
+fn select_generation_model(registry: &ProviderRegistry) -> Result<(ModelInfo, Arc<dyn AiProvider>)> {
+    let models = registry.get_all_models();
+    let selected_model = models
+        .iter()
+        .find(|model| model.provider.eq_ignore_ascii_case("vercel"))
+        .or_else(|| models.first())
+        .cloned()
+        .context("No AI models available in provider registry")?;
+
+    let provider = registry
+        .find_provider_for_model(&selected_model.id)
+        .cloned()
+        .with_context(|| {
+            format!(
+                "No provider found for selected model '{}' (state=provider_missing)",
+                selected_model.id
+            )
+        })?;
+
+    Ok((selected_model, provider))
+}
+
+fn generated_scripts_dir() -> PathBuf {
+    PathBuf::from(shellexpand::tilde(AI_SCRIPT_OUTPUT_DIR).as_ref())
+}
+
+fn split_fence_header_and_body(fence: &str) -> (&str, &str) {
+    match fence.find('\n') {
+        Some(newline_index) => (&fence[..newline_index], &fence[newline_index + 1..]),
+        None => ("", fence),
+    }
+}
+
+fn extract_fenced_code(response: &str, preferred_languages: Option<&[&str]>) -> Option<String> {
+    let mut remaining = response;
+
+    while let Some(start) = remaining.find("```") {
+        let after_start = &remaining[start + 3..];
+        let Some(end) = after_start.find("```") else {
+            break;
+        };
+
+        let fence_contents = &after_start[..end];
+        let (header, body) = split_fence_header_and_body(fence_contents);
+        let language = header
+            .trim()
+            .split(|c: char| c.is_whitespace() || c == '{')
+            .next()
+            .unwrap_or("")
+            .to_ascii_lowercase();
+        let code = body.trim();
+
+        if !code.is_empty() {
+            match preferred_languages {
+                Some(preferred) => {
+                    if preferred.iter().any(|candidate| *candidate == language) {
+                        return Some(code.to_string());
+                    }
+                }
+                None => return Some(code.to_string()),
+            }
+        }
+
+        remaining = &after_start[end + 3..];
+    }
+
+    None
+}
+
+fn extract_script_code(response: &str) -> String {
+    const PREFERRED_LANGUAGES: [&str; 6] = ["typescript", "ts", "javascript", "js", "tsx", "jsx"];
+
+    extract_fenced_code(response, Some(&PREFERRED_LANGUAGES))
+        .or_else(|| extract_fenced_code(response, None))
+        .unwrap_or_else(|| response.trim().to_string())
+}
+
+fn slugify_script_name(prompt: &str) -> String {
+    let mut slug = String::new();
+    let mut last_was_hyphen = false;
+
+    for character in prompt.to_ascii_lowercase().chars() {
+        if character.is_ascii_alphanumeric() {
+            slug.push(character);
+            last_was_hyphen = false;
+        } else if matches!(character, ' ' | '_' | '-') {
+            if !slug.is_empty() && !last_was_hyphen {
+                slug.push('-');
+                last_was_hyphen = true;
+            }
+        }
+    }
+
+    while slug.ends_with('-') {
+        slug.pop();
+    }
+
+    if slug.len() > AI_SCRIPT_MAX_SLUG_LEN {
+        slug.truncate(AI_SCRIPT_MAX_SLUG_LEN);
+        while slug.ends_with('-') {
+            slug.pop();
+        }
+    }
+
+    if slug.is_empty() {
+        AI_SCRIPT_DEFAULT_SLUG.to_string()
+    } else {
+        slug
+    }
+}
+
+fn slug_to_title(slug: &str) -> String {
+    slug.split('-')
+        .filter(|segment| !segment.is_empty())
+        .map(|segment| {
+            let mut chars = segment.chars();
+            match chars.next() {
+                Some(first) => first.to_uppercase().collect::<String>() + chars.as_str(),
+                None => String::new(),
+            }
+        })
+        .collect::<Vec<_>>()
+        .join(" ")
+}
+
+fn description_from_prompt(prompt: &str) -> String {
+    let normalized = prompt.split_whitespace().collect::<Vec<_>>().join(" ");
+    if normalized.is_empty() {
+        return "AI-generated Script Kit script".to_string();
+    }
+
+    let mut shortened = normalized;
+    if shortened.chars().count() > 110 {
+        shortened = format!("{}...", shortened.chars().take(107).collect::<String>());
+    }
+    shortened
+}
+
+fn has_kit_import(script: &str) -> bool {
+    script.contains("import \"@johnlindquist/kit\";")
+        || script.contains("import '@johnlindquist/kit';")
+        || script.contains("import \"@scriptkit/sdk\";")
+        || script.contains("import '@scriptkit/sdk';")
+}
+
+fn enforce_script_kit_conventions(script: &str, prompt: &str, slug: &str) -> String {
+    let mut prefix_lines: Vec<String> = Vec::new();
+    let trimmed_script = script.trim();
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Name:"))
+    {
+        prefix_lines.push(format!("// Name: {}", slug_to_title(slug)));
+    }
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Description:"))
+    {
+        prefix_lines.push(format!("// Description: {}", description_from_prompt(prompt)));
+    }
+
+    if !has_kit_import(trimmed_script) {
+        prefix_lines.push("import \"@johnlindquist/kit\";".to_string());
+    }
+
+    let mut output = String::new();
+    if !prefix_lines.is_empty() {
+        output.push_str(&prefix_lines.join("\n"));
+        output.push_str("\n\n");
+    }
+
+    output.push_str(trimmed_script);
+    if !output.ends_with('\n') {
+        output.push('\n');
+    }
+    output
+}
+
+fn write_generated_script(slug: &str, script_content: &str) -> Result<PathBuf> {
+    write_generated_script_in_dir(&generated_scripts_dir(), slug, script_content)
+}
+
+fn write_generated_script_in_dir(output_dir: &Path, slug: &str, script_content: &str) -> Result<PathBuf> {
+    fs::create_dir_all(output_dir)
+        .with_context(|| format!("Failed to create output dir: {}", output_dir.display()))?;
+
+    for suffix in 0usize.. {
+        let candidate = if suffix == 0 {
+            slug.to_string()
+        } else {
+            format!("{slug}-{suffix}")
+        };
+        let path = output_dir.join(format!("{}.ts", candidate));
+        match OpenOptions::new().write(true).create_new(true).open(&path) {
+            Ok(mut file) => {
+                file.write_all(script_content.as_bytes())
+                    .with_context(|| format!("Failed writing generated script to {}", path.display()))?;
+                return Ok(path);
+            }
+            Err(error) if error.kind() == ErrorKind::AlreadyExists => continue,
+            Err(error) => {
+                return Err(error).with_context(|| {
+                    format!(
+                        "Failed creating generated script file {} (slug={})",
+                        path.display(),
+                        slug
+                    )
+                });
+            }
+        }
+    }
+
+    unreachable!("suffix loop should eventually create a unique script filename")
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+    use tempfile::tempdir;
+
+    #[test]
+    fn test_slugify_script_name_handles_spaces_and_symbols() {
+        assert_eq!(slugify_script_name("Build: API Client!"), "build-api-client");
+        assert_eq!(slugify_script_name("  ___  "), "ai-script");
+    }
+
+    #[test]
+    fn test_extract_script_code_prefers_typescript_fence_when_multiple_blocks_exist() {
+        let response = r#"
+Here's one idea:
+```markdown
+Not code
+```
+```typescript
+await div("hello");
+```
+"#;
+        assert_eq!(extract_script_code(response), "await div(\"hello\");");
+    }
+
+    #[test]
+    fn test_extract_script_code_falls_back_to_first_fenced_block() {
+        let response = r#"
+```python
+print("hello")
+```
+"#;
+        assert_eq!(extract_script_code(response), "print(\"hello\")");
+    }
+
+    #[test]
+    fn test_extract_script_code_returns_trimmed_response_when_no_fence_exists() {
+        let response = "const answer = 42;";
+        assert_eq!(extract_script_code(response), "const answer = 42;");
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_adds_missing_metadata_and_import() {
+        let script = "const name = await arg(\"Name?\");";
+        let output = enforce_script_kit_conventions(script, "Ask for user name", "ask-user-name");
+
+        assert!(output.contains("// Name: Ask User Name"));
+        assert!(output.contains("// Description: Ask for user name"));
+        assert!(output.contains("import \"@johnlindquist/kit\";"));
+        assert!(output.contains("await arg(\"Name?\");"));
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_keeps_existing_metadata_and_import() {
+        let script = r#"// Name: Existing
+// Description: Existing description
+import "@johnlindquist/kit";
+
+await div("ready");
+"#;
+        let output = enforce_script_kit_conventions(script, "ignored", "ignored");
+
+        assert_eq!(
+            output.matches("// Name:").count(),
+            1,
+            "should not duplicate existing Name metadata"
+        );
+        assert_eq!(
+            output.matches("// Description:").count(),
+            1,
+            "should not duplicate existing Description metadata"
+        );
+        assert_eq!(
+            output.matches("import \"@johnlindquist/kit\";").count(),
+            1,
+            "should not duplicate existing import"
+        );
+    }
+
+    #[test]
+    fn test_write_generated_script_in_dir_appends_numeric_suffix_for_collisions() {
+        let temp_dir = tempdir().unwrap();
+        let first = write_generated_script_in_dir(temp_dir.path(), "my-script", "a").unwrap();
+        let second = write_generated_script_in_dir(temp_dir.path(), "my-script", "b").unwrap();
+
+        assert_eq!(first.file_name().unwrap(), "my-script.ts");
+        assert_eq!(second.file_name().unwrap(), "my-script-1.ts");
+    }
+}
diff --git a/src/app_execute/builtin_execution.rs b/src/app_execute/builtin_execution.rs
index c2ec833eff5ada1847787967c7b1195720fa43db..beb3a48c404f463d5edf049315cbbb188d07d3a9
--- a/src/app_execute/builtin_execution.rs
+++ b/src/app_execute/builtin_execution.rs
@@ -544,6 +544,30 @@
 
                 use builtins::AiCommandType;
 
+                // Capture prompt text before reset for Shift+Tab/script-generation flows.
+                let script_generation_prompt = if matches!(cmd_type, AiCommandType::GenerateScript)
+                {
+                    Some(self.filter_text.trim().to_string())
+                } else {
+                    None
+                };
+
+                if matches!(cmd_type, AiCommandType::GenerateScript)
+                    && script_generation_prompt
+                        .as_ref()
+                        .is_some_and(|prompt| prompt.is_empty())
+                {
+                    self.toast_manager.push(
+                        components::toast::Toast::warning(
+                            "Type a prompt first, then run Generate Script with AI.",
+                            &self.theme,
+                        )
+                        .duration_ms(Some(3500)),
+                    );
+                    cx.notify();
+                    return;
+                }
+
                 // All AI commands: reset state, hide main window
                 script_kit_gpui::set_main_window_visible(false);
                 self.reset_to_script_list(cx);
@@ -614,6 +638,132 @@
                         }
                     }
 
+                    AiCommandType::GenerateScript => {
+                        let Some(prompt_description) = script_generation_prompt.clone() else {
+                            logging::log(
+                                "AI_SCRIPT_GEN",
+                                "state=failed attempted=capture_prompt failure=missing_prompt",
+                            );
+                            self.toast_manager.push(
+                                components::toast::Toast::error(
+                                    "No prompt available for AI script generation",
+                                    &self.theme,
+                                )
+                                .duration_ms(Some(5000)),
+                            );
+                            cx.notify();
+                            return;
+                        };
+
+                        let config = self.config.clone();
+                        let (tx, rx) = async_channel::bounded::<
+                            std::result::Result<ai::GeneratedScriptOutput, String>,
+                        >(1);
+
+                        logging::log(
+                            "AI_SCRIPT_GEN",
+                            &format!(
+                                "state=queued attempted=builtin_generate_script prompt_len={}",
+                                prompt_description.len()
+                            ),
+                        );
+
+                        std::thread::spawn(move || {
+                            let generation_result =
+                                ai::generate_script_from_prompt(&prompt_description, Some(&config))
+                                    .map_err(|error| error.to_string());
+
+                            if tx.send_blocking(generation_result).is_err() {
+                                logging::log(
+                                    "AI_SCRIPT_GEN",
+                                    "state=aborted attempted=send_result failure=result_channel_closed",
+                                );
+                            }
+                        });
+
+                        cx.spawn(async move |this, cx| {
+                            let Ok(result) = rx.recv().await else {
+                                logging::log(
+                                    "AI_SCRIPT_GEN",
+                                    "state=aborted attempted=recv_result failure=result_channel_closed",
+                                );
+                                return;
+                            };
+
+                            let _ = cx.update(|cx| {
+                                this.update(cx, |app, cx| match result {
+                                    Ok(generated) => {
+                                        let script_name = generated
+                                            .path
+                                            .file_name()
+                                            .and_then(|name| name.to_str())
+                                            .unwrap_or("generated script");
+
+                                        if let Err(error) =
+                                            script_creation::open_in_editor(&generated.path, &app.config)
+                                        {
+                                            logging::log(
+                                                "AI_SCRIPT_GEN",
+                                                &format!(
+                                                    "state=failed attempted=open_editor path={} error={}",
+                                                    generated.path.display(),
+                                                    error
+                                                ),
+                                            );
+                                            app.toast_manager.push(
+                                                components::toast::Toast::error(
+                                                    format!(
+                                                        "Generated {}, but failed to open editor: {}",
+                                                        script_name, error
+                                                    ),
+                                                    &app.theme,
+                                                )
+                                                .duration_ms(Some(7000)),
+                                            );
+                                            cx.notify();
+                                        } else {
+                                            logging::log(
+                                                "AI_SCRIPT_GEN",
+                                                &format!(
+                                                    "state=completed attempted=builtin_generate_script path={} model_id={} provider_id={}",
+                                                    generated.path.display(),
+                                                    generated.model_id,
+                                                    generated.provider_id
+                                                ),
+                                            );
+                                            app.toast_manager.push(
+                                                components::toast::Toast::success(
+                                                    format!("Generated and opened {}", script_name),
+                                                    &app.theme,
+                                                )
+                                                .duration_ms(Some(3500)),
+                                            );
+                                            app.close_and_reset_window(cx);
+                                        }
+                                    }
+                                    Err(error) => {
+                                        logging::log(
+                                            "AI_SCRIPT_GEN",
+                                            &format!(
+                                                "state=failed attempted=builtin_generate_script error={}",
+                                                error
+                                            ),
+                                        );
+                                        app.toast_manager.push(
+                                            components::toast::Toast::error(
+                                                format!("Failed to generate script: {}", error),
+                                                &app.theme,
+                                            )
+                                            .duration_ms(Some(7000)),
+                                        );
+                                        cx.notify();
+                                    }
+                                })
+                            });
+                        })
+                        .detach();
+                    }
+
                     AiCommandType::SendScreenToAi => {
                         // Capture entire screen and send to AI
                         match platform::capture_screen_screenshot() {
diff --git a/src/builtins/part_000.rs b/src/builtins/part_000.rs
index d6b9c2a9b35b40c5005dbb9f65147f528702cb9e..5f6d27d28d72e51126d10d8beccf931c689ef2bb
--- a/src/builtins/part_000.rs
+++ b/src/builtins/part_000.rs
@@ -96,6 +96,8 @@
     OpenAi,
     NewConversation,
     ClearConversation,
+    /// Generate a new Script Kit script from the main prompt text
+    GenerateScript,
     /// Send a screenshot of the entire screen to AI Chat
     SendScreenToAi,
     /// Send a screenshot of the focused window to AI Chat
diff --git a/src/builtins/part_001_entries/entries_002.rs b/src/builtins/part_001_entries/entries_002.rs
index 6d1c9334f0ccaf0aab48582aaf42dcb129e1cb6e..72b318c66aeaf124359f4ecd276dae0350287328
--- a/src/builtins/part_001_entries/entries_002.rs
+++ b/src/builtins/part_001_entries/entries_002.rs
@@ -61,6 +61,17 @@
     ));
 
     entries.push(BuiltInEntry::new_with_icon(
+        "builtin-generate-script-with-ai",
+        "Generate Script with AI",
+        "Generate a Script Kit script from your current prompt text",
+        vec![
+            "generate", "script", "ai", "create", "code", "typescript", "shift", "tab",
+        ],
+        BuiltInFeature::AiCommand(AiCommandType::GenerateScript),
+        "ðŸ§ ",
+    ));
+
+    entries.push(BuiltInEntry::new_with_icon(
         "builtin-send-screen-to-ai",
         "Send Screen to AI Chat",
         "Capture the full screen and send it to AI Chat",
diff --git a/src/builtins/tests/part_000.rs b/src/builtins/tests/part_000.rs
index b3ab2d78ecc147bbdbcfb63b851efbc98de5959a..81a22289bae63689059113341ceb5ac1dd91f2b2
--- a/src/builtins/tests/part_000.rs
+++ b/src/builtins/tests/part_000.rs
@@ -302,6 +302,26 @@
             open_ai.unwrap().feature,
             BuiltInFeature::AiCommand(AiCommandType::OpenAi)
         );
+
+        let generate_script = entries
+            .iter()
+            .find(|e| e.id == "builtin-generate-script-with-ai");
+        assert!(
+            generate_script.is_some(),
+            "builtin-generate-script-with-ai should exist"
+        );
+        let generate_script = generate_script.unwrap();
+        assert_eq!(
+            generate_script.feature,
+            BuiltInFeature::AiCommand(AiCommandType::GenerateScript)
+        );
+        assert!(
+            generate_script
+                .keywords
+                .iter()
+                .any(|keyword| keyword.eq_ignore_ascii_case("shift")),
+            "Generate Script command should be discoverable via Shift+Tab wording"
+        );
     }
     #[test]
     fn test_get_builtin_entries_hides_preview_ai_commands() {


thinking
**Exploring targeted test and check limitations**
codex
`cargo check --lib` and `cargo check --bin script-kit-gpui` both pass with this change set. Iâ€™m now reviewing the exact diff for the touched files, then Iâ€™ll finalize with validation notes (including the unrelated test-harness failures that blocked targeted `cargo test`).

thinking
**Checking file diffs and formatting**
exec
/bin/zsh -lc 'git diff -- src/ai/mod.rs src/ai/script_generation.rs src/builtins/part_000.rs src/builtins/part_001_entries/entries_002.rs src/builtins/tests/part_000.rs src/app_execute/builtin_execution.rs' in /Users/johnlindquist/dev/script-kit-gpuiexec
/bin/zsh -lc 'git status --short src/ai/mod.rs src/ai/script_generation.rs src/builtins/part_000.rs src/builtins/part_001_entries/entries_002.rs src/builtins/tests/part_000.rs src/app_execute/builtin_execution.rs' in /Users/johnlindquist/dev/script-kit-gpui succeeded in 51ms:
 M src/ai/mod.rs
 M src/app_execute/builtin_execution.rs
 M src/builtins/part_000.rs
 M src/builtins/part_001_entries/entries_002.rs
 M src/builtins/tests/part_000.rs
?? src/ai/script_generation.rs
 succeeded in 51ms:
diff --git a/src/ai/mod.rs b/src/ai/mod.rs
index a420b1a..9a73e94 100644
--- a/src/ai/mod.rs
+++ b/src/ai/mod.rs
@@ -37,6 +37,7 @@ pub(crate) mod model;
 pub(crate) mod providers;
 pub(crate) mod sdk_handlers;
 pub(crate) mod session;
+pub(crate) mod script_generation;
 pub(crate) mod storage;
 pub(crate) mod window;
 
@@ -44,6 +45,7 @@ pub(crate) mod window;
 pub use self::config::{DetectedKeys, ModelInfo, ProviderConfig};
 pub use self::model::{Chat, ChatId, ChatSource, Message, MessageRole};
 pub use self::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+pub use self::script_generation::{generate_script_from_prompt, GeneratedScriptOutput};
 pub use self::sdk_handlers::try_handle_ai_message;
 pub use self::storage::{
     clear_all_chats, create_chat, delete_chat, get_all_chats, get_chat, get_chat_messages,
file update:
diff --git a/src/ai/mod.rs b/src/ai/mod.rs
index a420b1a5faf59506acdb7caf60681c153a3f9bb6..9a73e9491862633b325b2c52b51a3e20395ff85c
--- a/src/ai/mod.rs
+++ b/src/ai/mod.rs
@@ -37,6 +37,7 @@
 pub(crate) mod providers;
 pub(crate) mod sdk_handlers;
 pub(crate) mod session;
+pub(crate) mod script_generation;
 pub(crate) mod storage;
 pub(crate) mod window;
 
@@ -44,6 +45,7 @@
 pub use self::config::{DetectedKeys, ModelInfo, ProviderConfig};
 pub use self::model::{Chat, ChatId, ChatSource, Message, MessageRole};
 pub use self::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+pub use self::script_generation::{generate_script_from_prompt, GeneratedScriptOutput};
 pub use self::sdk_handlers::try_handle_ai_message;
 pub use self::storage::{
     clear_all_chats, create_chat, delete_chat, get_all_chats, get_chat, get_chat_messages,
diff --git a/src/ai/script_generation.rs b/src/ai/script_generation.rs
new file mode 100644
index 0000000000000000000000000000000000000000..7f2ec8e7576ed50cd10f7aea31a6522875ef667a
--- /dev/null
+++ b/src/ai/script_generation.rs
@@ -0,0 +1,417 @@
+use anyhow::{Context, Result};
+use std::fs::{self, OpenOptions};
+use std::io::{ErrorKind, Write};
+use std::path::{Path, PathBuf};
+use std::sync::Arc;
+
+use super::config::ModelInfo;
+use super::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+
+const AI_SCRIPT_OUTPUT_DIR: &str = "~/.kenv/scripts";
+const AI_SCRIPT_DEFAULT_SLUG: &str = "ai-script";
+const AI_SCRIPT_MAX_SLUG_LEN: usize = 64;
+
+const AI_SCRIPT_GENERATION_SYSTEM_PROMPT: &str = r#"You write production-ready Script Kit scripts.
+
+Return ONLY TypeScript source code for one Script Kit script. Do not include explanations.
+
+Required output conventions:
+1) Include metadata comments at the top:
+   // Name: <clear title>
+   // Description: <one-line summary>
+2) Include: import "@johnlindquist/kit";
+3) Use await arg() for user input when useful.
+4) Use await div() for display output when useful.
+5) Keep the script runnable as-is with sensible defaults and light error handling."#;
+
+#[derive(Debug, Clone)]
+pub struct GeneratedScriptOutput {
+    pub path: PathBuf,
+    pub slug: String,
+    pub model_id: String,
+    pub provider_id: String,
+}
+
+pub fn generate_script_from_prompt(
+    prompt: &str,
+    config: Option<&crate::config::Config>,
+) -> Result<GeneratedScriptOutput> {
+    let normalized_prompt = prompt.trim();
+    if normalized_prompt.is_empty() {
+        anyhow::bail!("AI script generation requires a non-empty prompt");
+    }
+
+    let registry = ProviderRegistry::from_environment_with_config(config);
+    if !registry.has_any_provider() {
+        anyhow::bail!(
+            "No AI providers configured. Configure an API key first (Vercel, OpenAI, Anthropic, etc.)."
+        );
+    }
+
+    let (selected_model, provider) = select_generation_model(&registry)?;
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=provider_ready model_id={} provider_id={} prompt_len={}",
+            selected_model.id,
+            selected_model.provider,
+            normalized_prompt.len()
+        ),
+    );
+
+    let messages = vec![
+        ProviderMessage::system(AI_SCRIPT_GENERATION_SYSTEM_PROMPT),
+        ProviderMessage::user(format!(
+            "Generate a Script Kit script for this user request:\n\n{}",
+            normalized_prompt
+        )),
+    ];
+
+    let raw_response = provider
+        .send_message(&messages, &selected_model.id)
+        .with_context(|| {
+            format!(
+                "AI script generation failed (attempted=send_message, model_id={}, provider_id={})",
+                selected_model.id, selected_model.provider
+            )
+        })?;
+
+    let extracted = extract_script_code(&raw_response);
+    if extracted.trim().is_empty() {
+        anyhow::bail!(
+            "AI returned an empty response for script generation (state=empty_response)"
+        );
+    }
+
+    let slug = slugify_script_name(normalized_prompt);
+    let finalized = enforce_script_kit_conventions(&extracted, normalized_prompt, &slug);
+    let path = write_generated_script(&slug, &finalized).with_context(|| {
+        format!(
+            "Failed writing AI-generated script (state=write_failed, slug={})",
+            slug
+        )
+    })?;
+
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=script_written path={} slug={}",
+            path.display(),
+            slug
+        ),
+    );
+
+    Ok(GeneratedScriptOutput {
+        path,
+        slug,
+        model_id: selected_model.id,
+        provider_id: selected_model.provider,
+    })
+}
+
+fn select_generation_model(registry: &ProviderRegistry) -> Result<(ModelInfo, Arc<dyn AiProvider>)> {
+    let models = registry.get_all_models();
+    let selected_model = models
+        .iter()
+        .find(|model| model.provider.eq_ignore_ascii_case("vercel"))
+        .or_else(|| models.first())
+        .cloned()
+        .context("No AI models available in provider registry")?;
+
+    let provider = registry
+        .find_provider_for_model(&selected_model.id)
+        .cloned()
+        .with_context(|| {
+            format!(
+                "No provider found for selected model '{}' (state=provider_missing)",
+                selected_model.id
+            )
+        })?;
+
+    Ok((selected_model, provider))
+}
+
+fn generated_scripts_dir() -> PathBuf {
+    PathBuf::from(shellexpand::tilde(AI_SCRIPT_OUTPUT_DIR).as_ref())
+}
+
+fn split_fence_header_and_body(fence: &str) -> (&str, &str) {
+    match fence.find('\n') {
+        Some(newline_index) => (&fence[..newline_index], &fence[newline_index + 1..]),
+        None => ("", fence),
+    }
+}
+
+fn extract_fenced_code(response: &str, preferred_languages: Option<&[&str]>) -> Option<String> {
+    let mut remaining = response;
+
+    while let Some(start) = remaining.find("```") {
+        let after_start = &remaining[start + 3..];
+        let Some(end) = after_start.find("```") else {
+            break;
+        };
+
+        let fence_contents = &after_start[..end];
+        let (header, body) = split_fence_header_and_body(fence_contents);
+        let language = header
+            .trim()
+            .split(|c: char| c.is_whitespace() || c == '{')
+            .next()
+            .unwrap_or("")
+            .to_ascii_lowercase();
+        let code = body.trim();
+
+        if !code.is_empty() {
+            match preferred_languages {
+                Some(preferred) => {
+                    if preferred.iter().any(|candidate| *candidate == language) {
+                        return Some(code.to_string());
+                    }
+                }
+                None => return Some(code.to_string()),
+            }
+        }
+
+        remaining = &after_start[end + 3..];
+    }
+
+    None
+}
+
+fn extract_script_code(response: &str) -> String {
+    const PREFERRED_LANGUAGES: [&str; 6] = ["typescript", "ts", "javascript", "js", "tsx", "jsx"];
+
+    extract_fenced_code(response, Some(&PREFERRED_LANGUAGES))
+        .or_else(|| extract_fenced_code(response, None))
+        .unwrap_or_else(|| response.trim().to_string())
+}
+
+fn slugify_script_name(prompt: &str) -> String {
+    let mut slug = String::new();
+    let mut last_was_hyphen = false;
+
+    for character in prompt.to_ascii_lowercase().chars() {
+        if character.is_ascii_alphanumeric() {
+            slug.push(character);
+            last_was_hyphen = false;
+        } else if matches!(character, ' ' | '_' | '-') {
+            if !slug.is_empty() && !last_was_hyphen {
+                slug.push('-');
+                last_was_hyphen = true;
+            }
+        }
+    }
+
+    while slug.ends_with('-') {
+        slug.pop();
+    }
+
+    if slug.len() > AI_SCRIPT_MAX_SLUG_LEN {
+        slug.truncate(AI_SCRIPT_MAX_SLUG_LEN);
+        while slug.ends_with('-') {
+            slug.pop();
+        }
+    }
+
+    if slug.is_empty() {
+        AI_SCRIPT_DEFAULT_SLUG.to_string()
+    } else {
+        slug
+    }
+}
+
+fn slug_to_title(slug: &str) -> String {
+    slug.split('-')
+        .filter(|segment| !segment.is_empty())
+        .map(|segment| {
+            let mut chars = segment.chars();
+            match chars.next() {
+                Some(first) => first.to_uppercase().collect::<String>() + chars.as_str(),
+                None => String::new(),
+            }
+        })
+        .collect::<Vec<_>>()
+        .join(" ")
+}
+
+fn description_from_prompt(prompt: &str) -> String {
+    let normalized = prompt.split_whitespace().collect::<Vec<_>>().join(" ");
+    if normalized.is_empty() {
+        return "AI-generated Script Kit script".to_string();
+    }
+
+    let mut shortened = normalized;
+    if shortened.chars().count() > 110 {
+        shortened = format!("{}...", shortened.chars().take(107).collect::<String>());
+    }
+    shortened
+}
+
+fn has_kit_import(script: &str) -> bool {
+    script.contains("import \"@johnlindquist/kit\";")
+        || script.contains("import '@johnlindquist/kit';")
+        || script.contains("import \"@scriptkit/sdk\";")
+        || script.contains("import '@scriptkit/sdk';")
+}
+
+fn enforce_script_kit_conventions(script: &str, prompt: &str, slug: &str) -> String {
+    let mut prefix_lines: Vec<String> = Vec::new();
+    let trimmed_script = script.trim();
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Name:"))
+    {
+        prefix_lines.push(format!("// Name: {}", slug_to_title(slug)));
+    }
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Description:"))
+    {
+        prefix_lines.push(format!("// Description: {}", description_from_prompt(prompt)));
+    }
+
+    if !has_kit_import(trimmed_script) {
+        prefix_lines.push("import \"@johnlindquist/kit\";".to_string());
+    }
+
+    let mut output = String::new();
+    if !prefix_lines.is_empty() {
+        output.push_str(&prefix_lines.join("\n"));
+        output.push_str("\n\n");
+    }
+
+    output.push_str(trimmed_script);
+    if !output.ends_with('\n') {
+        output.push('\n');
+    }
+    output
+}
+
+fn write_generated_script(slug: &str, script_content: &str) -> Result<PathBuf> {
+    write_generated_script_in_dir(&generated_scripts_dir(), slug, script_content)
+}
+
+fn write_generated_script_in_dir(output_dir: &Path, slug: &str, script_content: &str) -> Result<PathBuf> {
+    fs::create_dir_all(output_dir)
+        .with_context(|| format!("Failed to create output dir: {}", output_dir.display()))?;
+
+    for suffix in 0usize.. {
+        let candidate = if suffix == 0 {
+            slug.to_string()
+        } else {
+            format!("{slug}-{suffix}")
+        };
+        let path = output_dir.join(format!("{}.ts", candidate));
+        match OpenOptions::new().write(true).create_new(true).open(&path) {
+            Ok(mut file) => {
+                file.write_all(script_content.as_bytes())
+                    .with_context(|| format!("Failed writing generated script to {}", path.display()))?;
+                return Ok(path);
+            }
+            Err(error) if error.kind() == ErrorKind::AlreadyExists => continue,
+            Err(error) => {
+                return Err(error).with_context(|| {
+                    format!(
+                        "Failed creating generated script file {} (slug={})",
+                        path.display(),
+                        slug
+                    )
+                });
+            }
+        }
+    }
+
+    unreachable!("suffix loop should eventually create a unique script filename")
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+    use tempfile::tempdir;
+
+    #[test]
+    fn test_slugify_script_name_handles_spaces_and_symbols() {
+        assert_eq!(slugify_script_name("Build: API Client!"), "build-api-client");
+        assert_eq!(slugify_script_name("  ___  "), "ai-script");
+    }
+
+    #[test]
+    fn test_extract_script_code_prefers_typescript_fence_when_multiple_blocks_exist() {
+        let response = r#"
+Here's one idea:
+```markdown
+Not code
+```
+```typescript
+await div("hello");
+```
+"#;
+        assert_eq!(extract_script_code(response), "await div(\"hello\");");
+    }
+
+    #[test]
+    fn test_extract_script_code_falls_back_to_first_fenced_block() {
+        let response = r#"
+```python
+print("hello")
+```
+"#;
+        assert_eq!(extract_script_code(response), "print(\"hello\")");
+    }
+
+    #[test]
+    fn test_extract_script_code_returns_trimmed_response_when_no_fence_exists() {
+        let response = "const answer = 42;";
+        assert_eq!(extract_script_code(response), "const answer = 42;");
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_adds_missing_metadata_and_import() {
+        let script = "const name = await arg(\"Name?\");";
+        let output = enforce_script_kit_conventions(script, "Ask for user name", "ask-user-name");
+
+        assert!(output.contains("// Name: Ask User Name"));
+        assert!(output.contains("// Description: Ask for user name"));
+        assert!(output.contains("import \"@johnlindquist/kit\";"));
+        assert!(output.contains("await arg(\"Name?\");"));
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_keeps_existing_metadata_and_import() {
+        let script = r#"// Name: Existing
+// Description: Existing description
+import "@johnlindquist/kit";
+
+await div("ready");
+"#;
+        let output = enforce_script_kit_conventions(script, "ignored", "ignored");
+
+        assert_eq!(
+            output.matches("// Name:").count(),
+            1,
+            "should not duplicate existing Name metadata"
+        );
+        assert_eq!(
+            output.matches("// Description:").count(),
+            1,
+            "should not duplicate existing Description metadata"
+        );
+        assert_eq!(
+            output.matches("import \"@johnlindquist/kit\";").count(),
+            1,
+            "should not duplicate existing import"
+        );
+    }
+
+    #[test]
+    fn test_write_generated_script_in_dir_appends_numeric_suffix_for_collisions() {
+        let temp_dir = tempdir().unwrap();
+        let first = write_generated_script_in_dir(temp_dir.path(), "my-script", "a").unwrap();
+        let second = write_generated_script_in_dir(temp_dir.path(), "my-script", "b").unwrap();
+
+        assert_eq!(first.file_name().unwrap(), "my-script.ts");
+        assert_eq!(second.file_name().unwrap(), "my-script-1.ts");
+    }
+}
diff --git a/src/app_execute/builtin_execution.rs b/src/app_execute/builtin_execution.rs
index c2ec833eff5ada1847787967c7b1195720fa43db..beb3a48c404f463d5edf049315cbbb188d07d3a9
--- a/src/app_execute/builtin_execution.rs
+++ b/src/app_execute/builtin_execution.rs
@@ -544,6 +544,30 @@
 
                 use builtins::AiCommandType;
 
+                // Capture prompt text before reset for Shift+Tab/script-generation flows.
+                let script_generation_prompt = if matches!(cmd_type, AiCommandType::GenerateScript)
+                {
+                    Some(self.filter_text.trim().to_string())
+                } else {
+                    None
+                };
+
+                if matches!(cmd_type, AiCommandType::GenerateScript)
+                    && script_generation_prompt
+                        .as_ref()
+                        .is_some_and(|prompt| prompt.is_empty())
+                {
+                    self.toast_manager.push(
+                        components::toast::Toast::warning(
+                            "Type a prompt first, then run Generate Script with AI.",
+                            &self.theme,
+                        )
+                        .duration_ms(Some(3500)),
+                    );
+                    cx.notify();
+                    return;
+                }
+
                 // All AI commands: reset state, hide main window
                 script_kit_gpui::set_main_window_visible(false);
                 self.reset_to_script_list(cx);
@@ -614,6 +638,132 @@
                         }
                     }
 
+                    AiCommandType::GenerateScript => {
+                        let Some(prompt_description) = script_generation_prompt.clone() else {
+                            logging::log(
+                                "AI_SCRIPT_GEN",
+                                "state=failed attempted=capture_prompt failure=missing_prompt",
+                            );
+                            self.toast_manager.push(
+                                components::toast::Toast::error(
+                                    "No prompt available for AI script generation",
+                                    &self.theme,
+                                )
+                                .duration_ms(Some(5000)),
+                            );
+                            cx.notify();
+                            return;
+                        };
+
+                        let config = self.config.clone();
+                        let (tx, rx) = async_channel::bounded::<
+                            std::result::Result<ai::GeneratedScriptOutput, String>,
+                        >(1);
+
+                        logging::log(
+                            "AI_SCRIPT_GEN",
+                            &format!(
+                                "state=queued attempted=builtin_generate_script prompt_len={}",
+                                prompt_description.len()
+                            ),
+                        );
+
+                        std::thread::spawn(move || {
+                            let generation_result =
+                                ai::generate_script_from_prompt(&prompt_description, Some(&config))
+                                    .map_err(|error| error.to_string());
+
+                            if tx.send_blocking(generation_result).is_err() {
+                                logging::log(
+                                    "AI_SCRIPT_GEN",
+                                    "state=aborted attempted=send_result failure=result_channel_closed",
+                                );
+                            }
+                        });
+
+                        cx.spawn(async move |this, cx| {
+                            let Ok(result) = rx.recv().await else {
+                                logging::log(
+                                    "AI_SCRIPT_GEN",
+                                    "state=aborted attempted=recv_result failure=result_channel_closed",
+                                );
+                                return;
+                            };
+
+                            let _ = cx.update(|cx| {
+                                this.update(cx, |app, cx| match result {
+                                    Ok(generated) => {
+                                        let script_name = generated
+                                            .path
+                                            .file_name()
+                                            .and_then(|name| name.to_str())
+                                            .unwrap_or("generated script");
+
+                                        if let Err(error) =
+                                            script_creation::open_in_editor(&generated.path, &app.config)
+                                        {
+                                            logging::log(
+                                                "AI_SCRIPT_GEN",
+                                                &format!(
+                                                    "state=failed attempted=open_editor path={} error={}",
+                                                    generated.path.display(),
+                                                    error
+                                                ),
+                                            );
+                                            app.toast_manager.push(
+                                                components::toast::Toast::error(
+                                                    format!(
+                                                        "Generated {}, but failed to open editor: {}",
+                                                        script_name, error
+                                                    ),
+                                                    &app.theme,
+                                                )
+                                                .duration_ms(Some(7000)),
+                                            );
+                                            cx.notify();
+                                        } else {
+                                            logging::log(
+                                                "AI_SCRIPT_GEN",
+                                                &format!(
+                                                    "state=completed attempted=builtin_generate_script path={} model_id={} provider_id={}",
+                                                    generated.path.display(),
+                                                    generated.model_id,
+                                                    generated.provider_id
+                                                ),
+                                            );
+                                            app.toast_manager.push(
+                                                components::toast::Toast::success(
+                                                    format!("Generated and opened {}", script_name),
+                                                    &app.theme,
+                                                )
+                                                .duration_ms(Some(3500)),
+                                            );
+                                            app.close_and_reset_window(cx);
+                                        }
+                                    }
+                                    Err(error) => {
+                                        logging::log(
+                                            "AI_SCRIPT_GEN",
+                                            &format!(
+                                                "state=failed attempted=builtin_generate_script error={}",
+                                                error
+                                            ),
+                                        );
+                                        app.toast_manager.push(
+                                            components::toast::Toast::error(
+                                                format!("Failed to generate script: {}", error),
+                                                &app.theme,
+                                            )
+                                            .duration_ms(Some(7000)),
+                                        );
+                                        cx.notify();
+                                    }
+                                })
+                            });
+                        })
+                        .detach();
+                    }
+
                     AiCommandType::SendScreenToAi => {
                         // Capture entire screen and send to AI
                         match platform::capture_screen_screenshot() {
diff --git a/src/builtins/part_000.rs b/src/builtins/part_000.rs
index d6b9c2a9b35b40c5005dbb9f65147f528702cb9e..5f6d27d28d72e51126d10d8beccf931c689ef2bb
--- a/src/builtins/part_000.rs
+++ b/src/builtins/part_000.rs
@@ -96,6 +96,8 @@
     OpenAi,
     NewConversation,
     ClearConversation,
+    /// Generate a new Script Kit script from the main prompt text
+    GenerateScript,
     /// Send a screenshot of the entire screen to AI Chat
     SendScreenToAi,
     /// Send a screenshot of the focused window to AI Chat
diff --git a/src/builtins/part_001_entries/entries_002.rs b/src/builtins/part_001_entries/entries_002.rs
index 6d1c9334f0ccaf0aab48582aaf42dcb129e1cb6e..72b318c66aeaf124359f4ecd276dae0350287328
--- a/src/builtins/part_001_entries/entries_002.rs
+++ b/src/builtins/part_001_entries/entries_002.rs
@@ -61,6 +61,17 @@
     ));
 
     entries.push(BuiltInEntry::new_with_icon(
+        "builtin-generate-script-with-ai",
+        "Generate Script with AI",
+        "Generate a Script Kit script from your current prompt text",
+        vec![
+            "generate", "script", "ai", "create", "code", "typescript", "shift", "tab",
+        ],
+        BuiltInFeature::AiCommand(AiCommandType::GenerateScript),
+        "ðŸ§ ",
+    ));
+
+    entries.push(BuiltInEntry::new_with_icon(
         "builtin-send-screen-to-ai",
         "Send Screen to AI Chat",
         "Capture the full screen and send it to AI Chat",
diff --git a/src/builtins/tests/part_000.rs b/src/builtins/tests/part_000.rs
index b3ab2d78ecc147bbdbcfb63b851efbc98de5959a..81a22289bae63689059113341ceb5ac1dd91f2b2
--- a/src/builtins/tests/part_000.rs
+++ b/src/builtins/tests/part_000.rs
@@ -302,6 +302,26 @@
             open_ai.unwrap().feature,
             BuiltInFeature::AiCommand(AiCommandType::OpenAi)
         );
+
+        let generate_script = entries
+            .iter()
+            .find(|e| e.id == "builtin-generate-script-with-ai");
+        assert!(
+            generate_script.is_some(),
+            "builtin-generate-script-with-ai should exist"
+        );
+        let generate_script = generate_script.unwrap();
+        assert_eq!(
+            generate_script.feature,
+            BuiltInFeature::AiCommand(AiCommandType::GenerateScript)
+        );
+        assert!(
+            generate_script
+                .keywords
+                .iter()
+                .any(|keyword| keyword.eq_ignore_ascii_case("shift")),
+            "Generate Script command should be discoverable via Shift+Tab wording"
+        );
     }
     #[test]
     fn test_get_builtin_entries_hides_preview_ai_commands() {


thinking
**Assessing unexpected kit_store additions**
codex
I spotted unrelated-looking diffs in `builtin_execution`/`builtins` (Kit Store command scaffolding and AI error helper refactors) mixed into this file history. Iâ€™m checking whether those are required dependencies or accidental drift before finalizing.
exec
/bin/zsh -lc "sed -n '1,260p' src/builtins/part_001_entries/entries_003.rs" in /Users/johnlindquist/dev/script-kit-gpui succeeded in 51ms:
{
    // Settings Commands
    // =========================================================================

    // Only show reset if there are custom positions
    if crate::window_state::has_custom_positions() {
        entries.push(BuiltInEntry::new_with_icon(
            "builtin-reset-window-positions",
            "Reset Window Positions",
            "Restore all windows to default positions",
            vec![
                "reset", "window", "position", "default", "restore", "layout", "location",
            ],
            BuiltInFeature::SettingsCommand(SettingsCommandType::ResetWindowPositions),
            "ðŸ”„",
        ));
    }

    // API Key Configuration
    entries.push(BuiltInEntry::new_with_icon(
file update:
diff --git a/src/ai/mod.rs b/src/ai/mod.rs
index a420b1a5faf59506acdb7caf60681c153a3f9bb6..9a73e9491862633b325b2c52b51a3e20395ff85c
--- a/src/ai/mod.rs
+++ b/src/ai/mod.rs
@@ -37,6 +37,7 @@
 pub(crate) mod providers;
 pub(crate) mod sdk_handlers;
 pub(crate) mod session;
+pub(crate) mod script_generation;
 pub(crate) mod storage;
 pub(crate) mod window;
 
@@ -44,6 +45,7 @@
 pub use self::config::{DetectedKeys, ModelInfo, ProviderConfig};
 pub use self::model::{Chat, ChatId, ChatSource, Message, MessageRole};
 pub use self::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+pub use self::script_generation::{generate_script_from_prompt, GeneratedScriptOutput};
 pub use self::sdk_handlers::try_handle_ai_message;
 pub use self::storage::{
     clear_all_chats, create_chat, delete_chat, get_all_chats, get_chat, get_chat_messages,
diff --git a/src/ai/script_generation.rs b/src/ai/script_generation.rs
new file mode 100644
index 0000000000000000000000000000000000000000..7f2ec8e7576ed50cd10f7aea31a6522875ef667a
--- /dev/null
+++ b/src/ai/script_generation.rs
@@ -0,0 +1,417 @@
+use anyhow::{Context, Result};
+use std::fs::{self, OpenOptions};
+use std::io::{ErrorKind, Write};
+use std::path::{Path, PathBuf};
+use std::sync::Arc;
+
+use super::config::ModelInfo;
+use super::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+
+const AI_SCRIPT_OUTPUT_DIR: &str = "~/.kenv/scripts";
+const AI_SCRIPT_DEFAULT_SLUG: &str = "ai-script";
+const AI_SCRIPT_MAX_SLUG_LEN: usize = 64;
+
+const AI_SCRIPT_GENERATION_SYSTEM_PROMPT: &str = r#"You write production-ready Script Kit scripts.
+
+Return ONLY TypeScript source code for one Script Kit script. Do not include explanations.
+
+Required output conventions:
+1) Include metadata comments at the top:
+   // Name: <clear title>
+   // Description: <one-line summary>
+2) Include: import "@johnlindquist/kit";
+3) Use await arg() for user input when useful.
+4) Use await div() for display output when useful.
+5) Keep the script runnable as-is with sensible defaults and light error handling."#;
+
+#[derive(Debug, Clone)]
+pub struct GeneratedScriptOutput {
+    pub path: PathBuf,
+    pub slug: String,
+    pub model_id: String,
+    pub provider_id: String,
+}
+
+pub fn generate_script_from_prompt(
+    prompt: &str,
+    config: Option<&crate::config::Config>,
+) -> Result<GeneratedScriptOutput> {
+    let normalized_prompt = prompt.trim();
+    if normalized_prompt.is_empty() {
+        anyhow::bail!("AI script generation requires a non-empty prompt");
+    }
+
+    let registry = ProviderRegistry::from_environment_with_config(config);
+    if !registry.has_any_provider() {
+        anyhow::bail!(
+            "No AI providers configured. Configure an API key first (Vercel, OpenAI, Anthropic, etc.)."
+        );
+    }
+
+    let (selected_model, provider) = select_generation_model(&registry)?;
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=provider_ready model_id={} provider_id={} prompt_len={}",
+            selected_model.id,
+            selected_model.provider,
+            normalized_prompt.len()
+        ),
+    );
+
+    let messages = vec![
+        ProviderMessage::system(AI_SCRIPT_GENERATION_SYSTEM_PROMPT),
+        ProviderMessage::user(format!(
+            "Generate a Script Kit script for this user request:\n\n{}",
+            normalized_prompt
+        )),
+    ];
+
+    let raw_response = provider
+        .send_message(&messages, &selected_model.id)
+        .with_context(|| {
+            format!(
+                "AI script generation failed (attempted=send_message, model_id={}, provider_id={})",
+                selected_model.id, selected_model.provider
+            )
+        })?;
+
+    let extracted = extract_script_code(&raw_response);
+    if extracted.trim().is_empty() {
+        anyhow::bail!(
+            "AI returned an empty response for script generation (state=empty_response)"
+        );
+    }
+
+    let slug = slugify_script_name(normalized_prompt);
+    let finalized = enforce_script_kit_conventions(&extracted, normalized_prompt, &slug);
+    let path = write_generated_script(&slug, &finalized).with_context(|| {
+        format!(
+            "Failed writing AI-generated script (state=write_failed, slug={})",
+            slug
+        )
+    })?;
+
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=script_written path={} slug={}",
+            path.display(),
+            slug
+        ),
+    );
+
+    Ok(GeneratedScriptOutput {
+        path,
+        slug,
+        model_id: selected_model.id,
+        provider_id: selected_model.provider,
+    })
+}
+
+fn select_generation_model(registry: &ProviderRegistry) -> Result<(ModelInfo, Arc<dyn AiProvider>)> {
+    let models = registry.get_all_models();
+    let selected_model = models
+        .iter()
+        .find(|model| model.provider.eq_ignore_ascii_case("vercel"))
+        .or_else(|| models.first())
+        .cloned()
+        .context("No AI models available in provider registry")?;
+
+    let provider = registry
+        .find_provider_for_model(&selected_model.id)
+        .cloned()
+        .with_context(|| {
+            format!(
+                "No provider found for selected model '{}' (state=provider_missing)",
+                selected_model.id
+            )
+        })?;
+
+    Ok((selected_model, provider))
+}
+
+fn generated_scripts_dir() -> PathBuf {
+    PathBuf::from(shellexpand::tilde(AI_SCRIPT_OUTPUT_DIR).as_ref())
+}
+
+fn split_fence_header_and_body(fence: &str) -> (&str, &str) {
+    match fence.find('\n') {
+        Some(newline_index) => (&fence[..newline_index], &fence[newline_index + 1..]),
+        None => ("", fence),
+    }
+}
+
+fn extract_fenced_code(response: &str, preferred_languages: Option<&[&str]>) -> Option<String> {
+    let mut remaining = response;
+
+    while let Some(start) = remaining.find("```") {
+        let after_start = &remaining[start + 3..];
+        let Some(end) = after_start.find("```") else {
+            break;
+        };
+
+        let fence_contents = &after_start[..end];
+        let (header, body) = split_fence_header_and_body(fence_contents);
+        let language = header
+            .trim()
+            .split(|c: char| c.is_whitespace() || c == '{')
+            .next()
+            .unwrap_or("")
+            .to_ascii_lowercase();
+        let code = body.trim();
+
+        if !code.is_empty() {
+            match preferred_languages {
+                Some(preferred) => {
+                    if preferred.iter().any(|candidate| *candidate == language) {
+                        return Some(code.to_string());
+                    }
+                }
+                None => return Some(code.to_string()),
+            }
+        }
+
+        remaining = &after_start[end + 3..];
+    }
+
+    None
+}
+
+fn extract_script_code(response: &str) -> String {
+    const PREFERRED_LANGUAGES: [&str; 6] = ["typescript", "ts", "javascript", "js", "tsx", "jsx"];
+
+    extract_fenced_code(response, Some(&PREFERRED_LANGUAGES))
+        .or_else(|| extract_fenced_code(response, None))
+        .unwrap_or_else(|| response.trim().to_string())
+}
+
+fn slugify_script_name(prompt: &str) -> String {
+    let mut slug = String::new();
+    let mut last_was_hyphen = false;
+
+    for character in prompt.to_ascii_lowercase().chars() {
+        if character.is_ascii_alphanumeric() {
+            slug.push(character);
+            last_was_hyphen = false;
+        } else if matches!(character, ' ' | '_' | '-') {
+            if !slug.is_empty() && !last_was_hyphen {
+                slug.push('-');
+                last_was_hyphen = true;
+            }
+        }
+    }
+
+    while slug.ends_with('-') {
+        slug.pop();
+    }
+
+    if slug.len() > AI_SCRIPT_MAX_SLUG_LEN {
+        slug.truncate(AI_SCRIPT_MAX_SLUG_LEN);
+        while slug.ends_with('-') {
+            slug.pop();
+        }
+    }
+
+    if slug.is_empty() {
+        AI_SCRIPT_DEFAULT_SLUG.to_string()
+    } else {
+        slug
+    }
+}
+
+fn slug_to_title(slug: &str) -> String {
+    slug.split('-')
+        .filter(|segment| !segment.is_empty())
+        .map(|segment| {
+            let mut chars = segment.chars();
+            match chars.next() {
+                Some(first) => first.to_uppercase().collect::<String>() + chars.as_str(),
+                None => String::new(),
+            }
+        })
+        .collect::<Vec<_>>()
+        .join(" ")
+}
+
+fn description_from_prompt(prompt: &str) -> String {
+    let normalized = prompt.split_whitespace().collect::<Vec<_>>().join(" ");
+    if normalized.is_empty() {
+        return "AI-generated Script Kit script".to_string();
+    }
+
+    let mut shortened = normalized;
+    if shortened.chars().count() > 110 {
+        shortened = format!("{}...", shortened.chars().take(107).collect::<String>());
+    }
+    shortened
+}
+
+fn has_kit_import(script: &str) -> bool {
+    script.contains("import \"@johnlindquist/kit\";")
+        || script.contains("import '@johnlindquist/kit';")
+        || script.contains("import \"@scriptkit/sdk\";")
+        || script.contains("import '@scriptkit/sdk';")
+}
+
+fn enforce_script_kit_conventions(script: &str, prompt: &str, slug: &str) -> String {
+    let mut prefix_lines: Vec<String> = Vec::new();
+    let trimmed_script = script.trim();
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Name:"))
+    {
+        prefix_lines.push(format!("// Name: {}", slug_to_title(slug)));
+    }
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Description:"))
+    {
+        prefix_lines.push(format!("// Description: {}", description_from_prompt(prompt)));
+    }
+
+    if !has_kit_import(trimmed_script) {
+        prefix_lines.push("import \"@johnlindquist/kit\";".to_string());
+    }
+
+    let mut output = String::new();
+    if !prefix_lines.is_empty() {
+        output.push_str(&prefix_lines.join("\n"));
+        output.push_str("\n\n");
+    }
+
+    output.push_str(trimmed_script);
+    if !output.ends_with('\n') {
+        output.push('\n');
+    }
+    output
+}
+
+fn write_generated_script(slug: &str, script_content: &str) -> Result<PathBuf> {
+    write_generated_script_in_dir(&generated_scripts_dir(), slug, script_content)
+}
+
+fn write_generated_script_in_dir(output_dir: &Path, slug: &str, script_content: &str) -> Result<PathBuf> {
+    fs::create_dir_all(output_dir)
+        .with_context(|| format!("Failed to create output dir: {}", output_dir.display()))?;
+
+    for suffix in 0usize.. {
+        let candidate = if suffix == 0 {
+            slug.to_string()
+        } else {
+            format!("{slug}-{suffix}")
+        };
+        let path = output_dir.join(format!("{}.ts", candidate));
+        match OpenOptions::new().write(true).create_new(true).open(&path) {
+            Ok(mut file) => {
+                file.write_all(script_content.as_bytes())
+                    .with_context(|| format!("Failed writing generated script to {}", path.display()))?;
+                return Ok(path);
+            }
+            Err(error) if error.kind() == ErrorKind::AlreadyExists => continue,
+            Err(error) => {
+                return Err(error).with_context(|| {
+                    format!(
+                        "Failed creating generated script file {} (slug={})",
+                        path.display(),
+                        slug
+                    )
+                });
+            }
+        }
+    }
+
+    unreachable!("suffix loop should eventually create a unique script filename")
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+    use tempfile::tempdir;
+
+    #[test]
+    fn test_slugify_script_name_handles_spaces_and_symbols() {
+        assert_eq!(slugify_script_name("Build: API Client!"), "build-api-client");
+        assert_eq!(slugify_script_name("  ___  "), "ai-script");
+    }
+
+    #[test]
+    fn test_extract_script_code_prefers_typescript_fence_when_multiple_blocks_exist() {
+        let response = r#"
+Here's one idea:
+```markdown
+Not code
+```
+```typescript
+await div("hello");
+```
+"#;
+        assert_eq!(extract_script_code(response), "await div(\"hello\");");
+    }
+
+    #[test]
+    fn test_extract_script_code_falls_back_to_first_fenced_block() {
+        let response = r#"
+```python
+print("hello")
+```
+"#;
+        assert_eq!(extract_script_code(response), "print(\"hello\")");
+    }
+
+    #[test]
+    fn test_extract_script_code_returns_trimmed_response_when_no_fence_exists() {
+        let response = "const answer = 42;";
+        assert_eq!(extract_script_code(response), "const answer = 42;");
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_adds_missing_metadata_and_import() {
+        let script = "const name = await arg(\"Name?\");";
+        let output = enforce_script_kit_conventions(script, "Ask for user name", "ask-user-name");
+
+        assert!(output.contains("// Name: Ask User Name"));
+        assert!(output.contains("// Description: Ask for user name"));
+        assert!(output.contains("import \"@johnlindquist/kit\";"));
+        assert!(output.contains("await arg(\"Name?\");"));
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_keeps_existing_metadata_and_import() {
+        let script = r#"// Name: Existing
+// Description: Existing description
+import "@johnlindquist/kit";
+
+await div("ready");
+"#;
+        let output = enforce_script_kit_conventions(script, "ignored", "ignored");
+
+        assert_eq!(
+            output.matches("// Name:").count(),
+            1,
+            "should not duplicate existing Name metadata"
+        );
+        assert_eq!(
+            output.matches("// Description:").count(),
+            1,
+            "should not duplicate existing Description metadata"
+        );
+        assert_eq!(
+            output.matches("import \"@johnlindquist/kit\";").count(),
+            1,
+            "should not duplicate existing import"
+        );
+    }
+
+    #[test]
+    fn test_write_generated_script_in_dir_appends_numeric_suffix_for_collisions() {
+        let temp_dir = tempdir().unwrap();
+        let first = write_generated_script_in_dir(temp_dir.path(), "my-script", "a").unwrap();
+        let second = write_generated_script_in_dir(temp_dir.path(), "my-script", "b").unwrap();
+
+        assert_eq!(first.file_name().unwrap(), "my-script.ts");
+        assert_eq!(second.file_name().unwrap(), "my-script-1.ts");
+    }
+}
diff --git a/src/app_execute/builtin_execution.rs b/src/app_execute/builtin_execution.rs
index c2ec833eff5ada1847787967c7b1195720fa43db..beb3a48c404f463d5edf049315cbbb188d07d3a9
--- a/src/app_execute/builtin_execution.rs
+++ b/src/app_execute/builtin_execution.rs
@@ -544,6 +544,30 @@
 
                 use builtins::AiCommandType;
 
+                // Capture prompt text before reset for Shift+Tab/script-generation flows.
+                let script_generation_prompt = if matches!(cmd_type, AiCommandType::GenerateScript)
+                {
+                    Some(self.filter_text.trim().to_string())
+                } else {
+                    None
+                };
+
+                if matches!(cmd_type, AiCommandType::GenerateScript)
+                    && script_generation_prompt
+                        .as_ref()
+                        .is_some_and(|prompt| prompt.is_empty())
+                {
+                    self.toast_manager.push(
+                        components::toast::Toast::warning(
+                            "Type a prompt first, then run Generate Script with AI.",
+                            &self.theme,
+                        )
+                        .duration_ms(Some(3500)),
+                    );
+                    cx.notify();
+                    return;
+                }
+
                 // All AI commands: reset state, hide main window
                 script_kit_gpui::set_main_window_visible(false);
                 self.reset_to_script_list(cx);
@@ -614,6 +638,132 @@
                         }
                     }
 
+                    AiCommandType::GenerateScript => {
+                        let Some(prompt_description) = script_generation_prompt.clone() else {
+                            logging::log(
+                                "AI_SCRIPT_GEN",
+                                "state=failed attempted=capture_prompt failure=missing_prompt",
+                            );
+                            self.toast_manager.push(
+                                components::toast::Toast::error(
+                                    "No prompt available for AI script generation",
+                                    &self.theme,
+                                )
+                                .duration_ms(Some(5000)),
+                            );
+                            cx.notify();
+                            return;
+                        };
+
+                        let config = self.config.clone();
+                        let (tx, rx) = async_channel::bounded::<
+                            std::result::Result<ai::GeneratedScriptOutput, String>,
+                        >(1);
+
+                        logging::log(
+                            "AI_SCRIPT_GEN",
+                            &format!(
+                                "state=queued attempted=builtin_generate_script prompt_len={}",
+                                prompt_description.len()
+                            ),
+                        );
+
+                        std::thread::spawn(move || {
+                            let generation_result =
+                                ai::generate_script_from_prompt(&prompt_description, Some(&config))
+                                    .map_err(|error| error.to_string());
+
+                            if tx.send_blocking(generation_result).is_err() {
+                                logging::log(
+                                    "AI_SCRIPT_GEN",
+                                    "state=aborted attempted=send_result failure=result_channel_closed",
+                                );
+                            }
+                        });
+
+                        cx.spawn(async move |this, cx| {
+                            let Ok(result) = rx.recv().await else {
+                                logging::log(
+                                    "AI_SCRIPT_GEN",
+                                    "state=aborted attempted=recv_result failure=result_channel_closed",
+                                );
+                                return;
+                            };
+
+                            let _ = cx.update(|cx| {
+                                this.update(cx, |app, cx| match result {
+                                    Ok(generated) => {
+                                        let script_name = generated
+                                            .path
+                                            .file_name()
+                                            .and_then(|name| name.to_str())
+                                            .unwrap_or("generated script");
+
+                                        if let Err(error) =
+                                            script_creation::open_in_editor(&generated.path, &app.config)
+                                        {
+                                            logging::log(
+                                                "AI_SCRIPT_GEN",
+                                                &format!(
+                                                    "state=failed attempted=open_editor path={} error={}",
+                                                    generated.path.display(),
+                                                    error
+                                                ),
+                                            );
+                                            app.toast_manager.push(
+                                                components::toast::Toast::error(
+                                                    format!(
+                                                        "Generated {}, but failed to open editor: {}",
+                                                        script_name, error
+                                                    ),
+                                                    &app.theme,
+                                                )
+                                                .duration_ms(Some(7000)),
+                                            );
+                                            cx.notify();
+                                        } else {
+                                            logging::log(
+                                                "AI_SCRIPT_GEN",
+                                                &format!(
+                                                    "state=completed attempted=builtin_generate_script path={} model_id={} provider_id={}",
+                                                    generated.path.display(),
+                                                    generated.model_id,
+                                                    generated.provider_id
+                                                ),
+                                            );
+                                            app.toast_manager.push(
+                                                components::toast::Toast::success(
+                                                    format!("Generated and opened {}", script_name),
+                                                    &app.theme,
+                                                )
+                                                .duration_ms(Some(3500)),
+                                            );
+                                            app.close_and_reset_window(cx);
+                                        }
+                                    }
+                                    Err(error) => {
+                                        logging::log(
+                                            "AI_SCRIPT_GEN",
+                                            &format!(
+                                                "state=failed attempted=builtin_generate_script error={}",
+                                                error
+                                            ),
+                                        );
+                                        app.toast_manager.push(
+                                            components::toast::Toast::error(
+                                                format!("Failed to generate script: {}", error),
+                                                &app.theme,
+                                            )
+                                            .duration_ms(Some(7000)),
+                                        );
+                                        cx.notify();
+                                    }
+                                })
+                            });
+                        })
+                        .detach();
+                    }
+
                     AiCommandType::SendScreenToAi => {
                         // Capture entire screen and send to AI
                         match platform::capture_screen_screenshot() {
diff --git a/src/builtins/part_000.rs b/src/builtins/part_000.rs
index d6b9c2a9b35b40c5005dbb9f65147f528702cb9e..5f6d27d28d72e51126d10d8beccf931c689ef2bb
--- a/src/builtins/part_000.rs
+++ b/src/builtins/part_000.rs
@@ -96,6 +96,8 @@
     OpenAi,
     NewConversation,
     ClearConversation,
+    /// Generate a new Script Kit script from the main prompt text
+    GenerateScript,
     /// Send a screenshot of the entire screen to AI Chat
     SendScreenToAi,
     /// Send a screenshot of the focused window to AI Chat
diff --git a/src/builtins/part_001_entries/entries_002.rs b/src/builtins/part_001_entries/entries_002.rs
index 6d1c9334f0ccaf0aab48582aaf42dcb129e1cb6e..72b318c66aeaf124359f4ecd276dae0350287328
--- a/src/builtins/part_001_entries/entries_002.rs
+++ b/src/builtins/part_001_entries/entries_002.rs
@@ -61,6 +61,17 @@
     ));
 
     entries.push(BuiltInEntry::new_with_icon(
+        "builtin-generate-script-with-ai",
+        "Generate Script with AI",
+        "Generate a Script Kit script from your current prompt text",
+        vec![
+            "generate", "script", "ai", "create", "code", "typescript", "shift", "tab",
+        ],
+        BuiltInFeature::AiCommand(AiCommandType::GenerateScript),
+        "ðŸ§ ",
+    ));
+
+    entries.push(BuiltInEntry::new_with_icon(
         "builtin-send-screen-to-ai",
         "Send Screen to AI Chat",
         "Capture the full screen and send it to AI Chat",
diff --git a/src/builtins/tests/part_000.rs b/src/builtins/tests/part_000.rs
index b3ab2d78ecc147bbdbcfb63b851efbc98de5959a..81a22289bae63689059113341ceb5ac1dd91f2b2
--- a/src/builtins/tests/part_000.rs
+++ b/src/builtins/tests/part_000.rs
@@ -302,6 +302,26 @@
             open_ai.unwrap().feature,
             BuiltInFeature::AiCommand(AiCommandType::OpenAi)
         );
+
+        let generate_script = entries
+            .iter()
+            .find(|e| e.id == "builtin-generate-script-with-ai");
+        assert!(
+            generate_script.is_some(),
+            "builtin-generate-script-with-ai should exist"
+        );
+        let generate_script = generate_script.unwrap();
+        assert_eq!(
+            generate_script.feature,
+            BuiltInFeature::AiCommand(AiCommandType::GenerateScript)
+        );
+        assert!(
+            generate_script
+                .keywords
+                .iter()
+                .any(|keyword| keyword.eq_ignore_ascii_case("shift")),
+            "Generate Script command should be discoverable via Shift+Tab wording"
+        );
     }
     #[test]
     fn test_get_builtin_entries_hides_preview_ai_commands() {


thinking
**Assessing codebase changes and coverage**
exec
/bin/zsh -lc '~/.claude/bin/swarm.ts status' in /Users/johnlindquist/dev/script-kit-gpui succeeded in 52ms:
Repo: /Users/johnlindquist/dev/script-kit-gpui
Updated: 2026-02-08T02:57:17.917Z

Active agents (2):
codex-script-gen-builtin [in_progress] codex/gpt-5.3-codex/exec
  task: In Script Kit GPUI, there needs to be a built-in feature or action for AI script generation triggered by Shift+Tab. Looâ€¦
  scope: src/builtins/**,src/app_execute/**,src/ai/**,src/kit_store/**
  claims(6): src/builtins/part_001_entries/entries_002.rs, src/builtins/part_000.rs, src/builtins/tests/part_000.rs, src/app_execute/builtin_execution.rs, src/ai/script_genâ€¦
  notes: Claimed builtin/app_execute/ai files; implementing AI script generation command + tests

codex-wire-favorites [in_progress] codex/gpt-5.3-codex/exec
  task: Wire up the existing src/favorites/mod.rs storage module into the app as a working feature. The module already has loadâ€¦
  scope: src/favorites/**,src/builtins/part_000.rs,src/builtins/part_001_entries/**,src/app_execute/builtin_execution.rs,src/actâ€¦
  claims: (none)
  notes: Inspecting favorites wiring points and planning minimal scoped edits

Inactive agents (254):
- codex-accessibility [done] done. exit=0. final=.ai/logs/codex-accessibility.final.md. See final message file.
- codex-action-labels [failed] failed. exit=1. final=.ai/logs/codex-action-labels.final.md.
- codex-actions-audit [failed] failed. exit=1. final=.ai/logs/codex-actions-audit.final.md. See final message file.
file update:
diff --git a/src/ai/mod.rs b/src/ai/mod.rs
index a420b1a5faf59506acdb7caf60681c153a3f9bb6..9a73e9491862633b325b2c52b51a3e20395ff85c
--- a/src/ai/mod.rs
+++ b/src/ai/mod.rs
@@ -37,6 +37,7 @@
 pub(crate) mod providers;
 pub(crate) mod sdk_handlers;
 pub(crate) mod session;
+pub(crate) mod script_generation;
 pub(crate) mod storage;
 pub(crate) mod window;
 
@@ -44,6 +45,7 @@
 pub use self::config::{DetectedKeys, ModelInfo, ProviderConfig};
 pub use self::model::{Chat, ChatId, ChatSource, Message, MessageRole};
 pub use self::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+pub use self::script_generation::{generate_script_from_prompt, GeneratedScriptOutput};
 pub use self::sdk_handlers::try_handle_ai_message;
 pub use self::storage::{
     clear_all_chats, create_chat, delete_chat, get_all_chats, get_chat, get_chat_messages,
diff --git a/src/ai/script_generation.rs b/src/ai/script_generation.rs
new file mode 100644
index 0000000000000000000000000000000000000000..7f2ec8e7576ed50cd10f7aea31a6522875ef667a
--- /dev/null
+++ b/src/ai/script_generation.rs
@@ -0,0 +1,417 @@
+use anyhow::{Context, Result};
+use std::fs::{self, OpenOptions};
+use std::io::{ErrorKind, Write};
+use std::path::{Path, PathBuf};
+use std::sync::Arc;
+
+use super::config::ModelInfo;
+use super::providers::{AiProvider, ProviderMessage, ProviderRegistry};
+
+const AI_SCRIPT_OUTPUT_DIR: &str = "~/.kenv/scripts";
+const AI_SCRIPT_DEFAULT_SLUG: &str = "ai-script";
+const AI_SCRIPT_MAX_SLUG_LEN: usize = 64;
+
+const AI_SCRIPT_GENERATION_SYSTEM_PROMPT: &str = r#"You write production-ready Script Kit scripts.
+
+Return ONLY TypeScript source code for one Script Kit script. Do not include explanations.
+
+Required output conventions:
+1) Include metadata comments at the top:
+   // Name: <clear title>
+   // Description: <one-line summary>
+2) Include: import "@johnlindquist/kit";
+3) Use await arg() for user input when useful.
+4) Use await div() for display output when useful.
+5) Keep the script runnable as-is with sensible defaults and light error handling."#;
+
+#[derive(Debug, Clone)]
+pub struct GeneratedScriptOutput {
+    pub path: PathBuf,
+    pub slug: String,
+    pub model_id: String,
+    pub provider_id: String,
+}
+
+pub fn generate_script_from_prompt(
+    prompt: &str,
+    config: Option<&crate::config::Config>,
+) -> Result<GeneratedScriptOutput> {
+    let normalized_prompt = prompt.trim();
+    if normalized_prompt.is_empty() {
+        anyhow::bail!("AI script generation requires a non-empty prompt");
+    }
+
+    let registry = ProviderRegistry::from_environment_with_config(config);
+    if !registry.has_any_provider() {
+        anyhow::bail!(
+            "No AI providers configured. Configure an API key first (Vercel, OpenAI, Anthropic, etc.)."
+        );
+    }
+
+    let (selected_model, provider) = select_generation_model(&registry)?;
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=provider_ready model_id={} provider_id={} prompt_len={}",
+            selected_model.id,
+            selected_model.provider,
+            normalized_prompt.len()
+        ),
+    );
+
+    let messages = vec![
+        ProviderMessage::system(AI_SCRIPT_GENERATION_SYSTEM_PROMPT),
+        ProviderMessage::user(format!(
+            "Generate a Script Kit script for this user request:\n\n{}",
+            normalized_prompt
+        )),
+    ];
+
+    let raw_response = provider
+        .send_message(&messages, &selected_model.id)
+        .with_context(|| {
+            format!(
+                "AI script generation failed (attempted=send_message, model_id={}, provider_id={})",
+                selected_model.id, selected_model.provider
+            )
+        })?;
+
+    let extracted = extract_script_code(&raw_response);
+    if extracted.trim().is_empty() {
+        anyhow::bail!(
+            "AI returned an empty response for script generation (state=empty_response)"
+        );
+    }
+
+    let slug = slugify_script_name(normalized_prompt);
+    let finalized = enforce_script_kit_conventions(&extracted, normalized_prompt, &slug);
+    let path = write_generated_script(&slug, &finalized).with_context(|| {
+        format!(
+            "Failed writing AI-generated script (state=write_failed, slug={})",
+            slug
+        )
+    })?;
+
+    crate::logging::log(
+        "AI",
+        &format!(
+            "correlation_id=ai-script-generation state=script_written path={} slug={}",
+            path.display(),
+            slug
+        ),
+    );
+
+    Ok(GeneratedScriptOutput {
+        path,
+        slug,
+        model_id: selected_model.id,
+        provider_id: selected_model.provider,
+    })
+}
+
+fn select_generation_model(registry: &ProviderRegistry) -> Result<(ModelInfo, Arc<dyn AiProvider>)> {
+    let models = registry.get_all_models();
+    let selected_model = models
+        .iter()
+        .find(|model| model.provider.eq_ignore_ascii_case("vercel"))
+        .or_else(|| models.first())
+        .cloned()
+        .context("No AI models available in provider registry")?;
+
+    let provider = registry
+        .find_provider_for_model(&selected_model.id)
+        .cloned()
+        .with_context(|| {
+            format!(
+                "No provider found for selected model '{}' (state=provider_missing)",
+                selected_model.id
+            )
+        })?;
+
+    Ok((selected_model, provider))
+}
+
+fn generated_scripts_dir() -> PathBuf {
+    PathBuf::from(shellexpand::tilde(AI_SCRIPT_OUTPUT_DIR).as_ref())
+}
+
+fn split_fence_header_and_body(fence: &str) -> (&str, &str) {
+    match fence.find('\n') {
+        Some(newline_index) => (&fence[..newline_index], &fence[newline_index + 1..]),
+        None => ("", fence),
+    }
+}
+
+fn extract_fenced_code(response: &str, preferred_languages: Option<&[&str]>) -> Option<String> {
+    let mut remaining = response;
+
+    while let Some(start) = remaining.find("```") {
+        let after_start = &remaining[start + 3..];
+        let Some(end) = after_start.find("```") else {
+            break;
+        };
+
+        let fence_contents = &after_start[..end];
+        let (header, body) = split_fence_header_and_body(fence_contents);
+        let language = header
+            .trim()
+            .split(|c: char| c.is_whitespace() || c == '{')
+            .next()
+            .unwrap_or("")
+            .to_ascii_lowercase();
+        let code = body.trim();
+
+        if !code.is_empty() {
+            match preferred_languages {
+                Some(preferred) => {
+                    if preferred.iter().any(|candidate| *candidate == language) {
+                        return Some(code.to_string());
+                    }
+                }
+                None => return Some(code.to_string()),
+            }
+        }
+
+        remaining = &after_start[end + 3..];
+    }
+
+    None
+}
+
+fn extract_script_code(response: &str) -> String {
+    const PREFERRED_LANGUAGES: [&str; 6] = ["typescript", "ts", "javascript", "js", "tsx", "jsx"];
+
+    extract_fenced_code(response, Some(&PREFERRED_LANGUAGES))
+        .or_else(|| extract_fenced_code(response, None))
+        .unwrap_or_else(|| response.trim().to_string())
+}
+
+fn slugify_script_name(prompt: &str) -> String {
+    let mut slug = String::new();
+    let mut last_was_hyphen = false;
+
+    for character in prompt.to_ascii_lowercase().chars() {
+        if character.is_ascii_alphanumeric() {
+            slug.push(character);
+            last_was_hyphen = false;
+        } else if matches!(character, ' ' | '_' | '-') {
+            if !slug.is_empty() && !last_was_hyphen {
+                slug.push('-');
+                last_was_hyphen = true;
+            }
+        }
+    }
+
+    while slug.ends_with('-') {
+        slug.pop();
+    }
+
+    if slug.len() > AI_SCRIPT_MAX_SLUG_LEN {
+        slug.truncate(AI_SCRIPT_MAX_SLUG_LEN);
+        while slug.ends_with('-') {
+            slug.pop();
+        }
+    }
+
+    if slug.is_empty() {
+        AI_SCRIPT_DEFAULT_SLUG.to_string()
+    } else {
+        slug
+    }
+}
+
+fn slug_to_title(slug: &str) -> String {
+    slug.split('-')
+        .filter(|segment| !segment.is_empty())
+        .map(|segment| {
+            let mut chars = segment.chars();
+            match chars.next() {
+                Some(first) => first.to_uppercase().collect::<String>() + chars.as_str(),
+                None => String::new(),
+            }
+        })
+        .collect::<Vec<_>>()
+        .join(" ")
+}
+
+fn description_from_prompt(prompt: &str) -> String {
+    let normalized = prompt.split_whitespace().collect::<Vec<_>>().join(" ");
+    if normalized.is_empty() {
+        return "AI-generated Script Kit script".to_string();
+    }
+
+    let mut shortened = normalized;
+    if shortened.chars().count() > 110 {
+        shortened = format!("{}...", shortened.chars().take(107).collect::<String>());
+    }
+    shortened
+}
+
+fn has_kit_import(script: &str) -> bool {
+    script.contains("import \"@johnlindquist/kit\";")
+        || script.contains("import '@johnlindquist/kit';")
+        || script.contains("import \"@scriptkit/sdk\";")
+        || script.contains("import '@scriptkit/sdk';")
+}
+
+fn enforce_script_kit_conventions(script: &str, prompt: &str, slug: &str) -> String {
+    let mut prefix_lines: Vec<String> = Vec::new();
+    let trimmed_script = script.trim();
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Name:"))
+    {
+        prefix_lines.push(format!("// Name: {}", slug_to_title(slug)));
+    }
+
+    if !trimmed_script
+        .lines()
+        .any(|line| line.trim_start().starts_with("// Description:"))
+    {
+        prefix_lines.push(format!("// Description: {}", description_from_prompt(prompt)));
+    }
+
+    if !has_kit_import(trimmed_script) {
+        prefix_lines.push("import \"@johnlindquist/kit\";".to_string());
+    }
+
+    let mut output = String::new();
+    if !prefix_lines.is_empty() {
+        output.push_str(&prefix_lines.join("\n"));
+        output.push_str("\n\n");
+    }
+
+    output.push_str(trimmed_script);
+    if !output.ends_with('\n') {
+        output.push('\n');
+    }
+    output
+}
+
+fn write_generated_script(slug: &str, script_content: &str) -> Result<PathBuf> {
+    write_generated_script_in_dir(&generated_scripts_dir(), slug, script_content)
+}
+
+fn write_generated_script_in_dir(output_dir: &Path, slug: &str, script_content: &str) -> Result<PathBuf> {
+    fs::create_dir_all(output_dir)
+        .with_context(|| format!("Failed to create output dir: {}", output_dir.display()))?;
+
+    for suffix in 0usize.. {
+        let candidate = if suffix == 0 {
+            slug.to_string()
+        } else {
+            format!("{slug}-{suffix}")
+        };
+        let path = output_dir.join(format!("{}.ts", candidate));
+        match OpenOptions::new().write(true).create_new(true).open(&path) {
+            Ok(mut file) => {
+                file.write_all(script_content.as_bytes())
+                    .with_context(|| format!("Failed writing generated script to {}", path.display()))?;
+                return Ok(path);
+            }
+            Err(error) if error.kind() == ErrorKind::AlreadyExists => continue,
+            Err(error) => {
+                return Err(error).with_context(|| {
+                    format!(
+                        "Failed creating generated script file {} (slug={})",
+                        path.display(),
+                        slug
+                    )
+                });
+            }
+        }
+    }
+
+    unreachable!("suffix loop should eventually create a unique script filename")
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+    use tempfile::tempdir;
+
+    #[test]
+    fn test_slugify_script_name_handles_spaces_and_symbols() {
+        assert_eq!(slugify_script_name("Build: API Client!"), "build-api-client");
+        assert_eq!(slugify_script_name("  ___  "), "ai-script");
+    }
+
+    #[test]
+    fn test_extract_script_code_prefers_typescript_fence_when_multiple_blocks_exist() {
+        let response = r#"
+Here's one idea:
+```markdown
+Not code
+```
+```typescript
+await div("hello");
+```
+"#;
+        assert_eq!(extract_script_code(response), "await div(\"hello\");");
+    }
+
+    #[test]
+    fn test_extract_script_code_falls_back_to_first_fenced_block() {
+        let response = r#"
+```python
+print("hello")
+```
+"#;
+        assert_eq!(extract_script_code(response), "print(\"hello\")");
+    }
+
+    #[test]
+    fn test_extract_script_code_returns_trimmed_response_when_no_fence_exists() {
+        let response = "const answer = 42;";
+        assert_eq!(extract_script_code(response), "const answer = 42;");
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_adds_missing_metadata_and_import() {
+        let script = "const name = await arg(\"Name?\");";
+        let output = enforce_script_kit_conventions(script, "Ask for user name", "ask-user-name");
+
+        assert!(output.contains("// Name: Ask User Name"));
+        assert!(output.contains("// Description: Ask for user name"));
+        assert!(output.contains("import \"@johnlindquist/kit\";"));
+        assert!(output.contains("await arg(\"Name?\");"));
+    }
+
+    #[test]
+    fn test_enforce_script_kit_conventions_keeps_existing_metadata_and_import() {
+        let script = r#"// Name: Existing
+// Description: Existing description
+import "@johnlindquist/kit";
+
+await div("ready");
+"#;
+        let output = enforce_script_kit_conventions(script, "ignored", "ignored");
+
+        assert_eq!(
+            output.matches("// Name:").count(),
+            1,
+            "should not duplicate existing Name metadata"
+        );
+        assert_eq!(
+            output.matches("// Description:").count(),
+            1,
+            "should not duplicate existing Description metadata"
+        );
+        assert_eq!(
+            output.matches("import \"@johnlindquist/kit\";").count(),
+            1,
+            "should not duplicate existing import"
+        );
+    }
+
+    #[test]
+    fn test_write_generated_script_in_dir_appends_numeric_suffix_for_collisions() {
+        let temp_dir = tempdir().unwrap();
+        let first = write_generated_script_in_dir(temp_dir.path(), "my-script", "a").unwrap();
+        let second = write_generated_script_in_dir(temp_dir.path(), "my-script", "b").unwrap();
+
+        assert_eq!(first.file_name().unwrap(), "my-script.ts");
+        assert_eq!(second.file_name().unwrap(), "my-script-1.ts");
+    }
+}
diff --git a/src/app_execute/builtin_execution.rs b/src/app_execute/builtin_execution.rs
index c2ec833eff5ada1847787967c7b1195720fa43db..beb3a48c404f463d5edf049315cbbb188d07d3a9
--- a/src/app_execute/builtin_execution.rs
+++ b/src/app_execute/builtin_execution.rs
@@ -544,6 +544,30 @@
 
                 use builtins::AiCommandType;
 
+                // Capture prompt text before reset for Shift+Tab/script-generation flows.
+                let script_generation_prompt = if matches!(cmd_type, AiCommandType::GenerateScript)
+                {
+                    Some(self.filter_text.trim().to_string())
+                } else {
+                    None
+                };
+
+                if matches!(cmd_type, AiCommandType::GenerateScript)
+                    && script_generation_prompt
+                        .as_ref()
+                        .is_some_and(|prompt| prompt.is_empty())
+                {
+                    self.toast_manager.push(
+                        components::toast::Toast::warning(
+                            "Type a prompt first, then run Generate Script with AI.",
+                            &self.theme,
+                        )
+                        .duration_ms(Some(3500)),
+                    );
+                    cx.notify();
+                    return;
+                }
+
                 // All AI commands: reset state, hide main window
                 script_kit_gpui::set_main_window_visible(false);
                 self.reset_to_script_list(cx);
@@ -614,6 +638,132 @@
                         }
                     }
 
+                    AiCommandType::GenerateScript => {
+                        let Some(prompt_description) = script_generation_prompt.clone() else {
+                            logging::log(
+                                "AI_SCRIPT_GEN",
+                                "state=failed attempted=capture_prompt failure=missing_prompt",
+                            );
+                            self.toast_manager.push(
+                                components::toast::Toast::error(
+                                    "No prompt available for AI script generation",
+                                    &self.theme,
+                                )
+                                .duration_ms(Some(5000)),
+                            );
+                            cx.notify();
+                            return;
+                        };
+
+                        let config = self.config.clone();
+                        let (tx, rx) = async_channel::bounded::<
+                            std::result::Result<ai::GeneratedScriptOutput, String>,
+                        >(1);
+
+                        logging::log(
+                            "AI_SCRIPT_GEN",
+                            &format!(
+                                "state=queued attempted=builtin_generate_script prompt_len={}",
+                                prompt_description.len()
+                            ),
+                        );
+
+                        std::thread::spawn(move || {
+                            let generation_result =
+                                ai::generate_script_from_prompt(&prompt_description, Some(&config))
+                                    .map_err(|error| error.to_string());
+
+                            if tx.send_blocking(generation_result).is_err() {
+                                logging::log(
+                                    "AI_SCRIPT_GEN",
+                                    "state=aborted attempted=send_result failure=result_channel_closed",
+                                );
+                            }
+                        });
+
+                        cx.spawn(async move |this, cx| {
+                            let Ok(result) = rx.recv().await else {
+                                logging::log(
+                                    "AI_SCRIPT_GEN",
+                                    "state=aborted attempted=recv_result failure=result_channel_closed",
+                                );
+                                return;
+                            };
+
+                            let _ = cx.update(|cx| {
+                                this.update(cx, |app, cx| match result {
+                                    Ok(generated) => {
+                                        let script_name = generated
+                                            .path
+                                            .file_name()
+                                            .and_then(|name| name.to_str())
+                                            .unwrap_or("generated script");
+
+                                        if let Err(error) =
+                                            script_creation::open_in_editor(&generated.path, &app.config)
+                                        {
+                                            logging::log(
+                                                "AI_SCRIPT_GEN",
+                                                &format!(
+                                                    "state=failed attempted=open_editor path={} error={}",
+                                                    generated.path.display(),
+                                                    error
+                                                ),
+                                            );
+                                            app.toast_manager.push(
+                                                components::toast::Toast::error(
+                                                    format!(
+                                                        "Generated {}, but failed to open editor: {}",
+                                                        script_name, error
+                                                    ),
+                                                    &app.theme,
+                                                )
+                                                .duration_ms(Some(7000)),
+                                            );
+                                            cx.notify();
+                                        } else {
+                                            logging::log(
+                                                "AI_SCRIPT_GEN",
+                                                &format!(
+                                                    "state=completed attempted=builtin_generate_script path={} model_id={} provider_id={}",
+                                                    generated.path.display(),
+                                                    generated.model_id,
+                                                    generated.provider_id
+                                                ),
+                                            );
+                                            app.toast_manager.push(
+                                                components::toast::Toast::success(
+                                                    format!("Generated and opened {}", script_name),
+                                                    &app.theme,
+                                                )
+                                                .duration_ms(Some(3500)),
+                                            );
+                                            app.close_and_reset_window(cx);
+                                        }
+                                    }
+                                    Err(error) => {
+                                        logging::log(
+                                            "AI_SCRIPT_GEN",
+                                            &format!(
+                                                "state=failed attempted=builtin_generate_script error={}",
+                                                error
+                                            ),
+                                        );
+                                        app.toast_manager.push(
+                                            components::toast::Toast::error(
+                                                format!("Failed to generate script: {}", error),
+                                                &app.theme,
+                                            )
+                                            .duration_ms(Some(7000)),
+                                        );
+                                        cx.notify();
+                                    }
+                                })
+                            });
+                        })
+                        .detach();
+                    }
+
                     AiCommandType::SendScreenToAi => {
                         // Capture entire screen and send to AI
                         match platform::capture_screen_screenshot() {
diff --git a/src/builtins/part_000.rs b/src/builtins/part_000.rs
index d6b9c2a9b35b40c5005dbb9f65147f528702cb9e..5f6d27d28d72e51126d10d8beccf931c689ef2bb
--- a/src/builtins/part_000.rs
+++ b/src/builtins/part_000.rs
@@ -96,6 +96,8 @@
     OpenAi,
     NewConversation,
     ClearConversation,
+    /// Generate a new Script Kit script from the main prompt text
+    GenerateScript,
     /// Send a screenshot of the entire screen to AI Chat
     SendScreenToAi,
     /// Send a screenshot of the focused window to AI Chat
diff --git a/src/builtins/part_001_entries/entries_002.rs b/src/builtins/part_001_entries/entries_002.rs
index 6d1c9334f0ccaf0aab48582aaf42dcb129e1cb6e..72b318c66aeaf124359f4ecd276dae0350287328
--- a/src/builtins/part_001_entries/entries_002.rs
+++ b/src/builtins/part_001_entries/entries_002.rs
@@ -61,6 +61,17 @@
     ));
 
     entries.push(BuiltInEntry::new_with_icon(
+        "builtin-generate-script-with-ai",
+        "Generate Script with AI",
+        "Generate a Script Kit script from your current prompt text",
+        vec![
+            "generate", "script", "ai", "create", "code", "typescript", "shift", "tab",
+        ],
+        BuiltInFeature::AiCommand(AiCommandType::GenerateScript),
+        "ðŸ§ ",
+    ));
+
+    entries.push(BuiltInEntry::new_with_icon(
         "builtin-send-screen-to-ai",
         "Send Screen to AI Chat",
         "Capture the full screen and send it to AI Chat",
diff --git a/src/builtins/tests/part_000.rs b/src/builtins/tests/part_000.rs
index b3ab2d78ecc147bbdbcfb63b851efbc98de5959a..81a22289bae63689059113341ceb5ac1dd91f2b2
--- a/src/builtins/tests/part_000.rs
+++ b/src/builtins/tests/part_000.rs
@@ -302,6 +302,26 @@
             open_ai.unwrap().feature,
             BuiltInFeature::AiCommand(AiCommandType::OpenAi)
         );
+
+        let generate_script = entries
+            .iter()
+            .find(|e| e.id == "builtin-generate-script-with-ai");
+        assert!(
+            generate_script.is_some(),
+            "builtin-generate-script-with-ai should exist"
+        );
+        let generate_script = generate_script.unwrap();
+        assert_eq!(
+            generate_script.feature,
+            BuiltInFeature::AiCommand(AiCommandType::GenerateScript)
+        );
+        assert!(
+            generate_script
+                .keywords
+                .iter()
+                .any(|keyword| keyword.eq_ignore_ascii_case("shift")),
+            "Generate Script command should be discoverable via Shift+Tab wording"
+        );
     }
     #[test]
     fn test_get_builtin_entries_hides_preview_ai_commands() {


[swarm-timeout] max runtime 600s reached; sending SIGTERM


==== exit @ 2026-02-08T02:57:23.160Z code=0 status=needs_split ====
