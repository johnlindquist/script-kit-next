I now have the full Oracle analysis. Let me synthesize the findings into the swarm task list format. I have 6 issues but need to consolidate to max 4 tasks, prioritizing by impact.

Here are the swarm tasks:

---

### Task 1: `fix-regex-lazy-lock`

**Scope:** `src/scripts/input_detection/detection.rs`

**Task:**
In `src/scripts/input_detection/detection.rs`, the function `is_code_snippet()` at lines 245-257 constructs two `Regex` objects via `Regex::new()` inside the function body on every single invocation. Every other regex in this same file (lines 20-27) correctly uses `static LazyLock<Regex>` for compile-once semantics. This is both a performance regression (regex compilation is expensive) and an inconsistency with the file's own established pattern.

Add two new `static LazyLock<Regex>` declarations near the existing ones (after `MATH_REGEX`, before `CODE_KEYWORDS`): `CODE_FUNC_CALL_REGEX` with pattern `r"\w+\s*\([^)]*\)"` and `CODE_IDENT_CALL_PREFIX_REGEX` with pattern `r"[a-zA-Z_]\w*\s*\("`. Both should use `.expect("...")` like the existing statics. Then replace the two `Regex::new(...)` calls at lines 245-257 with direct `.is_match(trimmed)` calls on the new statics, removing the `.map(|r| r.is_match(trimmed)).unwrap_or(false)` pattern entirely. The file already imports `LazyLock` from `std::sync` and `Regex` from `regex`.

Existing tests in `src/scripts/input_detection/tests.rs` cover `is_code_snippet` thoroughly — verify with `cargo test`. Also run `cargo check && cargo clippy --all-targets -- -D warnings`. The regex patterns themselves are valid (they work today), so the only change is moving compilation from per-call to static init. Do NOT modify any test files.

---

### Task 2: `rm-dead-search-helpers`

**Scope:** `src/scripts/search/nucleo.rs, src/scripts/search/ascii.rs`

**Task:**
Two files in `src/scripts/search/` contain dead code that should be cleaned up. First, `src/scripts/search/nucleo.rs` lines 4-14 contains a function `nucleo_score()` explicitly marked `/// DEPRECATED: Prefer using NucleoCtx::score()`. It allocates a new `Vec` on every call and is superseded by `NucleoCtx::score()` which reuses a buffer. Delete the entire `nucleo_score` function (lines 4-14 including the doc comment). After deletion, also remove the unused imports `Pattern`, `Matcher`, and `Utf32Str` if they become unused at the top level — but check first since `NucleoCtx` uses them. Second, `src/scripts/search/ascii.rs` has two functions `is_fuzzy_match` (lines 150-161) and `fuzzy_match_with_indices` (lines 165-181) both gated with `#[allow(dead_code)]`. Replace `#[allow(dead_code)]` with `#[cfg(test)]` on both functions so they compile only in test builds. If any non-test code calls them, the build will fail — in that case, remove the `#[cfg(test)]` and leave the functions as-is.

Run `cargo check && cargo clippy --all-targets -- -D warnings && cargo test` to verify. If `nucleo_score` has any remaining callers (in tests or production), the build will error — switch those callers to use `NucleoCtx::new(query).score(haystack)` instead. Do NOT add any new files.

---

### Task 3: `dedup-type-order-unified`

**Scope:** `src/scripts/search/unified.rs`

**Task:**
In `src/scripts/search/unified.rs`, the `type_order` closure that maps `SearchResult` variants to sort-priority integers is copy-pasted identically in two places: inside `fuzzy_search_unified_all` (lines 136-146) and inside `fuzzy_search_unified_with_windows` (lines 250-260). Both closures have the exact same body mapping BuiltIn→0, App→1, Window→2, Script→3, Scriptlet→4, Agent→5, Fallback→6. This is a maintenance hazard — if a new variant is added, both copies must be updated.

Extract the closure into a standalone `#[inline] fn result_type_order(r: &SearchResult) -> i32` function, placed after the `use` imports but before `fuzzy_search_unified`. The function body is the same `match r { ... }` block. Then in both `sort_by` closures, delete the inline `let type_order = |r: &SearchResult| -> i32 { ... };` and replace `type_order(a)` / `type_order(b)` with `result_type_order(a)` / `result_type_order(b)`. The `SearchResult` type is already imported via `super::super::types::SearchResult` — verify this import path exists and add it if needed.

Run `cargo check && cargo clippy --all-targets -- -D warnings && cargo test`. The sort behavior must remain identical — the function returns the exact same values as the closures it replaces. No test changes needed.

---

### Task 4: `name-score-constants`

**Scope:** `src/scripts/search/scripts.rs, src/scripts/search/scriptlets.rs`

**Task:**
Both `src/scripts/search/scripts.rs` and `src/scripts/search/scriptlets.rs` contain ~20 magic number literals each for search scoring weights (500, 100, 75, 50, 35, 25, 20, 15, 10, 5, etc.) scattered throughout `fuzzy_search_scripts` and `fuzzy_search_scriptlets`. These are hard to understand and maintain. Replace them with named `const` declarations at the top of each file.

In `scripts.rs`, add after the `use` block: `SCORE_EXACT_NAME_MATCH: i32 = 500`, `SCORE_NAME_PREFIX: i32 = 100`, `SCORE_NAME_SUBSTRING: i32 = 75`, `SCORE_WORD_BOUNDARY: i32 = 20`, `SCORE_NAME_FUZZY_BASE: i32 = 50`, `SCORE_NAME_FUZZY_DIV: u32 = 20`, `SCORE_FILENAME_PREFIX: i32 = 60`, `SCORE_FILENAME_SUBSTRING: i32 = 45`, `SCORE_FILENAME_FUZZY_BASE: i32 = 35`, `SCORE_FILENAME_FUZZY_DIV: u32 = 30`, `SCORE_ALIAS_PREFIX: i32 = 80`, `SCORE_ALIAS_SUBSTRING: i32 = 60`, `SCORE_SHORTCUT_PREFIX: i32 = 80`, `SCORE_SHORTCUT_SUBSTRING: i32 = 60`, `SCORE_KIT_PREFIX: i32 = 30`, `SCORE_KIT_SUBSTRING: i32 = 20`, `SCORE_TAG_PREFIX: i32 = 40`, `SCORE_TAG_SUBSTRING: i32 = 25`, `SCORE_AUTHOR_PREFIX: i32 = 30`, `SCORE_AUTHOR_SUBSTRING: i32 = 20`, `SCORE_PROPERTY_KEYWORD: i32 = 35`, `SCORE_DESC_SUBSTRING: i32 = 25`, `SCORE_DESC_FUZZY_BASE: i32 = 15`, `SCORE_DESC_FUZZY_DIV: u32 = 30`, `SCORE_PATH_SUBSTRING: i32 = 10`. Then replace every magic number literal in the scoring function with its corresponding constant. Do the same for `scriptlets.rs` with analogous constants (some names differ: `SCORE_FILE_PATH_*` instead of `SCORE_FILENAME_*`, `SCORE_CODE_SUBSTRING: i32 = 5`, `SCORE_METADATA_PREFIX: i32 = 80`, `SCORE_METADATA_SUBSTRING: i32 = 60`, `SCORE_GROUP_PREFIX: i32 = 30`, `SCORE_GROUP_SUBSTRING: i32 = 20`, `SCORE_TOOL_TYPE: i32 = 10`).

The values must be EXACTLY the same as the current literals — this is a purely cosmetic/readability change with zero behavioral impact. Run `cargo check && cargo clippy --all-targets -- -D warnings && cargo test`. All existing search tests must pass unchanged. Do NOT modify test files.

---

NEXT_AREA: `src/scripts/search/builtins.rs` and `src/scripts/search/apps.rs` — likely have the same magic-number scoring pattern and may share duplicated scoring logic with scripts.rs/scriptlets.rs that could be unified into a shared scoring helper module
